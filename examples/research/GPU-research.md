现在需要整理一篇GPU的全面调研工作，首先是认识GPU，其次是看清楚GPU在大语言模型进程当中的作用，这个分享需要分享给做搜广推的算法工程师，所以最后希望以GPU原生的模型优化工作应该怎么做收尾，请帮我完成这篇调研文档。

文档的主要结构，以及章节内容要求：
一. 认识GPU
    /* 首先介绍GPU是什么，跟cpu，tpu，asic等的区别，其次介绍下目前各种各样的GPU产品，他的市场定位是什么，为什么会有这部分产品 */
1.1 GPU，CPU，TPU等芯片差异
1.2 GPU图像处理
1.3 GPU集群
1.4 游戏GPU
1.5 个人GPU工作站
二. GPU的核心参数
    /* 介绍GPU的核心参数都有哪些，以及不同参数都是哪些场景重点关注，比如游戏关注什么，AI训练关注什么参数之类的 */
三. NVIDIA-GPU的核心优势
    /* 介绍Nvidia的核心优势，为什么GPU领域，它可以一家独大，介绍下nvidia的gpu的架构升级的时间线，介绍下跟gpu相关的软件适配能力 */
四. GPU在LLM训练当中的作用
    /* GPU在大语言模型训练发挥了什么作用，一个经典的LLM预训练，比如7B模型，需要多少GPU，大概多少数据量，能训练ok；进一步，说明如果是500B+的大模型训练的训练消耗 */
五. GPU在LLM推理当中的作用
    /* 在推理当中，GPU发挥的作用是什么，单卡，多卡，集群推理的差别是什么，如果要提高并发的手段有哪些？ */
六. GPU的性能测试差异
    /* 不同GPU的性能差异，在LLM训练和推理当中，性能差异表现如何，重点以H100，A100，H800，A800，H20，L20等举例对比 */
七. 原生GPU优化应该怎么做
    /* 作为一个llm优化的算法工程师，以及搜广推的算法工程师，日常工作，在模型结构，tensor计算，特征引入的过程中，如何跟原生的GPU的架构想贴合，做到原生的GPU优化 */

注意事项：
1. 文章的篇幅比较长，内容比较多，可以逐个章节的完善，然后再汇总；
2. 尽可能的图文并茂；
3. 不要过多的总结归纳，表达要通顺详细，附录中有一个历史的调研文档的风格，可以参考下；

好了，现在请一步步思考，来完成这篇GPU的全面调研文档？