# Global LLM configuration
[llm] #BURNCLOUD:
api_type = 'burncloud'
model = "claude-sonnet-4-20250514"                                 # The LLM model to use
base_url = "https://ai.burncloud.com/v1"                           # API endpoint URL
api_key = "your burncloud api key"                                 # Your API key
max_tokens = 8192                                                  # Maximum number of tokens in the response
temperature = 0.0                                                  # Controls randomness


[llm.vision] #BURNCLOUD VISION:
api_type = 'burncloud'
model = "claude-sonnet-4-20250514"                                 # The vision model to use
base_url = "https://ai.burncloud.com/v1"                           # API endpoint URL for vision model
api_key = "your burncloud api key"                                 # Your API key for vision model
max_tokens = 8192                                                  # Maximum number of tokens in the response
temperature = 0.0                                                  # Controls randomness for vision model
