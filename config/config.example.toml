# Global LLM configuration
[llm]
model = "claude-3-7-sonnet-20250219"       # The LLM model to use
base_url = "https://api.anthropic.com/v1/" # API endpoint URL
api_key = "YOUR_API_KEY"                   # Your API key
max_tokens = 8192                          # Maximum number of tokens in the response
temperature = 0.0                          # Controls randomness

# [llm] # Amazon Bedrock
# api_type = "aws"                                       # Required
# model = "us.anthropic.claude-3-7-sonnet-20250219-v1:0" # Bedrock supported modelID
# base_url = "bedrock-runtime.us-west-2.amazonaws.com"   # Not used now
# max_tokens = 8192
# temperature = 1.0
# api_key = "bear"                                       # Required but not used for Bedrock

# [llm] #AZURE OPENAI:
# api_type= 'azure'
# model = "YOUR_MODEL_NAME" #"gpt-4o-mini"
# base_url = "{YOUR_AZURE_ENDPOINT.rstrip('/')}/openai/deployments/{AZURE_DEPLOYMENT_ID}"
# api_key = "AZURE API KEY"
# max_tokens = 8096
# temperature = 0.0
# api_version="AZURE API VERSION" #"2024-08-01-preview"

# [llm] #OLLAMA:
# api_type = 'ollama'
# model = "llama3.2"
# base_url = "http://localhost:11434/v1"
# api_key = "ollama"
# max_tokens = 4096
# temperature = 0.0

# Optional configuration for specific LLM models
[llm.vision]
model = "claude-3-7-sonnet-20250219"       # The vision model to use
base_url = "https://api.anthropic.com/v1/" # API endpoint URL for vision model
api_key = "YOUR_API_KEY"                   # Your API key for vision model
max_tokens = 8192                          # Maximum number of tokens in the response
temperature = 0.0                          # Controls randomness for vision model

# [llm.vision] #OLLAMA VISION:
# api_type = 'ollama'
# model = "llama3.2-vision"
# base_url = "http://localhost:11434/v1"
# api_key = "ollama"
# max_tokens = 4096
# temperature = 0.0

# Optional configuration for specific browser configuration
# [browser]
# Whether to run browser in headless mode (default: false)
#headless = false
# Disable browser security features (default: true)
#disable_security = true
# Extra arguments to pass to the browser
#extra_chromium_args = []
# Path to a Chrome instance to use to connect to your normal browser
# e.g. '/Applications/Google Chrome.app/Contents/MacOS/Google Chrome'
#chrome_instance_path = ""
# Connect to a browser instance via WebSocket
#wss_url = ""
# Connect to a browser instance via CDP
#cdp_url = ""

# Optional configuration, Proxy settings for the browser
# [browser.proxy]
# server = "http://proxy-server:port"
# username = "proxy-username"
# password = "proxy-password"

# Optional configuration, Search settings.
# [search]
# Search engine for agent to use. Default is "Google", can be set to "Baidu" or "DuckDuckGo" or "Bing".
#engine = "Google"
# Fallback engine order. Default is ["DuckDuckGo", "Baidu", "Bing"] - will try in this order after primary engine fails.
#fallback_engines = ["DuckDuckGo", "Baidu", "Bing"]
# Seconds to wait before retrying all engines again when they all fail due to rate limits. Default is 60.
#retry_delay = 60
# Maximum number of times to retry all engines when all fail. Default is 3.
#max_retries = 3
# Language code for search results. Options: "en" (English), "zh" (Chinese), etc.
#lang = "en"
# Country code for search results. Options: "us" (United States), "cn" (China), etc.
#country = "us"


## Sandbox configuration
#[sandbox]
#use_sandbox = false
#image = "python:3.12-slim"
#work_dir = "/workspace"
#memory_limit = "1g"  # 512m
#cpu_limit = 2.0
#timeout = 300
#network_enabled = true

# MCP (Model Context Protocol) configuration
[mcp]
server_reference = "app.mcp.server" # default server module reference

# Optional Runflow configuration
# Your can add additional agents into run-flow workflow to solve different-type tasks.
[runflow]
use_data_analysis_agent = false     # The Data Analysi Agent to solve various data analysis tasks
default_mode = "agent_flow"         # Default mode: chat, agent_flow, or ade
enable_ade_mode = true              # Enable ADE (Agentic Development Environment) mode

# Local Service configuration (replaces Daytona)
[local_service]
use_local_service = true             # Use local service instead of Daytona
workspace_directory = "./workspace"   # Local workspace directory
python_executable = "python3"         # Python executable path
max_concurrent_processes = 5          # Maximum concurrent processes
process_timeout = 300                 # Process timeout in seconds
enable_network = true                 # Enable network access
allowed_commands = ["python", "pip", "git", "npm", "node", "bash", "cmd", "powershell"]

# Editor configuration
[editor]
enable_editor = true                  # Enable code editor
default_language = "python"            # Default language for new files
default_theme = "default"             # Default editor theme
auto_save = true                      # Auto-save files
auto_save_interval = 60                # Auto-save interval in seconds
line_numbers = true                    # Show line numbers
syntax_highlighting = true              # Enable syntax highlighting
tab_size = 4                          # Tab size in spaces
use_spaces = true                      # Use spaces instead of tabs
font_size = 10                         # Editor font size
font_family = "Courier New"            # Editor font family
languages_config_dir = "config/languages"  # Directory for language definitions

# Versioning configuration
[versioning]
enable_versioning = true               # Enable file versioning
database_path = "workspace/.versions/versions.db"  # SQLite database path
storage_path = "workspace/.versions/storage"        # Content storage directory
auto_version = true                   # Automatically create versions on file saves
retention_days = 30                   # Default retention period for versions in days
max_storage_mb = 1024                  # Maximum storage size in MB
cleanup_interval_hours = 24            # Cleanup interval in hours
track_file_patterns = ["*.py", "*.js", "*.ts", "*.go", "*.rs", "*.sql", "*.sh", "*.md"]
exclude_patterns = [".git/*", "node_modules/*", "__pycache__/*", ".pytest_cache/*"]
enable_snapshots = true                 # Enable snapshot functionality
max_snapshots = 100                    # Maximum number of snapshots to keep
enable_guardian_checks = true           # Enable Guardian checks on rollback operations

# UI configuration
[ui]
enable_gui = true                     # Enable PyQt6 GUI
enable_webui = true                  # Enable web UI on localhost
webui_port = 8080                   # Port for web UI
webui_host = "localhost"             # Host for web UI
theme = "dark"                       # UI theme: light, dark, or auto
window_width = 1200                   # Default window width
window_height = 800                   # Default window height
auto_save = true                      # Auto-save conversations
