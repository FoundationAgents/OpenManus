# Global LLM configuration
[llm]
model = "Qwen/Qwen2.5-72B-Instruct-128K"
base_url = "https://api.siliconflow.cn/v1"
api_key = "sk-dbmrniiwbmebhgggcerwdlwunyurxhkndjzmuuqtvzbndata"
max_tokens = 4096
temperature = 0.0

# [llm] #AZURE OPENAI:
# api_type= 'azure'
# model = "YOUR_MODEL_NAME" #"gpt-4o-mini"
# base_url = "{YOUR_AZURE_ENDPOINT.rstrip('/')}/openai/deployments/{AZURE_DEPOLYMENT_ID}"
# api_key = "AZURE API KEY"
# max_tokens = 8096
# temperature = 0.0
# api_version="AZURE API VERSION" #"2024-08-01-preview"

# Optional configuration for specific LLM models
[llm.vision]
model = "Pro/deepseek-ai/DeepSeek-R1"
base_url = "https://api.siliconflow.cn/v1"
api_key = "sk-dbmrniiwbmebhgggcerwdlwunyurxhkndjzmuuqtvzbndata"

# Search engine configuration
[search_engine]
type = "searxng"  # Supported search engine types: google, searxng
base_url = "http://127.0.0.1:8080"  # SearxNG service address