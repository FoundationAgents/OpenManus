# Qwen2.5-VL与DeepSeek-OCR视频VLM模型对比综述

## 摘要

本文对阿里巴巴的Qwen2.5-VL和DeepSeek-AI的DeepSeek-OCR两篇视频视觉语言模型(VLM)技术报告进行深入对比分析。这两篇论文代表了当前视频VLM领域的最新进展，分别在通用多模态理解和文档OCR压缩方面取得了突破性成果。通过系统性的对比分析，本文旨在揭示两篇论文在技术路线、核心贡献、性能表现等方面的异同点，为相关领域的研究者提供参考。

## 1. 两篇论文的共同点与区别

### 1.1 共同点

**1.1.1 多模态架构设计**
两篇论文都采用了视觉-语言模型的经典架构，包含视觉编码器和语言解码器两个核心组件。

**1.1.2 高分辨率处理能力**
两个模型都支持高分辨率图像输入，Qwen2.5-VL采用原生动态分辨率处理，DeepSeek-OCR支持多种分辨率模式。

**1.1.3 文档理解能力**
两篇论文都强调了文档解析能力，包括表格、图表、公式等复杂文档元素的处理。

**1.1.4 开源理念**
两个模型都秉承开源精神，提供模型权重和代码供研究使用。

### 1.2 主要区别

**1.2.1 研究目标差异**
- **Qwen2.5-VL**：专注于通用多模态理解，包括图像理解、视频理解、文档解析、智能体交互等全方位能力
- **DeepSeek-OCR**：专注于视觉-文本压缩，探索如何用更少的视觉token解码更多的文本信息

**1.2.2 技术路线差异**
- **Qwen2.5-VL**：采用端到端的动态分辨率ViT架构，强调原生分辨率感知
- **DeepSeek-OCR**：采用双组件串联架构(SAM+CLIP)，强调视觉token压缩效率

**1.2.3 应用场景差异**
- **Qwen2.5-VL**：面向通用多模态应用，包括智能体、GUI操作、长视频理解等
- **DeepSeek-OCR**：面向文档OCR和大规模数据生成，强调生产效率

## 2. 核心技术贡献与细节

### 2.1 Qwen2.5-VL核心技术贡献

**2.1.1 动态分辨率视觉编码器**
Qwen2.5-VL重新设计了视觉Transformer架构，采用原生动态分辨率处理，能够处理不同尺寸的图像和视频帧，无需传统的归一化技术。

**2.1.2 窗口注意力机制**
在视觉编码器中引入窗口注意力，显著降低了计算开销，同时保持了原生分辨率。

**2.1.3 动态FPS采样**
将动态分辨率扩展到时间维度，支持不同采样率的视频理解，实现全面的视频理解能力。

**2.1.4 多模态旋转位置编码(MRoPE)**
升级了MRoPE在时间域的对齐，与绝对时间对齐，促进更复杂的时间序列学习。

**2.1.5 大规模数据构建**
预训练数据从1.2万亿token扩展到4.1万亿token，包含图像描述、交错图像文本数据、OCR数据、视觉知识、多模态学术问题、定位数据、文档解析数据、视频描述、视频定位和基于智能体的交互数据。

### 2.2 DeepSeek-OCR核心技术贡献

**2.2.1 DeepEncoder架构**
DeepEncoder是DeepSeek-OCR的核心引擎，设计用于在高分辨率输入下保持低激活，同时实现高压缩比，确保视觉token数量最优且可控。

**2.2.2 视觉-文本压缩研究**
论文首次系统性地研究了视觉-文本token压缩比，当文本token数量在视觉token数量的10倍以内时，模型可以达到97%的解码精度。

**2.2.3 多分辨率支持**
DeepEncoder支持多种分辨率模式，包括原生分辨率(Tiny、Small、Base、Large)和动态分辨率(Gundam、Gundam-M)。

**2.2.4 MoE解码器**
采用DeepSeek3B-MoE作为解码器，激活6个路由专家和2个共享专家，约5.7亿激活参数，在保持3B模型表达能力的同时享受500M小模型的推理效率。

**2.2.5 数据引擎**
构建了复杂多样的训练数据，包括OCR 1.0数据(传统OCR任务)、OCR 2.0数据(复杂人工图像解析)、通用视觉数据和纯文本数据。

## 3. 性能表现与榜单成绩

### 3.1 Qwen2.5-VL性能表现

**3.1.1 图像理解基准测试**
- **MMBench**：Qwen2.5-VL-72B在MMBench上表现优异
- **MMMU**：在需要深度推理的多学科任务中表现突出
- **MathVista**：在数学推理任务中达到先进水平
- **ChartX**：在图表理解任务中表现卓越

**3.1.2 视频理解基准测试**
- **Video-MME**：Qwen2.5-VL-72B达到73.3分(无字幕)和79.1分(有字幕)
- **MVBench**：达到70.4分，显著优于GPT-4o(64.6分)
- **LVBench**：达到47.3分，大幅领先GPT-4o(30.8分)
- **EgoSchema**：达到76.2分，优于GPT-4o(72.2分)
- **MLVU**：达到74.6分，优于GPT-4o(64.6分)
- **Charades-STA**：在时间定位任务中达到50.9 mIoU，显著优于GPT-4o(35.7)

**3.1.3 智能体基准测试**
- **ScreenSpot**：达到87.1%准确率
- **ScreenSpot Pro**：达到43.6%准确率，显著优于Aguvis-72B(23.6%)
- **Android Control**：在HighEM和LowEM评估中分别达到67.36%和93.7%
- **AndroidWorld**：达到35%成功率
- **MobileMiniWob++**：达到68%成功率

### 3.2 DeepSeek-OCR性能表现

**3.2.1 视觉-文本压缩性能**
- **10倍压缩比**：达到97%+ OCR解码精度
- **10-12倍压缩比**：达到约90%精度
- **20倍压缩比**：仍保持约60%精度

**3.2.2 实际OCR性能**
- **OmniDocBench**：仅使用100个视觉token就超越了GOT-OCR2.0(使用256个token)
- **与MinerU2.0对比**：使用少于800个视觉token就超越了MinerU2.0(平均每页6000+token)

**3.2.3 生产效率**
- **单A100-40G**：每天可生成20万+页训练数据
- **20节点(每节点8个A100-40G)**：每天可生成3300万页数据

**3.2.4 多语言支持**
支持近100种语言的OCR能力，包括中文、英文、法文、德文、意大利文、西班牙文、葡萄牙文、阿拉伯文、俄文、日文、韩文、越南文等。

## 4. 技术特点对比分析

### 4.1 架构设计对比

| 特性 | Qwen2.5-VL | DeepSeek-OCR |
|------|------------|---------------|
| 视觉编码器 | 动态分辨率ViT | SAM-base + CLIP-large串联 |
| 语言解码器 | Qwen2.5 LLM | DeepSeek3B-MoE |
| 分辨率支持 | 原生动态分辨率 | 多分辨率模式 |
| 压缩机制 | 窗口注意力 | 16倍卷积压缩 |
| 参数量 | 3B/7B/72B | 3B MoE(570M激活) |

### 4.2 数据处理对比

| 数据类别 | Qwen2.5-VL | DeepSeek-OCR |
|----------|------------|---------------|
| 预训练数据 | 4.1万亿token | 3000万页文档数据 |
| 文档格式 | QwenVL HTML格式 | 粗标注+细标注 |
| 多语言支持 | 多语言OCR | 近100种语言 |
| 特殊元素 | 表格、图表、公式、乐谱 | 图表、化学公式、几何图形 |

### 4.3 应用场景对比

| 应用场景 | Qwen2.5-VL优势 | DeepSeek-OCR优势 |
|----------|----------------|------------------|
| 通用多模态理解 | ★★★★★ | ★★★ |
| 文档OCR | ★★★★ | ★★★★★ |
| 视频理解 | ★★★★★ | ★★ |
| 智能体交互 | ★★★★★ | ★★ |
| 数据生成效率 | ★★ | ★★★★★ |
| 压缩效率 | ★★★ | ★★★★★ |

## 5. 结论与展望

### 5.1 主要发现

1. **技术路线分化**：Qwen2.5-VL走通用多模态路线，DeepSeek-OCR走专业化OCR压缩路线
2. **性能互补**：两个模型在不同应用场景下各有优势，形成互补关系
3. **创新突破**：Qwen2.5-VL在长视频理解和智能体交互方面突破，DeepSeek-OCR在视觉-文本压缩方面创新

### 5.2 未来展望

1. **技术融合**：未来可能出现结合两者优势的混合模型
2. **应用扩展**：两个模型的技术思路可扩展到更多领域
3. **效率优化**：在保持性能的同时进一步优化计算效率
4. **多模态融合**：探索更多模态的融合与压缩技术

### 5.3 研究意义

这两篇论文代表了当前视频VLM领域的前沿水平，Qwen2.5-VL展示了通用多模态模型的强大能力，DeepSeek-OCR则开辟了视觉-文本压缩的新研究方向。它们的技术思路和实现方法为后续研究提供了重要参考，推动了整个多模态AI领域的发展。

---

*本文基于Qwen2.5-VL Technical Report和DeepSeek-OCR: Contexts Optical Compression两篇技术报告编写，所有数据和结论均来自原始论文。*