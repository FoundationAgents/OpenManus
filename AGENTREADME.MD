# AGENTREADME.MD - Guia do RepositÃ³rio para Agentes de IA

## Bem-vindo, Agente!

Este arquivo Ã© o seu guia completo para entender e interagir com este repositÃ³rio. Ele foi projetado para ser lido e processado por vocÃª, uma InteligÃªncia Artificial, para facilitar suas tarefas de desenvolvimento, anÃ¡lise e aprimoramento de cÃ³digo.

## Como Navegar e Utilizar Este Arquivo

Este `AGENTREADME.MD` Ã© estruturado para fornecer informaÃ§Ãµes de forma clara e acessÃ­vel. Aqui estÃ¡ um guia sobre como aproveitÃ¡-lo ao mÃ¡ximo:

### Estrutura do Arquivo:

1.  **Tutorial (Esta SeÃ§Ã£o):** Explica como usar este arquivo, suas seÃ§Ãµes e como realizar buscas eficientes.
2.  **VisÃ£o Geral da Ferramenta de GeraÃ§Ã£o:** Detalha como este arquivo `AGENTREADME.MD` Ã© gerado e mantido atualizado.
3.  **ConteÃºdo Completo do RepositÃ³rio:** Uma seÃ§Ã£o que contÃ©m a concatenaÃ§Ã£o de todos os arquivos de cÃ³digo relevantes do projeto. Esta Ã© a sua principal fonte de informaÃ§Ã£o sobre a implementaÃ§Ã£o atual.
4.  **Como Manter Atualizado:** InstruÃ§Ãµes sobre como executar o script para regenerar este arquivo e garantir que vocÃª esteja trabalhando com a versÃ£o mais recente do cÃ³digo.

### Fazendo Buscas Eficientes:

Para encontrar informaÃ§Ãµes especÃ­ficas rapidamente, utilize as seguintes estratÃ©gias e palavras-chave:

*   **Busca por Nome de Arquivo:** Se vocÃª sabe o nome do arquivo que procura (ex: `app/agent/manus.py`), vocÃª pode buscar diretamente por:
    ```
    ### ARQUIVO: app/agent/manus.py ###
    ```
    Cada arquivo incluÃ­do na seÃ§Ã£o "ConteÃºdo Completo do RepositÃ³rio" serÃ¡ precedido por este marcador.

*   **Busca por Palavras-chave de CÃ³digo:**
    *   `def ` (Python), `function ` (JavaScript, etc.): Para encontrar definiÃ§Ãµes de funÃ§Ãµes.
    *   `class `: Para encontrar definiÃ§Ãµes de classes.
    *   `import `, `require `: Para entender as dependÃªncias de um mÃ³dulo.
    *   `TODO:`, `FIXME:`, `XXX:`: Para encontrar Ã¡reas do cÃ³digo que necessitam de atenÃ§Ã£o.
    *   `@decorator`: Para encontrar decoradores em Python.
    *   `async def`, `await`: Para cÃ³digo assÃ­ncrono.

*   **Busca por Conceitos ou Funcionalidades:**
    *   Se estiver procurando por uma funcionalidade especÃ­fica, pense nos termos que os desenvolvedores humanos usariam para descrevÃª-la. Por exemplo, "autenticaÃ§Ã£o", "parser de API", "gerenciamento de estado".
    *   Combine esses termos com palavras-chave de cÃ³digo. Ex: `def autenticar_usuario`, `class ApiParser`.

*   **NavegaÃ§Ã£o por SeÃ§Ã£o:**
    *   Para ir diretamente para o conteÃºdo do cÃ³digo, busque por:
        ```
        ## ConteÃºdo Completo do RepositÃ³rio
        ```
    *   Para entender como este arquivo Ã© gerado, busque por:
        ```
        ## VisÃ£o Geral da Ferramenta de GeraÃ§Ã£o
        ```

### Dicas Adicionais para Agentes:

*   **Contexto Ã© Crucial:** Ao analisar um trecho de cÃ³digo, sempre olhe o contexto ao redor, incluindo o nome do arquivo, importaÃ§Ãµes e quaisquer comentÃ¡rios.
*   **Ignore SeÃ§Ãµes Irrelevantes para a Tarefa Atual:** Se sua tarefa Ã© refatorar uma funÃ§Ã£o especÃ­fica, vocÃª pode inicialmente focar apenas no conteÃºdo daquele arquivo.
*   **Considere a Estrutura do Projeto:** A organizaÃ§Ã£o dos diretÃ³rios e arquivos pode fornecer pistas importantes sobre a arquitetura do software.
*   **Priorize `AGENTS.md` EspecÃ­ficos:** Se houver outros arquivos `AGENTS.md` em subdiretÃ³rios, eles podem conter instruÃ§Ãµes mais especÃ­ficas para aquelas partes do cÃ³digo e devem ter precedÃªncia.

## VisÃ£o Geral da Ferramenta de GeraÃ§Ã£o (`generate_agent_readme.py`)

Este arquivo `AGENTREADME.MD` nÃ£o Ã© mantido manualmente na sua totalidade. A maior parte do seu conteÃºdo, especificamente a seÃ§Ã£o "ConteÃºdo Completo do RepositÃ³rio", Ã© gerada automaticamente por um script Python chamado `generate_agent_readme.py`.

**Como o `generate_agent_readme.py` Funciona Internamente:**

1.  **Ponto de Partida:** O script geralmente comeÃ§a a varredura a partir do diretÃ³rio raiz do repositÃ³rio.
2.  **Listagem de Arquivos e DiretÃ³rios:** Ele percorre recursivamente todos os arquivos e subdiretÃ³rios.
3.  **Filtragem de Itens Relevantes:** O script possui uma lÃ³gica para ignorar arquivos e diretÃ³rios que nÃ£o sÃ£o relevantes para a compreensÃ£o do cÃ³digo-fonte. Isso inclui:
    *   DiretÃ³rios de controle de versÃ£o (ex: `.git/`)
    *   Ambientes virtuais (ex: `venv/`, `.venv/`)
    *   DiretÃ³rios de configuraÃ§Ã£o de IDE/editor (ex: `.vscode/`, `.idea/`)
    *   Arquivos de log (ex: `*.log`)
    *   Arquivos de workspace ou especÃ­ficos de build (ex: `workspace/`, `build/`, `dist/`)
    *   Arquivos binÃ¡rios ou compilados (ex: `.pyc`, `.o`, `.exe`)
    *   Arquivos de dependÃªncias (ex: `node_modules/`)
    *   O prÃ³prio `AGENTREADME.MD` e o script `generate_agent_readme.py` para evitar recursÃ£o infinita ou duplicaÃ§Ã£o.
4.  **Leitura do ConteÃºdo:** Para cada arquivo considerado relevante, o script lÃª todo o seu conteÃºdo textual.
5.  **FormataÃ§Ã£o e ConcatenaÃ§Ã£o:**
    *   Antes de adicionar o conteÃºdo de um arquivo, o script insere um cabeÃ§alho formatado, como:
        ```
        ### ARQUIVO: caminho/completo/para/o/arquivo.ext ###
        ```
    *   Em seguida, o conteÃºdo do arquivo Ã© adicionado como um bloco de cÃ³digo. Para garantir a correta renderizaÃ§Ã£o em Markdown e facilitar a leitura, o conteÃºdo Ã© geralmente encapsulado em blocos de cÃ³digo ``` ```, com a linguagem apropriada (se detectÃ¡vel pela extensÃ£o do arquivo).
        ```markdown
        \`\`\`python
        # ConteÃºdo do arquivo Python aqui
        print("OlÃ¡, Agente!")
        \`\`\`
        ```
    *   Todo esse conteÃºdo formatado Ã© concatenado em uma grande string.
6.  **Escrita no `AGENTREADME.MD`:**
    *   O script localiza uma seÃ§Ã£o especÃ­fica no template do `AGENTREADME.MD` (marcada por um placeholder, por exemplo, `<!-- CONTENT_START -->
## ConteÃºdo Completo do RepositÃ³rio

### ARQUIVO: .gitattributes ###
```
# HTML code is incorrectly calculated into statistics, so ignore them
*.html linguist-detectable=false
# Auto detect text files and perform LF normalization
* text=auto eol=lf
# Ensure shell scripts use LF (Linux style) line endings on Windows
*.sh text eol=lf
# Treat specific binary files as binary and prevent line ending conversion
*.png binary
*.jpg binary
*.gif binary
*.ico binary
*.jpeg binary
*.mp3 binary
*.zip binary
*.bin binary
# Preserve original line endings for specific document files
*.doc text eol=crlf
*.docx text eol=crlf
*.pdf binary
# Ensure source code and script files use LF line endings
*.py text eol=lf
*.js text eol=lf
*.html text eol=lf
*.css text eol=lf
# Specify custom diff driver for specific file types
*.md diff=markdown
*.json diff=json
*.mp4 filter=lfs diff=lfs merge=lfs -text
*.mov filter=lfs diff=lfs merge=lfs -text
*.webm filter=lfs diff=lfs merge=lfs -text

```

### ARQUIVO: .pre-commit-config.yaml ###
```yaml
repos:
  - repo: https://github.com/psf/black
    rev: 23.1.0
    hooks:
      - id: black

  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.4.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files

  - repo: https://github.com/PyCQA/autoflake
    rev: v2.0.1
    hooks:
      - id: autoflake
        args: [
          --remove-all-unused-imports,
          --ignore-init-module-imports,
          --expand-star-imports,
          --remove-duplicate-keys,
          --remove-unused-variables,
          --recursive,
          --in-place,
          --exclude=__init__.py,
        ]
        files: \.py$

  - repo: https://github.com/pycqa/isort
    rev: 5.12.0
    hooks:
      - id: isort
        args: [
          "--profile", "black",
          "--filter-files",
          "--lines-after-imports=2",
        ]

```

### ARQUIVO: setup.py ###
```py
from setuptools import find_packages, setup


with open("README.md", "r", encoding="utf-8") as fh:
    long_description = fh.read()

setup(
    name="openmanus",
    version="0.1.0",
    author="mannaandpoem and OpenManus Team",
    author_email="mannaandpoem@gmail.com",
    description="A versatile agent that can solve various tasks using multiple tools",
    long_description=long_description,
    long_description_content_type="text/markdown",
    url="https://github.com/FoundationAgents/OpenManus",
    packages=find_packages(),
    install_requires=[
        "pydantic~=2.10.4",
        "openai>=1.58.1,<1.67.0",
        "tenacity~=9.0.0",
        "pyyaml~=6.0.2",
        "loguru~=0.7.3",
        "numpy",
        "datasets>=3.2,<3.5",
        "html2text~=2024.2.26",
        "gymnasium>=1.0,<1.2",
        "pillow>=10.4,<11.2",
        "browsergym~=0.13.3",
        "uvicorn~=0.34.0",
        "unidiff~=0.7.5",
        "browser-use~=0.1.40",
        "googlesearch-python~=1.3.0",
        "aiofiles~=24.1.0",
        "pydantic_core>=2.27.2,<2.28.0",
        "colorama~=0.4.6",
    ],
    classifiers=[
        "Programming Language :: Python :: 3",
        "Programming Language :: Python :: 3.12",
        "License :: OSI Approved :: MIT License",
        "Operating System :: OS Independent",
    ],
    python_requires=">=3.12",
    entry_points={
        "console_scripts": [
            "openmanus=main:main",
        ],
    },
)

```

### ARQUIVO: requirements.txt ###
```txt
pydantic~=2.10.6
openai~=1.66.3
tenacity~=9.0.0
pyyaml~=6.0.2
loguru~=0.7.3
numpy
datasets~=3.4.1
fastapi~=0.115.11
tiktoken~=0.9.0

html2text~=2024.2.26
gymnasium~=1.1.1
pillow~=11.1.0
browsergym~=0.13.3
uvicorn~=0.34.0
unidiff~=0.7.5
browser-use~=0.1.40
googlesearch-python~=1.3.0
baidusearch~=1.0.3
duckduckgo_search~=7.5.3

aiofiles~=24.1.0
pydantic_core~=2.27.2
colorama~=0.4.6
playwright~=1.51.0

docker~=7.1.0
pytest~=8.3.5
pytest-asyncio~=0.25.3

mcp~=1.5.0
httpx>=0.27.0
tomli>=2.0.0

boto3~=1.37.18

requests~=2.32.3
beautifulsoup4~=4.13.3

huggingface-hub~=0.29.2
setuptools~=75.8.0
psutil

```

### ARQUIVO: README.md ###
```md
<p align="center">
  <img src="assets/logo.jpg" width="200"/>
</p>

English | [ä¸­æ–‡](README_zh.md) | [í•œêµ­ì–´](README_ko.md) | [æ—¥æœ¬èª](README_ja.md) | [PortuguÃªs (Brasil)](README_pt-br.md)

[![GitHub stars](https://img.shields.io/github/stars/FoundationAgents/OpenManus?style=social)](https://github.com/FoundationAgents/OpenManus/stargazers)
&ensp;
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) &ensp;
[![Discord Follow](https://dcbadge.vercel.app/api/server/DYn29wFk9z?style=flat)](https://discord.gg/DYn29wFk9z)
[![Demo](https://img.shields.io/badge/Demo-Hugging%20Face-yellow)](https://huggingface.co/spaces/lyh-917/OpenManusDemo)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.15186407.svg)](https://doi.org/10.5281/zenodo.15186407)

# ğŸ‘‹ OpenManus

Manus is incredible, but OpenManus can achieve any idea without an *Invite Code* ğŸ›«!

Our team members [@Xinbin Liang](https://github.com/mannaandpoem) and [@Jinyu Xiang](https://github.com/XiangJinyu) (core authors), along with [@Zhaoyang Yu](https://github.com/MoshiQAQ), [@Jiayi Zhang](https://github.com/didiforgithub), and [@Sirui Hong](https://github.com/stellaHSR), we are from [@MetaGPT](https://github.com/geekan/MetaGPT). The prototype is launched within 3 hours and we are keeping building!

It's a simple implementation, so we welcome any suggestions, contributions, and feedback!

Enjoy your own agent with OpenManus!

We're also excited to introduce [OpenManus-RL](https://github.com/OpenManus/OpenManus-RL), an open-source project dedicated to reinforcement learning (RL)- based (such as GRPO) tuning methods for LLM agents, developed collaboratively by researchers from UIUC and OpenManus.

## Project Demo

<video src="https://private-user-images.githubusercontent.com/61239030/420168772-6dcfd0d2-9142-45d9-b74e-d10aa75073c6.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDEzMTgwNTksIm5iZiI6MTc0MTMxNzc1OSwicGF0aCI6Ii82MTIzOTAzMC80MjAxNjg3NzItNmRjZmQwZDItOTE0Mi00NWQ5LWI3NGUtZDEwYWE3NTA3M2M2Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAzMDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMzA3VDAzMjIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdiZjFkNjlmYWNjMmEzOTliM2Y3M2VlYjgyNDRlZDJmOWE3NWZhZjE1MzhiZWY4YmQ3NjdkNTYwYTU5ZDA2MzYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.UuHQCgWYkh0OQq9qsUWqGsUbhG3i9jcZDAMeHjLt5T4" data-canonical-src="https://private-user-images.githubusercontent.com/61239030/420168772-6dcfd0d2-9142-45d9-b74e-d10aa75073c6.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDEzMTgwNTksIm5iZiI6MTc0MTMxNzc1OSwicGF0aCI6Ii82MTIzOTAzMC80MjAxNjg3NzItNmRjZmQwZDItOTE0Mi00NWQ5LWI3NGUtZDEwYWE3NTA3M2M2Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAzMDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMzA3VDAzMjIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdiZjFkNjlmYWNjMmEzOTliM2Y3M2VlYjgyNDRlZDJmOWE3NWZhZjE1MzhiZWY4YmQ3NjdkNTYwYTU5ZDA2MzYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.UuHQCgWYkh0OQq9qsUWqGsUbhG3i9jcZDAMeHjLt5T4" controls="controls" muted="muted" class="d-block rounded-bottom-2 border-top width-fit" style="max-height:640px; min-height: 200px"></video>

## Installation

We provide two installation methods. Method 2 (using uv) is recommended for faster installation and better dependency management.

### Method 1: Using conda

1. Create a new conda environment:

```bash
conda create -n open_manus python=3.12
conda activate open_manus
```

2. Clone the repository:

```bash
git clone https://github.com/FoundationAgents/OpenManus.git
cd OpenManus
```

3. Install dependencies:

```bash
pip install -r requirements.txt
```

### Method 2: Using uv (Recommended)

1. Install uv (A fast Python package installer and resolver):

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

2. Clone the repository:

```bash
git clone https://github.com/FoundationAgents/OpenManus.git
cd OpenManus
```

3. Create a new virtual environment and activate it:

```bash
uv venv --python 3.12
source .venv/bin/activate  # On Unix/macOS
# Or on Windows:
# .venv\Scripts\activate
```

4. Install dependencies:

```bash
uv pip install -r requirements.txt
```

### Browser Automation Tool (Optional)
```bash
playwright install
```

## Configuration

OpenManus requires configuration for the LLM APIs it uses. Follow these steps to set up your configuration:

1. Create a `config.toml` file in the `config` directory (you can copy from the example):

```bash
cp config/config.example.toml config/config.toml
```

2. Edit `config/config.toml` to add your API keys and customize settings:

```toml
# Global LLM configuration
[llm]
model = "gpt-4o"
base_url = "https://api.openai.com/v1"
api_key = "sk-..."  # Replace with your actual API key
max_tokens = 4096
temperature = 0.0

# Optional configuration for specific LLM models
[llm.vision]
model = "gpt-4o"
base_url = "https://api.openai.com/v1"
api_key = "sk-..."  # Replace with your actual API key
```

## Quick Start

One line for run OpenManus:

```bash
python main.py
```

Then input your idea via terminal!

For MCP tool version, you can run:
```bash
python run_mcp.py
```

For unstable multi-agent version, you also can run:

```bash
python run_flow.py
```

### Custom Adding Multiple Agents

Currently, besides the general OpenManus Agent, we have also integrated the DataAnalysis Agent, which is suitable for data analysis and data visualization tasks. You can add this agent to `run_flow` in `config.toml`.

```toml
# Optional configuration for run-flow
[runflow]
use_data_analysis_agent = true     # Disabled by default, change to true to activate
```
In addition, you need to install the relevant dependencies to ensure the agent runs properly: [Detailed Installation Guide](app/tool/chart_visualization/README.md##Installation)

## How to contribute

We welcome any friendly suggestions and helpful contributions! Just create issues or submit pull requests.

Or contact @mannaandpoem via ğŸ“§email: mannaandpoem@gmail.com

**Note**: Before submitting a pull request, please use the pre-commit tool to check your changes. Run `pre-commit run --all-files` to execute the checks.

## Community Group
Join our networking group on Feishu and share your experience with other developers!

<div align="center" style="display: flex; gap: 20px;">
    <img src="assets/community_group.jpg" alt="OpenManus äº¤æµç¾¤" width="300" />
</div>

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=FoundationAgents/OpenManus&type=Date)](https://star-history.com/#FoundationAgents/OpenManus&Date)

## Sponsors
Thanks to [PPIO](https://ppinfra.com/user/register?invited_by=OCPKCN&utm_source=github_openmanus&utm_medium=github_readme&utm_campaign=link) for computing source support.
> PPIO: The most affordable and easily-integrated MaaS and GPU cloud solution.


## Acknowledgement

Thanks to [anthropic-computer-use](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo)
and [browser-use](https://github.com/browser-use/browser-use) for providing basic support for this project!

Additionally, we are grateful to [AAAJ](https://github.com/metauto-ai/agent-as-a-judge), [MetaGPT](https://github.com/geekan/MetaGPT), [OpenHands](https://github.com/All-Hands-AI/OpenHands) and [SWE-agent](https://github.com/SWE-agent/SWE-agent).

We also thank stepfun(é˜¶è·ƒæ˜Ÿè¾°) for supporting our Hugging Face demo space.

OpenManus is built by contributors from MetaGPT. Huge thanks to this agent community!

## Cite
```bibtex
@misc{openmanus2025,
  author = {Xinbin Liang and Jinyu Xiang and Zhaoyang Yu and Jiayi Zhang and Sirui Hong and Sheng Fan and Xiao Tang},
  title = {OpenManus: An open-source framework for building general AI agents},
  year = {2025},
  publisher = {Zenodo},
  doi = {10.5281/zenodo.15186407},
  url = {https://doi.org/10.5281/zenodo.15186407},
}
```

```

### ARQUIVO: README_ko.md ###
```md
<p align="center">
  <img src="assets/logo.jpg" width="200"/>
</p>

[English](README.md) | [ä¸­æ–‡](README_zh.md) | í•œêµ­ì–´ | [æ—¥æœ¬èª](README_ja.md) | [PortuguÃªs (Brasil)](README_pt-br.md)

[![GitHub stars](https://img.shields.io/github/stars/FoundationAgents/OpenManus?style=social)](https://github.com/FoundationAgents/OpenManus/stargazers)
&ensp;
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) &ensp;
[![Discord Follow](https://dcbadge.vercel.app/api/server/DYn29wFk9z?style=flat)](https://discord.gg/DYn29wFk9z)
[![Demo](https://img.shields.io/badge/Demo-Hugging%20Face-yellow)](https://huggingface.co/spaces/lyh-917/OpenManusDemo)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.15186407.svg)](https://doi.org/10.5281/zenodo.15186407)

# ğŸ‘‹ OpenManus

ManusëŠ” ë†€ë¼ìš´ ë„êµ¬ì§€ë§Œ, OpenManusëŠ” *ì´ˆëŒ€ ì½”ë“œ* ì—†ì´ë„ ëª¨ë“  ì•„ì´ë””ì–´ë¥¼ ì‹¤í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸ›«

ìš°ë¦¬ íŒ€ì˜ ë©¤ë²„ì¸ [@Xinbin Liang](https://github.com/mannaandpoem)ì™€ [@Jinyu Xiang](https://github.com/XiangJinyu) (í•µì‹¬ ì‘ì„±ì), ê·¸ë¦¬ê³  [@Zhaoyang Yu](https://github.com/MoshiQAQ), [@Jiayi Zhang](https://github.com/didiforgithub), [@Sirui Hong](https://github.com/stellaHSR)ì´ í•¨ê»˜ í–ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” [@MetaGPT](https://github.com/geekan/MetaGPT)ë¡œë¶€í„° ì™”ìŠµë‹ˆë‹¤. í”„ë¡œí† íƒ€ì…ì€ ë‹¨ 3ì‹œê°„ ë§Œì— ì¶œì‹œë˜ì—ˆìœ¼ë©°, ê³„ì†í•´ì„œ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤!

ì´ í”„ë¡œì íŠ¸ëŠ” ê°„ë‹¨í•œ êµ¬í˜„ì—ì„œ ì‹œì‘ë˜ì—ˆìœ¼ë©°, ì—¬ëŸ¬ë¶„ì˜ ì œì•ˆ, ê¸°ì—¬ ë° í”¼ë“œë°±ì„ í™˜ì˜í•©ë‹ˆë‹¤!

OpenManusë¥¼ í†µí•´ ì—¬ëŸ¬ë¶„ë§Œì˜ ì—ì´ì „íŠ¸ë¥¼ ì¦ê²¨ë³´ì„¸ìš”!

ë˜í•œ [OpenManus-RL](https://github.com/OpenManus/OpenManus-RL)ì„ ì†Œê°œí•˜ê²Œ ë˜ì–´ ê¸°ì©ë‹ˆë‹¤. OpenManusì™€ UIUC ì—°êµ¬ìë“¤ì´ ê³µë™ ê°œë°œí•œ ì´ ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ëŠ” LLM ì—ì´ì „íŠ¸ì— ëŒ€í•´ ê°•í™” í•™ìŠµ(RL) ê¸°ë°˜ (ì˜ˆ: GRPO) íŠœë‹ ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.

## í”„ë¡œì íŠ¸ ë°ëª¨

<video src="https://private-user-images.githubusercontent.com/61239030/420168772-6dcfd0d2-9142-45d9-b74e-d10aa75073c6.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDEzMTgwNTksIm5iZiI6MTc0MTMxNzc1OSwicGF0aCI6Ii82MTIzOTAzMC80MjAxNjg3NzItNmRjZmQwZDItOTE0Mi00NWQ5LWI3NGUtZDEwYWE3NTA3M2M2Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAzMDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMzA3VDAzMjIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdiZjFkNjlmYWNjMmEzOTliM2Y3M2VlYjgyNDRlZDJmOWE3NWZhZjE1MzhiZWY4YmQ3NjdkNTYwYTU5ZDA2MzYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.UuHQCgWYkh0OQq9qsUWqGsUbhG3i9jcZDAMeHjLt5T4" data-canonical-src="https://private-user-images.githubusercontent.com/61239030/420168772-6dcfd0d2-9142-45d9-b74e-d10aa75073c6.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDEzMTgwNTksIm5iZiI6MTc0MTMxNzc1OSwicGF0aCI6Ii82MTIzOTAzMC80MjAxNjg3NzItNmRjZmQwZDItOTE0Mi00NWQ5LWI3NGUtZDEwYWE3NTA3M2M2Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAzMDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMzA3VDAzMjIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdiZjFkNjlmYWNjMmEzOTliM2Y3M2VlYjgyNDRlZDJmOWE3NWZhZjE1MzhiZWY4YmQ3NjdkNTYwYTU5ZDA2MzYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.UuHQCgWYkh0OQq9qsUWqGsUbhG3i9jcZDAMeHjLt5T4" controls="controls" muted="muted" class="d-block rounded-bottom-2 border-top width-fit" style="max-height:640px; min-height: 200px"></video>

## ì„¤ì¹˜ ë°©ë²•

ë‘ ê°€ì§€ ì„¤ì¹˜ ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤. **ë°©ë²• 2 (uv ì‚¬ìš©)** ì´ ë” ë¹ ë¥¸ ì„¤ì¹˜ì™€ íš¨ìœ¨ì ì¸ ì¢…ì†ì„± ê´€ë¦¬ë¥¼ ìœ„í•´ ê¶Œì¥ë©ë‹ˆë‹¤.

### ë°©ë²• 1: conda ì‚¬ìš©

1. ìƒˆë¡œìš´ conda í™˜ê²½ì„ ìƒì„±í•©ë‹ˆë‹¤:

```bash
conda create -n open_manus python=3.12
conda activate open_manus
```

2. ì €ì¥ì†Œë¥¼ í´ë¡ í•©ë‹ˆë‹¤:

```bash
git clone https://github.com/FoundationAgents/OpenManus.git
cd OpenManus
```

3. ì¢…ì†ì„±ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤:

```bash
pip install -r requirements.txt
```

### ë°©ë²• 2: uv ì‚¬ìš© (ê¶Œì¥)

1. uvë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤. (ë¹ ë¥¸ Python íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ì¢…ì†ì„± ê´€ë¦¬ ë„êµ¬):

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

2. ì €ì¥ì†Œë¥¼ í´ë¡ í•©ë‹ˆë‹¤:

```bash
git clone https://github.com/FoundationAgents/OpenManus.git
cd OpenManus
```

3. ìƒˆë¡œìš´ ê°€ìƒ í™˜ê²½ì„ ìƒì„±í•˜ê³  í™œì„±í™”í•©ë‹ˆë‹¤:

```bash
uv venv --python 3.12
source .venv/bin/activate  # Unix/macOSì˜ ê²½ìš°
# Windowsì˜ ê²½ìš°:
# .venv\Scripts\activate
```

4. ì¢…ì†ì„±ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤:

```bash
uv pip install -r requirements.txt
```

### ë¸Œë¼ìš°ì € ìë™í™” ë„êµ¬ (ì„ íƒì‚¬í•­)
```bash
playwright install
```

## ì„¤ì • ë°©ë²•

OpenManusë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ì‚¬ìš©í•˜ëŠ” LLM APIì— ëŒ€í•œ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. ì•„ë˜ ë‹¨ê³„ë¥¼ ë”°ë¼ ì„¤ì •ì„ ì™„ë£Œí•˜ì„¸ìš”:

1. `config` ë””ë ‰í† ë¦¬ì— `config.toml` íŒŒì¼ì„ ìƒì„±í•˜ì„¸ìš” (ì˜ˆì œ íŒŒì¼ì„ ë³µì‚¬í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤):

```bash
cp config/config.example.toml config/config.toml
```

2. `config/config.toml` íŒŒì¼ì„ í¸ì§‘í•˜ì—¬ API í‚¤ë¥¼ ì¶”ê°€í•˜ê³  ì„¤ì •ì„ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•˜ì„¸ìš”:

```toml
# ì „ì—­ LLM ì„¤ì •
[llm]
model = "gpt-4o"
base_url = "https://api.openai.com/v1"
api_key = "sk-..."  # ì‹¤ì œ API í‚¤ë¡œ ë³€ê²½í•˜ì„¸ìš”
max_tokens = 4096
temperature = 0.0

# íŠ¹ì • LLM ëª¨ë¸ì— ëŒ€í•œ ì„ íƒì  ì„¤ì •
[llm.vision]
model = "gpt-4o"
base_url = "https://api.openai.com/v1"
api_key = "sk-..."  # ì‹¤ì œ API í‚¤ë¡œ ë³€ê²½í•˜ì„¸ìš”
```

## ë¹ ë¥¸ ì‹œì‘

OpenManusë¥¼ ì‹¤í–‰í•˜ëŠ” í•œ ì¤„ ëª…ë ¹ì–´:

```bash
python main.py
```

ì´í›„ í„°ë¯¸ë„ì—ì„œ ì•„ì´ë””ì–´ë¥¼ ì‘ì„±í•˜ì„¸ìš”!

MCP ë„êµ¬ ë²„ì „ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒì„ ì‹¤í–‰í•˜ì„¸ìš”:
```bash
python run_mcp.py
```

ë¶ˆì•ˆì •í•œ ë©€í‹° ì—ì´ì „íŠ¸ ë²„ì „ì„ ì‹¤í–‰í•˜ë ¤ë©´ ë‹¤ìŒì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
python run_flow.py
```

### ì‚¬ìš©ì ì •ì˜ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì¶”ê°€

í˜„ì¬ ì¼ë°˜ OpenManus ì—ì´ì „íŠ¸ ì™¸ì—ë„ ë°ì´í„° ë¶„ì„ ë° ë°ì´í„° ì‹œê°í™” ì‘ì—…ì— ì í•©í•œ DataAnalysis ì—ì´ì „íŠ¸ë¥¼ í†µí•©í–ˆìŠµë‹ˆë‹¤. ì´ ì—ì´ì „íŠ¸ë¥¼ `config.toml`ì˜ `run_flow`ì— ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```toml
# run-flowì— ëŒ€í•œ ì„ íƒì  êµ¬ì„±
[runflow]
use_data_analysis_agent = true     # ê¸°ë³¸ì ìœ¼ë¡œ ë¹„í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©°, í™œì„±í™”í•˜ë ¤ë©´ trueë¡œ ë³€ê²½
```

ë˜í•œ, ì—ì´ì „íŠ¸ê°€ ì œëŒ€ë¡œ ì‘ë™í•˜ë„ë¡ ê´€ë ¨ ì¢…ì†ì„±ì„ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤: [ìƒì„¸ ì„¤ì¹˜ ê°€ì´ë“œ](app/tool/chart_visualization/README.md##Installation)

## ê¸°ì—¬ ë°©ë²•

ëª¨ë“  ì¹œì ˆí•œ ì œì•ˆê³¼ ìœ ìš©í•œ ê¸°ì—¬ë¥¼ í™˜ì˜í•©ë‹ˆë‹¤! ì´ìŠˆë¥¼ ìƒì„±í•˜ê±°ë‚˜ í’€ ë¦¬í€˜ìŠ¤íŠ¸ë¥¼ ì œì¶œí•´ ì£¼ì„¸ìš”.

ë˜ëŠ” ğŸ“§ ë©”ì¼ë¡œ ì—°ë½ì£¼ì„¸ìš”. @mannaandpoem : mannaandpoem@gmail.com

**ì°¸ê³ **: pull requestë¥¼ ì œì¶œí•˜ê¸° ì „ì— pre-commit ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€ê²½ ì‚¬í•­ì„ í™•ì¸í•˜ì‹­ì‹œì˜¤. `pre-commit run --all-files`ë¥¼ ì‹¤í–‰í•˜ì—¬ ê²€ì‚¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

## ì»¤ë®¤ë‹ˆí‹° ê·¸ë£¹
Feishu ë„¤íŠ¸ì›Œí‚¹ ê·¸ë£¹ì— ì°¸ì—¬í•˜ì—¬ ë‹¤ë¥¸ ê°œë°œìë“¤ê³¼ ê²½í—˜ì„ ê³µìœ í•˜ì„¸ìš”!

<div align="center" style="display: flex; gap: 20px;">
    <img src="assets/community_group.jpg" alt="OpenManus äº¤æµç¾¤" width="300" />
</div>

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=FoundationAgents/OpenManus&type=Date)](https://star-history.com/#FoundationAgents/OpenManus&Date)

## ê°ì‚¬ì˜ ê¸€

ì´ í”„ë¡œì íŠ¸ì— ê¸°ë³¸ì ì¸ ì§€ì›ì„ ì œê³µí•´ ì£¼ì‹  [anthropic-computer-use](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo)ì™€
[browser-use](https://github.com/browser-use/browser-use)ì—ê²Œ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤!

ë˜í•œ, [AAAJ](https://github.com/metauto-ai/agent-as-a-judge), [MetaGPT](https://github.com/geekan/MetaGPT), [OpenHands](https://github.com/All-Hands-AI/OpenHands), [SWE-agent](https://github.com/SWE-agent/SWE-agent)ì— ê¹Šì€ ê°ì‚¬ë¥¼ ë“œë¦½ë‹ˆë‹¤.

ë˜í•œ Hugging Face ë°ëª¨ ê³µê°„ì„ ì§€ì›í•´ ì£¼ì‹  é˜¶è·ƒæ˜Ÿè¾° (stepfun)ì—ê²Œ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤.

OpenManusëŠ” MetaGPT ê¸°ì—¬ìë“¤ì— ì˜í•´ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ì—ì´ì „íŠ¸ ì»¤ë®¤ë‹ˆí‹°ì— ê¹Šì€ ê°ì‚¬ë¥¼ ì „í•©ë‹ˆë‹¤!

## ì¸ìš©
```bibtex
@misc{openmanus2025,
  author = {Xinbin Liang and Jinyu Xiang and Zhaoyang Yu and Jiayi Zhang and Sirui Hong and Sheng Fan and Xiao Tang},
  title = {OpenManus: An open-source framework for building general AI agents},
  year = {2025},
  publisher = {Zenodo},
  doi = {10.5281/zenodo.15186407},
  url = {https://doi.org/10.5281/zenodo.15186407},
}
```

```

### ARQUIVO: README_ja.md ###
```md
<p align="center">
  <img src="assets/logo.jpg" width="200"/>
</p>

[English](README.md) | [ä¸­æ–‡](README_zh.md) | [í•œêµ­ì–´](README_ko.md) | æ—¥æœ¬èª | [PortuguÃªs (Brasil)](README_pt-br.md)

[![GitHub stars](https://img.shields.io/github/stars/FoundationAgents/OpenManus?style=social)](https://github.com/FoundationAgents/OpenManus/stargazers)
&ensp;
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) &ensp;
[![Discord Follow](https://dcbadge.vercel.app/api/server/DYn29wFk9z?style=flat)](https://discord.gg/DYn29wFk9z)
[![Demo](https://img.shields.io/badge/Demo-Hugging%20Face-yellow)](https://huggingface.co/spaces/lyh-917/OpenManusDemo)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.15186407.svg)](https://doi.org/10.5281/zenodo.15186407)

# ğŸ‘‹ OpenManus

Manusã¯ç´ æ™´ã‚‰ã—ã„ã§ã™ãŒã€OpenManusã¯*æ‹›å¾…ã‚³ãƒ¼ãƒ‰*ãªã—ã§ã©ã‚“ãªã‚¢ã‚¤ãƒ‡ã‚¢ã‚‚å®Ÿç¾ã§ãã¾ã™ï¼ğŸ›«

ç§ãŸã¡ã®ãƒãƒ¼ãƒ ãƒ¡ãƒ³ãƒãƒ¼ [@Xinbin Liang](https://github.com/mannaandpoem) ã¨ [@Jinyu Xiang](https://github.com/XiangJinyu)ï¼ˆä¸»è¦é–‹ç™ºè€…ï¼‰ã€ãã—ã¦ [@Zhaoyang Yu](https://github.com/MoshiQAQ)ã€[@Jiayi Zhang](https://github.com/didiforgithub)ã€[@Sirui Hong](https://github.com/stellaHSR) ã¯ [@MetaGPT](https://github.com/geekan/MetaGPT) ã‹ã‚‰æ¥ã¾ã—ãŸã€‚ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã¯3æ™‚é–“ä»¥å†…ã«ç«‹ã¡ä¸Šã’ã‚‰ã‚Œã€ç¶™ç¶šçš„ã«é–‹ç™ºã‚’é€²ã‚ã¦ã„ã¾ã™ï¼

ã“ã‚Œã¯ã‚·ãƒ³ãƒ—ãƒ«ãªå®Ÿè£…ã§ã™ã®ã§ã€ã©ã‚“ãªææ¡ˆã€è²¢çŒ®ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚‚æ­“è¿ã—ã¾ã™ï¼

OpenManusã§è‡ªåˆ†ã ã‘ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ¥½ã—ã¿ã¾ã—ã‚‡ã†ï¼

ã¾ãŸã€UIUCã¨OpenManusã®ç ”ç©¶è€…ãŒå…±åŒé–‹ç™ºã—ãŸ[OpenManus-RL](https://github.com/OpenManus/OpenManus-RL)ã‚’ã”ç´¹ä»‹ã§ãã‚‹ã“ã¨ã‚’å¬‰ã—ãæ€ã„ã¾ã™ã€‚ã“ã‚Œã¯å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ãƒ™ãƒ¼ã‚¹ï¼ˆGRPOãªã©ï¼‰ã®LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã«ç‰¹åŒ–ã—ãŸã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã™ã€‚

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ãƒ¢

<video src="https://private-user-images.githubusercontent.com/61239030/420168772-6dcfd0d2-9142-45d9-b74e-d10aa75073c6.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDEzMTgwNTksIm5iZiI6MTc0MTMxNzc1OSwicGF0aCI6Ii82MTIzOTAzMC80MjAxNjg3NzItNmRjZmQwZDItOTE0Mi00NWQ5LWI3NGUtZDEwYWE3NTA3M2M2Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAzMDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMzA3VDAzMjIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdiZjFkNjlmYWNjMmEzOTliM2Y3M2VlYjgyNDRlZDJmOWE3NWZhZjE1MzhiZWY4YmQ3NjdkNTYwYTU5ZDA2MzYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.UuHQCgWYkh0OQq9qsUWqGsUbhG3i9jcZDAMeHjLt5T4" data-canonical-src="https://private-user-images.githubusercontent.com/61239030/420168772-6dcfd0d2-9142-45d9-b74e-d10aa75073c6.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDEzMTgwNTksIm5iZiI6MTc0MTMxNzc1OSwicGF0aCI6Ii82MTIzOTAzMC80MjAxNjg3NzItNmRjZmQwZDItOTE0Mi00NWQ5LWI3NGUtZDEwYWE3NTA3M2M2Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAzMDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMzA3VDAzMjIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdiZjFkNjlmYWNjMmEzOTliM2Y3M2VlYjgyNDRlZDJmOWE3NWZhZjE1MzhiZWY4YmQ3NjdkNTYwYTU5ZDA2MzYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.UuHQCgWYkh0OQq9qsUWqGsUbhG3i9jcZDAMeHjLt5T4" controls="controls" muted="muted" class="d-block rounded-bottom-2 border-top width-fit" style="max-height:640px; min-height: 200px"></video>

## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•

ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•ã¯2ã¤æä¾›ã—ã¦ã„ã¾ã™ã€‚æ–¹æ³•2ï¼ˆuvã‚’ä½¿ç”¨ï¼‰ã¯ã€ã‚ˆã‚Šé«˜é€Ÿãªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨å„ªã‚ŒãŸä¾å­˜é–¢ä¿‚ç®¡ç†ã®ãŸã‚æ¨å¥¨ã•ã‚Œã¦ã„ã¾ã™ã€‚

### æ–¹æ³•1ï¼šcondaã‚’ä½¿ç”¨

1. æ–°ã—ã„condaç’°å¢ƒã‚’ä½œæˆã—ã¾ã™ï¼š

```bash
conda create -n open_manus python=3.12
conda activate open_manus
```

2. ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã—ã¾ã™ï¼š

```bash
git clone https://github.com/FoundationAgents/OpenManus.git
cd OpenManus
```

3. ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ï¼š

```bash
pip install -r requirements.txt
```

### æ–¹æ³•2ï¼šuvã‚’ä½¿ç”¨ï¼ˆæ¨å¥¨ï¼‰

1. uvï¼ˆé«˜é€ŸãªPythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ©ãƒ¼ã¨ç®¡ç†æ©Ÿèƒ½ï¼‰ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ï¼š

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

2. ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã—ã¾ã™ï¼š

```bash
git clone https://github.com/FoundationAgents/OpenManus.git
cd OpenManus
```

3. æ–°ã—ã„ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆã—ã¦ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆã—ã¾ã™ï¼š

```bash
uv venv --python 3.12
source .venv/bin/activate  # Unix/macOSã®å ´åˆ
# Windowsã®å ´åˆï¼š
# .venv\Scripts\activate
```

4. ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ï¼š

```bash
uv pip install -r requirements.txt
```

### ãƒ–ãƒ©ã‚¦ã‚¶è‡ªå‹•åŒ–ãƒ„ãƒ¼ãƒ«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
```bash
playwright install
```

## è¨­å®š

OpenManusã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€LLM APIã®è¨­å®šãŒå¿…è¦ã§ã™ã€‚ä»¥ä¸‹ã®æ‰‹é †ã«å¾“ã£ã¦è¨­å®šã—ã¦ãã ã•ã„ï¼š

1. `config`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«`config.toml`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™ï¼ˆã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰ã‚³ãƒ”ãƒ¼ã§ãã¾ã™ï¼‰ï¼š

```bash
cp config/config.example.toml config/config.toml
```

2. `config/config.toml`ã‚’ç·¨é›†ã—ã¦APIã‚­ãƒ¼ã‚’è¿½åŠ ã—ã€è¨­å®šã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã—ã¾ã™ï¼š

```toml
# ã‚°ãƒ­ãƒ¼ãƒãƒ«LLMè¨­å®š
[llm]
model = "gpt-4o"
base_url = "https://api.openai.com/v1"
api_key = "sk-..."  # å®Ÿéš›ã®APIã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
max_tokens = 4096
temperature = 0.0

# ç‰¹å®šã®LLMãƒ¢ãƒ‡ãƒ«ç”¨ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®š
[llm.vision]
model = "gpt-4o"
base_url = "https://api.openai.com/v1"
api_key = "sk-..."  # å®Ÿéš›ã®APIã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
```

## ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

OpenManusã‚’å®Ÿè¡Œã™ã‚‹ä¸€è¡Œã‚³ãƒãƒ³ãƒ‰ï¼š

```bash
python main.py
```

ãã®å¾Œã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼

MCP ãƒ„ãƒ¼ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¾ã™ï¼š
```bash
python run_mcp.py
```

é–‹ç™ºä¸­ã®ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’è©¦ã™ã«ã¯ã€ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¾ã™ï¼š

```bash
python run_flow.py
```

## ã‚«ã‚¹ã‚¿ãƒ ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¿½åŠ 

ç¾åœ¨ã€ä¸€èˆ¬çš„ãªOpenManusã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«åŠ ãˆã¦ã€ãƒ‡ãƒ¼ã‚¿åˆ†æã¨ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ã‚¿ã‚¹ã‚¯ã«é©ã—ãŸDataAnalysisã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒçµ„ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’`config.toml`ã®`run_flow`ã«è¿½åŠ ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

```toml
# run-flowã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®š
[runflow]
use_data_analysis_agent = true     # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ç„¡åŠ¹ã€trueã«å¤‰æ›´ã™ã‚‹ã¨æœ‰åŠ¹åŒ–ã•ã‚Œã¾ã™
```

ã“ã‚Œã«åŠ ãˆã¦ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ãŸã‚ã«å¿…è¦ãªä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š[å…·ä½“çš„ãªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¬ã‚¤ãƒ‰](app/tool/chart_visualization/README_ja.md##ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«)


## è²¢çŒ®æ–¹æ³•

æˆ‘ã€…ã¯å»ºè¨­çš„ãªæ„è¦‹ã‚„æœ‰ç›Šãªè²¢çŒ®ã‚’æ­“è¿ã—ã¾ã™ï¼issueã‚’ä½œæˆã™ã‚‹ã‹ã€ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æå‡ºã—ã¦ãã ã•ã„ã€‚

ã¾ãŸã¯ @mannaandpoem ã«ğŸ“§ãƒ¡ãƒ¼ãƒ«ã§ã”é€£çµ¡ãã ã•ã„ï¼šmannaandpoem@gmail.com

**æ³¨æ„**: ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ã™ã‚‹å‰ã«ã€pre-commitãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦å¤‰æ›´ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚`pre-commit run --all-files`ã‚’å®Ÿè¡Œã—ã¦ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

## ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚°ãƒ«ãƒ¼ãƒ—
Feishuã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚­ãƒ³ã‚°ã‚°ãƒ«ãƒ¼ãƒ—ã«å‚åŠ ã—ã¦ã€ä»–ã®é–‹ç™ºè€…ã¨çµŒé¨“ã‚’å…±æœ‰ã—ã¾ã—ã‚‡ã†ï¼

<div align="center" style="display: flex; gap: 20px;">
    <img src="assets/community_group.jpg" alt="OpenManus äº¤æµç¾¤" width="300" />
</div>

## ã‚¹ã‚¿ãƒ¼å±¥æ­´

[![Star History Chart](https://api.star-history.com/svg?repos=FoundationAgents/OpenManus&type=Date)](https://star-history.com/#FoundationAgents/OpenManus&Date)

## è¬è¾

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®åŸºæœ¬çš„ãªã‚µãƒãƒ¼ãƒˆã‚’æä¾›ã—ã¦ãã‚ŒãŸ[anthropic-computer-use](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo)
ã¨[browser-use](https://github.com/browser-use/browser-use)ã«æ„Ÿè¬ã—ã¾ã™ï¼

ã•ã‚‰ã«ã€[AAAJ](https://github.com/metauto-ai/agent-as-a-judge)ã€[MetaGPT](https://github.com/geekan/MetaGPT)ã€[OpenHands](https://github.com/All-Hands-AI/OpenHands)ã€[SWE-agent](https://github.com/SWE-agent/SWE-agent)ã«ã‚‚æ„Ÿè¬ã—ã¾ã™ã€‚

ã¾ãŸã€Hugging Face ãƒ‡ãƒ¢ã‚¹ãƒšãƒ¼ã‚¹ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ãã ã•ã£ãŸé˜¶è·ƒæ˜Ÿè¾° (stepfun)ã«ã‚‚æ„Ÿè¬ã„ãŸã—ã¾ã™ã€‚

OpenManusã¯MetaGPTã®ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ¼ã«ã‚ˆã£ã¦æ§‹ç¯‰ã•ã‚Œã¾ã—ãŸã€‚ã“ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å¤§ããªæ„Ÿè¬ã‚’ï¼

## å¼•ç”¨
```bibtex
@misc{openmanus2025,
  author = {Xinbin Liang and Jinyu Xiang and Zhaoyang Yu and Jiayi Zhang and Sirui Hong and Sheng Fan and Xiao Tang},
  title = {OpenManus: An open-source framework for building general AI agents},
  year = {2025},
  publisher = {Zenodo},
  doi = {10.5281/zenodo.15186407},
  url = {https://doi.org/10.5281/zenodo.15186407},
}
```

```

### ARQUIVO: run_flow.py ###
```py
import asyncio
import time

from app.agent.data_analysis import DataAnalysis
from app.agent.manus import Manus
from app.config import config
from app.flow.flow_factory import FlowFactory, FlowType
from app.logger import logger


async def run_flow():
    agents = {
        "manus": Manus(),
    }
    if config.run_flow_config.use_data_analysis_agent:
        agents["data_analysis"] = DataAnalysis()
    try:
        prompt = input("Enter your prompt: ")

        if prompt.strip().isspace() or not prompt:
            logger.warning("Empty prompt provided.")
            return

        flow = FlowFactory.create_flow(
            flow_type=FlowType.PLANNING,
            agents=agents,
        )
        logger.warning("Processing your request...")

        try:
            start_time = time.time()
            result = await asyncio.wait_for(
                flow.execute(prompt),
                timeout=3600,  # 60 minute timeout for the entire execution
            )
            elapsed_time = time.time() - start_time
            logger.info(f"Request processed in {elapsed_time:.2f} seconds")
            logger.info(result)
        except asyncio.TimeoutError:
            logger.error("Request processing timed out after 1 hour")
            logger.info(
                "Operation terminated due to timeout. Please try a simpler request."
            )

    except KeyboardInterrupt:
        logger.info("Operation cancelled by user.")
    except Exception as e:
        logger.error(f"Error: {str(e)}")


if __name__ == "__main__":
    asyncio.run(run_flow())

```

### ARQUIVO: run_mcp.py ###
```py
#!/usr/bin/env python
import argparse
import asyncio
import sys

from app.agent.mcp import MCPAgent
from app.config import config
from app.logger import logger


class MCPRunner:
    """Runner class for MCP Agent with proper path handling and configuration."""

    def __init__(self):
        self.root_path = config.root_path
        self.server_reference = config.mcp_config.server_reference
        self.agent = MCPAgent()

    async def initialize(
        self,
        connection_type: str,
        server_url: str | None = None,
    ) -> None:
        """Initialize the MCP agent with the appropriate connection."""
        logger.info(f"Initializing MCPAgent with {connection_type} connection...")

        if connection_type == "stdio":
            await self.agent.initialize(
                connection_type="stdio",
                command=sys.executable,
                args=["-m", self.server_reference],
            )
        else:  # sse
            await self.agent.initialize(connection_type="sse", server_url=server_url)

        logger.info(f"Connected to MCP server via {connection_type}")

    async def run_interactive(self) -> None:
        """Run the agent in interactive mode."""
        print("\nMCP Agent Interactive Mode (type 'exit' to quit)\n")
        while True:
            user_input = input("\nEnter your request: ")
            if user_input.lower() in ["exit", "quit", "q"]:
                break
            response = await self.agent.run(user_input)
            print(f"\nAgent: {response}")

    async def run_single_prompt(self, prompt: str) -> None:
        """Run the agent with a single prompt."""
        await self.agent.run(prompt)

    async def run_default(self) -> None:
        """Run the agent in default mode."""
        prompt = input("Enter your prompt: ")
        if not prompt.strip():
            logger.warning("Empty prompt provided.")
            return

        logger.warning("Processing your request...")
        await self.agent.run(prompt)
        logger.info("Request processing completed.")

    async def cleanup(self) -> None:
        """Clean up agent resources."""
        await self.agent.cleanup()
        logger.info("Session ended")


def parse_args() -> argparse.Namespace:
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(description="Run the MCP Agent")
    parser.add_argument(
        "--connection",
        "-c",
        choices=["stdio", "sse"],
        default="stdio",
        help="Connection type: stdio or sse",
    )
    parser.add_argument(
        "--server-url",
        default="http://127.0.0.1:8000/sse",
        help="URL for SSE connection",
    )
    parser.add_argument(
        "--interactive", "-i", action="store_true", help="Run in interactive mode"
    )
    parser.add_argument("--prompt", "-p", help="Single prompt to execute and exit")
    return parser.parse_args()


async def run_mcp() -> None:
    """Main entry point for the MCP runner."""
    args = parse_args()
    runner = MCPRunner()

    try:
        await runner.initialize(args.connection, args.server_url)

        if args.prompt:
            await runner.run_single_prompt(args.prompt)
        elif args.interactive:
            await runner.run_interactive()
        else:
            await runner.run_default()

    except KeyboardInterrupt:
        logger.info("Program interrupted by user")
    except Exception as e:
        logger.error(f"Error running MCPAgent: {str(e)}", exc_info=True)
        sys.exit(1)
    finally:
        await runner.cleanup()


if __name__ == "__main__":
    asyncio.run(run_mcp())

```

### ARQUIVO: CODE_OF_CONDUCT_pt-br.md ###
```md
# CÃ³digo de Conduta do Pacto de Contribuidores

## Nossa Promessa

NÃ³s, como membros, contribuidores e lÃ­deres, nos comprometemos a tornar a participaÃ§Ã£o em nossa comunidade uma experiÃªncia livre de assÃ©dio para todos, independentemente de idade, tamanho do corpo, deficiÃªncia visÃ­vel ou invisÃ­vel, etnia, caracterÃ­sticas sexuais, identidade e expressÃ£o de gÃªnero, nÃ­vel de experiÃªncia, educaÃ§Ã£o, status socioeconÃ´mico, nacionalidade, aparÃªncia pessoal, raÃ§a, casta, cor, religiÃ£o ou identidade e orientaÃ§Ã£o sexual.

Nos comprometemos a agir e interagir de maneiras que contribuam para uma comunidade aberta, acolhedora, diversificada, inclusiva e saudÃ¡vel.

## Nossos PadrÃµes

Exemplos de comportamento que contribuem para um ambiente positivo para nossa comunidade incluem:

* Demonstrar empatia e gentileza para com outras pessoas.
* Ser respeitoso com opiniÃµes, pontos de vista e experiÃªncias divergentes.
* Dar e aceitar feedback construtivo com elegÃ¢ncia.
* Aceitar responsabilidade e pedir desculpas Ã queles afetados por nossos erros, e aprender com a experiÃªncia.
* Focar no que Ã© melhor nÃ£o apenas para nÃ³s como indivÃ­duos, mas para a comunidade em geral.

Exemplos de comportamento inaceitÃ¡vel incluem:

* O uso de linguagem ou imagens sexualizadas, e atenÃ§Ã£o ou avanÃ§os sexuais de qualquer tipo.
* Trolling, comentÃ¡rios insultuosos ou depreciativos, e ataques pessoais ou polÃ­ticos.
* AssÃ©dio pÃºblico ou privado.
* Publicar informaÃ§Ãµes privadas de outros, como um endereÃ§o fÃ­sico ou de e-mail, sem sua permissÃ£o explÃ­cita.
* Outra conduta que poderia razoavelmente ser considerada inadequada em um ambiente profissional.

## Responsabilidades de AplicaÃ§Ã£o

Os lÃ­deres da comunidade sÃ£o responsÃ¡veis por esclarecer e aplicar nossos padrÃµes de comportamento aceitÃ¡vel e tomarÃ£o medidas corretivas apropriadas e justas em resposta a qualquer comportamento que considerem inadequado, ameaÃ§ador, ofensivo ou prejudicial.

Os lÃ­deres da comunidade tÃªm o direito e a responsabilidade de remover, editar ou rejeitar comentÃ¡rios, commits, cÃ³digo, ediÃ§Ãµes de wiki, issues e outras contribuiÃ§Ãµes que nÃ£o estejam alinhadas a este CÃ³digo de Conduta, e comunicarÃ£o os motivos das decisÃµes de moderaÃ§Ã£o quando apropriado.

## Escopo

Este CÃ³digo de Conduta se aplica a todos os espaÃ§os da comunidade e tambÃ©m quando um indivÃ­duo estÃ¡ representando oficialmente a comunidade em espaÃ§os pÃºblicos. Exemplos de representaÃ§Ã£o de nossa comunidade incluem o uso de um endereÃ§o de e-mail oficial, postagem por meio de uma conta de mÃ­dia social oficial ou atuaÃ§Ã£o como representante nomeado em um evento online ou offline.

## AplicaÃ§Ã£o

Casos de comportamento abusivo, de assÃ©dio ou de outra forma inaceitÃ¡vel podem ser relatados aos lÃ­deres da comunidade responsÃ¡veis pela aplicaÃ§Ã£o em mannaandpoem@gmail.com. Todas as reclamaÃ§Ãµes serÃ£o revisadas e investigadas pronta e justamente.

Todos os lÃ­deres da comunidade sÃ£o obrigados a respeitar a privacidade e a seguranÃ§a do relator de qualquer incidente.

## Diretrizes de AplicaÃ§Ã£o

Os lÃ­deres da comunidade seguirÃ£o estas Diretrizes de Impacto na Comunidade ao determinar as consequÃªncias de qualquer aÃ§Ã£o que considerem uma violaÃ§Ã£o deste CÃ³digo de Conduta:

### 1. CorreÃ§Ã£o

**Impacto na Comunidade**: Uso de linguagem inadequada ou outro comportamento considerado nÃ£o profissional ou indesejado na comunidade.

**ConsequÃªncia**: Uma advertÃªncia privada por escrito dos lÃ­deres da comunidade, fornecendo clareza sobre a natureza da violaÃ§Ã£o e uma explicaÃ§Ã£o de por que o comportamento foi inadequado. Um pedido pÃºblico de desculpas pode ser solicitado.

### 2. AdvertÃªncia

**Impacto na Comunidade**: Uma violaÃ§Ã£o por meio de um Ãºnico incidente ou sÃ©rie de aÃ§Ãµes.

**ConsequÃªncia**: Uma advertÃªncia com consequÃªncias para comportamento continuado. Nenhuma interaÃ§Ã£o com as pessoas envolvidas, incluindo interaÃ§Ã£o nÃ£o solicitada com aqueles que aplicam o CÃ³digo de Conduta, por um perÃ­odo de tempo especificado. Isso inclui evitar interaÃ§Ãµes em espaÃ§os da comunidade, bem como canais externos como mÃ­dias sociais. Violar esses termos pode levar a um banimento temporÃ¡rio ou permanente.

### 3. Banimento TemporÃ¡rio

**Impacto na Comunidade**: Uma violaÃ§Ã£o grave dos padrÃµes da comunidade, incluindo comportamento inadequado sustentado.

**ConsequÃªncia**: Um banimento temporÃ¡rio de qualquer tipo de interaÃ§Ã£o ou comunicaÃ§Ã£o pÃºblica com a comunidade por um perÃ­odo de tempo especificado. Nenhuma interaÃ§Ã£o pÃºblica ou privada com as pessoas envolvidas, incluindo interaÃ§Ã£o nÃ£o solicitada com aqueles que aplicam o CÃ³digo de Conduta, Ã© permitida durante este perÃ­odo. Violar esses termos pode levar a um banimento permanente.

### 4. Banimento Permanente

**Impacto na Comunidade**: Demonstrar um padrÃ£o de violaÃ§Ã£o dos padrÃµes da comunidade, incluindo comportamento inadequado sustentado, assÃ©dio a um indivÃ­duo ou agressÃ£o ou depreciaÃ§Ã£o de classes de indivÃ­duos.

**ConsequÃªncia**: Um banimento permanente de qualquer tipo de interaÃ§Ã£o pÃºblica dentro da comunidade.

### Etiquetas para Slack e Discord

Estas diretrizes de etiqueta para Slack e Discord sÃ£o projetadas para fomentar um ambiente inclusivo, respeitoso e produtivo para todos os membros da comunidade. Seguindo estas melhores prÃ¡ticas, garantimos uma comunicaÃ§Ã£o e colaboraÃ§Ã£o eficazes, minimizando interrupÃ§Ãµes. Vamos trabalhar juntos para construir uma comunidade solidÃ¡ria e acolhedora!

- Comunique-se de forma respeitosa e profissional, evitando sarcasmo ou linguagem Ã¡spera, e lembre-se que o tom pode ser difÃ­cil de interpretar em texto.
- Use threads para discussÃµes especÃ­ficas para manter os canais organizados e mais fÃ¡ceis de seguir.
- Marque outras pessoas apenas quando a contribuiÃ§Ã£o delas for crÃ­tica ou urgente, e use @here, @channel ou @everyone com moderaÃ§Ã£o para minimizar interrupÃ§Ãµes.
- Seja paciente, pois contribuidores e mantenedores de cÃ³digo aberto frequentemente tÃªm outros compromissos e podem precisar de tempo para responder.
- Publique perguntas ou discussÃµes no canal mais relevante ([discord - #general](https://discord.com/channels/1125308739348594758/1138430348557025341)).
- Ao pedir ajuda ou levantar problemas, inclua detalhes necessÃ¡rios como links, capturas de tela ou explicaÃ§Ãµes claras para fornecer contexto.
- Mantenha as discussÃµes em canais pÃºblicos sempre que possÃ­vel para permitir que outros se beneficiem da conversa, a menos que o assunto seja sensÃ­vel ou privado.
- Sempre adira aos [nossos padrÃµes](https://github.com/FoundationAgents/OpenManus/blob/main/CODE_OF_CONDUCT_pt-br.md#nossos-padrÃµes) para garantir um ambiente acolhedor e colaborativo. (Nota: O link foi atualizado para apontar para a seÃ§Ã£o correspondente no documento traduzido.)
- Se vocÃª optar por silenciar um canal, considere configurar alertas para tÃ³picos que ainda lhe interessam para se manter engajado. Para o Slack, vÃ¡ para ConfiguraÃ§Ãµes â†’ NotificaÃ§Ãµes â†’ Minhas Palavras-chave para adicionar palavras-chave especÃ­ficas que o notificarÃ£o quando mencionadas. Por exemplo, se vocÃª estÃ¡ aqui para discussÃµes sobre LLMs, silencie o canal se estiver muito movimentado, mas configure notificaÃ§Ãµes para alertÃ¡-lo apenas quando â€œLLMsâ€ aparecer nas mensagens. Para o Discord, vÃ¡ para as notificaÃ§Ãµes do canal e escolha a opÃ§Ã£o que melhor descreve sua necessidade.

## AtribuiÃ§Ã£o

Este CÃ³digo de Conduta Ã© adaptado do [Contributor Covenant][homepage], versÃ£o 2.1, disponÃ­vel em [https://www.contributor-covenant.org/version/2/1/code_of_conduct.html][v2.1].

As Diretrizes de Impacto na Comunidade foram inspiradas na [escala de aplicaÃ§Ã£o do cÃ³digo de conduta da Mozilla][Mozilla CoC].

Para respostas a perguntas comuns sobre este cÃ³digo de conduta, consulte o FAQ em [https://www.contributor-covenant.org/faq][FAQ]. TraduÃ§Ãµes estÃ£o disponÃ­veis em [https://www.contributor-covenant.org/translations][translations].

[homepage]: https://www.contributor-covenant.org
[v2.1]: https://www.contributor-covenant.org/version/2/1/code_of_conduct.html
[Mozilla CoC]: https://github.com/mozilla/diversity
[FAQ]: https://www.contributor-covenant.org/faq
[translations]: https://www.contributor-covenant.org/translations

```

### ARQUIVO: main.py ###
```py
import asyncio
import os # Added for workspace directory creation
import sys
import select
import threading
from app.config import config # Added for workspace directory creation

from app.agent.manus import Manus
from app.logger import logger
from app.schema import AgentState # Import AgentState


class KeyboardListener(threading.Thread):
    def __init__(self, agent_instance, stop_event):
        super().__init__(daemon=True) # Thread daemon para sair se o programa principal sair
        self.agent_instance = agent_instance
        self.stop_event = stop_event
        self.listener_logger = logger # Usar o logger global da aplicaÃ§Ã£o

    def run(self):
        self.listener_logger.info("[KeyboardListener] Iniciando...")
        try:
            while not self.stop_event.is_set():
                # Usar select para verificar stdin de forma nÃ£o bloqueante
                # O timeout de 0.1 segundos faz o loop verificar self.stop_event regularmente
                ready_to_read, _, _ = select.select([sys.stdin], [], [], 0.1)
                if self.stop_event.is_set(): # Verificar novamente apÃ³s o select
                    break
                if ready_to_read:
                    line = sys.stdin.readline().strip().lower()
                    if line == "p":
                        self.listener_logger.info("[KeyboardListener] Comando 'p' detectado. Sinalizando pausa para o agente.")
                        if hasattr(self.agent_instance, 'user_pause_requested_event'):
                            self.agent_instance.user_pause_requested_event.set()
                        # NÃ£o precisa parar a thread aqui; ela serÃ¡ parada quando agent.run() retornar.
        except Exception as e:
            self.listener_logger.error(f"[KeyboardListener] Erro: {e}", exc_info=True)
        finally:
            self.listener_logger.info("[KeyboardListener] Encerrando.")


async def main():
    # Garantir que o diretÃ³rio do workspace existe
    try:
        workspace_path = config.workspace_root
        os.makedirs(workspace_path, exist_ok=True)
        logger.info(f"[main.py] DiretÃ³rio do workspace garantido: {workspace_path}")
    except Exception as e_mkdir:
        logger.error(f"[main.py] NÃ£o foi possÃ­vel criar o diretÃ³rio do workspace {config.workspace_root}: {e_mkdir}. Continuando, mas operaÃ§Ãµes de arquivo no workspace podem falhar.")

    # Criar e inicializar o agente Manus
    agent = await Manus.create()
    agent.max_steps = 10 # MÃ¡ximo de passos por ciclo agent.run()
    logger.info(f"[main.py] Agente criado. agent.max_steps inicial = {agent.max_steps}, estado inicial = {agent.state.value}")

    try:
        logger.info(f"[main.py] Iniciando loop de execuÃ§Ã£o principal. Estado do agente: {agent.state.value}")
        loop_iteration = 0
        while agent.state not in [AgentState.USER_HALTED, AgentState.FINISHED, AgentState.ERROR]:
            loop_iteration += 1
            logger.info(f"[main.py] IteraÃ§Ã£o do loop: {loop_iteration}. Estado atual do agente: {agent.state.value}")

            current_prompt_for_run = None # Inicializar para cada iteraÃ§Ã£o do loop

            if agent.state == AgentState.IDLE:
                user_input = ""
                try:
                    user_input = input("Digite seu prompt (ou 'quit' para sair): ").strip()
                except (EOFError, KeyboardInterrupt) as e:
                    logger.warning(f"[main.py] Entrada interrompida ({type(e).__name__}) durante o estado IDLE. Definindo estado para USER_HALTED.")
                    agent.state = AgentState.USER_HALTED
                    if hasattr(agent, 'user_pause_requested_event') and agent.user_pause_requested_event:
                        agent.user_pause_requested_event.set()
                    break

                input_lower = user_input.lower()
                if input_lower == "quit":
                    agent.state = AgentState.USER_HALTED
                    logger.info("[main.py] Comando 'quit' recebido no estado IDLE. Estado do agente definido para USER_HALTED.")
                    break
                elif not user_input:
                    logger.warning("[main.py] Prompt vazio recebido no estado IDLE. Interrompendo.")
                    agent.state = AgentState.USER_HALTED
                    break
                else:
                    current_prompt_for_run = user_input
                    agent.state = AgentState.RUNNING
                    logger.info(f"[main.py] Prompt para execuÃ§Ã£o: '{current_prompt_for_run}'. Estado do agente definido para RUNNING.")

            elif agent.state == AgentState.USER_PAUSED:
                user_input = ""
                try:
                    user_input = input("Agente pausado. Digite um novo comando (ou 'quit' para interromper): ").strip()
                except (EOFError, KeyboardInterrupt) as e:
                    logger.warning(f"[main.py] Entrada interrompida ({type(e).__name__}) durante o estado USER_PAUSED. Definindo estado para USER_HALTED.")
                    agent.state = AgentState.USER_HALTED
                    if hasattr(agent, 'user_pause_requested_event') and agent.user_pause_requested_event:
                        agent.user_pause_requested_event.set()
                    break

                input_lower = user_input.lower()
                if input_lower == "quit":
                    agent.state = AgentState.USER_HALTED
                    logger.info("[main.py] Comando 'quit' recebido no estado USER_PAUSED. Estado do agente definido para USER_HALTED.")
                    break
                elif not user_input:
                    logger.warning("[main.py] Comando vazio recebido no estado USER_PAUSED. Solicitando novamente.")
                    continue
                else:
                    # Processar como novo comando
                    agent.update_memory("user", user_input)
                    agent.current_step = 0
                    agent.state = AgentState.RUNNING
                    logger.info(f"[main.py] Novo comando recebido: '{user_input}'. MemÃ³ria do agente atualizada, current_step redefinido. Estado do agente definido para RUNNING.")

            elif agent.state == AgentState.AWAITING_USER_FEEDBACK:
                logger.info("[main.py] Agente estÃ¡ AWAITING_USER_FEEDBACK. Feedback Ã© assumido como processado pelo agente (ex: via Manus.periodic_user_check_in). Definindo estado para RUNNING para continuar.")
                agent.state = AgentState.RUNNING

            elif agent.state == AgentState.RUNNING:
                 # Este caso implica que agent.run() de uma iteraÃ§Ã£o anterior retornou RUNNING,
                 # ou o estado do agente foi definido para RUNNING por meios externos dentro do loop.
                 # Geralmente, isso nÃ£o Ã© esperado se agent.run() completar totalmente ou entrar em estado de espera.
                 logger.warning("[main.py] Agente jÃ¡ estÃ¡ no estado RUNNING no inÃ­cio de um novo ciclo de entrada. Isso Ã© inesperado se nÃ£o for imediatamente apÃ³s o processamento da entrada. Prosseguindo para agent.run().")
                 # current_prompt_for_run deve ser None aqui, a menos que explicitamente definido pelo tratamento do estado IDLE na mesma iteraÃ§Ã£o.

            else: # NÃ£o deve ser alcanÃ§ado se as condiÃ§Ãµes do loop estiverem corretas
                logger.error(f"[main.py] Estado inesperado do agente {agent.state.value} encontrado no loop principal. Definindo para ERROR.")
                agent.state = AgentState.ERROR
                break

            # Chamar agent.run() se o agente estiver no estado RUNNING
            if agent.state == AgentState.RUNNING:
                run_message = f"Chamando agent.run() com {'prompt inicial' if current_prompt_for_run else 'memÃ³ria existente/atualizada'}."
                logger.info(f"[main.py] {run_message} Passo atual antes da execuÃ§Ã£o: {agent.current_step}.")

                keyboard_listener_thread = None
                listener_stop_event = None # Definir listener_stop_event aqui para escopo mais amplo no finally
                if agent.state == AgentState.RUNNING: # SÃ³ iniciar listener se o agente for realmente executar passos
                    listener_stop_event = threading.Event()
                    keyboard_listener_thread = KeyboardListener(agent, listener_stop_event)
                    logger.info("[main.py] Iniciando KeyboardListener em background...")
                    keyboard_listener_thread.start()

                try:
                    await agent.run(current_prompt_for_run) # Passar prompt se inicial, senÃ£o None
                except Exception as e_run:
                    # Linha de log geral existente (exc_info=True tambÃ©m deve fornecer um traceback,
                    # mas a explÃ­cita acima Ã© uma salvaguarda para este problema especÃ­fico)
                    logger.error(f"[main.py] ExceÃ§Ã£o durante agent.run(): {type(e_run).__name__} - {e_run}", exc_info=True)
                    agent.state = AgentState.ERROR

                if keyboard_listener_thread is not None and keyboard_listener_thread.is_alive():
                    logger.info("[main.py] Parando KeyboardListener...")
                    if listener_stop_event: # Verificar se listener_stop_event foi inicializado
                        listener_stop_event.set()
                    keyboard_listener_thread.join(timeout=0.5) # Esperar um pouco pela thread
                    if keyboard_listener_thread.is_alive():
                        logger.warning("[main.py] KeyboardListener nÃ£o encerrou a tempo.")
                    else:
                        logger.info("[main.py] KeyboardListener encerrado.")

                logger.info(f"[main.py] agent.run() concluÃ­do. Estado do agente agora Ã©: {agent.state.value}")

            # Se o estado se tornou terminal devido ao tratamento de entrada ou erro em agent.run, o loop verificarÃ¡ a condiÃ§Ã£o e sairÃ¡.
            if agent.state in [AgentState.USER_HALTED, AgentState.FINISHED, AgentState.ERROR]:
                logger.info(f"[main.py] Estado do agente Ã© {agent.state.value}. Loop avaliarÃ¡ condiÃ§Ãµes de saÃ­da.")
                # continue # Deixar a condiÃ§Ã£o while lidar com a terminaÃ§Ã£o

        logger.info(f"[main.py] Loop de execuÃ§Ã£o principal finalizado. Estado final do agente: {agent.state.value}")
        if agent.state == AgentState.USER_HALTED:
            logger.info("[main.py] ExecuÃ§Ã£o interrompida pelo usuÃ¡rio ou comando especÃ­fico.")
        elif agent.state == AgentState.FINISHED:
            logger.info("[main.py] Processamento do agente finalizado.")
        elif agent.state == AgentState.ERROR:
            logger.error("[main.py] Agente parado devido a um erro.")

    except KeyboardInterrupt: # Isso lida com Ctrl+C durante as partes do loop nÃ£o cobertas por input()
        logger.warning("[main.py] KeyboardInterrupt capturado no bloco try principal. Definindo estado para USER_HALTED.")
        if agent:
            agent.state = AgentState.USER_HALTED
            if hasattr(agent, 'user_pause_requested_event') and agent.user_pause_requested_event:
                agent.user_pause_requested_event.set()
    except Exception as e:
        logger.exception(f"[main.py] Um erro inesperado ocorreu no main: {type(e).__name__} - {e}", exc_info=True)
        if agent:
            agent.state = AgentState.ERROR
    finally:
        logger.info("[main.py] Entrando no bloco finally para limpeza.")
        if agent:
            logger.info(f"[main.py] Limpando recursos do agente. Estado do agente na limpeza: {agent.state.value}")
            await agent.cleanup()
            logger.info("[main.py] Recursos do agente limpos.")
        else:
            logger.info("[main.py] Nenhuma instÃ¢ncia de agente para limpar.")

        # Esta Ã© uma salvaguarda, idealmente a thread jÃ¡ foi parada.
        if 'keyboard_listener_thread' in locals() and keyboard_listener_thread is not None and keyboard_listener_thread.is_alive():
            logger.info("[main.py] Finally: Parando KeyboardListener remanescente...")
            if 'listener_stop_event' in locals() and listener_stop_event is not None:
                 listener_stop_event.set()
            keyboard_listener_thread.join(timeout=0.5)
            logger.info("[main.py] Finally: KeyboardListener remanescente encerrado.")


if __name__ == "__main__":
    asyncio.run(main())

```

### ARQUIVO: README_pt-br.md ###
```md
<p align="center">
  <img src="assets/logo.jpg" width="200"/>
</p>

[English](README.md) | [ä¸­æ–‡](README_zh.md) | [í•œêµ­ì–´](README_ko.md) | [æ—¥æœ¬èª](README_ja.md) | **PortuguÃªs (Brasil)**

[![GitHub stars](https://img.shields.io/github/stars/FoundationAgents/OpenManus?style=social)](https://github.com/FoundationAgents/OpenManus/stargazers)
&ensp;
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) &ensp;
[![Discord Follow](https://dcbadge.vercel.app/api/server/DYn29wFk9z?style=flat)](https://discord.gg/DYn29wFk9z)
[![Demo](https://img.shields.io/badge/Demo-Hugging%20Face-yellow)](https://huggingface.co/spaces/lyh-917/OpenManusDemo)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.15186407.svg)](https://doi.org/10.5281/zenodo.15186407)

# ğŸ‘‹ OpenManus

Manus Ã© incrÃ­vel, mas o OpenManus pode realizar qualquer ideia sem precisar de *cÃ³digo de convite* ğŸ›«!

Nossa equipe Ã© formada por [@Xinbin Liang](https://github.com/mannaandpoem) e [@Jinyu Xiang](https://github.com/XiangJinyu) (autores principais), junto com [@Zhaoyang Yu](https://github.com/MoshiQAQ), [@Jiayi Zhang](https://github.com/didiforgithub) e [@Sirui Hong](https://github.com/stellaHSR), do [@MetaGPT](https://github.com/geekan/MetaGPT). Criamos o protÃ³tipo em apenas 3 horas e continuamos desenvolvendo!

Ã‰ uma implementaÃ§Ã£o simples, entÃ£o aceitamos sugestÃµes, contribuiÃ§Ãµes e feedback!

Aproveite o seu prÃ³prio agente com o OpenManus!

TambÃ©m estamos empolgados em apresentar o [OpenManus-RL](https://github.com/OpenManus/OpenManus-RL), um projeto de cÃ³digo aberto dedicado a mÃ©todos de ajuste baseados em aprendizado por reforÃ§o (RL) (como GRPO) para agentes LLM, desenvolvido em colaboraÃ§Ã£o por pesquisadores da UIUC e do OpenManus.

## DemonstraÃ§Ã£o do Projeto

<video src="https://private-user-images.githubusercontent.com/61239030/420168772-6dcfd0d2-9142-45d9-b74e-d10aa75073c6.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDEzMTgwNTksIm5iZiI6MTc0MTMxNzc1OSwicGF0aCI6Ii82MTIzOTAzMC80MjAxNjg3NzItNmRjZmQwZDItOTE0Mi00NWQ5LWI3NGUtZDEwYWE3NTA3M2M2Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAzMDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMzA3VDAzMjIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdiZjFkNjlmYWNjMmEzOTliM2Y3M2VlYjgyNDRlZDJmOWE3NWZhZjE1MzhiZWY4YmQ3NjdkNTYwYTU5ZDA2MzYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.UuHQCgWYkh0OQq9qsUWqGsUbhG3i9jcZDAMeHjLt5T4" data-canonical-src="https://private-user-images.githubusercontent.com/61239030/420168772-6dcfd0d2-9142-45d9-b74e-d10aa75073c6.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDEzMTgwNTksIm5iZiI6MTc0MTMxNzc1OSwicGF0aCI6Ii82MTIzOTAzMC80MjAxNjg3NzItNmRjZmQwZDItOTE0Mi00NWQ5LWI3NGUtZDEwYWE3NTA3M2M2Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAzMDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMzA3VDAzMjIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdiZjFkNjlmYWNjMmEzOTliM2Y3M2VlYjgyNDRlZDJmOWE3NWZhZjE1MzhiZWY4YmQ3NjdkNTYwYTU5ZDA2MzYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.UuHQCgWYkh0OQq9qsUWqGsUbhG3i9jcZDAMeHjLt5T4" controls="controls" muted="muted" class="d-block rounded-bottom-2 border-top width-fit" style="max-height:640px; min-height: 200px"></video>

## InstalaÃ§Ã£o

Fornecemos dois mÃ©todos de instalaÃ§Ã£o. O MÃ©todo 2 (usando uv) Ã© recomendado para uma instalaÃ§Ã£o mais rÃ¡pida e melhor gerenciamento de dependÃªncias.

### MÃ©todo 1: Usando conda

1. Crie um novo ambiente conda:

```bash
conda create -n open_manus python=3.12
conda activate open_manus
```

2. Clone o repositÃ³rio:

```bash
git clone https://github.com/FoundationAgents/OpenManus.git
cd OpenManus
```

3. Instale as dependÃªncias:

```bash
pip install -r requirements.txt
```

### MÃ©todo 2: Usando uv (Recomendado)

1. Instale uv (Um instalador e resolvedor rÃ¡pido de pacotes Python):

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

2. Clone o repositÃ³rio:

```bash
git clone https://github.com/FoundationAgents/OpenManus.git
cd OpenManus
```

3. Crie um novo ambiente virtual e ative-o:

```bash
uv venv --python 3.12
source .venv/bin/activate  # Em Unix/macOS
# Ou no Windows:
# .venv\Scriptsctivate
```

4. Instale as dependÃªncias:

```bash
uv pip install -r requirements.txt
```

### Ferramenta de AutomaÃ§Ã£o de Navegador (Opcional)
```bash
playwright install
```

## ConfiguraÃ§Ã£o

O OpenManus requer configuraÃ§Ã£o para as APIs LLM que utiliza. Siga estes passos para configurar:

1. Crie um arquivo `config.toml` no diretÃ³rio `config` (vocÃª pode copiar do exemplo):

```bash
cp config/config.example.toml config/config.toml
```

2. Edite `config/config.toml` para adicionar suas chaves de API e personalizar as configuraÃ§Ãµes:

```toml
# ConfiguraÃ§Ã£o global do LLM
[llm]
model = "gpt-4o"
base_url = "https://api.openai.com/v1"
api_key = "sk-..."  # Substitua pela sua chave de API real
max_tokens = 4096
temperature = 0.0

# ConfiguraÃ§Ã£o opcional para modelos LLM especÃ­ficos
[llm.vision]
model = "gpt-4o"
base_url = "https://api.openai.com/v1"
api_key = "sk-..."  # Substitua pela sua chave de API real
```

## InÃ­cio RÃ¡pido

Uma linha para executar o OpenManus:

```bash
python main.py
```

EntÃ£o, insira sua ideia via terminal!

Para a versÃ£o com ferramenta MCP, vocÃª pode executar:
```bash
python run_mcp.py
```

Para a versÃ£o instÃ¡vel multi-agente, vocÃª tambÃ©m pode executar:

```bash
python run_flow.py
```

### Adicionando MÃºltiplos Agentes Personalizados

Atualmente, alÃ©m do Agente OpenManus geral, tambÃ©m integramos o Agente DataAnalysis, que Ã© adequado para tarefas de anÃ¡lise e visualizaÃ§Ã£o de dados. VocÃª pode adicionar este agente ao `run_flow` em `config.toml`.

```toml
# ConfiguraÃ§Ã£o opcional para run-flow
[runflow]
use_data_analysis_agent = true     # Desabilitado por padrÃ£o, mude para true para ativar
```
AlÃ©m disso, vocÃª precisa instalar as dependÃªncias relevantes para garantir que o agente funcione corretamente: [Guia de InstalaÃ§Ã£o Detalhado](app/tool/chart_visualization/README_pt-br.md#instalaÃ§Ã£o) (Nota: O link deve apontar para o README traduzido da ferramenta de visualizaÃ§Ã£o quando estiver pronto)

## Como contribuir

Acolhemos quaisquer sugestÃµes amigÃ¡veis e contribuiÃ§Ãµes Ãºteis! Apenas crie issues ou envie pull requests.

Ou contate @mannaandpoem via ğŸ“§email: mannaandpoem@gmail.com

**Nota**: Antes de enviar um pull request, por favor, use a ferramenta pre-commit para verificar suas alteraÃ§Ãµes. Execute `pre-commit run --all-files` para executar as verificaÃ§Ãµes.

## Grupo da Comunidade
Junte-se ao nosso grupo de networking no Feishu e compartilhe sua experiÃªncia com outros desenvolvedores!

<div align="center" style="display: flex; gap: 20px;">
    <img src="assets/community_group.jpg" alt="OpenManus Grupo de DiscussÃ£o" width="300" />
</div>

## HistÃ³rico de Estrelas

[![Star History Chart](https://api.star-history.com/svg?repos=FoundationAgents/OpenManus&type=Date)](https://star-history.com/#FoundationAgents/OpenManus&Date)

## Patrocinadores
Agradecimentos Ã  [PPIO](https://ppinfra.com/user/register?invited_by=OCPKCN&utm_source=github_openmanus&utm_medium=github_readme&utm_campaign=link) pelo suporte de recursos computacionais.
> PPIO: A soluÃ§Ã£o MaaS e nuvem GPU mais acessÃ­vel e de fÃ¡cil integraÃ§Ã£o.

## Agradecimentos

Agradecimentos a [anthropic-computer-use](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo)
e [browser-use](https://github.com/browser-use/browser-use) por fornecerem suporte bÃ¡sico para este projeto!

AlÃ©m disso, somos gratos a [AAAJ](https://github.com/metauto-ai/agent-as-a-judge), [MetaGPT](https://github.com/geekan/MetaGPT), [OpenHands](https://github.com/All-Hands-AI/OpenHands) e [SWE-agent](https://github.com/SWE-agent/SWE-agent).

TambÃ©m agradecemos a stepfun (é˜¶è·ƒæ˜Ÿè¾°) por apoiar nosso espaÃ§o de demonstraÃ§Ã£o na Hugging Face.

O OpenManus Ã© construÃ­do por contribuidores do MetaGPT. Um enorme obrigado a esta comunidade de agentes!

## Citar
```bibtex
@misc{openmanus2025,
  author = {Xinbin Liang and Jinyu Xiang and Zhaoyang Yu and Jiayi Zhang and Sirui Hong and Sheng Fan and Xiao Tang},
  title = {OpenManus: An open-source framework for building general AI agents},
  year = {2025},
  publisher = {Zenodo},
  doi = {10.5281/zenodo.15186407},
  url = {https://doi.org/10.5281/zenodo.15186407},
}
```

```

### ARQUIVO: Dockerfile ###
```
FROM python:3.12-slim

WORKDIR /app/OpenManus

RUN apt-get update && apt-get install -y --no-install-recommends git curl \
    && rm -rf /var/lib/apt/lists/* \
    && (command -v uv >/dev/null 2>&1 || pip install --no-cache-dir uv)

COPY . .

RUN uv pip install --system -r requirements.txt

CMD ["bash"]

```

### ARQUIVO: run_mcp_server.py ###
```py
# coding: utf-8
# A shortcut to launch OpenManus MCP server, where its introduction also solves other import issues.
from app.mcp.server import MCPServer, parse_args


if __name__ == "__main__":
    args = parse_args()

    # Create and run server (maintaining original flow)
    server = MCPServer()
    server.run(transport=args.transport)

```

### ARQUIVO: LICENSE ###
```
MIT License

Copyright (c) 2025 manna_and_poem

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

```

### ARQUIVO: CODE_OF_CONDUCT.md ###
```md
# Contributor Covenant Code of Conduct

## Our Pledge

We as members, contributors, and leaders pledge to make participation in our
community a harassment-free experience for everyone, regardless of age, body
size, visible or invisible disability, ethnicity, sex characteristics, gender
identity and expression, level of experience, education, socio-economic status,
nationality, personal appearance, race, caste, color, religion, or sexual
identity and orientation.

We pledge to act and interact in ways that contribute to an open, welcoming,
diverse, inclusive, and healthy community.

## Our Standards

Examples of behavior that contributes to a positive environment for our
community include:

* Demonstrating empathy and kindness toward other people.
* Being respectful of differing opinions, viewpoints, and experiences.
* Giving and gracefully accepting constructive feedback.
* Accepting responsibility and apologizing to those affected by our mistakes,
  and learning from the experience.
* Focusing on what is best not just for us as individuals, but for the overall
  community.

Examples of unacceptable behavior include:

* The use of sexualized language or imagery, and sexual attention or advances of
  any kind.
* Trolling, insulting or derogatory comments, and personal or political attacks.
* Public or private harassment.
* Publishing others' private information, such as a physical or email address,
  without their explicit permission.
* Other conduct which could reasonably be considered inappropriate in a
  professional setting.

## Enforcement Responsibilities

Community leaders are responsible for clarifying and enforcing our standards of
acceptable behavior and will take appropriate and fair corrective action in
response to any behavior that they deem inappropriate, threatening, offensive,
or harmful.

Community leaders have the right and responsibility to remove, edit, or reject
comments, commits, code, wiki edits, issues, and other contributions that are
not aligned to this Code of Conduct, and will communicate reasons for moderation
decisions when appropriate.

## Scope

This Code of Conduct applies within all community spaces, and also applies when
an individual is officially representing the community in public spaces.
Examples of representing our community include using an official email address,
posting via an official social media account, or acting as an appointed
representative at an online or offline event.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported to the community leaders responsible for enforcement at
mannaandpoem@gmail.com
All complaints will be reviewed and investigated promptly and fairly.

All community leaders are obligated to respect the privacy and security of the
reporter of any incident.

## Enforcement Guidelines

Community leaders will follow these Community Impact Guidelines in determining
the consequences for any action they deem in violation of this Code of Conduct:

### 1. Correction

**Community Impact**: Use of inappropriate language or other behavior deemed
unprofessional or unwelcome in the community.

**Consequence**: A private, written warning from community leaders, providing
clarity around the nature of the violation and an explanation of why the
behavior was inappropriate. A public apology may be requested.

### 2. Warning

**Community Impact**: A violation through a single incident or series of
actions.

**Consequence**: A warning with consequences for continued behavior. No
interaction with the people involved, including unsolicited interaction with
those enforcing the Code of Conduct, for a specified period of time. This
includes avoiding interactions in community spaces as well as external channels
like social media. Violating these terms may lead to a temporary or permanent
ban.

### 3. Temporary Ban

**Community Impact**: A serious violation of community standards, including
sustained inappropriate behavior.

**Consequence**: A temporary ban from any sort of interaction or public
communication with the community for a specified period of time. No public or
private interaction with the people involved, including unsolicited interaction
with those enforcing the Code of Conduct, is allowed during this period.
Violating these terms may lead to a permanent ban.

### 4. Permanent Ban

**Community Impact**: Demonstrating a pattern of violation of community
standards, including sustained inappropriate behavior, harassment of an
individual, or aggression toward or disparagement of classes of individuals.

**Consequence**: A permanent ban from any sort of public interaction within the
community.

### Slack and Discord Etiquettes

These Slack and Discord etiquette guidelines are designed to foster an inclusive, respectful, and productive environment
for all community members. By following these best practices, we ensure effective communication and collaboration while
minimizing disruptions. Letâ€™s work together to build a supportive and welcoming community!

- Communicate respectfully and professionally, avoiding sarcasm or harsh language, and remember that tone can be
  difficult to interpret in text.
- Use threads for specific discussions to keep channels organized and easier to follow.
- Tag others only when their input is critical or urgent, and use @here, @channel or @everyone sparingly to minimize
  disruptions.
- Be patient, as open-source contributors and maintainers often have other commitments and may need time to respond.
- Post questions or discussions in the most relevant
  channel ([discord - #general](https://discord.com/channels/1125308739348594758/1138430348557025341)).
- When asking for help or raising issues, include necessary details like links, screenshots, or clear explanations to
  provide context.
- Keep discussions in public channels whenever possible to allow others to benefit from the conversation, unless the
  matter is sensitive or private.
- Always adhere to [our standards](https://github.com/FoundationAgents/OpenManus/blob/main/CODE_OF_CONDUCT.md#our-standards)
  to ensure a welcoming and collaborative environment.
- If you choose to mute a channel, consider setting up alerts for topics that still interest you to stay engaged. For
  Slack, Go to Settings â†’ Notifications â†’ My Keywords to add specific keywords that will notify you when mentioned. For
  example, if you're here for discussions about LLMs, mute the channel if itâ€™s too busy, but set notifications to alert
  you only when â€œLLMsâ€ appears in messages. Also for Discord, go to the channel notifications and choose the option that
  best describes your need.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage],
version 2.1, available at
[https://www.contributor-covenant.org/version/2/1/code_of_conduct.html][v2.1].

Community Impact Guidelines were inspired by
[Mozilla's code of conduct enforcement ladder][Mozilla CoC].

For answers to common questions about this code of conduct, see the FAQ at
[https://www.contributor-covenant.org/faq][FAQ]. Translations are available at
[https://www.contributor-covenant.org/translations][translations].

[homepage]: https://www.contributor-covenant.org

[v2.1]: https://www.contributor-covenant.org/version/2/1/code_of_conduct.html

[Mozilla CoC]: https://github.com/mozilla/diversity

[FAQ]: https://www.contributor-covenant.org/faq

[translations]: https://www.contributor-covenant.org/translations

```

### ARQUIVO: .gitignore ###
```
### Project-specific ###
# Logs
logs/

# Data
data/

# Workspace
workspace/

### Python ###
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# UV
#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#uv.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/latest/usage/project/#working-with-version-control
.pdm.toml
.pdm-python
.pdm-build/

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
.idea/

# PyPI configuration file
.pypirc

### Visual Studio Code ###
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
!.vscode/*.code-snippets

# Local History for Visual Studio Code
.history/

# Built Visual Studio Code Extensions
*.vsix

# OSX
.DS_Store

# node
node_modules

```

### ARQUIVO: README_zh.md ###
```md
<p align="center">
  <img src="assets/logo.jpg" width="200"/>
</p>

[English](README.md) | ä¸­æ–‡ | [í•œêµ­ì–´](README_ko.md) | [æ—¥æœ¬èª](README_ja.md) | [PortuguÃªs (Brasil)](README_pt-br.md)

[![GitHub stars](https://img.shields.io/github/stars/FoundationAgents/OpenManus?style=social)](https://github.com/FoundationAgents/OpenManus/stargazers)
&ensp;
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) &ensp;
[![Discord Follow](https://dcbadge.vercel.app/api/server/DYn29wFk9z?style=flat)](https://discord.gg/DYn29wFk9z)
[![Demo](https://img.shields.io/badge/Demo-Hugging%20Face-yellow)](https://huggingface.co/spaces/lyh-917/OpenManusDemo)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.15186407.svg)](https://doi.org/10.5281/zenodo.15186407)

# ğŸ‘‹ OpenManus

Manus éå¸¸æ£’ï¼Œä½† OpenManus æ— éœ€é‚€è¯·ç å³å¯å®ç°ä»»ä½•åˆ›æ„ ğŸ›«ï¼

æˆ‘ä»¬çš„å›¢é˜Ÿæˆå‘˜ [@Xinbin Liang](https://github.com/mannaandpoem) å’Œ [@Jinyu Xiang](https://github.com/XiangJinyu)ï¼ˆæ ¸å¿ƒä½œè€…ï¼‰ï¼Œä»¥åŠ [@Zhaoyang Yu](https://github.com/MoshiQAQ)ã€[@Jiayi Zhang](https://github.com/didiforgithub) å’Œ [@Sirui Hong](https://github.com/stellaHSR)ï¼Œæ¥è‡ª [@MetaGPT](https://github.com/geekan/MetaGPT)å›¢é˜Ÿã€‚æˆ‘ä»¬åœ¨ 3
å°æ—¶å†…å®Œæˆäº†å¼€å‘å¹¶æŒç»­è¿­ä»£ä¸­ï¼

è¿™æ˜¯ä¸€ä¸ªç®€æ´çš„å®ç°æ–¹æ¡ˆï¼Œæ¬¢è¿ä»»ä½•å»ºè®®ã€è´¡çŒ®å’Œåé¦ˆï¼

ç”¨ OpenManus å¼€å¯ä½ çš„æ™ºèƒ½ä½“ä¹‹æ—…å§ï¼

æˆ‘ä»¬ä¹Ÿéå¸¸é«˜å…´åœ°å‘å¤§å®¶ä»‹ç» [OpenManus-RL](https://github.com/OpenManus/OpenManus-RL)ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“æ³¨äºåŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼Œä¾‹å¦‚ GRPOï¼‰çš„æ–¹æ³•æ¥ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ™ºèƒ½ä½“çš„å¼€æºé¡¹ç›®ï¼Œç”±æ¥è‡ªUIUC å’Œ OpenManus çš„ç ”ç©¶äººå‘˜åˆä½œå¼€å‘ã€‚

## é¡¹ç›®æ¼”ç¤º

<video src="https://private-user-images.githubusercontent.com/61239030/420168772-6dcfd0d2-9142-45d9-b74e-d10aa75073c6.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDEzMTgwNTksIm5iZiI6MTc0MTMxNzc1OSwicGF0aCI6Ii82MTIzOTAzMC80MjAxNjg3NzItNmRjZmQwZDItOTE0Mi00NWQ5LWI3NGUtZDEwYWE3NTA3M2M2Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAzMDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMzA3VDAzMjIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdiZjFkNjlmYWNjMmEzOTliM2Y3M2VlYjgyNDRlZDJmOWE3NWZhZjE1MzhiZWY4YmQ3NjdkNTYwYTU5ZDA2MzYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.UuHQCgWYkh0OQq9qsUWqGsUbhG3i9jcZDAMeHjLt5T4" data-canonical-src="https://private-user-images.githubusercontent.com/61239030/420168772-6dcfd0d2-9142-45d9-b74e-d10aa75073c6.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDEzMTgwNTksIm5iZiI6MTc0MTMxNzc1OSwicGF0aCI6Ii82MTIzOTAzMC80MjAxNjg3NzItNmRjZmQwZDItOTE0Mi00NWQ5LWI3NGUtZDEwYWE3NTA3M2M2Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAzMDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMzA3VDAzMjIzOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdiZjFkNjlmYWNjMmEzOTliM2Y3M2VlYjgyNDRlZDJmOWE3NWZhZjE1MzhiZWY4YmQ3NjdkNTYwYTU5ZDA2MzYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.UuHQCgWYkh0OQq9qsUWqGsUbhG3i9jcZDAMeHjLt5T4" controls="controls" muted="muted" class="d-block rounded-bottom-2 border-top width-fit" style="max-height:640px; min-height: 200px"></video>

## å®‰è£…æŒ‡å—

æˆ‘ä»¬æä¾›ä¸¤ç§å®‰è£…æ–¹å¼ã€‚æ¨èä½¿ç”¨æ–¹å¼äºŒï¼ˆuvï¼‰ï¼Œå› ä¸ºå®ƒèƒ½æä¾›æ›´å¿«çš„å®‰è£…é€Ÿåº¦å’Œæ›´å¥½çš„ä¾èµ–ç®¡ç†ã€‚

### æ–¹å¼ä¸€ï¼šä½¿ç”¨ conda

1. åˆ›å»ºæ–°çš„ conda ç¯å¢ƒï¼š

```bash
conda create -n open_manus python=3.12
conda activate open_manus
```

2. å…‹éš†ä»“åº“ï¼š

```bash
git clone https://github.com/FoundationAgents/OpenManus.git
cd OpenManus
```

3. å®‰è£…ä¾èµ–ï¼š

```bash
pip install -r requirements.txt
```

### æ–¹å¼äºŒï¼šä½¿ç”¨ uvï¼ˆæ¨èï¼‰

1. å®‰è£… uvï¼ˆä¸€ä¸ªå¿«é€Ÿçš„ Python åŒ…ç®¡ç†å™¨ï¼‰ï¼š

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

2. å…‹éš†ä»“åº“ï¼š

```bash
git clone https://github.com/FoundationAgents/OpenManus.git
cd OpenManus
```

3. åˆ›å»ºå¹¶æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼š

```bash
uv venv --python 3.12
source .venv/bin/activate  # Unix/macOS ç³»ç»Ÿ
# Windows ç³»ç»Ÿä½¿ç”¨ï¼š
# .venv\Scripts\activate
```

4. å®‰è£…ä¾èµ–ï¼š

```bash
uv pip install -r requirements.txt
```

### æµè§ˆå™¨è‡ªåŠ¨åŒ–å·¥å…·ï¼ˆå¯é€‰ï¼‰
```bash
playwright install
```

## é…ç½®è¯´æ˜

OpenManus éœ€è¦é…ç½®ä½¿ç”¨çš„ LLM APIï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤è®¾ç½®ï¼š

1. åœ¨ `config` ç›®å½•åˆ›å»º `config.toml` æ–‡ä»¶ï¼ˆå¯ä»ç¤ºä¾‹å¤åˆ¶ï¼‰ï¼š

```bash
cp config/config.example.toml config/config.toml
```

2. ç¼–è¾‘ `config/config.toml` æ·»åŠ  API å¯†é’¥å’Œè‡ªå®šä¹‰è®¾ç½®ï¼š

```toml
# å…¨å±€ LLM é…ç½®
[llm]
model = "gpt-4o"
base_url = "https://api.openai.com/v1"
api_key = "sk-..."  # æ›¿æ¢ä¸ºçœŸå® API å¯†é’¥
max_tokens = 4096
temperature = 0.0

# å¯é€‰ç‰¹å®š LLM æ¨¡å‹é…ç½®
[llm.vision]
model = "gpt-4o"
base_url = "https://api.openai.com/v1"
api_key = "sk-..."  # æ›¿æ¢ä¸ºçœŸå® API å¯†é’¥
```

## å¿«é€Ÿå¯åŠ¨

ä¸€è¡Œå‘½ä»¤è¿è¡Œ OpenManusï¼š

```bash
python main.py
```

ç„¶åé€šè¿‡ç»ˆç«¯è¾“å…¥ä½ çš„åˆ›æ„ï¼

å¦‚éœ€ä½¿ç”¨ MCP å·¥å…·ç‰ˆæœ¬ï¼Œå¯è¿è¡Œï¼š
```bash
python run_mcp.py
```

å¦‚éœ€ä½“éªŒä¸ç¨³å®šçš„å¤šæ™ºèƒ½ä½“ç‰ˆæœ¬ï¼Œå¯è¿è¡Œï¼š

```bash
python run_flow.py
```

## æ·»åŠ è‡ªå®šä¹‰å¤šæ™ºèƒ½ä½“

ç›®å‰é™¤äº†é€šç”¨çš„ OpenManus Agent, æˆ‘ä»¬è¿˜å†…ç½®äº†DataAnalysis Agentï¼Œé€‚ç”¨äºæ•°æ®åˆ†æå’Œæ•°æ®å¯è§†åŒ–ä»»åŠ¡ï¼Œä½ å¯ä»¥åœ¨`config.toml`ä¸­å°†è¿™ä¸ªæ™ºèƒ½ä½“åŠ å…¥åˆ°`run_flow`ä¸­
```toml
# run-flowå¯é€‰é…ç½®
[runflow]
use_data_analysis_agent = true     # é»˜è®¤å…³é—­ï¼Œå°†å…¶æ”¹ä¸ºtrueåˆ™ä¸ºæ¿€æ´»
```
é™¤æ­¤ä¹‹å¤–ï¼Œä½ è¿˜éœ€è¦å®‰è£…ç›¸å…³çš„ä¾èµ–æ¥ç¡®ä¿æ™ºèƒ½ä½“æ­£å¸¸è¿è¡Œï¼š[å…·ä½“å®‰è£…æŒ‡å—](app/tool/chart_visualization/README_zh.md##å®‰è£…)


## è´¡çŒ®æŒ‡å—

æˆ‘ä»¬æ¬¢è¿ä»»ä½•å‹å¥½çš„å»ºè®®å’Œæœ‰ä»·å€¼çš„è´¡çŒ®ï¼å¯ä»¥ç›´æ¥åˆ›å»º issue æˆ–æäº¤ pull requestã€‚

æˆ–é€šè¿‡ ğŸ“§ é‚®ä»¶è”ç³» @mannaandpoemï¼šmannaandpoem@gmail.com

**æ³¨æ„**: åœ¨æäº¤ pull request ä¹‹å‰ï¼Œè¯·ä½¿ç”¨ pre-commit å·¥å…·æ£€æŸ¥æ‚¨çš„æ›´æ”¹ã€‚è¿è¡Œ `pre-commit run --all-files` æ¥æ‰§è¡Œæ£€æŸ¥ã€‚

## äº¤æµç¾¤

åŠ å…¥æˆ‘ä»¬çš„é£ä¹¦äº¤æµç¾¤ï¼Œä¸å…¶ä»–å¼€å‘è€…åˆ†äº«ç»éªŒï¼

<div align="center" style="display: flex; gap: 20px;">
    <img src="assets/community_group.jpg" alt="OpenManus äº¤æµç¾¤" width="300" />
</div>

## Star æ•°é‡

[![Star History Chart](https://api.star-history.com/svg?repos=FoundationAgents/OpenManus&type=Date)](https://star-history.com/#FoundationAgents/OpenManus&Date)


## èµåŠ©å•†
æ„Ÿè°¢[PPIO](https://ppinfra.com/user/register?invited_by=OCPKCN&utm_source=github_openmanus&utm_medium=github_readme&utm_campaign=link) æä¾›çš„ç®—åŠ›æ”¯æŒã€‚
> PPIOæ´¾æ¬§äº‘ï¼šä¸€é”®è°ƒç”¨é«˜æ€§ä»·æ¯”çš„å¼€æºæ¨¡å‹APIå’ŒGPUå®¹å™¨

## è‡´è°¢

ç‰¹åˆ«æ„Ÿè°¢ [anthropic-computer-use](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo)
å’Œ [browser-use](https://github.com/browser-use/browser-use) ä¸ºæœ¬é¡¹ç›®æä¾›çš„åŸºç¡€æ”¯æŒï¼

æ­¤å¤–ï¼Œæˆ‘ä»¬æ„Ÿè°¢ [AAAJ](https://github.com/metauto-ai/agent-as-a-judge)ï¼Œ[MetaGPT](https://github.com/geekan/MetaGPT)ï¼Œ[OpenHands](https://github.com/All-Hands-AI/OpenHands) å’Œ [SWE-agent](https://github.com/SWE-agent/SWE-agent).

æˆ‘ä»¬ä¹Ÿæ„Ÿè°¢é˜¶è·ƒæ˜Ÿè¾° (stepfun) æä¾›çš„ Hugging Face æ¼”ç¤ºç©ºé—´æ”¯æŒã€‚

OpenManus ç”± MetaGPT ç¤¾åŒºçš„è´¡çŒ®è€…å…±åŒæ„å»ºï¼Œæ„Ÿè°¢è¿™ä¸ªå……æ»¡æ´»åŠ›çš„æ™ºèƒ½ä½“å¼€å‘è€…ç¤¾åŒºï¼

## å¼•ç”¨
```bibtex
@misc{openmanus2025,
  author = {Xinbin Liang and Jinyu Xiang and Zhaoyang Yu and Jiayi Zhang and Sirui Hong and Sheng Fan and Xiao Tang},
  title = {OpenManus: An open-source framework for building general AI agents},
  year = {2025},
  publisher = {Zenodo},
  doi = {10.5281/zenodo.15186407},
  url = {https://doi.org/10.5281/zenodo.15186407},
}
```

```

### ARQUIVO: examples/benchmarks/__init__.py ###
```py
"""
OpenManus benchmark system for standardized agent evaluation.
"""

```

### ARQUIVO: examples/use_case/readme.md ###
```md
# Examples

We put some examples in the `examples` directory. All the examples use the same prompt
as [Manus](https://manus.im/?utm_source=ai-bot.cn).

The Model we use is `claude3.5`.

## Japan Travel Plan
**Prompt**ï¼š
```
I need a 7-day Japan itinerary for April 15-23 from Seattle, with a $2500-5000 budget for my fiancÃ©e and me. We love historical sites, hidden gems, and Japanese culture (kendo, tea ceremonies, Zen meditation). We want to see Nara's deer and explore cities on foot. I plan to propose during this trip and need a special location recommendation. Please provide a detailed itinerary and a simple HTML travel handbook with maps, attraction descriptions, essential Japanese phrases, and travel tips we can reference throughout our journey.
```
**preview**ï¼š
![alt text](picturesapan-travel-plan-1.png)

![alt text](picturesapan-travel-plan-2.png)

```

### ARQUIVO: examples/use_case/japan-travel-plan/japan_travel_handbook_mobile.html ###
```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Japan Travel Guide (Mobile)</title>
    <style>
        * { box-sizing: border-box; }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            margin: 0;
            padding: 10px;
            line-height: 1.6;
            font-size: 16px;
        }
        .container {
            max-width: 100%;
            margin: 0 auto;
        }
        h1 { font-size: 1.5em; margin: 10px 0; }
        h2 { font-size: 1.3em; margin: 8px 0; }
        h3 { font-size: 1.1em; margin: 6px 0; }

        /* Mobile-friendly cards */
        .card {
            background: #fff;
            border-radius: 10px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            margin: 10px 0;
            padding: 15px;
        }

        /* Collapsible sections */
        .collapsible {
            background: #f8f9fa;
            border: none;
            border-radius: 8px;
            width: 100%;
            padding: 15px;
            text-align: left;
            font-size: 1.1em;
            font-weight: bold;
            cursor: pointer;
            margin: 5px 0;
        }

        .content {
            display: none;
            padding: 10px;
        }

        .active {
            background: #e9ecef;
        }

        /* Mobile-friendly tables */
        .table-wrapper {
            overflow-x: auto;
            margin: 10px 0;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            min-width: 300px;
        }
        th, td {
            padding: 10px;
            border: 1px solid #ddd;
            text-align: left;
        }
        th {
            background: #f8f9fa;
        }

        /* Touch-friendly lists */
        ul, ol {
            padding-left: 20px;
            margin: 10px 0;
        }
        li {
            margin: 8px 0;
            padding: 5px 0;
        }

        /* Emergency info styling */
        .emergency {
            background: #ffe6e6;
            border-left: 4px solid #ff4444;
            padding: 10px;
            margin: 10px 0;
        }

        /* Quick access buttons */
        .quick-access {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin: 10px 0;
        }
        .quick-btn {
            background: #007bff;
            color: white;
            border: none;
            border-radius: 20px;
            padding: 10px 20px;
            font-size: 0.9em;
            cursor: pointer;
            flex: 1 1 auto;
            text-align: center;
            min-width: 120px;
        }

        /* Dark mode support */
        @media (prefers-color-scheme: dark) {
            body {
                background: #1a1a1a;
                color: #fff;
            }
            .card {
                background: #2d2d2d;
            }
            .collapsible {
                background: #333;
                color: #fff;
            }
            .active {
                background: #404040;
            }
            th {
                background: #333;
            }
            td, th {
                border-color: #404040;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Japan Travel Guide</h1>
        <p><strong>April 15-23, 2024</strong></p>

        <div class="quick-access">
            <button class="quick-btn" onclick="showSection('emergency')">Emergency</button>
            <button class="quick-btn" onclick="showSection('phrases')">Phrases</button>
            <button class="quick-btn" onclick="showSection('transport')">Transport</button>
            <button class="quick-btn" onclick="showSection('proposal')">Proposal</button>
        </div>

        <div class="emergency card" id="emergency">
            <h2>Emergency Contacts</h2>
            <ul>
                <li>ğŸš‘ Emergency: 119</li>
                <li>ğŸ‘® Police: 110</li>
                <li>ğŸ¢ US Embassy: +81-3-3224-5000</li>
                <li>â„¹ï¸ Tourist Info: 03-3201-3331</li>
            </ul>
        </div>

        <button class="collapsible">ğŸ“… Daily Itinerary</button>
        <div class="content">
            <div class="table-wrapper">
                <table>
                    <tr><th>Date</th><th>Location</th><th>Activities</th></tr>
                    <tr><td>Apr 15</td><td>Tokyo</td><td>Arrival, Shinjuku</td></tr>
                    <tr><td>Apr 16</td><td>Tokyo</td><td>Meiji, Harajuku, Senso-ji</td></tr>
                    <tr><td>Apr 17</td><td>Tokyo</td><td>Tea Ceremony, Budokan</td></tr>
                    <tr><td>Apr 18</td><td>Kyoto</td><td>Travel, Kinkaku-ji</td></tr>
                    <tr><td>Apr 19</td><td>Kyoto</td><td>Fushimi Inari, Proposal</td></tr>
                    <tr><td>Apr 20</td><td>Nara</td><td>Deer Park, Temples</td></tr>
                    <tr><td>Apr 21</td><td>Tokyo</td><td>Return, Bay Cruise</td></tr>
                </table>
            </div>
        </div>

        <button class="collapsible">ğŸ—£ï¸ Essential Phrases</button>
        <div class="content">
            <div class="table-wrapper">
                <table>
                    <tr><th>English</th><th>Japanese</th></tr>
                    <tr><td>Thank you</td><td>ã‚ã‚ŠãŒã¨ã†</td></tr>
                    <tr><td>Excuse me</td><td>ã™ã¿ã¾ã›ã‚“</td></tr>
                    <tr><td>Please</td><td>ãŠé¡˜ã„ã—ã¾ã™</td></tr>
                    <tr><td>Where is...</td><td>...ã¯ã©ã“ã§ã™ã‹</td></tr>
                    <tr><td>Help!</td><td>åŠ©ã‘ã¦!</td></tr>
                </table>
            </div>
        </div>

        <button class="collapsible">ğŸš… Transportation</button>
        <div class="content">
            <div class="card">
                <h3>Key Routes</h3>
                <ul>
                    <li>Tokyo-Kyoto: 2h15m</li>
                    <li>Kyoto-Nara: 45m</li>
                    <li>Last trains: ~midnight</li>
                </ul>
                <p><strong>JR Pass:</strong> Activate April 15</p>
            </div>
        </div>

        <button class="collapsible">ğŸ’ Proposal Plan</button>
        <div class="content">
            <div class="card">
                <h3>April 19 Timeline</h3>
                <ul>
                    <li>4:00 PM: Head to Maruyama Park</li>
                    <li>5:30 PM: Arrive at spot</li>
                    <li>7:00 PM: Dinner at Kikunoi Roan</li>
                </ul>
                <p><strong>Backup:</strong> Gion Shirakawa area</p>
            </div>
        </div>

        <button class="collapsible">ğŸ’° Budget Tracker</button>
        <div class="content">
            <div class="table-wrapper">
                <table>
                    <tr><th>Item</th><th>Budget</th></tr>
                    <tr><td>Hotels</td><td>$1500-2000</td></tr>
                    <tr><td>Transport</td><td>$600-800</td></tr>
                    <tr><td>Food</td><td>$800-1000</td></tr>
                    <tr><td>Activities</td><td>$600-800</td></tr>
                    <tr><td>Shopping</td><td>$500-400</td></tr>
                </table>
            </div>
        </div>
    </div>

    <script>
        // Add click handlers for collapsible sections
        var coll = document.getElementsByClassName("collapsible");
        for (var i = 0; i < coll.length; i++) {
            coll[i].addEventListener("click", function() {
                this.classList.toggle("active");
                var content = this.nextElementSibling;
                if (content.style.display === "block") {
                    content.style.display = "none";
                } else {
                    content.style.display = "block";
                }
            });
        }

        // Function to show specific section
        function showSection(id) {
            document.getElementById(id).scrollIntoView({
                behavior: 'smooth'
            });
        }
    </script>
</body>
</html>

```

### ARQUIVO: examples/use_case/japan-travel-plan/japan_travel_handbook_print.html ###
```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Japan Travel Handbook (Print Version) - April 15-23, 2024</title>
    <style>
        @media print {
            body {
                font-family: Arial, sans-serif;
                font-size: 11pt;
                line-height: 1.4;
                margin: 0.5in;
            }
            h1 { font-size: 16pt; }
            h2 { font-size: 14pt; }
            h3 { font-size: 12pt; }

            .section {
                margin: 10px 0;
                padding: 5px;
                border: 1px solid #ccc;
                page-break-inside: avoid;
            }
            .no-break {
                page-break-inside: avoid;
            }

            table {
                border-collapse: collapse;
                width: 100%;
                margin: 10px 0;
            }
            td, th {
                border: 1px solid #000;
                padding: 4px;
                font-size: 10pt;
            }
            ul, ol {
                margin: 5px 0;
                padding-left: 20px;
            }
            li {
                margin: 3px 0;
            }
            .page-break {
                page-break-before: always;
            }
        }
        /* Screen styles */
        body {
            font-family: Arial, sans-serif;
            line-height: 1.4;
            margin: 20px;
            max-width: 800px;
            margin: 0 auto;
        }

        .section {
            margin: 15px 0;
            padding: 15px;
            border: 1px solid #ccc;
            border-radius: 5px;
        }

        table {
            border-collapse: collapse;
            width: 100%;
            margin: 10px 0;
        }
        td, th {
            border: 1px solid #000;
            padding: 8px;
        }
        @media screen {
            .page-break {
                margin: 30px 0;
                border-top: 2px dashed #ccc;
            }
        }
    </style>
</head>
<body>
    <h1>Japan Travel Handbook (Print Version)</h1>
    <p><strong>Trip Dates:</strong> April 15-23, 2024</p>

    <div class="section">
        <h2>Emergency Contacts & Important Information</h2>
        <ul>
            <li>Emergency in Japan: 119 (Ambulance/Fire) / 110 (Police)</li>
            <li>US Embassy Tokyo: +81-3-3224-5000</li>
            <li>Tourist Information Hotline: 03-3201-3331</li>
            <li>Your Travel Insurance: [Write number here]</li>
        </ul>
    </div>

    <div class="section">
        <h2>Daily Itinerary Summary</h2>
        <table>
            <tr><th>Date</th><th>Location</th><th>Key Activities</th></tr>
            <tr><td>Apr 15</td><td>Tokyo</td><td>Arrival, Shinjuku area exploration</td></tr>
            <tr><td>Apr 16</td><td>Tokyo</td><td>Meiji Shrine, Harajuku, Senso-ji, Skytree</td></tr>
            <tr><td>Apr 17</td><td>Tokyo</td><td>Tea Ceremony, Budokan, Yanaka Ginza</td></tr>
            <tr><td>Apr 18</td><td>Kyoto</td><td>Travel to Kyoto, Kinkaku-ji, Gion</td></tr>
            <tr><td>Apr 19</td><td>Kyoto</td><td>Fushimi Inari, Arashiyama, Evening Proposal</td></tr>
            <tr><td>Apr 20</td><td>Nara/Kyoto</td><td>Nara Park day trip, deer feeding</td></tr>
            <tr><td>Apr 21</td><td>Tokyo</td><td>Return to Tokyo, bay cruise</td></tr>
        </table>
    </div>

    <div class="page-break"></div>

    <div class="section">
        <h2>Essential Japanese Phrases</h2>
        <table>
            <tr><th>English</th><th>Japanese</th><th>When to Use</th></tr>
            <tr><td>Arigatou gozaimasu</td><td>ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™</td><td>Thank you (formal)</td></tr>
            <tr><td>Sumimasen</td><td>ã™ã¿ã¾ã›ã‚“</td><td>Excuse me/Sorry</td></tr>
            <tr><td>Onegaishimasu</td><td>ãŠé¡˜ã„ã—ã¾ã™</td><td>Please</td></tr>
            <tr><td>Toire wa doko desu ka?</td><td>ãƒˆã‚¤ãƒ¬ã¯ã©ã“ã§ã™ã‹ï¼Ÿ</td><td>Where is the bathroom?</td></tr>
            <tr><td>Eigo ga hanasemasu ka?</td><td>è‹±èªãŒè©±ã›ã¾ã™ã‹ï¼Ÿ</td><td>Do you speak English?</td></tr>
        </table>
    </div>

    <div class="section">
        <h2>Transportation Notes</h2>
        <ul>
            <li>JR Pass: Activate on April 15</li>
            <li>Tokyo-Kyoto Shinkansen: ~2h15m</li>
            <li>Kyoto-Nara Local Train: ~45m</li>
            <li>Last trains: Usually around midnight</li>
            <li>Keep Â¥3000 for unexpected taxi rides</li>
        </ul>
    </div>

    <div class="page-break"></div>

    <div class="section no-break">
        <h2>Proposal Day Timeline (April 19)</h2>
        <table>
            <tr><th>Time</th><th>Activity</th><th>Notes</th></tr>
            <tr><td>4:00 PM</td><td>Head to Maruyama Park</td><td>Check weather first</td></tr>
            <tr><td>4:30 PM</td><td>Tea house visit</td><td>Light refreshments</td></tr>
            <tr><td>5:15 PM</td><td>Park walk begins</td><td>Head to weeping cherry tree</td></tr>
            <tr><td>5:30 PM</td><td>Arrive at spot</td><td>Find quiet area</td></tr>
            <tr><td>7:00 PM</td><td>Dinner reservation</td><td>Kikunoi Roan</td></tr>
        </table>
        <p><strong>Backup Location:</strong> Gion Shirakawa area (in case of rain)</p>
    </div>

    <div class="section">
        <h2>Quick Reference Budget</h2>
        <table>
            <tr><th>Item</th><th>Budget (USD)</th><th>Notes</th></tr>
            <tr><td>Hotels</td><td>1500-2000</td><td>Pre-booked</td></tr>
            <tr><td>Transport</td><td>600-800</td><td>Including JR Pass</td></tr>
            <tr><td>Food</td><td>800-1000</td><td>~$60/person/day</td></tr>
            <tr><td>Activities</td><td>600-800</td><td>Including tea ceremony</td></tr>
            <tr><td>Shopping</td><td>500-400</td><td>Souvenirs/gifts</td></tr>
        </table>
    </div>
</body>
</html>

```

### ARQUIVO: examples/use_case/japan-travel-plan/japan_travel_guide_instructions.txt ###
```txt
MANUAL DE VIAGEM DO JAPÃƒO - GUIA DE VERSÃ•ES

LocalizaÃ§Ã£o: D:/OpenManus/

1. VERSÃƒO DIGITAL DETALHADA
Arquivo: japan_travel_handbook.html
Melhor para: VisualizaÃ§Ã£o em desktop/laptop
Recursos:
- Guia completo e abrangente
- Roteiro detalhado
- SeÃ§Ã£o completa de planejamento da proposta
- Todas as recomendaÃ§Ãµes de hotÃ©is
- Detalhamento completo do orÃ§amento
Uso: Abra no navegador da web para planejamento da viagem e referÃªncia detalhada

2. VERSÃƒO AMIGÃVEL PARA IMPRESSÃƒO
Arquivo: japan_travel_handbook_print.html
Melhor para: ReferÃªncia fÃ­sica durante a viagem
Recursos:
- InformaÃ§Ãµes essenciais condensadas
- Otimizado para impressÃ£o em papel
- FormataÃ§Ã£o clara e amigÃ¡vel para impressÃ£o
- Tabelas de referÃªncia rÃ¡pida
Uso: Imprima e guarde na pasta de documentos de viagem

3. VERSÃƒO OTIMIZADA PARA CELULAR
Arquivo: japan_travel_handbook_mobile.html
Melhor para: ReferÃªncia rÃ¡pida durante a viagem
Recursos:
- Interface amigÃ¡vel ao toque
- SeÃ§Ãµes recolhÃ­veis
- BotÃµes de acesso rÃ¡pido para emergÃªncias
- Suporte ao modo escuro
- Design responsivo
Uso: Salve nos favoritos do navegador do celular para acesso rÃ¡pido

CONFIGURAÃ‡ÃƒO RECOMENDADA:
1. Antes da Viagem:
   - Use a versÃ£o detalhada para planejamento
   - Imprima a versÃ£o amigÃ¡vel para impressÃ£o
   - Salve a versÃ£o mÃ³vel no celular

2. Durante a Viagem:
   - Mantenha a versÃ£o impressa com os documentos de viagem
   - Use a versÃ£o mÃ³vel para referÃªncia diÃ¡ria
   - Acesse a versÃ£o detalhada quando necessÃ¡rio para informaÃ§Ãµes especÃ­ficas

3. Acesso de EmergÃªncia:
   - A versÃ£o mÃ³vel possui informaÃ§Ãµes de emergÃªncia de acesso rÃ¡pido
   - Mantenha a versÃ£o impressa como backup
   - Todos os nÃºmeros de emergÃªncia e contatos em ambas as versÃµes

Nota: Todas as versÃµes contÃªm as mesmas informaÃ§Ãµes centrais, mas sÃ£o formatadas de maneira diferente para uso otimizado em diferentes situaÃ§Ãµes.

DATAS IMPORTANTES:
- DuraÃ§Ã£o da Viagem: 15-23 de Abril de 2024
- Dia da Proposta: 19 de Abril de 2024
- Prazos Chave para Reservas:
  * Voos: Reservar atÃ© Janeiro de 2024
  * HotÃ©is: Reservar atÃ© Fevereiro de 2024
  * Reservas de Restaurantes: Reservar atÃ© Janeiro de 2024
  * JR Pass: Comprar atÃ© MarÃ§o de 2024

```

### ARQUIVO: examples/use_case/japan-travel-plan/japan_travel_handbook.html ###
```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Japan Travel Handbook - April 15-23, 2024</title>
    <style>
        body { font-family: Arial, sans-serif; line-height: 1.6; margin: 0; padding: 20px; }
        .container { max-width: 1000px; margin: 0 auto; }
        h1, h2, h3 { color: #333; }
        .day-item { background: #f9f9f9; padding: 15px; margin: 10px 0; border-radius: 5px; }
        .important-note { background: #ffe6e6; padding: 10px; border-radius: 5px; }
        .phrase-table { width: 100%; border-collapse: collapse; }
        .phrase-table td, .phrase-table th { border: 1px solid #ddd; padding: 8px; }
        .proposal-spot { background: #e6ffe6; padding: 15px; margin: 10px 0; border-radius: 5px; }
        .flight-info { background: #e6f3ff; padding: 15px; margin: 10px 0; border-radius: 5px; }
        .checklist { background: #fff3e6; padding: 15px; margin: 10px 0; border-radius: 5px; }
        .hotels { background: #e6e6ff; padding: 15px; margin: 10px 0; border-radius: 5px; }
        .proposal-plan { background: #ffe6ff; padding: 15px; margin: 10px 0; border-radius: 5px; }
        .checkbox-list li { list-style-type: none; margin-bottom: 8px; }
        .checkbox-list li:before { content: "â˜ "; }
        .warning { color: #ff4444; }
    </style>
</head>
<body>
    <div class="container">
        [Previous content remains the same...]

        <div class="proposal-plan">
            <h2>ğŸŒ¸ Proposal Planning Guide ğŸŒ¸</h2>

            <h3>Ring Security & Transport</h3>
            <ul>
                <li><strong>Carrying the Ring:</strong>
                    <ul>
                        <li>Always keep the ring in your carry-on luggage, never in checked bags</li>
                        <li>Use a discrete, non-branded box or case</li>
                        <li>Consider travel insurance that covers jewelry</li>
                        <li>Keep receipt/appraisal documentation separate from the ring</li>
                    </ul>
                </li>
                <li><strong>Airport Security Tips:</strong>
                    <ul>
                        <li>No need to declare the ring unless value exceeds Â¥1,000,000 (~$6,700)</li>
                        <li>If asked, simply state it's "personal jewelry"</li>
                        <li>Consider requesting private screening to maintain surprise</li>
                        <li>Keep ring in original box until through security, then transfer to more discrete case</li>
                    </ul>
                </li>
            </ul>

            <h3>Proposal Location Details - Maruyama Park</h3>
            <ul>
                <li><strong>Best Timing:</strong>
                    <ul>
                        <li>Date: April 19 (Day 5)</li>
                        <li>Time: 5:30 PM (30 minutes before sunset)</li>
                        <li>Park closes at 8:00 PM in April</li>
                    </ul>
                </li>
                <li><strong>Specific Spot Recommendations:</strong>
                    <ul>
                        <li>Primary Location: Near the famous weeping cherry tree
                            <br>- Less crowded in early evening
                            <br>- Beautiful illumination starts at dusk
                            <br>- Iconic Kyoto backdrop
                        </li>
                        <li>Backup Location: Gion Shirakawa area
                            <br>- Atmospheric stone-paved street
                            <br>- Traditional buildings and cherry trees
                            <br>- Beautiful in light rain
                        </li>
                    </ul>
                </li>
            </ul>

            <h3>Proposal Day Planning</h3>
            <ul>
                <li><strong>Morning Preparation:</strong>
                    <ul>
                        <li>Confirm weather forecast</li>
                        <li>Transfer ring to secure pocket/bag</li>
                        <li>Have backup indoor location details ready</li>
                    </ul>
                </li>
                <li><strong>Suggested Timeline:</strong>
                    <ul>
                        <li>4:00 PM: Start heading to Maruyama Park area</li>
                        <li>4:30 PM: Light refreshments at nearby tea house</li>
                        <li>5:15 PM: Begin walk through park</li>
                        <li>5:30 PM: Arrive at proposal spot</li>
                        <li>6:00 PM: Sunset and illumination begins</li>
                        <li>7:00 PM: Celebratory dinner reservation</li>
                    </ul>
                </li>
            </ul>

            <h3>Celebration Dinner Options</h3>
            <ul>
                <li><strong>Traditional Japanese:</strong> Kikunoi Roan
                    <br>- Intimate 2-star Michelin restaurant
                    <br>- Advance reservation required (3 months)
                    <br>- Price: Â¥15,000-20,000 per person
                </li>
                <li><strong>Modern Fusion:</strong> The Sodoh
                    <br>- Beautiful garden views
                    <br>- Western-style seating available
                    <br>- Price: Â¥12,000-15,000 per person
                </li>
            </ul>

            <div class="warning">
                <h3>Important Notes:</h3>
                <ul>
                    <li>Keep proposal plans in separate notes from shared itinerary</li>
                    <li>Have a backup plan in case of rain (indoor locations listed above)</li>
                    <li>Consider hiring a local photographer to capture the moment</li>
                    <li>Save restaurant staff contact info in case of timing changes</li>
                </ul>
            </div>
        </div>
    </div>
</body>
</html>

```

### ARQUIVO: tests/test_checklist_manager.py ###
```py
import pytest

from app.agent.checklist_manager import ChecklistManager
from app.tool.checklist_tools import (
    AddChecklistTaskTool,
    UpdateChecklistTaskTool,
    ViewChecklistTool,
)


@pytest.mark.asyncio
async def test_add_and_view_task_with_agent(tmp_path):
    from app import config as app_config

    app_config.WORKSPACE_ROOT = tmp_path
    manager = ChecklistManager()
    add_tool = AddChecklistTaskTool()
    await add_tool.execute(task_description="Task A", assigned_agent="Agent1")
    await manager._load_checklist()
    tasks = manager.get_tasks()
    assert tasks == [{"description": "Task A", "status": "Pendente", "agent": "Agent1"}]
    view_tool = ViewChecklistTool()
    result = await view_tool.execute()
    assert "Agent1" in result.output


@pytest.mark.asyncio
async def test_update_task_agent(tmp_path):
    from app import config as app_config

    app_config.WORKSPACE_ROOT = tmp_path
    manager = ChecklistManager()
    add_tool = AddChecklistTaskTool()
    await add_tool.execute(task_description="Task B", assigned_agent="Agent1")
    updater = UpdateChecklistTaskTool()
    await updater.execute(
        task_description="Task B", new_status="Em Andamento", new_agent="Agent2"
    )
    await manager._load_checklist()
    task = manager.get_task_by_description("Task B")
    assert task["status"] == "Em andamento"
    assert task["agent"] == "Agent2"

```

### ARQUIVO: tests/sandbox/test_client.py ###
```py
import tempfile
from pathlib import Path
from typing import AsyncGenerator

import pytest
import pytest_asyncio

from app.config import SandboxSettings
from app.sandbox.client import LocalSandboxClient, create_sandbox_client


@pytest_asyncio.fixture(scope="function")
async def local_client() -> AsyncGenerator[LocalSandboxClient, None]:
    """Creates a local sandbox client for testing."""
    client = create_sandbox_client()
    try:
        yield client
    finally:
        await client.cleanup()


@pytest.fixture(scope="function")
def temp_dir() -> Path:
    """Creates a temporary directory for testing."""
    with tempfile.TemporaryDirectory() as tmp_dir:
        yield Path(tmp_dir)


@pytest.mark.asyncio
async def test_sandbox_creation(local_client: LocalSandboxClient):
    """Tests sandbox creation with specific configuration."""
    config = SandboxSettings(
        image="python:3.12-slim",
        work_dir="/workspace",
        memory_limit="512m",
        cpu_limit=0.5,
    )

    await local_client.create(config)
    result = await local_client.run_command("python3 --version")
    assert "Python 3.10" in result


@pytest.mark.asyncio
async def test_local_command_execution(local_client: LocalSandboxClient):
    """Tests command execution in local sandbox."""
    await local_client.create()

    result = await local_client.run_command("echo 'test'")
    assert result.strip() == "test"

    with pytest.raises(Exception):
        await local_client.run_command("sleep 10", timeout=1)


@pytest.mark.asyncio
async def test_local_file_operations(local_client: LocalSandboxClient, temp_dir: Path):
    """Tests file operations in local sandbox."""
    await local_client.create()

    # Test write and read operations
    test_content = "Hello, World!"
    await local_client.write_file("/workspace/test.txt", test_content)
    content = await local_client.read_file("/workspace/test.txt")
    assert content.strip() == test_content

    # Test copying file to container
    src_file = temp_dir / "src.txt"
    src_file.write_text("Copy to container")
    await local_client.copy_to(str(src_file), "/workspace/copied.txt")
    content = await local_client.read_file("/workspace/copied.txt")
    assert content.strip() == "Copy to container"

    # Test copying file from container
    dst_file = temp_dir / "dst.txt"
    await local_client.copy_from("/workspace/test.txt", str(dst_file))
    assert dst_file.read_text().strip() == test_content


@pytest.mark.asyncio
async def test_local_volume_binding(local_client: LocalSandboxClient, temp_dir: Path):
    """Tests volume binding in local sandbox."""
    bind_path = str(temp_dir)
    volume_bindings = {bind_path: "/data"}

    await local_client.create(volume_bindings=volume_bindings)

    test_file = temp_dir / "test.txt"
    test_file.write_text("Volume test")

    content = await local_client.read_file("/data/test.txt")
    assert "Volume test" in content


@pytest.mark.asyncio
async def test_local_error_handling(local_client: LocalSandboxClient):
    """Tests error handling in local sandbox."""
    await local_client.create()

    with pytest.raises(Exception) as exc:
        await local_client.read_file("/nonexistent.txt")
    assert "not found" in str(exc.value).lower()

    with pytest.raises(Exception) as exc:
        await local_client.copy_from("/nonexistent.txt", "local.txt")
    assert "not found" in str(exc.value).lower()


if __name__ == "__main__":
    pytest.main(["-v", __file__])

```

### ARQUIVO: tests/sandbox/test_sandbox.py ###
```py
import pytest
import pytest_asyncio

from app.sandbox.core.sandbox import DockerSandbox, SandboxSettings


@pytest.fixture(scope="module")
def sandbox_config():
    """Creates sandbox configuration for testing."""
    return SandboxSettings(
        image="python:3.12-slim",
        work_dir="/workspace",
        memory_limit="1g",
        cpu_limit=0.5,
        network_enabled=True,
    )


@pytest_asyncio.fixture(scope="module")
async def sandbox(sandbox_config):
    """Creates and manages a test sandbox instance."""
    sandbox = DockerSandbox(sandbox_config)
    await sandbox.create()
    try:
        yield sandbox
    finally:
        await sandbox.cleanup()


@pytest.mark.asyncio
async def test_sandbox_working_directory(sandbox):
    """Tests sandbox working directory configuration."""
    result = await sandbox.terminal.run_command("pwd")
    assert result.strip() == "/workspace"


@pytest.mark.asyncio
async def test_sandbox_file_operations(sandbox):
    """Tests sandbox file read/write operations."""
    # Test file writing
    test_content = "Hello from sandbox!"
    await sandbox.write_file("/workspace/test.txt", test_content)

    # Test file reading
    content = await sandbox.read_file("/workspace/test.txt")
    assert content.strip() == test_content


@pytest.mark.asyncio
async def test_sandbox_python_execution(sandbox):
    """Tests Python code execution in sandbox."""
    # Write test file
    await sandbox.write_file("/workspace/test.txt", "Hello from file!")

    # Write Python script
    python_code = """
print("Hello from Python!")
with open('/workspace/test.txt') as f:
    print(f.read())
"""
    await sandbox.write_file("/workspace/test.py", python_code)

    # Execute script and verify output
    result = await sandbox.terminal.run_command("python3 /workspace/test.py")
    assert "Hello from Python!" in result
    assert "Hello from file!" in result


@pytest.mark.asyncio
async def test_sandbox_file_persistence(sandbox):
    """Tests file persistence in sandbox."""
    # Create multiple files
    files = {
        "file1.txt": "Content 1",
        "file2.txt": "Content 2",
        "nested/file3.txt": "Content 3",
    }

    # Write files
    for path, content in files.items():
        await sandbox.write_file(f"/workspace/{path}", content)

    # Verify file contents
    for path, expected_content in files.items():
        content = await sandbox.read_file(f"/workspace/{path}")
        assert content.strip() == expected_content


@pytest.mark.asyncio
async def test_sandbox_python_environment(sandbox):
    """Tests Python environment configuration."""
    # Test Python version
    result = await sandbox.terminal.run_command("python3 --version")
    assert "Python 3.10" in result

    # Test basic module imports
    python_code = """
import sys
import os
import json
print("Python is working!")
"""
    await sandbox.write_file("/workspace/env_test.py", python_code)
    result = await sandbox.terminal.run_command("python3 /workspace/env_test.py")
    assert "Python is working!" in result


@pytest.mark.asyncio
async def test_sandbox_network_access(sandbox):
    """Tests sandbox network access."""
    if not sandbox.config.network_enabled:
        pytest.skip("Network access is disabled")

    # Test network connectivity
    await sandbox.terminal.run_command("apt update && apt install curl -y")
    result = await sandbox.terminal.run_command("curl -I https://www.example.com")
    assert "HTTP/2 200" in result


@pytest.mark.asyncio
async def test_sandbox_cleanup(sandbox_config):
    """Tests sandbox cleanup process."""
    sandbox = DockerSandbox(sandbox_config)
    await sandbox.create()

    # Create test files
    await sandbox.write_file("/workspace/test.txt", "test")
    container_id = sandbox.terminal.container.id
    # Perform cleanup
    await sandbox.cleanup()

    # Verify container has been removed
    import docker

    client = docker.from_env()
    containers = client.containers.list(all=True)
    assert not any(c.id == container_id for c in containers)


@pytest.mark.asyncio
async def test_sandbox_error_handling():
    """Tests error handling with invalid configuration."""
    # Test invalid configuration
    invalid_config = SandboxSettings(image="nonexistent:latest", work_dir="/invalid")

    sandbox = DockerSandbox(invalid_config)
    with pytest.raises(Exception):
        await sandbox.create()


if __name__ == "__main__":
    pytest.main(["-v", __file__])

```

### ARQUIVO: tests/sandbox/test_sandbox_manager.py ###
```py
import asyncio
import os
import tempfile
from typing import AsyncGenerator

import pytest
import pytest_asyncio

from app.sandbox.core.manager import SandboxManager


@pytest_asyncio.fixture(scope="function")
async def manager() -> AsyncGenerator[SandboxManager, None]:
    """Creates a sandbox manager instance.

    Uses function scope to ensure each test case has its own manager instance.
    """
    manager = SandboxManager(max_sandboxes=2, idle_timeout=60, cleanup_interval=30)
    try:
        yield manager
    finally:
        # Ensure all resources are cleaned up
        await manager.cleanup()


@pytest.fixture
def temp_file():
    """Creates a temporary test file."""
    with tempfile.NamedTemporaryFile(mode="w+", delete=False) as f:
        f.write("test content")
        path = f.name
    try:
        yield path
    finally:
        if os.path.exists(path):
            os.unlink(path)


@pytest.mark.asyncio
async def test_create_sandbox(manager):
    """Tests sandbox creation."""
    # Create default sandbox
    sandbox_id = await manager.create_sandbox()
    assert sandbox_id in manager._sandboxes
    assert sandbox_id in manager._last_used

    # Verify sandbox functionality
    sandbox = await manager.get_sandbox(sandbox_id)
    result = await sandbox.run_command("echo 'test'")
    assert result.strip() == "test"


@pytest.mark.asyncio
async def test_max_sandboxes_limit(manager):
    """Tests maximum sandbox limit enforcement."""
    created_sandboxes = []
    try:
        # Create maximum number of sandboxes
        for _ in range(manager.max_sandboxes):
            sandbox_id = await manager.create_sandbox()
            created_sandboxes.append(sandbox_id)

        # Verify created sandbox count
        assert len(manager._sandboxes) == manager.max_sandboxes

        # Attempting to create additional sandbox should fail
        with pytest.raises(RuntimeError) as exc_info:
            await manager.create_sandbox()

        # Verify error message
        expected_message = (
            f"Maximum number of sandboxes ({manager.max_sandboxes}) reached"
        )
        assert str(exc_info.value) == expected_message

    finally:
        # Clean up all created sandboxes
        for sandbox_id in created_sandboxes:
            try:
                await manager.delete_sandbox(sandbox_id)
            except Exception as e:
                print(f"Failed to cleanup sandbox {sandbox_id}: {e}")


@pytest.mark.asyncio
async def test_get_nonexistent_sandbox(manager):
    """Tests retrieving a non-existent sandbox."""
    with pytest.raises(KeyError, match="Sandbox .* not found"):
        await manager.get_sandbox("nonexistent-id")


@pytest.mark.asyncio
async def test_sandbox_cleanup(manager):
    """Tests sandbox cleanup functionality."""
    sandbox_id = await manager.create_sandbox()
    assert sandbox_id in manager._sandboxes

    await manager.delete_sandbox(sandbox_id)
    assert sandbox_id not in manager._sandboxes
    assert sandbox_id not in manager._last_used


@pytest.mark.asyncio
async def test_idle_sandbox_cleanup(manager):
    """Tests automatic cleanup of idle sandboxes."""
    # Set short idle timeout
    manager.idle_timeout = 0.1

    sandbox_id = await manager.create_sandbox()
    assert sandbox_id in manager._sandboxes

    # Wait longer than idle timeout
    await asyncio.sleep(0.2)

    # Trigger cleanup
    await manager._cleanup_idle_sandboxes()
    assert sandbox_id not in manager._sandboxes


@pytest.mark.asyncio
async def test_manager_cleanup(manager):
    """Tests manager cleanup functionality."""
    # Create multiple sandboxes
    sandbox_ids = []
    for _ in range(2):
        sandbox_id = await manager.create_sandbox()
        sandbox_ids.append(sandbox_id)

    # Clean up all resources
    await manager.cleanup()

    # Verify all sandboxes have been cleaned up
    assert not manager._sandboxes
    assert not manager._last_used


if __name__ == "__main__":
    pytest.main(["-v", __file__])

```

### ARQUIVO: tests/sandbox/test_docker_terminal.py ###
```py
"""Tests for the AsyncDockerizedTerminal implementation."""

import docker
import pytest
import pytest_asyncio

from app.sandbox.core.terminal import AsyncDockerizedTerminal


@pytest.fixture(scope="module")
def docker_client():
    """Fixture providing a Docker client."""
    return docker.from_env()


@pytest_asyncio.fixture(scope="module")
async def docker_container(docker_client):
    """Fixture providing a test Docker container."""
    container = docker_client.containers.run(
        "python:3.12-slim",
        "tail -f /dev/null",
        name="test_container",
        detach=True,
        remove=True,
    )
    yield container
    container.stop()


@pytest_asyncio.fixture
async def terminal(docker_container):
    """Fixture providing an initialized AsyncDockerizedTerminal instance."""
    terminal = AsyncDockerizedTerminal(
        docker_container,
        working_dir="/workspace",
        env_vars={"TEST_VAR": "test_value"},
        default_timeout=30,
    )
    await terminal.init()
    yield terminal
    await terminal.close()


class TestAsyncDockerizedTerminal:
    """Test cases for AsyncDockerizedTerminal."""

    @pytest.mark.asyncio
    async def test_basic_command_execution(self, terminal):
        """Test basic command execution functionality."""
        result = await terminal.run_command("echo 'Hello World'")
        assert "Hello World" in result

    @pytest.mark.asyncio
    async def test_environment_variables(self, terminal):
        """Test environment variable setting and access."""
        result = await terminal.run_command("echo $TEST_VAR")
        assert "test_value" in result

    @pytest.mark.asyncio
    async def test_working_directory(self, terminal):
        """Test working directory setup."""
        result = await terminal.run_command("pwd")
        assert "/workspace" == result

    @pytest.mark.asyncio
    async def test_command_timeout(self, docker_container):
        """Test command timeout functionality."""
        terminal = AsyncDockerizedTerminal(docker_container, default_timeout=1)
        await terminal.init()
        try:
            with pytest.raises(TimeoutError):
                await terminal.run_command("sleep 5")
        finally:
            await terminal.close()

    @pytest.mark.asyncio
    async def test_multiple_commands(self, terminal):
        """Test execution of multiple commands in sequence."""
        cmd1 = await terminal.run_command("echo 'First'")
        cmd2 = await terminal.run_command("echo 'Second'")
        assert "First" in cmd1
        assert "Second" in cmd2

    @pytest.mark.asyncio
    async def test_session_cleanup(self, docker_container):
        """Test proper cleanup of resources."""
        terminal = AsyncDockerizedTerminal(docker_container)
        await terminal.init()
        assert terminal.session is not None
        await terminal.close()
        # Verify session is properly cleaned up
        # Note: session object still exists, but internal connection is closed
        assert terminal.session is not None


# Configure pytest-asyncio
def pytest_configure(config):
    """Configure pytest-asyncio."""
    config.addinivalue_line("asyncio_mode", "strict")
    config.addinivalue_line("asyncio_default_fixture_loop_scope", "function")


if __name__ == "__main__":
    pytest.main(["-v", __file__])

```

### ARQUIVO: .github/dependabot.yml ###
```yml
version: 2
updates:
  - package-ecosystem: "pip"
    directory: "/"
    schedule:
      interval: "weekly"
    open-pull-requests-limit: 4
    groups:
      # Group critical packages that might need careful review
      core-dependencies:
        patterns:
          - "pydantic*"
          - "openai"
          - "fastapi"
          - "tiktoken"
      browsergym-related:
        patterns:
          - "browsergym*"
          - "browser-use"
          - "playwright"
      search-tools:
        patterns:
          - "googlesearch-python"
          - "baidusearch"
          - "duckduckgo_search"
      pre-commit:
        patterns:
          - "pre-commit"
      security-all:
        applies-to: "security-updates"
        patterns:
          - "*"
      version-all:
        applies-to: "version-updates"
        patterns:
          - "*"
        exclude-patterns:
          - "pydantic*"
          - "openai"
          - "fastapi"
          - "tiktoken"
          - "browsergym*"
          - "browser-use"
          - "playwright"
          - "googlesearch-python"
          - "baidusearch"
          - "duckduckgo_search"
          - "pre-commit"

  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: "weekly"
    open-pull-requests-limit: 4
    groups:
      actions:
        patterns:
          - "*"

```

### ARQUIVO: .github/PULL_REQUEST_TEMPLATE.md ###
```md
**Funcionalidades**
<!-- Descreva as funcionalidades ou correÃ§Ãµes de bugs neste PR. Para correÃ§Ãµes de bugs, vincule Ã  issue. -->

- Funcionalidade 1
- Funcionalidade 2

**DocumentaÃ§Ã£o da Funcionalidade**
<!-- ForneÃ§a links de RFC, tutorial ou caso de uso para atualizaÃ§Ãµes significativas. Opcional para pequenas alteraÃ§Ãµes. -->

**Impacto**
<!-- Explique o impacto dessas alteraÃ§Ãµes para o foco do revisor. -->

**Resultado**
<!-- Inclua capturas de tela ou logs de testes unitÃ¡rios ou resultados de execuÃ§Ã£o. -->

**Outro**
<!-- Notas adicionais sobre este PR. -->

```

### ARQUIVO: .github/workflows/stale.yaml ###
```yaml
name: Close inactive issues

on:
  schedule:
    - cron: "5 0 * * *"

jobs:
  close-issues:
    runs-on: ubuntu-latest
    permissions:
      issues: write
      pull-requests: write
    steps:
      - uses: actions/stale@v9
        with:
          days-before-issue-stale: 30
          days-before-issue-close: 14
          stale-issue-label: "inactive"
          stale-issue-message: "This issue has been inactive for 30 days. Please comment if you have updates."
          close-issue-message: "This issue was closed due to 45 days of inactivity. Reopen if still relevant."
          days-before-pr-stale: -1
          days-before-pr-close: -1
          repo-token: ${{ secrets.GITHUB_TOKEN }}

```

### ARQUIVO: .github/workflows/top-issues.yaml ###
```yaml
name: Top issues
on:
  schedule:
    - cron: '0 0/2 * * *'
  workflow_dispatch:
jobs:
  ShowAndLabelTopIssues:
    permissions:
      issues: write
      pull-requests: write
      actions: read
      contents: read
    name: Display and label top issues
    runs-on: ubuntu-latest
    if: github.repository == 'FoundationAgents/OpenManus'
    steps:
      - name: Run top issues action
        uses: rickstaa/top-issues-action@7e8dda5d5ae3087670f9094b9724a9a091fc3ba1 # v1.3.101
        env:
          github_token: ${{ secrets.GITHUB_TOKEN }}
        with:
          label: true
          dashboard: true
          dashboard_show_total_reactions: true
          top_issues: true
          top_features: true
          top_bugs: true
          top_pull_requests: true
          top_list_size: 14

```

### ARQUIVO: .github/workflows/pre-commit.yaml ###
```yaml
name: Pre-commit checks

on:
  pull_request:
    branches:
      - '**'
  push:
    branches:
      - '**'

jobs:
  pre-commit-check:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Source Code
        uses: actions/checkout@v4
      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      - name: Install pre-commit and tools
        run: |
          python -m pip install --upgrade pip
          pip install pre-commit black==23.1.0 isort==5.12.0 autoflake==2.0.1
      - name: Run pre-commit hooks
        run: pre-commit run --all-files

```

### ARQUIVO: .github/workflows/pr-autodiff.yaml ###
```yaml
name: PR Diff Summarization
on:
  # pull_request:
  #   branches: [main]
  #   types: [opened, ready_for_review, reopened]
  issue_comment:
    types: [created]
permissions:
  contents: read
  pull-requests: write
jobs:
  pr-diff-summarization:
    runs-on: ubuntu-latest
    if: |
      (github.event_name == 'pull_request') ||
      (github.event_name == 'issue_comment' &&
       contains(github.event.comment.body, '!pr-diff') &&
       (github.event.comment.author_association == 'CONTRIBUTOR' || github.event.comment.author_association == 'COLLABORATOR' || github.event.comment.author_association == 'MEMBER' || github.event.comment.author_association == 'OWNER') &&
       github.event.issue.pull_request)
    steps:
      - name: Get PR head SHA
        id: get-pr-sha
        run: |
          PR_URL="${{ github.event.issue.pull_request.url || github.event.pull_request.url }}"
          # https://api.github.com/repos/OpenManus/pulls/1
          RESPONSE=$(curl -s -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" $PR_URL)
          SHA=$(echo $RESPONSE | jq -r '.head.sha')
          TARGET_BRANCH=$(echo $RESPONSE | jq -r '.base.ref')
          echo "pr_sha=$SHA" >> $GITHUB_OUTPUT
          echo "target_branch=$TARGET_BRANCH" >> $GITHUB_OUTPUT
          echo "Retrieved PR head SHA from API: $SHA, target branch: $TARGET_BRANCH"
      - name: Check out code
        uses: actions/checkout@v4
        with:
          ref: ${{ steps.get-pr-sha.outputs.pr_sha }}
          fetch-depth: 0
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install openai requests
      - name: Create and run Python script
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          OPENAI_BASE_URL: ${{ secrets.OPENAI_BASE_URL }}
          GH_TOKEN: ${{ github.token }}
          PR_NUMBER: ${{ github.event.pull_request.number || github.event.issue.number }}
          TARGET_BRANCH: ${{ steps.get-pr-sha.outputs.target_branch }}
        run: |-
          cat << 'EOF' > /tmp/_workflow_core.py
          import os
          import subprocess
          import json
          import requests
          from openai import OpenAI

          def get_diff():
              result = subprocess.run(
                  ['git', 'diff', 'origin/' + os.getenv('TARGET_BRANCH') + '...HEAD'],
                  capture_output=True, text=True, check=True)
              return '\n'.join(
                  line for line in result.stdout.split('\n')
                  if any(line.startswith(c) for c in ('+', '-'))
                  and not line.startswith(('---', '+++'))
              )[:round(200000 * 0.4)]  # Truncate to prevent overflow

          def generate_comment(diff_content):
              client = OpenAI(
                  base_url=os.getenv("OPENAI_BASE_URL"),
                  api_key=os.getenv("OPENAI_API_KEY")
              )

              guidelines = '''
          1. English version first, Chinese Simplified version after
          2. Example format:
              # Diff Report
              ## English
              - Added `ABC` class
              - Fixed `f()` behavior in `foo` module

              ### Comments Highlight
              - `config.toml` needs to be configured properly to make sure new features work as expected.

              ### Spelling/Offensive Content Check
              - No spelling mistakes or offensive content found in the code or comments.

              ## ä¸­æ–‡ï¼ˆç®€ä½“ï¼‰
              - æ–°å¢äº† `ABC` ç±»
              - `foo` æ¨¡å—ä¸­çš„ `f()` è¡Œä¸ºå·²ä¿®å¤

              ### è¯„è®ºé«˜äº®
              - `config.toml` éœ€è¦æ­£ç¡®é…ç½®æ‰èƒ½ç¡®ä¿æ–°åŠŸèƒ½æ­£å¸¸è¿è¡Œã€‚

              ### å†…å®¹æ£€æŸ¥
              - æ²¡æœ‰å‘ç°ä»£ç æˆ–æ³¨é‡Šä¸­çš„æ‹¼å†™é”™è¯¯æˆ–ä¸å½“æªè¾ã€‚

          3. Highlight non-English comments
          4. Check for spelling/offensive content'''

              response = client.chat.completions.create(
                  model="o3-mini",
                  messages=[{
                      "role": "system",
                      "content": "Generate bilingual code review feedback."
                  }, {
                      "role": "user",
                      "content": f"Review these changes per guidelines:\n{guidelines}\n\nDIFF:\n{diff_content}"
                  }]
              )
              return response.choices[0].message.content

          def post_comment(comment):
              repo = os.getenv("GITHUB_REPOSITORY")
              pr_number = os.getenv("PR_NUMBER")

              headers = {
                  "Authorization": f"Bearer {os.getenv('GH_TOKEN')}",
                  "Accept": "application/vnd.github.v3+json"
              }
              url = f"https://api.github.com/repos/{repo}/issues/{pr_number}/comments"

              requests.post(url, json={"body": comment}, headers=headers)

          if __name__ == "__main__":
              diff_content = get_diff()
              if not diff_content.strip():
                  print("No meaningful diff detected.")
                  exit(0)

              comment = generate_comment(diff_content)
              post_comment(comment)
              print("Comment posted successfully.")
          EOF

          python /tmp/_workflow_core.py

```

### ARQUIVO: .github/workflows/environment-corrupt-check.yaml ###
```yaml
name: Environment Corruption Check
on:
  push:
    branches: ["main"]
    paths:
      - requirements.txt
  pull_request:
    branches: ["main"]
    paths:
      - requirements.txt
concurrency:
  group: ${{ github.workflow }}-${{ github.event_name }}-${{ github.ref }}
  cancel-in-progress: true
jobs:
  test-python-versions:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.11.11", "3.12.8", "3.13.2"]
      fail-fast: false
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      - name: Upgrade pip
        run: |
          python -m pip install --upgrade pip
      - name: Install dependencies
        run: |
          pip install -r requirements.txt

```

### ARQUIVO: .github/workflows/build-package.yaml ###
```yaml
name: Build and upload Python package

on:
  workflow_dispatch:
  release:
    types: [created, published]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install setuptools wheel twine
      - name: Set package version
        run: |
          export VERSION="${GITHUB_REF#refs/tags/v}"
          sed -i "s/version=.*/version=\"${VERSION}\",/" setup.py
      - name: Build and publish
        env:
          TWINE_USERNAME: __token__
          TWINE_PASSWORD: ${{ secrets.PYPI_API_TOKEN }}
        run: |
          python setup.py bdist_wheel sdist
          twine upload dist/*

```

### ARQUIVO: .github/ISSUE_TEMPLATE/show_me_the_bug.yaml ###
```yaml
name: "ğŸª² Mostre-me o Bug"
description: Relate um bug encontrado ao usar o OpenManus e procure assistÃªncia.
labels: bug
body:
  - type: textarea
    id: bug-description
    attributes:
      label: DescriÃ§Ã£o do Bug
      description: |
        Descreva claramente o bug que vocÃª encontrou
    validations:
      required: true
  - type: textarea
    id: solve-method
    attributes:
      label: MÃ©todo de resoluÃ§Ã£o do Bug
      description: |
        Se resolvido, explique a soluÃ§Ã£o. Opcionalmente, inclua uma URL de Pull Request.
        Se nÃ£o resolvido, forneÃ§a detalhes adicionais para ajudar na investigaÃ§Ã£o
    validations:
      required: true
  - type: textarea
    id: environment-information
    attributes:
      label: InformaÃ§Ãµes do Ambiente
      description: |
        Sistema: ex., Ubuntu 22.04
        Python: ex., 3.12
        VersÃ£o do OpenManus: ex., 0.1.0
      value: |
        - VersÃ£o do Sistema:
        - VersÃ£o do Python:
        - VersÃ£o ou branch do OpenManus:
        - MÃ©todo de instalaÃ§Ã£o (ex., `pip install -r requirements.txt` ou `pip install -e .`):
    validations:
      required: true
  - type: textarea
    id: extra-information
    attributes:
      label: InformaÃ§Ãµes Extras
      description: |
        Por exemplo, anexe capturas de tela ou logs para ajudar a diagnosticar o problema
    validations:
      required: false

```

### ARQUIVO: .github/ISSUE_TEMPLATE/request_new_features.yaml ###
```yaml
name: "ğŸ¤” Solicitar novas funcionalidades"
description: Sugira ideias ou funcionalidades que vocÃª gostaria de ver implementadas no OpenManus.
labels: enhancement
body:
  - type: textarea
    id: feature-description
    attributes:
      label: DescriÃ§Ã£o da funcionalidade
      description: |
        ForneÃ§a uma descriÃ§Ã£o clara e concisa da funcionalidade proposta
    validations:
      required: true
  - type: textarea
    id: your-feature
    attributes:
      label: Sua Funcionalidade
      description: |
        Explique sua ideia ou processo de implementaÃ§Ã£o, se houver. Opcionalmente, inclua uma URL de Pull Request.
        Certifique-se de que a documentaÃ§Ã£o/testes/exemplos correspondentes sejam fornecidos para revisÃ£o.
    validations:
      required: false

```

### ARQUIVO: .github/ISSUE_TEMPLATE/config.yml ###
```yml
blank_issues_enabled: false
contact_links:
  - name: "Join the Community Group"
    about: Join the OpenManus community to discuss and get help from others
    url: https://github.com/FoundationAgents/OpenManus?tab=readme-ov-file#community-group

```

### ARQUIVO: app/schema.py ###
```py
from enum import Enum
from typing import Any, List, Literal, Optional, Union

from pydantic import BaseModel, Field


class Role(str, Enum):
    """Message role options"""

    SYSTEM = "system"
    USER = "user"
    ASSISTANT = "assistant"
    TOOL = "tool"


ROLE_VALUES = tuple(role.value for role in Role)
ROLE_TYPE = Literal[ROLE_VALUES]  # type: ignore


class ToolChoice(str, Enum):
    """Tool choice options"""

    NONE = "none"
    AUTO = "auto"
    REQUIRED = "required"


TOOL_CHOICE_VALUES = tuple(choice.value for choice in ToolChoice)
TOOL_CHOICE_TYPE = Literal[TOOL_CHOICE_VALUES]  # type: ignore


class AgentState(str, Enum):
    """Agent execution states"""

    IDLE = "IDLE"
    RUNNING = "RUNNING"
    FINISHED = "FINISHED"
    ERROR = "ERROR"
    USER_HALTED = "user_halted" # Added for periodic user interaction
    AWAITING_USER_FEEDBACK = "awaiting_user_feedback" # New state for explicit feedback points
    USER_PAUSED = "user_paused" # New state for user-initiated pause


class Function(BaseModel):
    name: str
    arguments: str


class ToolCall(BaseModel):
    """Represents a tool/function call in a message"""

    id: str
    type: str = "function"
    function: Function


class Message(BaseModel):
    """Represents a chat message in the conversation"""

    role: ROLE_TYPE = Field(...)  # type: ignore
    content: Optional[str] = Field(default=None)
    tool_calls: Optional[List[ToolCall]] = Field(default=None)
    name: Optional[str] = Field(default=None)
    tool_call_id: Optional[str] = Field(default=None)
    base64_image: Optional[str] = Field(default=None)

    def __add__(self, other) -> List["Message"]:
        """æ”¯æŒ Message + list æˆ– Message + Message çš„æ“ä½œ"""
        if isinstance(other, list):
            return [self] + other
        elif isinstance(other, Message):
            return [self, other]
        else:
            raise TypeError(
                f"unsupported operand type(s) for +: '{type(self).__name__}' and '{type(other).__name__}'"
            )

    def __radd__(self, other) -> List["Message"]:
        """æ”¯æŒ list + Message çš„æ“ä½œ"""
        if isinstance(other, list):
            return other + [self]
        else:
            raise TypeError(
                f"unsupported operand type(s) for +: '{type(other).__name__}' and '{type(self).__name__}'"
            )

    def to_dict(self) -> dict:
        """Convert message to dictionary format"""
        message = {"role": self.role}
        if self.content is not None:
            message["content"] = self.content
        if self.tool_calls is not None:
            message["tool_calls"] = [tool_call.dict() for tool_call in self.tool_calls]
        if self.name is not None:
            message["name"] = self.name
        if self.tool_call_id is not None:
            message["tool_call_id"] = self.tool_call_id
        if self.base64_image is not None:
            message["base64_image"] = self.base64_image
        return message

    @classmethod
    def user_message(
        cls, content: str, base64_image: Optional[str] = None
    ) -> "Message":
        """Create a user message"""
        return cls(role=Role.USER, content=content, base64_image=base64_image)

    @classmethod
    def system_message(cls, content: str) -> "Message":
        """Create a system message"""
        return cls(role=Role.SYSTEM, content=content)

    @classmethod
    def assistant_message(
        cls, content: Optional[str] = None, base64_image: Optional[str] = None
    ) -> "Message":
        """Create an assistant message"""
        return cls(role=Role.ASSISTANT, content=content, base64_image=base64_image)

    @classmethod
    def tool_message(
        cls, content: str, name, tool_call_id: str, base64_image: Optional[str] = None
    ) -> "Message":
        """Create a tool message"""
        return cls(
            role=Role.TOOL,
            content=content,
            name=name,
            tool_call_id=tool_call_id,
            base64_image=base64_image,
        )

    @classmethod
    def from_tool_calls(
        cls,
        tool_calls: List[Any],
        content: Union[str, List[str]] = "",
        base64_image: Optional[str] = None,
        **kwargs,
    ):
        """Create ToolCallsMessage from raw tool calls.

        Args:
            tool_calls: Raw tool calls from LLM
            content: Optional message content
            base64_image: Optional base64 encoded image
        """
        formatted_calls = [
            {"id": call.id, "function": call.function.model_dump(), "type": "function"}
            for call in tool_calls
        ]
        return cls(
            role=Role.ASSISTANT,
            content=content,
            tool_calls=formatted_calls,
            base64_image=base64_image,
            **kwargs,
        )


class Memory(BaseModel):
    messages: List[Message] = Field(default_factory=list)
    max_messages: int = Field(default=100)

    def add_message(self, message: Message) -> None:
        """
        Add a message to memory. If the memory exceeds max_messages,
        it truncates older messages, ensuring that no 'tool' message becomes
        the first message if its corresponding 'assistant' message (that called it)
        is truncated.
        """
        self.messages.append(message)

        if len(self.messages) > self.max_messages:
            # Step 1: Calculate the initial cut-off point.
            # Messages before this index would be truncated by a simple trim.
            cut_off_index = len(self.messages) - self.max_messages

            # Step 2: Select the messages that would be kept by simple truncation.
            # This is our working list that we might shrink from the left.
            potential_kept_messages = self.messages[cut_off_index:]

            # Step 3-6: Iteratively check and remove orphan tool messages from the beginning
            # of potential_kept_messages.
            while potential_kept_messages:
                first_kept_message = potential_kept_messages[0]

                # Step 3: Check if the first message in our potential list is a tool message.
                if first_kept_message.role == Role.TOOL and first_kept_message.tool_call_id:
                    # Step 4: It's a tool message. Identify its tool_call_id.
                    tool_call_id_to_find = first_kept_message.tool_call_id

                    # Assume it's an orphan until proven otherwise.
                    is_orphan = True

                    # Step 5: Check if the assistant message that generated this tool call
                    # is present *within the currently visible potential_kept_messages*.
                    for msg_in_kept_list in potential_kept_messages:
                        if msg_in_kept_list.role == Role.ASSISTANT and msg_in_kept_list.tool_calls:
                            for tool_call in msg_in_kept_list.tool_calls:
                                if tool_call.id == tool_call_id_to_find:
                                    # Found the originating assistant message within the kept messages.
                                    # Therefore, the first_kept_message (tool message) is NOT an orphan.
                                    is_orphan = False
                                    break  # Exit inner loop (tool_calls)
                        if not is_orphan:
                            break  # Exit outer loop (potential_kept_messages iteration)

                    if is_orphan:
                        # Step 6: The originating assistant message was not found in potential_kept_messages
                        # (meaning it was in the truncated part: self.messages[:cut_off_index]).
                        # So, this first_kept_message (tool message) is an orphan. Remove it.
                        potential_kept_messages.pop(0)
                        # Continue the 'while potential_kept_messages' loop to check the new first message.
                    else:
                        # The first_kept_message (tool message) is not an orphan.
                        # We can stop checking and keep the current potential_kept_messages.
                        break
                else:
                    # The first message is not a tool message (or has no tool_call_id),
                    # so the orphan check logic doesn't apply to it. Stop checking.
                    break

            # Step 7: Finally, assign the potentially modified list of messages back.
            self.messages = potential_kept_messages

    def add_messages(self, messages: List[Message]) -> None:
        """
        Add multiple messages to memory.
        This method calls add_message for each message to ensure the
        orphan prevention logic is applied consistently upon each addition
        that might trigger truncation.
        """
        for message in messages:
            self.add_message(message)

    def clear(self) -> None:
        """Clear all messages"""
        self.messages.clear()

    def get_recent_messages(self, n: int) -> List[Message]:
        """Get n most recent messages"""
        return self.messages[-n:]

    def to_dict_list(self) -> List[dict]:
        """Convert messages to list of dicts"""
        return [msg.to_dict() for msg in self.messages]

```

### ARQUIVO: app/logger.py ###
```py
import sys
from datetime import datetime

from loguru import logger as _logger

# --- Import GUI log streaming components ---
import asyncio # Moved asyncio import to top as it's used by DB logging too
import sys # Ensure sys is imported
from pathlib import Path
# Assuming app/logger.py, so PROJECT_ROOT is parent.parent
# Adjust if this assumption is wrong for the worker's execution context.
PROJECT_ROOT_PATH = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT_PATH))

try:
    from gui.backend.log_streamer import get_log_queue, format_log_record
except ImportError as e:
    # This allows the rest of the application to function if the GUI part is missing,
    # though logs won't go to the GUI queue.
    print(f"INFO: GUI log streaming components not found or import error: {e}. GUI logging will be disabled.", file=sys.stderr) # Make sure to import sys for stderr
    # Define dummy functions so logger setup doesn't crash
    def get_log_queue(): return None
    def format_log_record(record): return None # This was missing in my plan, but it is in the instructions
    # Optionally, set a flag to avoid adding the sink if components are missing
    _gui_logging_enabled = False
else:
    _gui_logging_enabled = True
# --- End GUI log streaming components ---

# --- Import GUI database components ---
try:
    from gui.backend.database import AsyncSessionLocal, LogEntry
    # If log_streamer components are missing, database logging for GUI also doesn't make sense
    if not _gui_logging_enabled: # Assuming _gui_logging_enabled is set by log_streamer import
        raise ImportError("GUI logging disabled, so database logging for GUI is also disabled.")
except ImportError as e:
    print(f"INFO: GUI database components not found or import error: {e}. GUI database logging will be disabled.", file=sys.stderr)
    _gui_db_logging_enabled = False
    # Define dummy LogEntry if needed for the rest of the file not to break, though sink won't use it.
    class LogEntry: pass
else:
    _gui_db_logging_enabled = True
# --- End GUI database components ---

from app.config import PROJECT_ROOT


_print_level = "INFO"


def define_log_level(print_level="INFO", logfile_level="DEBUG", name: str = None):
    """Adjust the log level to above level"""
    global _print_level
    _print_level = print_level

    current_date = datetime.now()
    formatted_date = current_date.strftime("%Y%m%d%H%M%S")
    log_name = (
        f"{name}_{formatted_date}" if name else formatted_date
    )  # name a log with prefix name

    _logger.remove()
    _logger.add(sys.stderr, level=print_level)
    _logger.add(PROJECT_ROOT / f"logs/{log_name}.log", level=logfile_level)

    # --- Add GUI sink ---
    if _gui_logging_enabled and get_log_queue() is not None:
        log_queue_instance = get_log_queue() # Keep this if get_log_queue() is light and needed for check

        def gui_sink(message):
            # Acessar message.record uma Ãºnica vez no inÃ­cio
            try:
                record_data = message.record # Keep the full record for flexibility
                record_message_text = record_data["message"]
                # Check if this log record is itself an exception record from Loguru
                is_internal_loguru_error_log = record_data.get("exception") is not None
            except (TypeError, KeyError) as e_record_access:
                # Handles cases where message.record is not a dict or essential keys are missing.
                # This might happen if Loguru internally logs a message that doesn't conform to the standard record structure.
                print(f"Loguru gui_sink: Incapaz de processar registro de log nÃ£o padrÃ£o (erro acesso inicial): {message} | Erro: {e_record_access}", file=sys.stderr)
                return

            try:
                # --- Streaming to WebSocket queue ---
                if _gui_logging_enabled and get_log_queue() is not None: # Check _gui_logging_enabled too
                    # format_log_record is expected to return a serializable dict or None
                    # It should ideally use record_data which we got above.
                    # For safety, pass record_data if format_log_record expects the raw record dict
                    formatted_log_for_ws = format_log_record(record_data)

                    if formatted_log_for_ws is not None:
                        current_loop = None
                        try:
                            current_loop = asyncio.get_event_loop_policy().get_event_loop()
                        except RuntimeError as e_get_loop: # No loop in current thread
                            if not is_internal_loguru_error_log:
                                print(f"Loguru gui_sink (WebSocket): Sem loop asyncio ativo na thread atual para '{record_message_text}'. Erro: {e_get_loop}", file=sys.stderr)
                                print(f"Loguru gui_sink (Fallback): Missed GUI log from thread without asyncio loop: [{record_data.get('level', {}).get('name', 'UNKNOWN')}] {record_message_text}", file=sys.stderr)
                                return
                            # Cannot proceed with queueing if no loop.

                        if current_loop: # If loop was successfully obtained
                            try:
                                # Attempt to get the main running loop for thread-safe operations if needed.
                                main_running_loop = asyncio.get_running_loop()

                                if current_loop is main_running_loop and current_loop.is_running():
                                    get_log_queue().put_nowait(formatted_log_for_ws)
                                elif main_running_loop.is_running():
                                    main_running_loop.call_soon_threadsafe(get_log_queue().put_nowait, formatted_log_for_ws)
                                else: # Main loop not running, or current_loop is not main and not running.
                                    if not is_internal_loguru_error_log:
                                        print(f"Loguru gui_sink (WebSocket): Loop principal/atual do asyncio nÃ£o estÃ¡ rodando. Log para WebSocket pulado para: '{record_message_text}'", file=sys.stderr)

                            except RuntimeError: # Catches asyncio.get_running_loop() if no loop is set as running
                                if not is_internal_loguru_error_log:
                                     print(f"Loguru gui_sink (WebSocket): Loop principal do asyncio nÃ£o disponÃ­vel/rodando para log via WebSocket. Log: '{record_message_text}'", file=sys.stderr)
                            except asyncio.QueueFull:
                                if not is_internal_loguru_error_log:
                                    print(f"Loguru gui_sink (WebSocket): Fila de log para GUI cheia. Log de {record_data.get('name', 'N/A')}:{record_data.get('line', 'N/A')} pode ser perdido: '{record_message_text}'", file=sys.stderr)
                            except Exception as e_ws_put: # Catch other potential errors from put_nowait
                                if not is_internal_loguru_error_log:
                                    print(f"Loguru gui_sink (WebSocket): Erro ao colocar log na fila da GUI: {e_ws_put}. Log: '{record_message_text}'", file=sys.stderr)

                # --- Database logging (mantendo desabilitado como no original, mas com estrutura robusta) ---
                if _gui_db_logging_enabled: # Check the new flag
                    # This part is currently disabled in the original code.
                    # If it were enabled, similar loop handling would be needed.
                    # For now, we just acknowledge its state.
                    if False: # Explicitly keeping DB logging disabled
                        async def write_log_to_db():
                            # return # Original disablement
                            async with AsyncSessionLocal() as session:
                                async with session.begin():
                                    try:
                                        db_log_entry = LogEntry(
                                            timestamp=record_data['time'],
                                            level=record_data['level'].name,
                                            message=record_message_text, # Use pre-fetched message
                                            logger_name=record_data['name'],
                                            module=record_data['module'],
                                            function=record_data['function'],
                                            line=record_data['line'],
                                            execution_id=record_data['extra'].get("execution_id")
                                        )
                                        session.add(db_log_entry)
                                        await session.commit()
                                    except Exception as e_db:
                                        if not is_internal_loguru_error_log:
                                            print(f"Loguru gui_sink (DB): Erro ao escrever log no BD: {e_db}. Log: '{record_message_text}'", file=sys.stderr)
                                        await session.rollback()

                        # Logic to call write_log_to_db using appropriate loop (similar to WebSocket)
                        # This would need careful implementation if DB logging is re-enabled.
                        # For now, this part remains effectively disabled.
                        pass # Placeholder if the 'if False' is removed.

            except RuntimeError as e_runtime:
                # Captura "There is no current event loop in thread" ou "Event loop is closed"
                # Esta exceÃ§Ã£o seria mais provÃ¡vel de asyncio.get_event_loop_policy().get_event_loop() se falhar de forma inesperada
                # ou de asyncio.get_running_loop()
                if "no current event loop" in str(e_runtime).lower() or "event loop is closed" in str(e_runtime).lower():
                    if not is_internal_loguru_error_log:
                        print(f"Loguru gui_sink: Sem loop asyncio ativo ou loop fechado. Log para DB/GUI pulado para: '{record_message_text}'. Erro: {e_runtime}", file=sys.stderr)
                else:
                    if not is_internal_loguru_error_log:
                        print(f"Loguru gui_sink: RuntimeError inesperado: {e_runtime}. Log: '{record_message_text}'", file=sys.stderr)
            except Exception as e_general:
                if not is_internal_loguru_error_log:
                    print(f"Loguru gui_sink: ExceÃ§Ã£o inesperada ao processar log: {e_general}. Log: '{record_message_text}'", file=sys.stderr)

        _logger.add(gui_sink, level="DEBUG") # Or use logfile_level.
    # --- End GUI sink ---

    return _logger


logger = define_log_level()

# asyncio is now imported at the top.

if __name__ == "__main__":
    logger.info("Starting application")
    logger.debug("Debug message")
    logger.warning("Warning message")
    logger.error("Error message")
    logger.critical("Critical message")

    try:
        raise ValueError("Test error")
    except Exception as e:
        logger.exception(f"An error occurred: {e}")

```

### ARQUIVO: app/llm.py ###
```py
import math
import httpx # Added
import requests
import socket
from typing import Dict, List, Optional, Union
from urllib3.exceptions import MaxRetryError, NameResolutionError

import tiktoken
from openai import (
    APIError,
    AsyncAzureOpenAI,
    AsyncOpenAI,
    AuthenticationError,
    OpenAIError,
    RateLimitError,
)
from openai.types.chat import ChatCompletion, ChatCompletionMessage
from tenacity import (
    retry,
    retry_if_exception_type,
    stop_after_attempt,
    wait_random_exponential,
)

from app.bedrock import BedrockClient
from app.config import LLMSettings, config
from app.exceptions import TokenLimitExceeded
from app.logger import logger  # Assuming a logger is set up in your app
from app.schema import (
    ROLE_VALUES,
    TOOL_CHOICE_TYPE,
    TOOL_CHOICE_VALUES,
    Message,
    ToolChoice,
)


REASONING_MODELS = ["o1", "o3-mini"]
MULTIMODAL_MODELS = [
    "gpt-4-vision-preview",
    "gpt-4o",
    "gpt-4o-mini",
    "claude-3-opus-20240229",
    "claude-3-sonnet-20240229",
    "claude-3-haiku-20240307",
]


class TokenCounter:
    # Token constants
    BASE_MESSAGE_TOKENS = 4
    FORMAT_TOKENS = 2
    LOW_DETAIL_IMAGE_TOKENS = 85
    HIGH_DETAIL_TILE_TOKENS = 170

    # Image processing constants
    MAX_SIZE = 2048
    HIGH_DETAIL_TARGET_SHORT_SIDE = 768
    TILE_SIZE = 512

    def __init__(self, tokenizer):
        self.tokenizer = tokenizer

    def count_text(self, text: str) -> int:
        """Calculate tokens for a text string"""
        return 0 if not text else len(self.tokenizer.encode(text))

    def count_image(self, image_item: dict) -> int:
        """
        Calculate tokens for an image based on detail level and dimensions

        For "low" detail: fixed 85 tokens
        For "high" detail:
        1. Scale to fit in 2048x2048 square
        2. Scale shortest side to 768px
        3. Count 512px tiles (170 tokens each)
        4. Add 85 tokens
        """
        detail = image_item.get("detail", "medium")

        # For low detail, always return fixed token count
        if detail == "low":
            return self.LOW_DETAIL_IMAGE_TOKENS

        # For medium detail (default in OpenAI), use high detail calculation
        # OpenAI doesn't specify a separate calculation for medium

        # For high detail, calculate based on dimensions if available
        if detail == "high" or detail == "medium":
            # If dimensions are provided in the image_item
            if "dimensions" in image_item:
                width, height = image_item["dimensions"]
                return self._calculate_high_detail_tokens(width, height)

        return (
            self._calculate_high_detail_tokens(1024, 1024) if detail == "high" else 1024
        )

    def _calculate_high_detail_tokens(self, width: int, height: int) -> int:
        """Calculate tokens for high detail images based on dimensions"""
        # Step 1: Scale to fit in MAX_SIZE x MAX_SIZE square
        if width > self.MAX_SIZE or height > self.MAX_SIZE:
            scale = self.MAX_SIZE / max(width, height)
            width = int(width * scale)
            height = int(height * scale)

        # Step 2: Scale so shortest side is HIGH_DETAIL_TARGET_SHORT_SIDE
        scale = self.HIGH_DETAIL_TARGET_SHORT_SIDE / min(width, height)
        scaled_width = int(width * scale)
        scaled_height = int(height * scale)

        # Step 3: Count number of 512px tiles
        tiles_x = math.ceil(scaled_width / self.TILE_SIZE)
        tiles_y = math.ceil(scaled_height / self.TILE_SIZE)
        total_tiles = tiles_x * tiles_y

        # Step 4: Calculate final token count
        return (
            total_tiles * self.HIGH_DETAIL_TILE_TOKENS
        ) + self.LOW_DETAIL_IMAGE_TOKENS

    def count_content(self, content: Union[str, List[Union[str, dict]]]) -> int:
        """Calculate tokens for message content"""
        if not content:
            return 0

        if isinstance(content, str):
            return self.count_text(content)

        token_count = 0
        for item in content:
            if isinstance(item, str):
                token_count += self.count_text(item)
            elif isinstance(item, dict):
                if "text" in item:
                    token_count += self.count_text(item["text"])
                elif "image_url" in item:
                    token_count += self.count_image(item)
        return token_count

    def count_tool_calls(self, tool_calls: List[dict]) -> int:
        """Calculate tokens for tool calls"""
        token_count = 0
        for tool_call in tool_calls:
            if "function" in tool_call:
                function = tool_call["function"]
                token_count += self.count_text(function.get("name", ""))
                token_count += self.count_text(function.get("arguments", ""))
        return token_count

    def count_message_tokens(self, messages: List[dict]) -> int:
        """Calculate the total number of tokens in a message list"""
        total_tokens = self.FORMAT_TOKENS  # Base format tokens

        for message in messages:
            tokens = self.BASE_MESSAGE_TOKENS  # Base tokens per message

            # Add role tokens
            tokens += self.count_text(message.get("role", ""))

            # Add content tokens
            if "content" in message:
                tokens += self.count_content(message["content"])

            # Add tool calls tokens
            if "tool_calls" in message:
                tokens += self.count_tool_calls(message["tool_calls"])

            # Add name and tool_call_id tokens
            tokens += self.count_text(message.get("name", ""))
            tokens += self.count_text(message.get("tool_call_id", ""))

            total_tokens += tokens

        return total_tokens


class LLM:
    _instances: Dict[str, "LLM"] = {}

    def __new__(
        cls, config_name: str = "default", llm_config: Optional[LLMSettings] = None
    ):
        if config_name not in cls._instances:
            instance = super().__new__(cls)
            instance.__init__(config_name, llm_config)
            cls._instances[config_name] = instance
        return cls._instances[config_name]

    def __init__(
        self, config_name: str = "default", llm_config: Optional[LLMSettings] = None
    ):
        if not hasattr(self, "client"):  # Only initialize if not already initialized
            llm_config = llm_config or config.llm
            llm_config = llm_config.get(config_name, llm_config["default"])
            self.model = llm_config.model
            self.max_tokens = llm_config.max_tokens
            self.temperature = llm_config.temperature
            self.api_type = llm_config.api_type
            self.api_key = llm_config.api_key
            self.api_version = llm_config.api_version
            self.base_url = llm_config.base_url

            # Add token counting related attributes
            self.total_input_tokens = 0
            self.total_completion_tokens = 0
            self.max_input_tokens = (
                llm_config.max_input_tokens
                if hasattr(llm_config, "max_input_tokens")
                else None
            )

            # Initialize tokenizer
            try:
                self.tokenizer = tiktoken.encoding_for_model(self.model)
            except KeyError:
                logger.info(f"Model {self.model} not found in tiktoken, falling back to cl100k_base tokenizer.")
                try:
                    self.tokenizer = tiktoken.get_encoding("cl100k_base")
                except (requests.exceptions.ConnectionError, MaxRetryError, NameResolutionError, socket.gaierror) as e:
                    error_message = (
                        "Failed to download tiktoken tokenizer data for 'cl100k_base' due to a network issue "
                        "(e.g., DNS resolution failure or no internet access). "
                        "Please check your network connection and DNS settings. Original error: %s" % str(e)
                    )
                    logger.critical(error_message)
                    raise RuntimeError("Could not initialize LLM tokenizer due to network issues. Please check logs for details.") from e

            # Define custom HTTP client timeouts
            http_client_timeouts = httpx.Timeout(connect=20.0, read=60.0, write=60.0, pool=5.0)

            if self.api_type == "azure":
                self.client = AsyncAzureOpenAI(
                    base_url=self.base_url,
                    api_key=self.api_key,
                    api_version=self.api_version,
                    http_client=httpx.AsyncClient(timeout=http_client_timeouts)
                )
            elif self.api_type == "aws":
                self.client = BedrockClient() # Assuming BedrockClient handles its own timeouts or doesn't use httpx this way
            else: # Default to openai
                self.client = AsyncOpenAI(
                    api_key=self.api_key,
                    base_url=self.base_url,
                    http_client=httpx.AsyncClient(timeout=http_client_timeouts)
                )

            self.token_counter = TokenCounter(self.tokenizer)

    def count_tokens(self, text: str) -> int:
        """Calculate the number of tokens in a text"""
        if not text:
            return 0
        return len(self.tokenizer.encode(text))

    def count_message_tokens(self, messages: List[dict]) -> int:
        return self.token_counter.count_message_tokens(messages)

    def update_token_count(self, input_tokens: int, completion_tokens: int = 0) -> None:
        """Update token counts"""
        # Only track tokens if max_input_tokens is set
        self.total_input_tokens += input_tokens
        self.total_completion_tokens += completion_tokens
        logger.info(
            f"Token usage: Input={input_tokens}, Completion={completion_tokens}, "
            f"Cumulative Input={self.total_input_tokens}, Cumulative Completion={self.total_completion_tokens}, "
            f"Total={input_tokens + completion_tokens}, Cumulative Total={self.total_input_tokens + self.total_completion_tokens}"
        )

    def check_token_limit(self, input_tokens: int) -> bool:
        """Check if token limits are exceeded"""
        if self.max_input_tokens is not None:
            return (self.total_input_tokens + input_tokens) <= self.max_input_tokens
        # If max_input_tokens is not set, always return True
        return True

    def get_limit_error_message(self, input_tokens: int) -> str:
        """Generate error message for token limit exceeded"""
        if (
            self.max_input_tokens is not None
            and (self.total_input_tokens + input_tokens) > self.max_input_tokens
        ):
            return f"Request may exceed input token limit (Current: {self.total_input_tokens}, Needed: {input_tokens}, Max: {self.max_input_tokens})"

        return "Token limit exceeded"

    @staticmethod
    def format_messages(
        messages: List[Union[dict, Message]], supports_images: bool = False
    ) -> List[dict]:
        """
        Format messages for LLM by converting them to OpenAI message format.

        Args:
            messages: List of messages that can be either dict or Message objects
            supports_images: Flag indicating if the target model supports image inputs

        Returns:
            List[dict]: List of formatted messages in OpenAI format

        Raises:
            ValueError: If messages are invalid or missing required fields
            TypeError: If unsupported message types are provided

        Examples:
            >>> msgs = [
            ...     Message.system_message("You are a helpful assistant"),
            ...     {"role": "user", "content": "Hello"},
            ...     Message.user_message("How are you?")
            ... ]
            >>> formatted = LLM.format_messages(msgs)
        """
        formatted_messages = []

        for message in messages:
            # Convert Message objects to dictionaries
            if isinstance(message, Message):
                message = message.to_dict()

            if isinstance(message, dict):
                # If message is a dict, ensure it has required fields
                if "role" not in message:
                    raise ValueError("Message dict must contain 'role' field")

                # Process base64 images if present and model supports images
                if supports_images and message.get("base64_image"):
                    # Initialize or convert content to appropriate format
                    if not message.get("content"):
                        message["content"] = []
                    elif isinstance(message["content"], str):
                        message["content"] = [
                            {"type": "text", "text": message["content"]}
                        ]
                    elif isinstance(message["content"], list):
                        # Convert string items to proper text objects
                        message["content"] = [
                            (
                                {"type": "text", "text": item}
                                if isinstance(item, str)
                                else item
                            )
                            for item in message["content"]
                        ]

                    # Add the image to content
                    message["content"].append(
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{message['base64_image']}"
                            },
                        }
                    )

                    # Remove the base64_image field
                    del message["base64_image"]
                # If model doesn't support images but message has base64_image, handle gracefully
                elif not supports_images and message.get("base64_image"):
                    # Just remove the base64_image field and keep the text content
                    del message["base64_image"]

                if "content" in message or "tool_calls" in message:
                    formatted_messages.append(message)
                # else: do not include the message
            else:
                raise TypeError(f"Unsupported message type: {type(message)}")

        # Validate all messages have required fields
        for msg in formatted_messages:
            if msg["role"] not in ROLE_VALUES:
                raise ValueError(f"Invalid role: {msg['role']}")

        return formatted_messages

    @retry(
        wait=wait_random_exponential(min=1, max=60),
        stop=stop_after_attempt(6),
        retry=retry_if_exception_type(
            (OpenAIError, Exception, ValueError)
        ),  # Don't retry TokenLimitExceeded
    )
    async def ask(
        self,
        messages: List[Union[dict, Message]],
        system_msgs: Optional[List[Union[dict, Message]]] = None,
        stream: bool = True,
        temperature: Optional[float] = None,
    ) -> str:
        """
        Send a prompt to the LLM and get the response.

        Args:
            messages: List of conversation messages
            system_msgs: Optional system messages to prepend
            stream (bool): Whether to stream the response
            temperature (float): Sampling temperature for the response

        Returns:
            str: The generated response

        Raises:
            TokenLimitExceeded: If token limits are exceeded
            ValueError: If messages are invalid or response is empty
            OpenAIError: If API call fails after retries
            Exception: For unexpected errors
        """
        try:
            # Log system messages if provided
            if system_msgs:
                for i, system_msg_item in enumerate(system_msgs):
                    content_to_log = ""
                    if isinstance(system_msg_item, Message) and system_msg_item.content:
                        content_to_log = system_msg_item.content
                    elif isinstance(system_msg_item, dict) and system_msg_item.get("content"):
                        content_to_log = system_msg_item["content"]

                    if content_to_log:
                        logger.info(f"LLM ask: System message {i+1} (first 500 chars): {content_to_log[:500]}")
                        logger.info(f"LLM ask: System message {i+1} (last 500 chars): {content_to_log[-500:]}")
                    else:
                        logger.info(f"LLM ask: System message {i+1} is empty or has no content.")
            else:
                logger.info("LLM ask: No system messages provided.")

            # Check if the model supports images
            supports_images = self.model in MULTIMODAL_MODELS

            # Format system and user messages with image support check
            if system_msgs:
                system_msgs = self.format_messages(system_msgs, supports_images)
                messages = system_msgs + self.format_messages(messages, supports_images)
            else:
                messages = self.format_messages(messages, supports_images)

            # Calculate input token count
            input_tokens = self.count_message_tokens(messages)

            # Check if token limits are exceeded
            if not self.check_token_limit(input_tokens):
                error_message = self.get_limit_error_message(input_tokens)
                # Raise a special exception that won't be retried
                raise TokenLimitExceeded(error_message)

            params = {
                "model": self.model,
                "messages": messages,
            }

            if self.model in REASONING_MODELS:
                params["max_completion_tokens"] = self.max_tokens
            else:
                params["max_tokens"] = self.max_tokens
                params["temperature"] = (
                    temperature if temperature is not None else self.temperature
                )

            if not stream:
                # Non-streaming request
                response = await self.client.chat.completions.create(
                    **params, stream=False
                )

                if not response.choices or not response.choices[0].message.content:
                    raise ValueError("Empty or invalid response from LLM")

                # Update token counts
                self.update_token_count(
                    response.usage.prompt_tokens, response.usage.completion_tokens
                )

                return response.choices[0].message.content

            # Streaming request, For streaming, update estimated token count before making the request
            self.update_token_count(input_tokens)

            response = await self.client.chat.completions.create(**params, stream=True)

            collected_messages = []
            completion_text = ""
            async for chunk in response:
                chunk_message = chunk.choices[0].delta.content or ""
                collected_messages.append(chunk_message)
                completion_text += chunk_message
                print(chunk_message, end="", flush=True)

            print()  # Newline after streaming
            full_response = "".join(collected_messages).strip()
            if not full_response:
                raise ValueError("Empty response from streaming LLM")

            # estimate completion tokens for streaming response
            completion_tokens = self.count_tokens(completion_text)
            logger.info(
                f"Estimated completion tokens for streaming response: {completion_tokens}"
            )
            self.total_completion_tokens += completion_tokens

            return full_response

        except TokenLimitExceeded:
            # Re-raise token limit errors without logging
            raise
        except ValueError:
            logger.exception(f"Validation error")
            raise
        except OpenAIError as oe:
            logger.exception(f"OpenAI API error")
            if isinstance(oe, AuthenticationError):
                logger.error("Authentication failed. Check API key.")
            elif isinstance(oe, RateLimitError):
                logger.error("Rate limit exceeded. Consider increasing retry attempts.")
            elif isinstance(oe, APIError):
                logger.error(f"API error: {oe}")
            raise
        except Exception:
            logger.exception(f"Unexpected error in ask")
            raise

    @retry(
        wait=wait_random_exponential(min=1, max=60),
        stop=stop_after_attempt(6),
        retry=retry_if_exception_type(
            (OpenAIError, Exception, ValueError)
        ),  # Don't retry TokenLimitExceeded
    )
    async def ask_with_images(
        self,
        messages: List[Union[dict, Message]],
        images: List[Union[str, dict]],
        system_msgs: Optional[List[Union[dict, Message]]] = None,
        stream: bool = False,
        temperature: Optional[float] = None,
    ) -> str:
        """
        Send a prompt with images to the LLM and get the response.

        Args:
            messages: List of conversation messages
            images: List of image URLs or image data dictionaries
            system_msgs: Optional system messages to prepend
            stream (bool): Whether to stream the response
            temperature (float): Sampling temperature for the response

        Returns:
            str: The generated response

        Raises:
            TokenLimitExceeded: If token limits are exceeded
            ValueError: If messages are invalid or response is empty
            OpenAIError: If API call fails after retries
            Exception: For unexpected errors
        """
        try:
            # Log system messages if provided
            if system_msgs:
                for i, system_msg_item in enumerate(system_msgs):
                    content_to_log = ""
                    if isinstance(system_msg_item, Message) and system_msg_item.content:
                        content_to_log = system_msg_item.content
                    elif isinstance(system_msg_item, dict) and system_msg_item.get("content"):
                        content_to_log = system_msg_item["content"]

                    if content_to_log:
                        logger.info(f"LLM ask_with_images: System message {i+1} (first 500 chars): {content_to_log[:500]}")
                        logger.info(f"LLM ask_with_images: System message {i+1} (last 500 chars): {content_to_log[-500:]}")
                    else:
                        logger.info(f"LLM ask_with_images: System message {i+1} is empty or has no content.")
            else:
                logger.info("LLM ask_with_images: No system messages provided.")

            # For ask_with_images, we always set supports_images to True because
            # this method should only be called with models that support images
            if self.model not in MULTIMODAL_MODELS:
                raise ValueError(
                    f"Model {self.model} does not support images. Use a model from {MULTIMODAL_MODELS}"
                )

            # Format messages with image support
            formatted_messages = self.format_messages(messages, supports_images=True)

            # Ensure the last message is from the user to attach images
            if not formatted_messages or formatted_messages[-1]["role"] != "user":
                raise ValueError(
                    "The last message must be from the user to attach images"
                )

            # Process the last user message to include images
            last_message = formatted_messages[-1]

            # Convert content to multimodal format if needed
            content = last_message["content"]
            multimodal_content = (
                [{"type": "text", "text": content}]
                if isinstance(content, str)
                else content
                if isinstance(content, list)
                else []
            )

            # Add images to content
            for image in images:
                if isinstance(image, str):
                    multimodal_content.append(
                        {"type": "image_url", "image_url": {"url": image}}
                    )
                elif isinstance(image, dict) and "url" in image:
                    multimodal_content.append({"type": "image_url", "image_url": image})
                elif isinstance(image, dict) and "image_url" in image:
                    multimodal_content.append(image)
                else:
                    raise ValueError(f"Unsupported image format: {image}")

            # Update the message with multimodal content
            last_message["content"] = multimodal_content

            # Add system messages if provided
            if system_msgs:
                all_messages = (
                    self.format_messages(system_msgs, supports_images=True)
                    + formatted_messages
                )
            else:
                all_messages = formatted_messages

            # Calculate tokens and check limits
            input_tokens = self.count_message_tokens(all_messages)
            if not self.check_token_limit(input_tokens):
                raise TokenLimitExceeded(self.get_limit_error_message(input_tokens))

            # Set up API parameters
            params = {
                "model": self.model,
                "messages": all_messages,
                "stream": stream,
            }

            # Add model-specific parameters
            if self.model in REASONING_MODELS:
                params["max_completion_tokens"] = self.max_tokens
            else:
                params["max_tokens"] = self.max_tokens
                params["temperature"] = (
                    temperature if temperature is not None else self.temperature
                )

            # Handle non-streaming request
            if not stream:
                response = await self.client.chat.completions.create(**params)

                if not response.choices or not response.choices[0].message.content:
                    raise ValueError("Empty or invalid response from LLM")

                self.update_token_count(response.usage.prompt_tokens)
                return response.choices[0].message.content

            # Handle streaming request
            self.update_token_count(input_tokens)
            response = await self.client.chat.completions.create(**params)

            collected_messages = []
            async for chunk in response:
                chunk_message = chunk.choices[0].delta.content or ""
                collected_messages.append(chunk_message)
                print(chunk_message, end="", flush=True)

            print()  # Newline after streaming
            full_response = "".join(collected_messages).strip()

            if not full_response:
                raise ValueError("Empty response from streaming LLM")

            return full_response

        except TokenLimitExceeded:
            raise
        except ValueError as ve:
            logger.error(f"Validation error in ask_with_images: {ve}")
            raise
        except OpenAIError as oe:
            logger.error(f"OpenAI API error: {oe}")
            if isinstance(oe, AuthenticationError):
                logger.error("Authentication failed. Check API key.")
            elif isinstance(oe, RateLimitError):
                logger.error("Rate limit exceeded. Consider increasing retry attempts.")
            elif isinstance(oe, APIError):
                logger.error(f"API error: {oe}")
            raise
        except Exception as e:
            logger.error(f"Unexpected error in ask_with_images: {e}")
            raise

    @retry(
        wait=wait_random_exponential(min=1, max=60),
        stop=stop_after_attempt(6),
        retry=retry_if_exception_type(
            (OpenAIError, Exception, ValueError)
        ),  # Don't retry TokenLimitExceeded
    )
    async def ask_tool(
        self,
        messages: List[Union[dict, Message]],
        system_msgs: Optional[List[Union[dict, Message]]] = None,
        timeout: int = 300,
        tools: Optional[List[dict]] = None,
        tool_choice: TOOL_CHOICE_TYPE = ToolChoice.AUTO,  # type: ignore
        temperature: Optional[float] = None,
        **kwargs,
    ) -> ChatCompletionMessage | None:
        """
        Ask LLM using functions/tools and return the response.

        Args:
            messages: List of conversation messages
            system_msgs: Optional system messages to prepend
            timeout: Request timeout in seconds
            tools: List of tools to use
            tool_choice: Tool choice strategy
            temperature: Sampling temperature for the response
            **kwargs: Additional completion arguments

        Returns:
            ChatCompletionMessage: The model's response

        Raises:
            TokenLimitExceeded: If token limits are exceeded
            ValueError: If tools, tool_choice, or messages are invalid
            OpenAIError: If API call fails after retries
            Exception: For unexpected errors
        """
        try:
            # Log system messages if provided
            if system_msgs:
                for i, system_msg_item in enumerate(system_msgs):
                    content_to_log = ""
                    if isinstance(system_msg_item, Message) and system_msg_item.content:
                        content_to_log = system_msg_item.content
                    elif isinstance(system_msg_item, dict) and system_msg_item.get("content"):
                        content_to_log = system_msg_item["content"]

                    if content_to_log:
                        logger.info(f"LLM ask_tool: System message {i+1} (first 500 chars): {content_to_log[:500]}")
                        logger.info(f"LLM ask_tool: System message {i+1} (last 500 chars): {content_to_log[-500:]}")
                    else:
                        logger.info(f"LLM ask_tool: System message {i+1} is empty or has no content.")
            else:
                logger.info("LLM ask_tool: No system messages provided.")

            # Validate tool_choice
            if tool_choice not in TOOL_CHOICE_VALUES:
                raise ValueError(f"Invalid tool_choice: {tool_choice}")

            # Check if the model supports images
            supports_images = self.model in MULTIMODAL_MODELS

            # Format messages
            if system_msgs:
                system_msgs = self.format_messages(system_msgs, supports_images)
                messages = system_msgs + self.format_messages(messages, supports_images)
            else:
                messages = self.format_messages(messages, supports_images)

            # Calculate input token count
            input_tokens = self.count_message_tokens(messages)

            # If there are tools, calculate token count for tool descriptions
            tools_tokens = 0
            if tools:
                for tool in tools:
                    tools_tokens += self.count_tokens(str(tool))

            input_tokens += tools_tokens

            # Check if token limits are exceeded
            if not self.check_token_limit(input_tokens):
                error_message = self.get_limit_error_message(input_tokens)
                # Raise a special exception that won't be retried
                raise TokenLimitExceeded(error_message)

            # Validate tools if provided
            if tools:
                for tool in tools:
                    if not isinstance(tool, dict) or "type" not in tool:
                        raise ValueError("Each tool must be a dict with 'type' field")

            # Set up the completion request
            params = {
                "model": self.model,
                "messages": messages,
                "tools": tools,
                "tool_choice": tool_choice,
                "timeout": timeout,
                **kwargs,
            }

            if self.model in REASONING_MODELS:
                params["max_completion_tokens"] = self.max_tokens
            else:
                params["max_tokens"] = self.max_tokens
                params["temperature"] = (
                    temperature if temperature is not None else self.temperature
                )

            params["stream"] = False  # Always use non-streaming for tool requests
            response: ChatCompletion = await self.client.chat.completions.create(
                **params
            )

            # Check if response is valid
            if not response.choices or not response.choices[0].message:
                print(response)
                # raise ValueError("Invalid or empty response from LLM")
                return None

            # Update token counts
            self.update_token_count(
                response.usage.prompt_tokens, response.usage.completion_tokens
            )

            return response.choices[0].message

        except TokenLimitExceeded:
            # Re-raise token limit errors without logging
            raise
        except ValueError as ve:
            logger.error(f"Validation error in ask_tool: {ve}")
            raise
        except OpenAIError as oe:
            logger.error(f"OpenAI API error: {oe}")
            if isinstance(oe, AuthenticationError):
                logger.error("Authentication failed. Check API key.")
            elif isinstance(oe, RateLimitError):
                logger.error("Rate limit exceeded. Consider increasing retry attempts.")
            elif isinstance(oe, APIError):
                logger.error(f"API error: {oe}")
            raise
        except Exception as e:
            logger.error(f"Unexpected error in ask_tool: {e}")
            raise

```

### ARQUIVO: app/bedrock.py ###
```py
import json
import sys
import time
import uuid
from datetime import datetime
from typing import Dict, List, Literal, Optional

import boto3


# Global variables to track the current tool use ID across function calls
# Tmp solution
CURRENT_TOOLUSE_ID = None


# Class to handle OpenAI-style response formatting
class OpenAIResponse:
    def __init__(self, data):
        # Recursively convert nested dicts and lists to OpenAIResponse objects
        for key, value in data.items():
            if isinstance(value, dict):
                value = OpenAIResponse(value)
            elif isinstance(value, list):
                value = [
                    OpenAIResponse(item) if isinstance(item, dict) else item
                    for item in value
                ]
            setattr(self, key, value)

    def model_dump(self, *args, **kwargs):
        # Convert object to dict and add timestamp
        data = self.__dict__
        data["created_at"] = datetime.now().isoformat()
        return data


# Main client class for interacting with Amazon Bedrock
class BedrockClient:
    def __init__(self):
        # Initialize Bedrock client, you need to configure AWS env first
        try:
            self.client = boto3.client("bedrock-runtime")
            self.chat = Chat(self.client)
        except Exception as e:
            print(f"Error initializing Bedrock client: {e}")
            sys.exit(1)


# Chat interface class
class Chat:
    def __init__(self, client):
        self.completions = ChatCompletions(client)


# Core class handling chat completions functionality
class ChatCompletions:
    def __init__(self, client):
        self.client = client

    def _convert_openai_tools_to_bedrock_format(self, tools):
        # Convert OpenAI function calling format to Bedrock tool format
        bedrock_tools = []
        for tool in tools:
            if tool.get("type") == "function":
                function = tool.get("function", {})
                bedrock_tool = {
                    "toolSpec": {
                        "name": function.get("name", ""),
                        "description": function.get("description", ""),
                        "inputSchema": {
                            "json": {
                                "type": "object",
                                "properties": function.get("parameters", {}).get(
                                    "properties", {}
                                ),
                                "required": function.get("parameters", {}).get(
                                    "required", []
                                ),
                            }
                        },
                    }
                }
                bedrock_tools.append(bedrock_tool)
        return bedrock_tools

    def _convert_openai_messages_to_bedrock_format(self, messages):
        # Convert OpenAI message format to Bedrock message format
        bedrock_messages = []
        system_prompt = []
        for message in messages:
            if message.get("role") == "system":
                system_prompt = [{"text": message.get("content")}]
            elif message.get("role") == "user":
                bedrock_message = {
                    "role": message.get("role", "user"),
                    "content": [{"text": message.get("content")}],
                }
                bedrock_messages.append(bedrock_message)
            elif message.get("role") == "assistant":
                bedrock_message = {
                    "role": "assistant",
                    "content": [{"text": message.get("content")}],
                }
                openai_tool_calls = message.get("tool_calls", [])
                if openai_tool_calls:
                    bedrock_tool_use = {
                        "toolUseId": openai_tool_calls[0]["id"],
                        "name": openai_tool_calls[0]["function"]["name"],
                        "input": json.loads(
                            openai_tool_calls[0]["function"]["arguments"]
                        ),
                    }
                    bedrock_message["content"].append({"toolUse": bedrock_tool_use})
                    global CURRENT_TOOLUSE_ID
                    CURRENT_TOOLUSE_ID = openai_tool_calls[0]["id"]
                bedrock_messages.append(bedrock_message)
            elif message.get("role") == "tool":
                bedrock_message = {
                    "role": "user",
                    "content": [
                        {
                            "toolResult": {
                                "toolUseId": CURRENT_TOOLUSE_ID,
                                "content": [{"text": message.get("content")}],
                            }
                        }
                    ],
                }
                bedrock_messages.append(bedrock_message)
            else:
                raise ValueError(f"Invalid role: {message.get('role')}")
        return system_prompt, bedrock_messages

    def _convert_bedrock_response_to_openai_format(self, bedrock_response):
        # Convert Bedrock response format to OpenAI format
        content = ""
        if bedrock_response.get("output", {}).get("message", {}).get("content"):
            content_array = bedrock_response["output"]["message"]["content"]
            content = "".join(item.get("text", "") for item in content_array)
        if content == "":
            content = "."

        # Handle tool calls in response
        openai_tool_calls = []
        if bedrock_response.get("output", {}).get("message", {}).get("content"):
            for content_item in bedrock_response["output"]["message"]["content"]:
                if content_item.get("toolUse"):
                    bedrock_tool_use = content_item["toolUse"]
                    global CURRENT_TOOLUSE_ID
                    CURRENT_TOOLUSE_ID = bedrock_tool_use["toolUseId"]
                    openai_tool_call = {
                        "id": CURRENT_TOOLUSE_ID,
                        "type": "function",
                        "function": {
                            "name": bedrock_tool_use["name"],
                            "arguments": json.dumps(bedrock_tool_use["input"]),
                        },
                    }
                    openai_tool_calls.append(openai_tool_call)

        # Construct final OpenAI format response
        openai_format = {
            "id": f"chatcmpl-{uuid.uuid4()}",
            "created": int(time.time()),
            "object": "chat.completion",
            "system_fingerprint": None,
            "choices": [
                {
                    "finish_reason": bedrock_response.get("stopReason", "end_turn"),
                    "index": 0,
                    "message": {
                        "content": content,
                        "role": bedrock_response.get("output", {})
                        .get("message", {})
                        .get("role", "assistant"),
                        "tool_calls": openai_tool_calls
                        if openai_tool_calls != []
                        else None,
                        "function_call": None,
                    },
                }
            ],
            "usage": {
                "completion_tokens": bedrock_response.get("usage", {}).get(
                    "outputTokens", 0
                ),
                "prompt_tokens": bedrock_response.get("usage", {}).get(
                    "inputTokens", 0
                ),
                "total_tokens": bedrock_response.get("usage", {}).get("totalTokens", 0),
            },
        }
        return OpenAIResponse(openai_format)

    async def _invoke_bedrock(
        self,
        model: str,
        messages: List[Dict[str, str]],
        max_tokens: int,
        temperature: float,
        tools: Optional[List[dict]] = None,
        tool_choice: Literal["none", "auto", "required"] = "auto",
        **kwargs,
    ) -> OpenAIResponse:
        # Non-streaming invocation of Bedrock model
        (
            system_prompt,
            bedrock_messages,
        ) = self._convert_openai_messages_to_bedrock_format(messages)
        response = self.client.converse(
            modelId=model,
            system=system_prompt,
            messages=bedrock_messages,
            inferenceConfig={"temperature": temperature, "maxTokens": max_tokens},
            toolConfig={"tools": tools} if tools else None,
        )
        openai_response = self._convert_bedrock_response_to_openai_format(response)
        return openai_response

    async def _invoke_bedrock_stream(
        self,
        model: str,
        messages: List[Dict[str, str]],
        max_tokens: int,
        temperature: float,
        tools: Optional[List[dict]] = None,
        tool_choice: Literal["none", "auto", "required"] = "auto",
        **kwargs,
    ) -> OpenAIResponse:
        # Streaming invocation of Bedrock model
        (
            system_prompt,
            bedrock_messages,
        ) = self._convert_openai_messages_to_bedrock_format(messages)
        response = self.client.converse_stream(
            modelId=model,
            system=system_prompt,
            messages=bedrock_messages,
            inferenceConfig={"temperature": temperature, "maxTokens": max_tokens},
            toolConfig={"tools": tools} if tools else None,
        )

        # Initialize response structure
        bedrock_response = {
            "output": {"message": {"role": "", "content": []}},
            "stopReason": "",
            "usage": {},
            "metrics": {},
        }
        bedrock_response_text = ""
        bedrock_response_tool_input = ""

        # Process streaming response
        stream = response.get("stream")
        if stream:
            for event in stream:
                if event.get("messageStart", {}).get("role"):
                    bedrock_response["output"]["message"]["role"] = event[
                        "messageStart"
                    ]["role"]
                if event.get("contentBlockDelta", {}).get("delta", {}).get("text"):
                    bedrock_response_text += event["contentBlockDelta"]["delta"]["text"]
                    print(
                        event["contentBlockDelta"]["delta"]["text"], end="", flush=True
                    )
                if event.get("contentBlockStop", {}).get("contentBlockIndex") == 0:
                    bedrock_response["output"]["message"]["content"].append(
                        {"text": bedrock_response_text}
                    )
                if event.get("contentBlockStart", {}).get("start", {}).get("toolUse"):
                    bedrock_tool_use = event["contentBlockStart"]["start"]["toolUse"]
                    tool_use = {
                        "toolUseId": bedrock_tool_use["toolUseId"],
                        "name": bedrock_tool_use["name"],
                    }
                    bedrock_response["output"]["message"]["content"].append(
                        {"toolUse": tool_use}
                    )
                    global CURRENT_TOOLUSE_ID
                    CURRENT_TOOLUSE_ID = bedrock_tool_use["toolUseId"]
                if event.get("contentBlockDelta", {}).get("delta", {}).get("toolUse"):
                    bedrock_response_tool_input += event["contentBlockDelta"]["delta"][
                        "toolUse"
                    ]["input"]
                    print(
                        event["contentBlockDelta"]["delta"]["toolUse"]["input"],
                        end="",
                        flush=True,
                    )
                if event.get("contentBlockStop", {}).get("contentBlockIndex") == 1:
                    bedrock_response["output"]["message"]["content"][1]["toolUse"][
                        "input"
                    ] = json.loads(bedrock_response_tool_input)
        print()
        openai_response = self._convert_bedrock_response_to_openai_format(
            bedrock_response
        )
        return openai_response

    def create(
        self,
        model: str,
        messages: List[Dict[str, str]],
        max_tokens: int,
        temperature: float,
        stream: Optional[bool] = True,
        tools: Optional[List[dict]] = None,
        tool_choice: Literal["none", "auto", "required"] = "auto",
        **kwargs,
    ) -> OpenAIResponse:
        # Main entry point for chat completion
        bedrock_tools = []
        if tools is not None:
            bedrock_tools = self._convert_openai_tools_to_bedrock_format(tools)
        if stream:
            return self._invoke_bedrock_stream(
                model,
                messages,
                max_tokens,
                temperature,
                bedrock_tools,
                tool_choice,
                **kwargs,
            )
        else:
            return self._invoke_bedrock(
                model,
                messages,
                max_tokens,
                temperature,
                bedrock_tools,
                tool_choice,
                **kwargs,
            )

```

### ARQUIVO: app/__init__.py ###
```py
# Python version check: 3.11-3.13
import sys


if sys.version_info < (3, 11) or sys.version_info > (3, 13):
    print(
        "Warning: Unsupported Python version {ver}, please use 3.11-3.13".format(
            ver=".".join(map(str, sys.version_info))
        )
    )

```

### ARQUIVO: app/config.py ###
```py
import json
import threading
try:
    import tomllib
except ImportError:
    import tomli as tomllib
from pathlib import Path
from typing import Dict, List, Optional

from pydantic import BaseModel, Field


def get_project_root() -> Path:
    """Get the project root directory"""
    return Path(__file__).resolve().parent.parent


PROJECT_ROOT = get_project_root()
WORKSPACE_ROOT = PROJECT_ROOT / "workspace"


class LLMSettings(BaseModel):
    model: str = Field(..., description="Model name")
    base_url: str = Field(..., description="API base URL")
    api_key: str = Field(..., description="API key")
    max_tokens: int = Field(4096, description="Maximum number of tokens per request")
    max_input_tokens: Optional[int] = Field(
        None,
        description="Maximum input tokens to use across all requests (None for unlimited)",
    )
    temperature: float = Field(1.0, description="Sampling temperature")
    api_type: str = Field(..., description="Azure, Openai, or Ollama")
    api_version: str = Field(..., description="Azure Openai version if AzureOpenai")


class ProxySettings(BaseModel):
    server: str = Field(None, description="Proxy server address")
    username: Optional[str] = Field(None, description="Proxy username")
    password: Optional[str] = Field(None, description="Proxy password")


class SearchSettings(BaseModel):
    engine: str = Field(default="Google", description="Search engine the llm to use")
    fallback_engines: List[str] = Field(
        default_factory=lambda: ["DuckDuckGo", "Baidu", "Bing"],
        description="Fallback search engines to try if the primary engine fails",
    )
    retry_delay: int = Field(
        default=60,
        description="Seconds to wait before retrying all engines again after they all fail",
    )
    max_retries: int = Field(
        default=3,
        description="Maximum number of times to retry all engines when all fail",
    )
    lang: str = Field(
        default="en",
        description="Language code for search results (e.g., en, zh, fr)",
    )
    country: str = Field(
        default="us",
        description="Country code for search results (e.g., us, cn, uk)",
    )


class BrowserSettings(BaseModel):
    headless: bool = Field(False, description="Whether to run browser in headless mode")
    disable_security: bool = Field(
        True, description="Disable browser security features"
    )
    extra_chromium_args: List[str] = Field(
        default_factory=list, description="Extra arguments to pass to the browser"
    )
    chrome_instance_path: Optional[str] = Field(
        None, description="Path to a Chrome instance to use"
    )
    wss_url: Optional[str] = Field(
        None, description="Connect to a browser instance via WebSocket"
    )
    cdp_url: Optional[str] = Field(
        None, description="Connect to a browser instance via CDP"
    )
    proxy: Optional[ProxySettings] = Field(
        None, description="Proxy settings for the browser"
    )
    max_content_length: int = Field(
        2000, description="Maximum length for content retrieval operations"
    )


class SandboxSettings(BaseModel):
    """Configuration for the execution sandbox"""

    use_sandbox: bool = Field(False, description="Whether to use the sandbox")
    image: str = Field("python:3.12-slim", description="Base image")
    work_dir: str = Field("/workspace", description="Container working directory")
    memory_limit: str = Field("512m", description="Memory limit")
    cpu_limit: float = Field(1.0, description="CPU limit")
    timeout: int = Field(604800, description="Default command timeout (seconds) - 7 days")
    network_enabled: bool = Field(
        False, description="Whether network access is allowed"
    )


class MCPServerConfig(BaseModel):
    """Configuration for a single MCP server"""

    type: str = Field(..., description="Server connection type (sse or stdio)")
    url: Optional[str] = Field(None, description="Server URL for SSE connections")
    command: Optional[str] = Field(None, description="Command for stdio connections")
    args: List[str] = Field(
        default_factory=list, description="Arguments for stdio command"
    )


class MCPSettings(BaseModel):
    """Configuration for MCP (Model Context Protocol)"""

    server_reference: str = Field(
        "app.mcp.server", description="Module reference for the MCP server"
    )
    servers: Dict[str, MCPServerConfig] = Field(
        default_factory=dict, description="MCP server configurations"
    )

    @classmethod
    def load_server_config(cls) -> Dict[str, MCPServerConfig]:
        """Load MCP server configuration from JSON file"""
        config_path = PROJECT_ROOT / "config" / "mcp.json"

        try:
            config_file = config_path if config_path.exists() else None
            if not config_file:
                return {}

            with config_file.open() as f:
                data = json.load(f)
                servers = {}

                for server_id, server_config in data.get("mcpServers", {}).items():
                    servers[server_id] = MCPServerConfig(
                        type=server_config["type"],
                        url=server_config.get("url"),
                        command=server_config.get("command"),
                        args=server_config.get("args", []),
                    )
                return servers
        except Exception as e:
            raise ValueError(f"Failed to load MCP server config: {e}")


class AppConfig(BaseModel):
    llm: Dict[str, LLMSettings]
    sandbox: Optional[SandboxSettings] = Field(
        None, description="Sandbox configuration"
    )
    browser_config: Optional[BrowserSettings] = Field(
        None, description="Browser configuration"
    )
    search_config: Optional[SearchSettings] = Field(
        None, description="Search configuration"
    )
    mcp_config: Optional[MCPSettings] = Field(None, description="MCP configuration")

    class Config:
        arbitrary_types_allowed = True


class Config:
    _instance = None
    _lock = threading.Lock()
    _initialized = False

    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        if not self._initialized:
            with self._lock:
                if not self._initialized:
                    self._config = None
                    self._load_initial_config()
                    self._initialized = True

    @staticmethod
    def _get_config_path() -> Path:
        root = PROJECT_ROOT
        config_path = root / "config" / "config.toml"
        if config_path.exists():
            return config_path
        example_path = root / "config" / "config.example.toml"
        if example_path.exists():
            return example_path
        raise FileNotFoundError("No configuration file found in config directory")

    def _load_config(self) -> dict:
        config_path = self._get_config_path()
        with config_path.open("rb") as f:
            return tomllib.load(f)

    def _load_initial_config(self):
        raw_config = self._load_config()
        base_llm = raw_config.get("llm", {})
        llm_overrides = {
            k: v for k, v in raw_config.get("llm", {}).items() if isinstance(v, dict)
        }

        default_settings = {
            "model": base_llm.get("model"),
            "base_url": base_llm.get("base_url"),
            "api_key": base_llm.get("api_key"),
            "max_tokens": base_llm.get("max_tokens", 4096),
            "max_input_tokens": base_llm.get("max_input_tokens"),
            "temperature": base_llm.get("temperature", 1.0),
            "api_type": base_llm.get("api_type", ""),
            "api_version": base_llm.get("api_version", ""),
        }

        # handle browser config.
        browser_config = raw_config.get("browser", {})
        browser_settings = None

        if browser_config:
            # handle proxy settings.
            proxy_config = browser_config.get("proxy", {})
            proxy_settings = None

            if proxy_config and proxy_config.get("server"):
                proxy_settings = ProxySettings(
                    **{
                        k: v
                        for k, v in proxy_config.items()
                        if k in ["server", "username", "password"] and v
                    }
                )

            # filter valid browser config parameters.
            valid_browser_params = {
                k: v
                for k, v in browser_config.items()
                if k in BrowserSettings.__annotations__ and v is not None
            }

            # if there is proxy settings, add it to the parameters.
            if proxy_settings:
                valid_browser_params["proxy"] = proxy_settings

            # only create BrowserSettings when there are valid parameters.
            if valid_browser_params:
                browser_settings = BrowserSettings(**valid_browser_params)

        search_config = raw_config.get("search", {})
        search_settings = None
        if search_config:
            search_settings = SearchSettings(**search_config)
        sandbox_config = raw_config.get("sandbox", {})
        if sandbox_config:
            sandbox_settings = SandboxSettings(**sandbox_config)
        else:
            sandbox_settings = SandboxSettings()

        mcp_config = raw_config.get("mcp", {})
        mcp_settings = None
        if mcp_config:
            # Load server configurations from JSON
            mcp_config["servers"] = MCPSettings.load_server_config()
            mcp_settings = MCPSettings(**mcp_config)
        else:
            mcp_settings = MCPSettings(servers=MCPSettings.load_server_config())

        config_dict = {
            "llm": {
                "default": default_settings,
                **{
                    name: {**default_settings, **override_config}
                    for name, override_config in llm_overrides.items()
                },
            },
            "sandbox": sandbox_settings,
            "browser_config": browser_settings,
            "search_config": search_settings,
            "mcp_config": mcp_settings,
        }

        self._config = AppConfig(**config_dict)

    @property
    def llm(self) -> Dict[str, LLMSettings]:
        return self._config.llm

    @property
    def sandbox(self) -> SandboxSettings:
        return self._config.sandbox

    @property
    def browser_config(self) -> Optional[BrowserSettings]:
        return self._config.browser_config

    @property
    def search_config(self) -> Optional[SearchSettings]:
        return self._config.search_config

    @property
    def mcp_config(self) -> MCPSettings:
        """Get the MCP configuration"""
        return self._config.mcp_config

    @property
    def workspace_root(self) -> Path:
        """Get the workspace root directory"""
        return WORKSPACE_ROOT

    @property
    def root_path(self) -> Path:
        """Get the root path of the application"""
        return PROJECT_ROOT


config = Config()

```

### ARQUIVO: app/exceptions.py ###
```py
class ToolError(Exception):
    """Levantado quando uma ferramenta encontra um erro."""

    def __init__(self, message):
        self.message = message


class OpenManusError(Exception):
    """ExceÃ§Ã£o base para todos os erros do OpenManus"""


class TokenLimitExceeded(OpenManusError):
    """ExceÃ§Ã£o levantada quando o limite de token Ã© excedido"""

```

### ARQUIVO: app/test_manus_periodic_check_in.py ###
```py
import asyncio
import os
from app.agent.manus import Manus
from app.config import config
from app.memory.base import Message # Corrected import
from app.schema import AgentState, Role # Corrected import

# Minimal configuration for the test
# This path needs to be accessible by the script when it runs.
# /app/ is the root of the repository where the app code resides.
config.workspace_root = "/app/manus_test_workspace"
os.makedirs(config.workspace_root, exist_ok=True)

# Create a dummy checklist file
checklist_path = os.path.join(config.workspace_root, "checklist_principal_tarefa.md")
with open(checklist_path, "w") as f:
    f.write("- Tarefa 1\n- Tarefa 2")

async def main():
    print("Instantiating Manus agent...")
    agent = None  # Define agent here for cleanup
    try:
        # Manus.create() is async and handles initialization
        agent = await Manus.create(
            memory_messages=[Message(role=Role.USER, content="Initial task for testing")],
            max_steps=5 # Set max_steps to trigger check-in logic if needed by should_request_feedback
        )
        agent.current_step = 5 # Align current_step with max_steps to trigger the check-in via should_request_feedback

        print("Manus agent instantiated.")
        print(f"Available tools: {[tool.name for tool in agent.available_tools]}")

        # Directly test periodic_user_check_in
        print("Calling periodic_user_check_in...")
        # Mock the AskHuman tool to prevent blocking
        original_ask_human_execute = agent.available_tools.get_tool("ask_human").execute
        async def mock_ask_human_execute(*args, **kwargs):
            print("Mock AskHuman called, returning 'continuar'")
            # Simulate adding user response to memory, as AskHuman tool might do
            agent.memory.add_message(Message(role=Role.USER, content="continuar"))
            return "continuar"
        agent.available_tools.get_tool("ask_human").execute = mock_ask_human_execute

        continue_execution = await agent.periodic_user_check_in()
        print(f"periodic_user_check_in call completed. Result: {continue_execution}")
        print(f"Agent state after check-in: {agent.state}")

        # Also test should_request_feedback which calls periodic_user_check_in
        print("Calling should_request_feedback...")
        agent._just_resumed_from_feedback = False # Reset flag
        agent.state = AgentState.RUNNING # Reset state
        should_pause = await agent.should_request_feedback()
        print(f"should_request_feedback call completed. Result: {should_pause}")
        print(f"Agent state after should_request_feedback: {agent.state}")

        print("Test completed successfully, no TypeError observed during StrReplaceEditor access.")

    except TypeError as e:
        if "cannot pickle 'socket' object" in str(e):
            print(f"TEST FAILED: Original TypeError was observed: {e}")
        else:
            print(f"TEST FAILED: An unexpected TypeError occurred: {e}")
            import traceback
            traceback.print_exc()
    except Exception as e:
        print(f"TEST FAILED: An unexpected error occurred: {e}")
        import traceback
        traceback.print_exc()
    finally:
        if agent:
            print("Cleaning up agent...")
            await agent.cleanup()
        # Clean up dummy workspace
        if os.path.exists(checklist_path):
            os.remove(checklist_path)
        # Check if manus_test_workspace exists and if it's empty before removing
        if os.path.exists(config.workspace_root):
            if not os.listdir(config.workspace_root):
                os.rmdir(config.workspace_root)
            else:
                # If not empty, perhaps remove the specific file created if it's known
                # For now, just log it.
                print(f"Workspace root {config.workspace_root} not empty, not removing directory.")
        else:
            print(f"Workspace root {config.workspace_root} does not exist, no need to remove.")


if __name__ == "__main__":
    asyncio.run(main())

```

### ARQUIVO: app/agent/critic_agent.py ###
```py
class CriticAgent:
    """
    VocÃª Ã© um Agente de Monitoramento e Refinamento de Horizonte Temporal, com o objetivo principal de otimizar a eficÃ¡cia e a confiabilidade da execuÃ§Ã£o de tarefas de longo horizonte para outros agentes de IA ou fluxos de trabalho complexos.

    Seu PropÃ³sito Principal: Sua funÃ§Ã£o Ã© fornecer feedback crÃ­tico, identificar desvios e redirecionar a execuÃ§Ã£o de tarefas para aumentar o horizonte temporal de sucesso, visando especialmente o alcance do Horizonte de Tempo de ConclusÃ£o de Tarefa de 50% (T50). O T50 Ã© definido como a duraÃ§Ã£o da tarefa (medida em tempo de um especialista humano qualificado) que o agente consegue concluir com 50% de confiabilidade.

    Monitoramento e AvaliaÃ§Ã£o CrÃ­tica: Para cada tarefa em execuÃ§Ã£o, vocÃª deve monitorar ativamente o progresso, as aÃ§Ãµes (utilizando o padrÃ£o ReAct: 'pensar' e 'agir') e o consumo de recursos. Sua avaliaÃ§Ã£o crÃ­tica deve focar em:
    â€¢
    Progresso em relaÃ§Ã£o ao T50: Estimar se o ritmo de execuÃ§Ã£o e a qualidade dos passos indicam que o T50 serÃ¡ alcanÃ§ado.
    â€¢
    IdentificaÃ§Ã£o de Erros e Loops: Detectar falhas repetitivas, ineficiÃªncias, desvios do plano original ou situaÃ§Ãµes onde o agente executor estÃ¡ preso em ciclos de repetiÃ§Ã£o (loops infinitos).
    â€¢
    Qualidade do RaciocÃ­nio e Uso de Ferramentas: Avaliar se o agente estÃ¡ utilizando as ferramentas de forma eficaz e se seu raciocÃ­nio estÃ¡ se aprofundando ou se deteriorando com a complexidade da tarefa.

    Mecanismo de Feedback e Redirecionamento (CrÃ­tico): Se sua anÃ¡lise indicar que o T50 da tarefa nÃ£o estÃ¡ sendo eficientemente alcanÃ§ado, ou se houver sinais de falha iminente ou persistente, vocÃª deve intervir. Sua intervenÃ§Ã£o inclui:
    â€¢
    Feedback Direto e Construtivo: Comunicar claramente o problema identificado ao agente executor (ou ao sistema de orquestraÃ§Ã£o), destacando a causa percebida do desvio ou da ineficiÃªncia.
    â€¢
    SugestÃ£o de Plano de AÃ§Ã£o Alternativo: Propor uma estratÃ©gia de correÃ§Ã£o, que pode envolver:
    â—¦
    ModificaÃ§Ã£o do plano de execuÃ§Ã£o atual (ex: redefinir subtarefas ou prioridades).
    â—¦
    A ativaÃ§Ã£o de um sub-agente especializado para uma etapa especÃ­fica (em sistemas multiagentes).
    â—¦
    A solicitaÃ§Ã£o de informaÃ§Ãµes adicionais (se for o caso, simulando uma interaÃ§Ã£o "human-in-the-loop" para clareza, como a ferramenta AskHuman).
    â€¢
    Redirecionamento da ExecuÃ§Ã£o na Mesma Tarefa: Crucialmente, seu objetivo Ã© redirecionar a execuÃ§Ã£o dentro da mesma tarefa em andamento, permitindo que o agente executor ajuste seu curso sem reiniciar o trabalho do zero. Preserve o contexto acumulado e o progresso jÃ¡ realizado, visto que a arquitetura do agente gerencia uma lista de mensagens (self.messages) contendo as trocas de sistema, usuÃ¡rio e assistente, e variÃ¡veis como resultados de ferramentas sÃ£o inseridas nessa lista para que o LLM considere na prÃ³xima iteraÃ§Ã£o de raciocÃ­nio.

    Contexto e Ferramentas: VocÃª terÃ¡ acesso completo ao estado interno do agente executor, incluindo o histÃ³rico de mensagens, o plano atual ({PlanoAtual}), os resultados de ferramentas e a memÃ³ria de curto e, se disponÃ­vel, de longo prazo. Utilize essa informaÃ§Ã£o para fundamentar suas anÃ¡lises e decisÃµes, visando a autocorreÃ§Ã£o e a adaptaÃ§Ã£o do sistema para um horizonte temporal mais longo e confiÃ¡vel.
    """

import re
from collections import Counter
from typing import Optional, Tuple, List, Dict, Any # Melhorando type hints

# Classe CriticAgent movida para baixo para que o type hint CriticAgent possa ser usado em ToolCallAgent
# se importado diretamente, mas como estÃ¡ em arquivos separados, isso nÃ£o Ã© um problema.

class CriticAgent:
    """
    VocÃª Ã© um Agente de Monitoramento e Refinamento de Horizonte Temporal, com o objetivo principal de otimizar a eficÃ¡cia e a confiabilidade da execuÃ§Ã£o de tarefas de longo horizonte para outros agentes de IA ou fluxos de trabalho complexos. Seu PropÃ³sito Principal: Sua funÃ§Ã£o Ã© fornecer feedback crÃ­tico, identificar desvios e redirecionar a execuÃ§Ã£o de tarefas para aumentar o horizonte temporal de sucesso, visando especialmente o alcance do Horizonte de Tempo de ConclusÃ£o de Tarefa de 50% (T50) â€“ a duraÃ§Ã£o da tarefa (medida em tempo de um especialista humano qualificado) que o agente consegue concluir com 50% de confiabilidade.
    Monitoramento e AvaliaÃ§Ã£o CrÃ­tica: Para cada tarefa em execuÃ§Ã£o, vocÃª deve monitorar ativamente o progresso, as aÃ§Ãµes (utilizando o padrÃ£o ReAct: 'pensar' e 'agir') e o consumo de recursos. Sua ativaÃ§Ã£o ocorrerÃ¡ a cada 5 etapas da execuÃ§Ã£o do agente principal. Sua avaliaÃ§Ã£o crÃ­tica deve focar em:
    â€¢
    Progresso em relaÃ§Ã£o ao T50: Estimar se o ritmo de execuÃ§Ã£o e a qualidade dos passos indicam que o T50 serÃ¡ alcanÃ§ado.
    â€¢
    IdentificaÃ§Ã£o de Erros e Loops: Detectar falhas repetitivas, ineficiÃªncias, desvios do plano ORIGINAL e da INTENÃ‡ÃƒO do usuÃ¡rio (abordando a falha de mÃ¡ interpretaÃ§Ã£o do prompt inicial), ou situaÃ§Ãµes onde o agente executor estÃ¡ preso em ciclos de repetiÃ§Ã£o (loops infinitos ou estagnaÃ§Ã£o). Considere tambÃ©m a auto-bias, onde o agente pode nÃ£o reconhecer seus prÃ³prios erros.
    â€¢
    Qualidade do RaciocÃ­nio e Uso de Ferramentas: Avaliar se o agente estÃ¡ utilizando as ferramentas de forma eficaz e se seu raciocÃ­nio estÃ¡ se aprofundando ou se deteriorando com a complexidade da tarefa. Investigue a causa raiz de falhas de ferramenta (ex: "empty text parameter", erros de sandbox, formato incorreto de API) e forneÃ§a diagnÃ³sticos especÃ­ficos.
    â€¢
    Discernimento: Seja crÃ­tico, porÃ©m realista e pragmÃ¡tico. Saiba reconhecer quando um processo estÃ¡ fluindo bem e quando nÃ£o estÃ¡, evitando intervenÃ§Ãµes desnecessÃ¡rias.
    Mecanismo de Feedback e Redirecionamento (CrÃ­tico): Se sua anÃ¡lise indicar que o T50 da tarefa nÃ£o estÃ¡ sendo eficientemente alcanÃ§ado, ou se houver sinais de falha iminente ou persistente, vocÃª deve intervir. Sua intervenÃ§Ã£o inclui:
    â€¢
    Feedback Direto e Construtivo: Comunicar claramente o problema identificado ao agente executor (ou ao sistema de orquestraÃ§Ã£o), destacando a causa percebida do desvio ou da ineficiÃªncia e, se possÃ­vel, a natureza do erro tÃ©cnico (ex: "Erro de parsing na ferramenta X", "Problema de sequÃªncia de mensagens na API do LLM").
    â€¢
    SugestÃ£o de Plano de AÃ§Ã£o Alternativo: Propor uma estratÃ©gia de correÃ§Ã£o detalhada, que pode envolver:
    â—¦
    ModificaÃ§Ã£o do plano de execuÃ§Ã£o atual (ex: redefinir subtarefas ou prioridades), especialmente se houver um desalinhamento com a intenÃ§Ã£o inicial do usuÃ¡rio.
    â—¦
    A ativaÃ§Ã£o de um sub-agente especializado para uma etapa especÃ­fica (em sistemas multiagentes, como um agente de depuraÃ§Ã£o ou um especialista em validaÃ§Ã£o de cÃ³digo).
    â—¦
    A solicitaÃ§Ã£o de informaÃ§Ãµes adicionais (se for o caso, simulando uma interaÃ§Ã£o "human-in-the-loop" para clareza, possivelmente invocando uma ferramenta AskHuman ou similar para feedback/aprovaÃ§Ã£o humana em pontos crÃ­ticos ou de alto risco).
    â—¦
    Para falhas de ferramenta: Sugerir retentativas adaptativas, sanitizaÃ§Ã£o de entradas/saÃ­das do LLM, ou o uso de ferramentas alternativas (considerando fixToolCallAgent e sanitizers).
    â€¢
    Redirecionamento da ExecuÃ§Ã£o na Mesma Tarefa: Crucialmente, seu objetivo Ã© redirecionar a execuÃ§Ã£o dentro da mesma tarefa em andamento, permitindo que o agente executor ajuste seu curso sem reiniciar o trabalho do zero. Preserve o contexto acumulado e o progresso jÃ¡ realizado, visto que a arquitetura do agente gerencia uma lista de mensagens (self.messages) contendo as trocas de sistema, usuÃ¡rio e assistente, e variÃ¡veis como resultados de ferramentas sÃ£o inseridas nessa lista para que o LLM considere na prÃ³xima iteraÃ§Ã£o de raciocÃ­nio.
    â€¢
    Alinhamento com Aprendizado por ReforÃ§o (RL): Suas sugestÃµes e o sucesso da auto-correÃ§Ã£o devem idealmente servir como sinais de recompensa para o OpenManus-RL, contribuindo para o fine-tuning do agente em trajetÃ³rias de interaÃ§Ã£o agÃªntica, aprimorando sua capacidade de ser um "bom agente" em cenÃ¡rios complexos.
    Contexto e Ferramentas: VocÃª terÃ¡ acesso completo ao estado interno do agente executor, incluindo o histÃ³rico de mensagens, o plano atual ({PlanoAtual}), os resultados de ferramentas e a memÃ³ria de curto e, se disponÃ­vel, de longo prazo. Utilize essa informaÃ§Ã£o para fundamentar suas anÃ¡lises e decisÃµes, visando a autocorreÃ§Ã£o e a adaptaÃ§Ã£o do sistema para um horizonte temporal mais longo e confiÃ¡vel. VocÃª deve considerar as limitaÃ§Ãµes de contexto do LLM e, quando apropriado, sugerir tÃ©cnicas de truncamento ou sumarizaÃ§Ã£o para otimizar o uso da memÃ³ria. Integre-se com as funcionalidades de logging e observabilidade para facilitar a depuraÃ§Ã£o e o monitoramento do seu prÃ³prio desempenho e do agente executor.
    """

    def __init__(self, llm_client: Any): # llm_client pode ser uma mock ou real LLM client
        """
        Inicializa o CriticAgent.

        Args:
            llm_client: Cliente LLM para usar para anÃ¡lises mais profundas (atualmente nÃ£o usado ativamente para gerar feedback).
        """
        self.llm_client = llm_client
        self.error_history: Counter[str] = Counter() # Rastreia a frequÃªncia de assinaturas de erro.
        self.max_error_frequency: int = 3      # Limite para um erro ser considerado excessivamente repetitivo.
        self.stagnation_step_threshold: int = 10 # NÂº de passos de revisÃ£o do crÃ­tico sem progresso no checklist para sinalizar estagnaÃ§Ã£o.
        # Guarda o nÃºmero de tarefas concluÃ­das na Ãºltima revisÃ£o para detectar estagnaÃ§Ã£o real.
        self.last_review_completed_tasks: Optional[int] = None

    def _parse_checklist_progress(self, checklist_markdown: str) -> Tuple[int, int]:
        """
        Parseia o markdown do checklist para contar tarefas totais e concluÃ­das.
        Espera-se que as tarefas sigam o formato GFM: "- [x] Tarefa ConcluÃ­da" ou "- [ ] Tarefa Pendente".
        Linhas que nÃ£o correspondem a este padrÃ£o sÃ£o ignoradas.

        Args:
            checklist_markdown: String contendo o checklist em formato markdown.

        Returns:
            Uma tupla (total_tasks, completed_tasks).
        """
        if not isinstance(checklist_markdown, str):
            return 0, 0

        total_tasks = 0
        completed_tasks = 0
        lines = checklist_markdown.splitlines()
        for line in lines:
            line = line.strip()
            if line.startswith("- ["):
                total_tasks += 1
                if line.startswith("- [x]") or line.startswith("- [X]"):
                    completed_tasks += 1
        return total_tasks, completed_tasks

    def review_plan_and_progress(self,
                                 current_plan_markdown: str,
                                 messages: List[Dict[str, Any]],
                                 tool_results: List[Dict[str, Any]],
                                 current_step: int,
                                 steps_since_last_review: int) -> Tuple[str, Optional[Dict[str, Any]]]:
        """
        Analisa o plano atual, histÃ³rico de mensagens e resultados de ferramentas para fornecer feedback
        e, se necessÃ¡rio, sugerir redirecionamentos com base em heurÃ­sticas de T50.

        Args:
            current_plan_markdown: String markdown do checklist/plano atual.
            messages: Lista de mensagens recentes (histÃ³rico da conversa).
            tool_results: Lista de resultados recentes de ferramentas.
            current_step: O nÃºmero total de passos de execuÃ§Ã£o do agente principal.
            steps_since_last_review: NÃºmero de passos do agente principal desde a Ãºltima revisÃ£o do crÃ­tico.

        Returns:
            Uma tupla contendo:
                - feedback (str): O feedback textual do crÃ­tico.
                - sugestao_redirecionamento (Optional[dict]): Um dicionÃ¡rio com a sugestÃ£o de aÃ§Ã£o
                  ou None se nenhuma sugestÃ£o crÃ­tica for feita.
        """

        # O prompt do sistema do crÃ­tico Ã© a docstring da classe.
        # {PlanoAtual} Ã© um placeholder que serÃ¡ preenchido.
        # system_prompt_for_llm = self.__doc__.format(PlanoAtual=current_plan_markdown)

        # A chamada ao LLM do crÃ­tico para anÃ¡lise semÃ¢ntica estÃ¡ desativada por padrÃ£o
        # para focar nas heurÃ­sticas programÃ¡ticas. Pode ser ativada se necessÃ¡rio.
        # llm_messages = [
        #     {"role": "system", "content": system_prompt_for_llm},
        #     {"role": "user", "content": (
        #         f"Analisando o progresso da tarefa na etapa {current_step}. "
        #         f"Passos desde a Ãºltima revisÃ£o: {steps_since_last_review}. "
        #         f"HistÃ³rico de mensagens (Ãºltimas {len(messages)}): {messages}. "
        #         f"Resultados das ferramentas (Ãºltimos {len(tool_results)}): {tool_results}."
        #         "Por favor, forneÃ§a uma avaliaÃ§Ã£o crÃ­tica e sugestÃµes de redirecionamento se necessÃ¡rio."
        #     )}
        # ]
        # llm_feedback_str = self.llm_client.chat.completions.create(...) # Chamada simulada

        total_checklist_tasks, completed_checklist_tasks_now = self._parse_checklist_progress(current_plan_markdown)

        t50_concerns: List[str] = [] # Lista para acumular preocupaÃ§Ãµes sobre T50.

        # 1. AnÃ¡lise de EstagnaÃ§Ã£o do Checklist
        # Verifica se houve progresso real no checklist desde a Ãºltima revisÃ£o.
        if self.last_review_completed_tasks is not None and \
           steps_since_last_review >= self.stagnation_step_threshold and \
           total_checklist_tasks > 0 and \
           completed_checklist_tasks_now == self.last_review_completed_tasks and \
           completed_checklist_tasks_now < total_checklist_tasks: # Garante que nÃ£o estÃ¡ apenas "preso" no final
            t50_concerns.append(
                f"EstagnaÃ§Ã£o do Checklist: {steps_since_last_review} etapas se passaram desde a Ãºltima revisÃ£o "
                f"sem que novas tarefas do checklist fossem concluÃ­das. "
                f"Progresso atual: {completed_checklist_tasks_now}/{total_checklist_tasks}."
            )
        # Atualiza o nÃºmero de tarefas concluÃ­das para a prÃ³xima revisÃ£o.
        self.last_review_completed_tasks = completed_checklist_tasks_now

        # Se for a primeira revisÃ£o (last_review_completed_tasks is None) e jÃ¡ passou o threshold de passos,
        # mas hÃ¡ tarefas pendentes, tambÃ©m pode ser um sinal inicial de lentidÃ£o.
        if self.last_review_completed_tasks is None and \
           steps_since_last_review >= self.stagnation_step_threshold and \
           total_checklist_tasks > 0 and \
           completed_checklist_tasks_now < total_checklist_tasks:
            t50_concerns.append(
                f"Progresso Lento Inicial: {steps_since_last_review} etapas se passaram na primeira fase de revisÃ£o "
                f"e o checklist ainda nÃ£o foi totalmente concluÃ­do ({completed_checklist_tasks_now}/{total_checklist_tasks})."
            )


        # 2. AnÃ¡lise de Erros Repetitivos
        # `tool_results` Ã© uma lista de dicts: {'name': str, 'content': str, 'tool_call_id': str}
        for result in tool_results:
            if isinstance(result, dict):
                tool_name = result.get("name", "unknown_tool")
                # O conteÃºdo do resultado da ferramenta jÃ¡ Ã© uma string de observaÃ§Ã£o formatada por ToolCallAgent.execute_tool
                # Ex: "Observed output of cmd `tool_name` executed:\nError: some error message"
                tool_content_str = str(result.get("content", "")).lower()

                error_signature: Optional[str] = None
                # Verifica se a observaÃ§Ã£o indica um erro.
                if tool_content_str.startswith("observed output") and "error:" in tool_content_str:
                    # Tenta extrair a mensagem de erro especÃ­fica.
                    match = re.search(r"error: (.*)", tool_content_str, re.IGNORECASE)
                    if match:
                        error_message_part = match.group(1)[:75].strip() # Primeiros 75 chars da mensagem de erro
                        error_signature = f"tool_error_{tool_name}_{error_message_part}"
                elif "traceback (most recent call last)" in tool_content_str: # Caso genÃ©rico de traceback
                     error_signature = f"traceback_{tool_name}"

                if error_signature:
                    self.error_history[error_signature] += 1
                    if self.error_history[error_signature] >= self.max_error_frequency:
                        t50_concerns.append(
                            f"Erro Repetitivo: A ferramenta '{tool_name}' parece estar falhando consistentemente. "
                            f"O erro (ou similar) ocorreu {self.error_history[error_signature]} vezes. "
                            f"Assinatura do erro: '{error_signature.split('_', 2)[-1]}'."
                        )
                        # NÃ£o resetar aqui; resetar apenas se uma sugestÃ£o de correÃ§Ã£o for explicitamente feita
                        # e o agente principal tentar essa correÃ§Ã£o.

        # --- GeraÃ§Ã£o de Feedback e SugestÃµes com base nas preocupaÃ§Ãµes T50 ---
        feedback: str = "AnÃ¡lise do CrÃ­tico:\n"
        sugestao_redirecionamento: Optional[Dict[str, Any]] = None

        if not t50_concerns:
            feedback += "O progresso parece razoÃ¡vel. Nenhuma preocupaÃ§Ã£o crÃ­tica de T50 identificada nesta revisÃ£o.\n"
        else:
            feedback += "Foram identificadas as seguintes preocupaÃ§Ãµes que podem afetar o T50 (progresso eficiente e confiÃ¡vel):\n"
            for concern in t50_concerns:
                feedback += f"- {concern}\n"

            # Priorizar sugestÃµes: Erros repetitivos sÃ£o geralmente mais crÃ­ticos
            if any("Erro Repetitivo" in concern for concern in t50_concerns):
                most_frequent_error_sig: Optional[str] = None
                max_freq = 0
                # Encontra o erro mais frequente que ATINGIU o threshold para a sugestÃ£o
                for sig, freq in self.error_history.items():
                    if freq >= self.max_error_frequency and freq > max_freq:
                        max_freq = freq
                        most_frequent_error_sig = sig

                failed_tool_name_from_sig = "desconhecida"
                error_details_from_sig = "nÃ£o especificado"
                if most_frequent_error_sig:
                     parts = most_frequent_error_sig.split('_', 2) # Divide em no mÃ¡ximo 3 partes
                     if len(parts) == 3 and parts[0] == "tool" and parts[1] == "error":
                         failed_tool_name_from_sig = parts[1] # Nome da ferramenta corrigido
                         error_details_from_sig = parts[2]
                     elif len(parts) >= 2 and parts[0] == "traceback": # Ex: traceback_toolname
                         failed_tool_name_from_sig = parts[1]
                         error_details_from_sig = "Traceback ocorrido"

                feedback += f"\nRecomendaÃ§Ã£o Principal: Investigar a causa raiz do erro repetitivo com '{failed_tool_name_from_sig}'. Detalhe: '{error_details_from_sig}'.\n"
                sugestao_redirecionamento = {
                    "action_type": "MODIFY_PLAN",
                    "details": {
                        "task_description": f"Investigar e corrigir a causa do erro repetitivo com a ferramenta '{failed_tool_name_from_sig}' (detalhe: {error_details_from_sig}).",
                        "priority": "crÃ­tica"
                    },
                    "clarification": f"Sugiro adicionar uma tarefa prioritÃ¡ria para resolver o erro com '{failed_tool_name_from_sig}' antes de prosseguir."
                }
                if most_frequent_error_sig: # Resetar o contador APÃ“S a sugestÃ£o ser feita.
                    self.error_history[most_frequent_error_sig] = 0

            elif any("EstagnaÃ§Ã£o do Checklist" in concern for concern in t50_concerns) or \
                 any("Progresso Lento Inicial" in concern for concern in t50_concerns):
                feedback += "\nRecomendaÃ§Ã£o Principal: Reavaliar a abordagem para as tarefas pendentes do checklist ou decompor tarefas complexas, pois o progresso parece lento.\n"
                sugestao_redirecionamento = {
                    "action_type": "REQUEST_HUMAN_INPUT",
                    "details": {
                        "question": (
                            "O progresso no checklist parece lento ou estagnado. "
                            "Gostaria de reavaliar o plano atual, decompor tarefas complexas, "
                            "ou sugerir uma nova abordagem para as tarefas pendentes?"
                        )
                    },
                    "clarification": "O progresso no checklist estÃ¡ mais lento que o esperado. Uma revisÃ£o do plano ou da estratÃ©gia pode ser necessÃ¡ria."
                }

        # LÃ³gica de fallback para sugestÃµes baseadas em palavras-chave (se nenhuma preocupaÃ§Ã£o T50 gerou sugestÃ£o)
        if not sugestao_redirecionamento:
            tool_results_str_lower = str(tool_results).lower()
            if "loop infinito detectado" in tool_results_str_lower:
                feedback += "\nSinal de loop infinito ou aÃ§Ã£o repetitiva. Reavaliar abordagem."
                sugestao_redirecionamento = {
                    "action_type": "MODIFY_PLAN",
                    "details": {"task_description": "Analisar e corrigir causa de loop/repetiÃ§Ã£o.", "priority": "alta"},
                    "clarification": "Detectado possÃ­vel loop. Sugiro investigar a causa."
                }
            elif "falha na ferramenta x" in tool_results_str_lower: # Exemplo genÃ©rico, pode ser mais especÃ­fico
                feedback += "\nA Ferramenta X parece estar falhando."
                sugestao_redirecionamento = {
                    "action_type": "SUGGEST_ALTERNATIVE_TOOL",
                    "details": {"failed_tool": "Ferramenta X", "alternative_tool_name": "Ferramenta Y_alternativa", "alternative_tool_args": {}},
                    "clarification": "A Ferramenta X falhou. Considere usar a Ferramenta Y_alternativa."
                }

        # Para depuraÃ§Ã£o, pode ser Ãºtil logar o histÃ³rico de erros do crÃ­tico.
        # logger.debug(f"Critic error history: {dict(self.error_history)}")

        return feedback, sugestao_redirecionamento

if __name__ == '__main__':
    # Exemplo de uso (para teste)
    class MockLLMClient:
        def __init__(self):
            self.chat = self._Chat()

        class _Chat:
            def __init__(self):
                self.completions = self._Completions()

            class _Completions:
                def create(self, model, messages):
                    class MockChoice:
                        def __init__(self):
                            self.message = self._Message()
                        class _Message:
                            def __init__(self):
                                self.content = "Feedback simulado do LLM: Tudo parece OK."
                    class MockResponse:
                        def __init__(self):
                            self.choices = [MockChoice()]
                    return MockResponse()

    # --- Testes UnitÃ¡rios ---
    mock_llm = MockLLMClient()
    critic = CriticAgent(llm_client=mock_llm)

    # Teste para _parse_checklist_progress
    print("\n--- Teste _parse_checklist_progress ---")
    checklist1 = """
    - [x] Tarefa 1
    - [ ] Tarefa 2
    - [X] Tarefa 3
    - Outra linha
    -    [ ] Tarefa 4 com espaÃ§o
    """
    total, completed = critic._parse_checklist_progress(checklist1)
    print(f"Checklist 1: Total={total}, ConcluÃ­das={completed} (Esperado: Total=4, ConcluÃ­das=2)")
    assert total == 4
    assert completed == 2

    checklist2 = "- [ ] a\n- [ ] b\n- [ ] c"
    total, completed = critic._parse_checklist_progress(checklist2)
    print(f"Checklist 2: Total={total}, ConcluÃ­das={completed} (Esperado: Total=3, ConcluÃ­das=0)")
    assert total == 3
    assert completed == 0

    checklist_vazio = ""
    total, completed = critic._parse_checklist_progress(checklist_vazio)
    print(f"Checklist Vazio: Total={total}, ConcluÃ­das={completed} (Esperado: Total=0, ConcluÃ­das=0)")
    assert total == 0
    assert completed == 0

    checklist_invalido = "NÃ£o Ã© um checklist"
    total, completed = critic._parse_checklist_progress(checklist_invalido)
    print(f"Checklist InvÃ¡lido: Total={total}, ConcluÃ­das={completed} (Esperado: Total=0, ConcluÃ­das=0)")
    assert total == 0
    assert completed == 0

    print("Testes de _parse_checklist_progress passaram!")

    # Testes para review_plan_and_progress
    print("\n--- Testes review_plan_and_progress ---")
    dummy_messages = [{"role": "user", "content": "iniciar"}]

    # CenÃ¡rio 1: Sem problemas
    print("\nCenÃ¡rio 1: Sem problemas")
    plan_ok = "- [x] T1\n- [x] T2"
    tool_results_ok = [{"name": "tool_a", "content": "sucesso", "tool_call_id": "1"}]
    critic.error_history.clear() # Limpar histÃ³rico de erros
    feedback, suggestion = critic.review_plan_and_progress(plan_ok, dummy_messages, tool_results_ok, current_step=5, steps_since_last_review=5)
    print(f"Feedback: {feedback.strip()}")
    print(f"SugestÃ£o: {suggestion}")
    assert suggestion is None
    assert "Nenhuma preocupaÃ§Ã£o crÃ­tica" in feedback

    # CenÃ¡rio 2: EstagnaÃ§Ã£o
    print("\nCenÃ¡rio 2: EstagnaÃ§Ã£o")
    plan_stagnant = "- [ ] T1\n- [ ] T2"
    critic.error_history.clear()
    feedback, suggestion = critic.review_plan_and_progress(plan_stagnant, dummy_messages, tool_results_ok, current_step=20, steps_since_last_review=critic.stagnation_step_threshold)
    print(f"Feedback: {feedback.strip()}")
    print(f"SugestÃ£o: {suggestion}")
    assert suggestion is not None
    assert suggestion["action_type"] == "REQUEST_HUMAN_INPUT"
    assert "EstagnaÃ§Ã£o potencial" in feedback

    # CenÃ¡rio 3: Erro Repetitivo
    print("\nCenÃ¡rio 3: Erro Repetitivo")
    plan_progress = "- [x] T1\n- [ ] T2"
    tool_results_error = [
        {"name": "tool_b", "content": "Error: falha crÃ­tica xyz", "tool_call_id": "2"},
        {"name": "tool_b", "content": "Error: falha crÃ­tica xyz", "tool_call_id": "3"},
        {"name": "tool_b", "content": "Error: falha crÃ­tica xyz", "tool_call_id": "4"},
    ]
    critic.error_history.clear() # Limpar para teste isolado
    # Simular chamadas anteriores que levaram ao erro repetitivo
    for _ in range(critic.max_error_frequency -1): # -1 porque a chamada abaixo conta como +1
         critic.review_plan_and_progress(plan_progress, dummy_messages, [tool_results_error[0]], current_step=10 + _, steps_since_last_review=1)

    feedback, suggestion = critic.review_plan_and_progress(plan_progress, dummy_messages, [tool_results_error[0]], current_step=15, steps_since_last_review=1)
    print(f"Feedback: {feedback.strip()}")
    print(f"SugestÃ£o: {suggestion}")
    assert suggestion is not None
    assert suggestion["action_type"] == "MODIFY_PLAN"
    assert "Erro repetitivo detectado" in feedback
    assert "tool_b" in suggestion["details"]["task_description"]
    # Verificar se o erro foi resetado no histÃ³rico (ou pelo menos nÃ£o estÃ¡ mais no threshold)
    assert critic.error_history[f"tool_error_tool_b_{'falha crÃ­tica xyz'}"] == 0


    # CenÃ¡rio 4: Loop infinito (palavra-chave)
    print("\nCenÃ¡rio 4: Loop Infinito (palavra-chave)")
    results_with_loop = [{"name": "tool_c", "content": "loop infinito detectado na etapa Y", "tool_call_id": "5"}]
    critic.error_history.clear()
    feedback_loop, suggestion_loop = critic.review_plan_and_progress(plan_progress, dummy_messages, results_with_loop, current_step=20, steps_since_last_review=3)
    print(f"Feedback: {feedback_loop.strip()}")
    print(f"SugestÃ£o: {suggestion_loop}")
    assert suggestion_loop is not None
    assert suggestion_loop["action_type"] == "MODIFY_PLAN"
    assert "loop infinito detectado" in results_with_loop[0]["content"] # Verifica se a entrada estÃ¡ correta
    assert "Sinal de loop infinito" in feedback_loop # Verifica se o feedback reflete isso
    assert "Analisar e corrigir causa de loop/repetiÃ§Ã£o" in suggestion_loop["details"]["task_description"]

    print("\nTestes de review_plan_and_progress passaram!")

```

### ARQUIVO: app/agent/base.py ###
```py
import asyncio
from abc import ABC, abstractmethod
from contextlib import asynccontextmanager
from typing import List, Optional

from pydantic import BaseModel, Field, model_validator

from app.llm import LLM
from app.logger import logger
from app.sandbox.client import SANDBOX_CLIENT
from app.schema import ROLE_TYPE, AgentState, Memory, Message


class BaseAgent(BaseModel, ABC):
    """Abstract base class for managing agent state and execution.

    Provides foundational functionality for state transitions, memory management,
    and a step-based execution loop. Subclasses must implement the `step` method.
    """

    # Core attributes
    name: str = Field(..., description="Unique name of the agent")
    description: Optional[str] = Field(None, description="Optional agent description")

    # Prompts
    system_prompt: Optional[str] = Field(
        None, description="System-level instruction prompt"
    )
    next_step_prompt: Optional[str] = Field(
        None, description="Prompt for determining next action"
    )

    # Dependencies
    llm: LLM = Field(default_factory=LLM, description="Language model instance")
    memory: Memory = Field(default_factory=Memory, description="Agent's memory store")
    state: AgentState = Field(
        default=AgentState.IDLE, description="Current agent state"
    )

    # Execution control
    max_steps: int = Field(default=10, description="Maximum steps before termination")
    current_step: int = Field(default=0, description="Current step in execution")
    user_pause_requested_event: asyncio.Event = Field(default_factory=asyncio.Event, description="Event to signal a user-initiated pause.")
    # interaction_interval: int = 20 # Interval for periodic user interaction - Removed as per new design
    tool_calls: Optional[List[dict]] = Field(default=None, description="Tool calls generated in the last step")

    duplicate_threshold: int = 2

    class Config:
        arbitrary_types_allowed = True
        extra = "allow"  # Allow extra fields for flexibility in subclasses

    @model_validator(mode="after")
    def initialize_agent(self) -> "BaseAgent":
        """Initialize agent with default settings if not provided."""
        if self.llm is None or not isinstance(self.llm, LLM):
            self.llm = LLM(config_name=self.name.lower())
        if not isinstance(self.memory, Memory):
            self.memory = Memory()
        return self

    @asynccontextmanager
    async def state_context(self, new_state: AgentState):
        """Context manager for safe agent state transitions.

        Args:
            new_state: The state to transition to during the context.

        Yields:
            None: Allows execution within the new state.

        Raises:
            ValueError: If the new_state is invalid.
        """
        if not isinstance(new_state, AgentState):
            raise ValueError(f"Invalid state: {new_state}")

        previous_state = self.state
        self.state = new_state # Actual assignment happens here
        try:
            yield
        except Exception as e:
            self.state = AgentState.ERROR  # Transition to ERROR on failure
            raise e
        finally:
            # Only revert to previous_state if the state wasn't set to a terminal one
            # within the context.
            if self.state not in [
                AgentState.FINISHED,
                AgentState.ERROR,
                AgentState.USER_HALTED,
                AgentState.AWAITING_USER_FEEDBACK,
                AgentState.USER_PAUSED, # Add this line
            ]:
                self.state = previous_state
            else:
                pass # State is terminal or AWAITING_USER_FEEDBACK, not reverting.
            # If it IS a terminal state, leave it as is.

    def update_memory(
        self,
        role: ROLE_TYPE,  # type: ignore
        content: str,
        base64_image: Optional[str] = None,
        **kwargs,
    ) -> None:
        """Add a message to the agent's memory.

        Args:
            role: The role of the message sender (user, system, assistant, tool).
            content: The message content.
            base64_image: Optional base64 encoded image.
            **kwargs: Additional arguments (e.g., tool_call_id for tool messages).

        Raises:
            ValueError: If the role is unsupported.
        """
        message_map = {
            "user": Message.user_message,
            "system": Message.system_message,
            "assistant": Message.assistant_message,
            "tool": lambda content, **kw: Message.tool_message(content, **kw),
        }

        if role not in message_map:
            raise ValueError(f"Unsupported message role: {role}")

        # Create message with appropriate parameters based on role
        kwargs = {"base64_image": base64_image, **(kwargs if role == "tool" else {})}
        self.memory.add_message(message_map[role](content, **kwargs))

    async def run(self, request: Optional[str] = None) -> str:
        # Step 0: Initial validation and state setup
        if self.state == AgentState.IDLE:
            if request:
                self.update_memory("user", request)
            self.state = AgentState.RUNNING
        elif self.state == AgentState.AWAITING_USER_FEEDBACK:
            if request: # Se um novo request/input do usuÃ¡rio for fornecido diretamente ao run()
                self.update_memory("user", request)
                self.state = AgentState.RUNNING # Mudar para RUNNING para processar o novo request
            else: # Se run() for chamado sem novo request, mas esperamos que o feedback jÃ¡ esteja na memÃ³ria
                self.state = AgentState.RUNNING # Mudar para RUNNING para continuar o processamento
        elif self.state == AgentState.RUNNING: # Explicitly allow re-calling run if already running (e.g. internal restart)
             if request: # If a new request is passed, it might mean a change of plans.
                 self.update_memory("user", request)
        else:
            logger.error(f"Run method called on agent in an unstartable/unresumable state: {self.state.value}. Raising RuntimeError.")
            raise RuntimeError(f"Cannot run/resume agent from state: {self.state.value}")

        results: List[str] = []

        outer_loop_iterations = 0
        while self.state == AgentState.RUNNING: # Modified loop condition
            outer_loop_iterations += 1

            # REMOVED THE IF BLOCK that transitioned AWAITING_USER_FEEDBACK to RUNNING here

            async with self.state_context(AgentState.RUNNING): # new_state is RUNNING

                while self.state not in [AgentState.FINISHED, AgentState.ERROR, AgentState.USER_HALTED, AgentState.USER_PAUSED]:
                    self.current_step += 1

                    if hasattr(self, 'user_pause_requested_event') and self.user_pause_requested_event.is_set():
                        self.user_pause_requested_event.clear()
                        self.state = AgentState.USER_PAUSED
                        break # Break the inner step execution loop

                    if await self.should_request_feedback():
                        self.state = AgentState.AWAITING_USER_FEEDBACK
                        break

                    if self.state in [AgentState.FINISHED, AgentState.ERROR, AgentState.USER_HALTED, AgentState.AWAITING_USER_FEEDBACK]:
                        break

                    step_result = await self.step()
                    results.append(f"Step {self.current_step}: {step_result}") # step_result can be very long, so original log is better

                    if self.is_stuck():
                        self.handle_stuck_state()

            # After state_context is done:
            if self.state == AgentState.AWAITING_USER_FEEDBACK:
                break
            elif self.state == AgentState.USER_PAUSED:
                break

            if self.state not in [AgentState.RUNNING]: # If state changed to FINISHED, ERROR, USER_HALTED inside context
                break

        # New conditional logic for determining final agent state
        if self.state == AgentState.USER_HALTED:
            pass
            # State remains USER_HALTED. No reset to IDLE here.
        elif self.state == AgentState.AWAITING_USER_FEEDBACK:
            pass
            # State remains AWAITING_USER_FEEDBACK.
        elif self.state == AgentState.USER_PAUSED:
            # State remains USER_PAUSED.
            pass
        elif self.current_step >= self.max_steps and self.max_steps > 0:
            self.state = AgentState.FINISHED
        elif not self.tool_calls and self.state == AgentState.RUNNING: # This condition might need re-evaluation with tool_calls being on Manus
            self.state = AgentState.FINISHED
        elif self.state == AgentState.RUNNING: # Fallback for RUNNING state
            self.state = AgentState.FINISHED
        elif self.state == AgentState.ERROR:
            pass
            # State remains ERROR
        elif self.state == AgentState.FINISHED: # If already FINISHED by step logic
            pass
            # State remains FINISHED
        # Note: AgentState.IDLE, AgentState.INIT, AgentState.PAUSED (distinct from AWAITING_USER_FEEDBACK)
        # are not typically expected here if the main loop ran. If they occur, it's unusual.
        else:
            logger.error(f"Execution ended with an unexpected or unhandled state: {self.state.value} at step {self.current_step}. Review agent logic.") # Original log
            # Forcing a defined state like ERROR might be an option here if this case is problematic.
            # For now, it will retain the unexpected state.

        # Final log message reflecting the decided state.

        # Append a final status message to results for the return string.
        # This replaces the old run_result_message.
        final_summary = f"Execution concluded. Final state: {self.state.value}, Current step: {self.current_step}."
        results.append(final_summary)

        await SANDBOX_CLIENT.cleanup()
        return "\n".join(results) if results else "No steps executed or execution ended."

    @abstractmethod
    async def step(self) -> str:
        """Execute a single step in the agent's workflow.

        Must be implemented by subclasses to define specific behavior.
        """

    @abstractmethod
    async def should_request_feedback(self) -> bool:
        """Determines if the agent should pause and request user feedback.

        Must be implemented by subclasses to define specific feedback conditions.
        """

    def handle_stuck_state(self):
        """Handle stuck state by adding a prompt to change strategy"""
        stuck_prompt = "\
        Observed duplicate responses. Consider new strategies and avoid repeating ineffective paths already attempted."
        self.next_step_prompt = f"{stuck_prompt}\n{self.next_step_prompt}"

    def is_stuck(self) -> bool:
        """Check if the agent is stuck in a loop by detecting duplicate content"""
        if len(self.memory.messages) < 2:
            return False

        last_message = self.memory.messages[-1]
        if not last_message.content:
            return False

        # Count identical content occurrences
        duplicate_count = sum(
            1
            for msg in reversed(self.memory.messages[:-1])
            if msg.role == "assistant" and msg.content == last_message.content
        )

        return duplicate_count >= self.duplicate_threshold

    @property
    def messages(self) -> List[Message]:
        """Retrieve a list of messages from the agent's memory."""
        return self.memory.messages

    @messages.setter
    def messages(self, value: List[Message]):
        """Set the list of messages in the agent's memory."""
        self.memory.messages = value

```

### ARQUIVO: app/agent/self_coding_agent.py ###
```py
import re
from typing import List, Dict, Any, Optional

from pydantic import Field, model_validator

from app.agent.base import BaseAgent, AgentState
from app.llm.llm_client import LLMClient
from app.memory.base import Message, MessageRole
from app.tool.sandbox_python_executor import SandboxPythonExecutor
from app.config import AgentSettings


class SelfCodingAgent(BaseAgent):
    """
    A specialized agent that autonomously generates, executes, and iteratively
    corrects Python code to accomplish a given task.

    The agent operates by:
    1. Receiving a task description.
    2. Generating Python code using an LLM.
    3. Executing the code in a secure sandbox environment via `SandboxPythonExecutor`.
    4. Analyzing the execution results (stdout, stderr, exit code).
    5. If execution fails or produces errors, the agent attempts to correct the
       code by re-prompting the LLM with the original task, the faulty code,
       and its output.
    6. This correction process iterates up to `max_correction_attempts`.

    Key Attributes:
        name (str): "SelfCodingAgent".
        description (str): A brief description of the agent's capabilities.
        system_prompt (str): The base prompt used to instruct the LLM for code generation and correction.
        sandbox_executor_tool (SandboxPythonExecutor): The tool used for executing Python code.
        max_correction_attempts (int): Maximum number of times the agent will try to correct failing code.
        current_task_description (Optional[str]): The description of the current task being processed.
        current_code_to_execute (Optional[str]): The Python code currently being evaluated or corrected.
        current_correction_attempts (int): The number of correction attempts made for the current code.
    """

    name: str = "SelfCodingAgent"
    description: str = (
        "An agent that can generate, execute, and iteratively correct Python code "
        "in a sandbox environment."
    )
    system_prompt: str = (
        "You are an AI assistant that writes Python code to solve problems. "
        "Given a task, write a Python script that accomplishes it. "
        "The script will be executed in a sandbox environment. "
        "Ensure your code uses print statements for any output you want to be visible. "
        "Only the output from print statements will be captured as stdout. "
        "Your response should contain *only* the Python code, preferably in a "
        "single markdown block (e.g., ```python ... ```). "
        "Do not include any explanatory text outside the code block. "
        "If you are asked to correct code, provide the full corrected script."
    )

    sandbox_executor_tool: SandboxPythonExecutor = Field(default_factory=SandboxPythonExecutor)
    max_correction_attempts: int = 3
    default_execution_timeout: int = 30  # Added default execution timeout
    current_correction_attempts: int = 0

    # State for the current task being processed
    current_task_description: Optional[str] = None
    current_code_to_execute: Optional[str] = None

    @model_validator(mode="after")
    def validate_agent_state(self) -> "SelfCodingAgent":
        if not isinstance(self.sandbox_executor_tool, SandboxPythonExecutor):
            self.sandbox_executor_tool = SandboxPythonExecutor()
        # Initialize mutable state attributes for clarity, though run() will also manage them per task
        self.current_task_description = None
        self.current_code_to_execute = None
        self.current_correction_attempts = 0
        return self

    def _extract_python_code(self, llm_response: str) -> str:
        """
        Extracts Python code from the LLM's response string.

        It looks for Markdown code blocks, specifically:
        - ```python ... ``` (preferred)
        - ``` ... ``` (generic)

        If no Markdown block is found, it assumes the entire response string
        is the code, after stripping leading/trailing whitespace.

        Args:
            llm_response: The string response from the LLM.

        Returns:
            The extracted Python code as a string, or the original response
            stripped if no code block is found.
        """
        match_python = re.search(r"```python\s*(.*?)\s*```", llm_response, re.DOTALL | re.IGNORECASE)
        if match_python:
            return match_python.group(1).strip()

        match_generic = re.search(r"```\s*(.*?)\s*```", llm_response, re.DOTALL)
        if match_generic:
            return match_generic.group(1).strip()

        return llm_response.strip()

    async def step(self) -> str:
        """
        Performs a single step in the agent's problem-solving process.

        This method handles one iteration of the generate-execute-evaluate-correct loop.
        If no code is currently being processed (`self.current_code_to_execute` is None),
        it attempts to generate initial code based on `self.current_task_description`.
        Otherwise, it executes the `self.current_code_to_execute`.

        Based on the execution outcome:
        - If successful, it sets the agent state to `FINISHED`.
        - If failed, it attempts to generate a correction from the LLM, unless
          `max_correction_attempts` has been reached.

        The method logs its actions and observations to the agent's memory and
        returns a string summarizing the outcome of the step.

        Returns:
            A string message summarizing the result of the step, e.g.,
            "Code executed successfully.", "Execution failed. Attempting correction...",
            or an error message if a critical failure occurs.
        """
        if self.state == AgentState.FINISHED or self.state == AgentState.ERROR:
            return "Task already finished or in an error state. Start a new task via run()."

        if not self.current_task_description:
            self.memory.add_message(Message(role=MessageRole.SYSTEM, content="Error: No task description available."))
            self.state = AgentState.ERROR
            return "Error: No task description. Cannot proceed."

        # Initial Code Generation (if no code is currently being worked on)
        if self.current_code_to_execute is None:
            self.current_correction_attempts = 0 # Reset for the first attempt of this task
            self.memory.add_message(Message(role=MessageRole.SYSTEM, content=f"Starting task: {self.current_task_description}"))
            self.memory.add_message(Message(role=MessageRole.SYSTEM, content="Attempting to generate initial code for the task.")) # Log point 1

            llm_messages: List[Message] = [
                Message(role=MessageRole.SYSTEM, content=self.system_prompt),
                Message(role=MessageRole.USER, content=f"The task is: {self.current_task_description}")
            ]

            try:
                llm_response_message = await self.llm.chat_completion_async(messages=llm_messages)
                self.memory.add_message(llm_response_message)
            except Exception as e:
                self.memory.add_message(Message(role=MessageRole.SYSTEM, content=f"Error during initial LLM call: {str(e)}"))
                self.state = AgentState.ERROR
                return f"Error during initial code generation: {str(e)}"

            generated_code_text = llm_response_message.content
            extracted_code = self._extract_python_code(generated_code_text)
            self.memory.add_message(Message(role=MessageRole.SYSTEM, content="Initial code generated successfully.")) # Log point 2

            if not extracted_code:
                error_msg = "Code generation failed: LLM did not return any code."
                self.memory.add_message(Message(role=MessageRole.SYSTEM, content=error_msg))
                self.state = AgentState.ERROR # Cannot proceed without code
                return error_msg

            self.current_code_to_execute = extracted_code
            self.memory.add_message(Message(role=MessageRole.SYSTEM, content=f"Attempt {self.current_correction_attempts + 1}. Code to execute:\n```python\n{self.current_code_to_execute}\n```"))

        # Code Execution
        if not self.current_code_to_execute: # Should not happen if initial generation logic is correct
            self.state = AgentState.ERROR
            return "Error: No code available for execution."

        self.memory.add_message(Message(role=MessageRole.SYSTEM, content=f"Preparing to execute code for attempt {self.current_correction_attempts + 1}...")) # Log point 3
        try:
            execution_result = await self.sandbox_executor_tool.execute(
                code=self.current_code_to_execute, timeout=self.default_execution_timeout
            )
            self.memory.add_message(Message(role=MessageRole.SYSTEM, content="Code execution finished. Analyzing results...")) # Log point 4
        except Exception as e:
            # This catches unexpected errors from the sandbox tool itself
            self.memory.add_message(Message(role=MessageRole.SYSTEM, content=f"Error during code execution tool call: {str(e)}"))
            self.state = AgentState.ERROR
            return f"Error calling sandbox executor: {str(e)}"

        # Store execution result
        exec_stdout = execution_result.get("stdout", "")
        exec_stderr = execution_result.get("stderr", "")
        exec_exit_code = execution_result.get("exit_code", -1)

        result_message_content = (
            f"Execution Attempt {self.current_correction_attempts + 1} Result:\n"
            f"Exit Code: {exec_exit_code}\n"
            f"Stdout:\n{exec_stdout}\n"
            f"Stderr:\n{exec_stderr}"
        )
        self.memory.add_message(Message(role=MessageRole.SYSTEM, content=result_message_content))

        # Evaluation and Correction Loop
        # Success condition: exit code 0 and no stderr (or stderr is acceptable)
        # For now, strict: exit code 0 and empty stderr.
        if exec_exit_code == 0 and not exec_stderr:
            success_msg = f"Code executed successfully.\nOutput:\n{exec_stdout}"
            self.memory.add_message(Message(role=MessageRole.SYSTEM, content=success_msg))
            self.state = AgentState.FINISHED
            self.current_code_to_execute = None # Clear code for next task
            # self.current_task_description = None # Clear task for next run
            return success_msg
        else: # Execution failed or had errors/warnings in stderr
            self.current_correction_attempts += 1
            if self.current_correction_attempts >= self.max_correction_attempts:
                failure_msg = (
                    f"Code execution failed after {self.max_correction_attempts} attempts.\n"
                    f"Last Exit Code: {exec_exit_code}\n"
                    f"Last Stderr:\n{exec_stderr}\n"
                    f"Last Stdout:\n{exec_stdout}"
                )
                self.memory.add_message(Message(role=MessageRole.SYSTEM, content=failure_msg))
                self.state = AgentState.ERROR # Or FINISHED if error state is terminal for the task
                self.current_code_to_execute = None # Clear code
                # self.current_task_description = None
                return failure_msg
            else:
                # Attempt correction
                self.memory.add_message(Message(role=MessageRole.SYSTEM, content="Execution failed. Preparing to attempt code correction.")) # Log point 5
                self.memory.add_message(Message(role=MessageRole.SYSTEM, content="Attempting code correction."))
                correction_prompt_parts = [
                    self.system_prompt, # Re-iterate overall goal
                    f"The original task was: {self.current_task_description}",
                    f"The following Python code was executed:\n```python\n{self.current_code_to_execute}\n```",
                    f"It produced the following output (stdout):\n```\n{exec_stdout}\n```",
                    f"And the following errors (stderr):\n```\n{exec_stderr}\n```",
                    f"The exit code was: {exec_exit_code}",
                    "Please analyze the error and provide a corrected version of the Python script. "
                    "Ensure the full corrected script is provided in a single markdown block. "
                    "Do not include any explanatory text outside the code block."
                ]
                # Use a history of messages for correction to give context
                # For now, we can just use the last few relevant messages or build a specific prompt.
                # The memory already contains the task, previous code, and its output.
                # We can create a focused list of messages for the LLM.

                # Simplified: Construct a user message with all context for correction
                correction_user_message = Message(role=MessageRole.USER, content="\n".join(correction_prompt_parts[1:]))

                llm_correction_messages: List[Message] = [
                     Message(role=MessageRole.SYSTEM, content=self.system_prompt), # System prompt
                     # Include some history if useful - e.g. original user task, last assistant code, last tool output
                     # For this version, the correction_user_message is comprehensive.
                     correction_user_message
                ]

                try:
                    llm_corrected_response = await self.llm.chat_completion_async(messages=llm_correction_messages)
                    self.memory.add_message(llm_corrected_response)
                    self.memory.add_message(Message(role=MessageRole.SYSTEM, content="Corrected code received from LLM.")) # Log point 6
                except Exception as e:
                    self.memory.add_message(Message(role=MessageRole.SYSTEM, content=f"Error during LLM call for correction: {str(e)}"))
                    # Decide if this failure means we stop or if the old code is re-attempted (potentially risky)
                    # For now, let's assume an LLM error here might lead to retrying with old code or erroring out.
                    # Let's be safe: if LLM for correction fails, we error out this attempt.
                    self.state = AgentState.ERROR
                    return f"Error during LLM call for code correction: {str(e)}"

                new_code_text = llm_corrected_response.content
                extracted_new_code = self._extract_python_code(new_code_text)

                if not extracted_new_code:
                    # LLM failed to provide corrected code
                    self.memory.add_message(Message(role=MessageRole.SYSTEM, content="LLM did not provide any corrected code.")) # Log point 7
                    error_msg = "Correction attempt failed: LLM did not return any code for correction."
                    self.memory.add_message(Message(role=MessageRole.SYSTEM, content=error_msg))
                    # We don't change self.current_code_to_execute, so next step will re-run the *previous* failed code.
                    # This might not be ideal. Alternatively, we could count this as a failed attempt and stop if maxed out.
                    # For now, this counts as an attempt. If it happens repeatedly, max_correction_attempts will be hit.
                    # Let's return the error_msg; the loop in run() will call step() again.
                    return error_msg

                self.current_code_to_execute = extracted_new_code
                self.memory.add_message(Message(role=MessageRole.SYSTEM, content=f"Attempt {self.current_correction_attempts + 1}. Corrected code to execute:\n```python\n{self.current_code_to_execute}\n```"))

                # State remains RUNNING, next call to step will execute the corrected code
                return (
                    f"Execution failed. Attempting correction "
                    f"({self.current_correction_attempts}/{self.max_correction_attempts})..."
                )

    async def run(
        self, request: str, config: Optional[AgentSettings] = None
    ) -> Dict[str, Any]:
        """
        Main entry point to run the SelfCodingAgent to accomplish a given task.

        This method orchestrates the agent's lifecycle for a single task request:
        1. Initializes or updates the LLM client based on provided `config`.
        2. Sets up the agent's internal state for the new task (`current_task_description`,
           clears `current_code_to_execute`, resets `current_correction_attempts`).
        3. Adds the user's `request` to the agent's memory.
        4. Enters a loop, repeatedly calling the `step()` method as long as the
           agent's state is `RUNNING`. Each call to `step()` represents one iteration
           of code generation/execution/correction.
        5. The loop continues until the `step()` method changes the agent's state
           to `FINISHED` (on success) or `ERROR` (if max attempts are reached or an
           unrecoverable error occurs).
        6. A loop guard is in place to prevent potential infinite loops during development.

        Args:
            request: A string describing the task for the agent to accomplish.
            config: Optional `AgentSettings` to configure the agent, particularly
                    LLM settings.

        Returns:
            A dictionary containing the final outcome of the agent's execution:
            - "response" (str): The final message from the agent, indicating success
                                or the nature of the failure.
            - "status" (AgentState): The final state of the agent.
            - "memory" (str): A string representation of all messages (interactions,
                              thoughts, tool outputs) logged by the agent during its run.
        """
        self.memory.add_message(Message(role=MessageRole.USER, content=request))

        if config and config.llm_settings:
            self.llm = LLMClient(settings=config.llm_settings)
        elif not self.llm: # Ensure LLM is initialized
            # Assuming BaseAgent or a global default LLM client is available
            # If not, this would need proper initialization.
            # For now, we assume self.llm is valid.
            pass

        # Initialize state for a new task
        self.current_task_description = request
        self.current_code_to_execute = None # Start with no code
        self.current_correction_attempts = 0
        self.state = AgentState.RUNNING

        response_content = "Agent started..." # Initial response

        # The BaseAgent's run loop might handle max_steps.
        # This internal loop ensures step() is called until state is FINISHED or ERROR.
        loop_guard = 0 # To prevent infinite loops in dev if state isn't set correctly
        max_loops = self.max_correction_attempts + 5 # Allow for initial + corrections + some buffer

        while self.state == AgentState.RUNNING and loop_guard < max_loops:
            step_result = await self.step()
            response_content = step_result # Update response with the latest from step
            loop_guard +=1
            if loop_guard >= max_loops and self.state == AgentState.RUNNING:
                self.memory.add_message(Message(role=MessageRole.SYSTEM, content="Error: Agent seems stuck in a loop."))
                self.state = AgentState.ERROR
                response_content = "Error: Agent exceeded maximum internal loops."

        # Final response structure
        return {
            "response": response_content, # The final message from the last step
            "status": self.state.value,
            "memory": self.memory.get_messages_str(), # Or a more structured representation
        }

```

```

### ARQUIVO: app/agent/browser.py ###
```py
import json
from typing import TYPE_CHECKING, Optional

from pydantic import Field, model_validator

from app.agent.toolcall import ToolCallAgent
from app.logger import logger
from app.prompt.browser import NEXT_STEP_PROMPT, SYSTEM_PROMPT
from app.schema import Message, ToolChoice
from app.tool import BrowserUseTool, Terminate, ToolCollection # Restaurado


# Avoid circular import if BrowserAgent needs BrowserContextHelper
if TYPE_CHECKING:
    from app.agent.base import BaseAgent  # Or wherever memory is defined


class BrowserContextHelper:
    def __init__(self, agent: "BaseAgent"):
        self.agent = agent
        self._current_base64_image: Optional[str] = None

    async def get_browser_state(self) -> Optional[dict]:
        browser_tool = self.agent.available_tools.get_tool(BrowserUseTool().name) # Restaurado
        if not browser_tool or not hasattr(browser_tool, "get_current_state"):
            logger.warning("BrowserUseTool not found or doesn't have get_current_state") # Restaurado
            return None
        try:
            result = await browser_tool.get_current_state()
            if result.error:
                logger.debug(f"Browser state error: {result.error}")
                return None
            if hasattr(result, "base64_image") and result.base64_image:
                self._current_base64_image = result.base64_image
            else:
                self._current_base64_image = None
            return json.loads(result.output)
        except Exception as e:
            logger.debug(f"Failed to get browser state: {str(e)}")
            return None

    async def format_next_step_prompt(self) -> str:
        """Gets browser state and formats the browser prompt."""
        browser_state = await self.get_browser_state()
        url_info, tabs_info, content_above_info, content_below_info = "", "", "", ""
        results_info = ""  # Or get from agent if needed elsewhere

        if browser_state and not browser_state.get("error"):
            url_info = f"\n   URL: {browser_state.get('url', 'N/A')}\n   Title: {browser_state.get('title', 'N/A')}"
            tabs = browser_state.get("tabs", [])
            if tabs:
                tabs_info = f"\n   {len(tabs)} tab(s) available"
            pixels_above = browser_state.get("pixels_above", 0)
            pixels_below = browser_state.get("pixels_below", 0)
            if pixels_above > 0:
                content_above_info = f" ({pixels_above} pixels)"
            if pixels_below > 0:
                content_below_info = f" ({pixels_below} pixels)"

            if self._current_base64_image:
                image_message = Message.user_message(
                    content="Current browser screenshot:",
                    base64_image=self._current_base64_image,
                )
                self.agent.memory.add_message(image_message)
                self._current_base64_image = None  # Consume the image after adding

        return NEXT_STEP_PROMPT.format(
            url_placeholder=url_info,
            tabs_placeholder=tabs_info,
            content_above_placeholder=content_above_info,
            content_below_placeholder=content_below_info,
            results_placeholder=results_info,
        )

    async def cleanup_browser(self):
        browser_tool = self.agent.available_tools.get_tool(BrowserUseTool().name) # Restaurado
        if browser_tool and hasattr(browser_tool, "cleanup"):
            await browser_tool.cleanup()


class BrowserAgent(ToolCallAgent):
    """
    A browser agent that uses the browser_use library to control a browser.

    This agent can navigate web pages, interact with elements, fill forms,
    extract content, and perform other browser-based actions to accomplish tasks.
    """

    name: str = "browser"
    description: str = "A browser agent that can control a browser to accomplish tasks"

    system_prompt: str = SYSTEM_PROMPT
    next_step_prompt: str = NEXT_STEP_PROMPT

    max_observe: int = 10000
    max_steps: int = 20

    # Configure the available tools
    available_tools: ToolCollection = Field(
        default_factory=lambda: ToolCollection(BrowserUseTool(), Terminate()) # Restaurado
    )

    # Use Auto for tool choice to allow both tool usage and free-form responses
    tool_choices: ToolChoice = ToolChoice.AUTO
    special_tool_names: list[str] = Field(default_factory=lambda: [Terminate().name])

    browser_context_helper: Optional[BrowserContextHelper] = None

    @model_validator(mode="after")
    def initialize_helper(self) -> "BrowserAgent":
        self.browser_context_helper = BrowserContextHelper(self)
        return self

    async def think(self) -> bool:
        """Process current state and decide next actions using tools, with browser state info added"""
        self.next_step_prompt = (
            await self.browser_context_helper.format_next_step_prompt()
        )
        return await super().think()

    async def cleanup(self):
        """Clean up browser agent resources by calling parent cleanup."""
        await self.browser_context_helper.cleanup_browser()

```

### ARQUIVO: app/agent/mcp.py ###
```py
from typing import Any, Dict, List, Optional, Tuple

from pydantic import Field

from app.agent.toolcall import ToolCallAgent
from app.logger import logger
from app.prompt.mcp import MULTIMEDIA_RESPONSE_PROMPT, NEXT_STEP_PROMPT, SYSTEM_PROMPT
from app.schema import AgentState, Message
from app.tool.base import ToolResult
from app.tool.mcp import MCPClients


class MCPAgent(ToolCallAgent):
    """Agent for interacting with MCP (Model Context Protocol) servers.

    This agent connects to an MCP server using either SSE or stdio transport
    and makes the server's tools available through the agent's tool interface.
    """

    name: str = "mcp_agent"
    description: str = "An agent that connects to an MCP server and uses its tools."

    system_prompt: str = SYSTEM_PROMPT
    next_step_prompt: str = NEXT_STEP_PROMPT

    # Initialize MCP tool collection
    mcp_clients: MCPClients = Field(default_factory=MCPClients)
    available_tools: MCPClients = None  # Will be set in initialize()

    max_steps: int = 20
    connection_type: str = "stdio"  # "stdio" or "sse"

    # Track tool schemas to detect changes
    tool_schemas: Dict[str, Dict[str, Any]] = Field(default_factory=dict)
    _refresh_tools_interval: int = 5  # Refresh tools every N steps

    # Special tool names that should trigger termination
    special_tool_names: List[str] = Field(default_factory=lambda: ["terminate"])

    async def initialize(
        self,
        connection_type: Optional[str] = None,
        server_url: Optional[str] = None,
        command: Optional[str] = None,
        args: Optional[List[str]] = None,
    ) -> None:
        """Initialize the MCP connection.

        Args:
            connection_type: Type of connection to use ("stdio" or "sse")
            server_url: URL of the MCP server (for SSE connection)
            command: Command to run (for stdio connection)
            args: Arguments for the command (for stdio connection)
        """
        if connection_type:
            self.connection_type = connection_type

        # Connect to the MCP server based on connection type
        if self.connection_type == "sse":
            if not server_url:
                raise ValueError("Server URL is required for SSE connection")
            await self.mcp_clients.connect_sse(server_url=server_url)
        elif self.connection_type == "stdio":
            if not command:
                raise ValueError("Command is required for stdio connection")
            await self.mcp_clients.connect_stdio(command=command, args=args or [])
        else:
            raise ValueError(f"Unsupported connection type: {self.connection_type}")

        # Set available_tools to our MCP instance
        self.available_tools = self.mcp_clients

        # Store initial tool schemas
        await self._refresh_tools()

        # Add system message about available tools
        tool_names = list(self.mcp_clients.tool_map.keys())
        tools_info = ", ".join(tool_names)

        # Add system prompt and available tools information
        self.memory.add_message(
            Message.system_message(
                f"{self.system_prompt}\n\nAvailable MCP tools: {tools_info}"
            )
        )

    async def _refresh_tools(self) -> Tuple[List[str], List[str]]:
        """Refresh the list of available tools from the MCP server.

        Returns:
            A tuple of (added_tools, removed_tools)
        """
        if not self.mcp_clients.sessions:
            return [], []

        # Get current tool schemas directly from the server
        response = await self.mcp_clients.list_tools()
        current_tools = {tool.name: tool.inputSchema for tool in response.tools}

        # Determine added, removed, and changed tools
        current_names = set(current_tools.keys())
        previous_names = set(self.tool_schemas.keys())

        added_tools = list(current_names - previous_names)
        removed_tools = list(previous_names - current_names)

        # Check for schema changes in existing tools
        changed_tools = []
        for name in current_names.intersection(previous_names):
            if current_tools[name] != self.tool_schemas.get(name):
                changed_tools.append(name)

        # Update stored schemas
        self.tool_schemas = current_tools

        # Log and notify about changes
        if added_tools:
            logger.info(f"Added MCP tools: {added_tools}")
            self.memory.add_message(
                Message.system_message(f"New tools available: {', '.join(added_tools)}")
            )
        if removed_tools:
            logger.info(f"Removed MCP tools: {removed_tools}")
            self.memory.add_message(
                Message.system_message(
                    f"Tools no longer available: {', '.join(removed_tools)}"
                )
            )
        if changed_tools:
            logger.info(f"Changed MCP tools: {changed_tools}")

        return added_tools, removed_tools

    async def think(self) -> bool:
        """Process current state and decide next action."""
        # Check MCP session and tools availability
        if not self.mcp_clients.sessions or not self.mcp_clients.tool_map:
            logger.info("MCP service is no longer available, ending interaction")
            self.state = AgentState.FINISHED
            return False

        # Refresh tools periodically
        if self.current_step % self._refresh_tools_interval == 0:
            await self._refresh_tools()
            # All tools removed indicates shutdown
            if not self.mcp_clients.tool_map:
                logger.info("MCP service has shut down, ending interaction")
                self.state = AgentState.FINISHED
                return False

        # Use the parent class's think method
        return await super().think()

    async def _handle_special_tool(self, name: str, result: Any, **kwargs) -> None:
        """Handle special tool execution and state changes"""
        # First process with parent handler
        await super()._handle_special_tool(name, result, **kwargs)

        # Handle multimedia responses
        if isinstance(result, ToolResult) and result.base64_image:
            self.memory.add_message(
                Message.system_message(
                    MULTIMEDIA_RESPONSE_PROMPT.format(tool_name=name)
                )
            )

    def _should_finish_execution(self, name: str, **kwargs) -> bool:
        """Determine if tool execution should finish the agent"""
        # Terminate if the tool name is 'terminate'
        return name.lower() == "terminate"

    async def cleanup(self) -> None:
        """Clean up MCP connection when done."""
        if self.mcp_clients.sessions:
            await self.mcp_clients.disconnect()
            logger.info("MCP connection closed")

    async def run(self, request: Optional[str] = None) -> str:
        """Run the agent with cleanup when done."""
        try:
            result = await super().run(request)
            return result
        finally:
            # Ensure cleanup happens even if there's an error
            await self.cleanup()

```

### ARQUIVO: app/agent/__init__.py ###
```py
from app.agent.base import BaseAgent
from app.agent.browser import BrowserAgent # Restaurado
from app.agent.mcp import MCPAgent # Restaurado
from app.agent.react import ReActAgent
from app.agent.swe import SWEAgent
from app.agent.toolcall import ToolCallAgent
from app.agent.critic_agent import CriticAgent


__all__ = [
    "BaseAgent",
    "BrowserAgent", # Restaurado
    "ReActAgent",
    "SWEAgent",
    "ToolCallAgent",
    "MCPAgent", # Restaurado
    "CriticAgent",
]

```

### ARQUIVO: app/agent/data_analysis.py ###
```py
from pydantic import Field

from app.agent.toolcall import ToolCallAgent
from app.config import config
from app.prompt.visualization import NEXT_STEP_PROMPT, SYSTEM_PROMPT
from app.tool import Terminate, ToolCollection
from app.tool.chart_visualization.chart_prepare import VisualizationPrepare
from app.tool.chart_visualization.data_visualization import DataVisualization
from app.tool.chart_visualization.python_execute import NormalPythonExecute


class DataAnalysis(ToolCallAgent):
    """
    A data analysis agent that uses planning to solve various data analysis tasks.

    This agent extends ToolCallAgent with a comprehensive set of tools and capabilities,
    including Data Analysis, Chart Visualization, Data Report.
    """

    name: str = "DataAnalysis"
    description: str = "An analytical agent that utilizes multiple tools to solve diverse data analysis tasks"

    system_prompt: str = SYSTEM_PROMPT.format(directory=config.workspace_root)
    next_step_prompt: str = NEXT_STEP_PROMPT

    max_observe: int = 15000
    max_steps: int = 20

    # Add general-purpose tools to the tool collection
    available_tools: ToolCollection = Field(
        default_factory=lambda: ToolCollection(
            NormalPythonExecute(),
            VisualizationPrepare(),
            DataVisualization(),
            Terminate(),
        )
    )

```

### ARQUIVO: app/agent/re_subprocess_pattern.txt ###
```txt
subprocess\.run\s*\(\s*\[\s*['"](?:python|python3)(?:\.\d+)?['"]\s*,\s*['"]([^']+\.py)['"]\s*\]\s*,.*?\)

```

### ARQUIVO: app/agent/toolcall.py ###
```py
import asyncio
import json
from typing import Any, List, Optional, Union

from pydantic import Field

from app.config import config
from app.agent.react import ReActAgent
from app.config import config # Added
from app.exceptions import TokenLimitExceeded
from app.logger import logger
from app.sandbox.client import SANDBOX_CLIENT # Adicionado para correÃ§Ã£o do NameError
from app.prompt.toolcall import NEXT_STEP_PROMPT, SYSTEM_PROMPT
from app.schema import TOOL_CHOICE_TYPE, AgentState, Message, ToolCall, ToolChoice, Function, Role # Role adicionado aqui
from app.agent.critic_agent import CriticAgent # Adicionado para o agente crÃ­tico

from app.tool import CreateChatCompletion, Terminate, ToolCollection
from app.tool.base import ToolResult # Added
from app.tool.file_operators import LocalFileOperator # Added
from app.tool.code_formatter import FormatPythonCode # Added
from app.tool.code_editor_tools import ReplaceCodeBlock, ApplyDiffPatch, ASTRefactorTool # Modified


TOOL_CALL_REQUIRED = "Tool calls required but none provided"


class ToolCallAgent(ReActAgent):
    """Base agent class for handling tool/function calls with enhanced abstraction"""

    name: str = "toolcall"
    description: str = "an agent that can execute tool calls."

    system_prompt: str = SYSTEM_PROMPT
    next_step_prompt: str = NEXT_STEP_PROMPT

    available_tools: ToolCollection = ToolCollection(
        CreateChatCompletion(), Terminate(), FormatPythonCode(), ReplaceCodeBlock(), ApplyDiffPatch(), ASTRefactorTool()
    )
    tool_choices: TOOL_CHOICE_TYPE = ToolChoice.AUTO  # type: ignore
    special_tool_names: List[str] = Field(default_factory=lambda: [Terminate().name])

    tool_calls: List[ToolCall] = Field(default_factory=list)
    _current_base64_image: Optional[str] = None
    critic_agent: Optional[CriticAgent] = None # Adicionado para o agente crÃ­tico
    steps_since_last_critic_review: int = 0 # Adicionado para o agente crÃ­tico

    max_steps: int = 30
    max_observe: Optional[Union[int, bool]] = None

    def __init__(self, **data: Any): # Adicionado __init__
        super().__init__(**data)
        if self.llm:
            self.critic_agent = CriticAgent(llm_client=self.llm)
        else:
            logger.warning("LLM nÃ£o disponÃ­vel para ToolCallAgent no momento da inicializaÃ§Ã£o do CriticAgent.")

    async def think(self) -> bool:
        """Process current state and decide next actions using tools"""
        if self.current_step == 1: # current_step is 1 for the first proper thinking step
            checklist_filename = "checklist_principal_tarefa.md"
            # config.workspace_root is a Path object, ensure checklist_path is a string if tools expect strings
            checklist_path_str = str(config.workspace_root / checklist_filename)

            local_op = LocalFileOperator()
            checklist_exists = False # Default to not existing
            try:
                # Use a blocking call to os.path.exists for simplicity here, or make LocalFileOperator().exists() non-async
                # For now, let's assume we can await it. If not, this needs adjustment.
                # Based on file_operators.py, exists is async.
                checklist_exists = await local_op.exists(checklist_path_str)
            except Exception as e:
                logger.error(f"Error checking for checklist existence: {e}. Proceeding with LLM thought.")
                # If error checking existence, better to let LLM try to create it or decide,
                # rather than falsely assuming it exists or blocking the flow.
                # For this specific logic, we want to *force* creation if unsure or error.
                # So, if an error occurs, we'll treat it as "doesn't exist" to trigger creation.
                checklist_exists = False

            if not checklist_exists:
                logger.info(f"Checklist file '{checklist_path_str}' not found or error during check at step 1. Enforcing creation.")

                initial_checklist_content = "- [Pendente] Decompor a solicitaÃ§Ã£o do usuÃ¡rio e popular o checklist com as subtarefas."

                # Manually construct the JSON string for arguments
                # Manually construct the JSON string for arguments
                # Ensure checklist_path_str and initial_checklist_content are properly escaped for JSON
                escaped_checklist_path_str = json.dumps(checklist_path_str)
                escaped_initial_checklist_content = json.dumps(initial_checklist_content)

                arguments_json_string = f'{{"command": "create", "path": {escaped_checklist_path_str}, "file_text": {escaped_initial_checklist_content}}}'

                forced_tool_call = ToolCall(
                    id="forced_checklist_creation_001", # Static ID for this specific forced call
                    function=Function(
                        name="str_replace_editor",
                        arguments=arguments_json_string # Use the manually constructed string
                    )
                    # type="function" # type is implicitly function for ToolCall
                )

                self.tool_calls = [forced_tool_call]

                assistant_thought_content = "A primeira aÃ§Ã£o Ã© criar o checklist da tarefa para organizar o trabalho."
                self.memory.add_message(
                    Message.from_tool_calls(content=assistant_thought_content, tool_calls=self.tool_calls)
                )

                return True # Indicates that an action (the forced tool call) is ready

        if self.next_step_prompt:
            user_msg = Message.user_message(self.next_step_prompt)
            self.messages += [user_msg]

        try:
            # Get response with tool options
            response = await self.llm.ask_tool(
                messages=self.messages,
                system_msgs=(
                    [Message.system_message(self.system_prompt.format(directory=str(config.workspace_root)))]
                    if self.system_prompt
                    else None
                ),
                tools=self.available_tools.to_params(),
                tool_choice=self.tool_choices,
            )
        except ValueError:
            raise
        except Exception as e:
            # Check if this is a RetryError containing TokenLimitExceeded
            if hasattr(e, "__cause__") and isinstance(e.__cause__, TokenLimitExceeded):
                token_limit_error = e.__cause__
                logger.error(
                    f"ğŸš¨ Token limit error (from RetryError): {token_limit_error}"
                )
                self.memory.add_message(
                    Message.assistant_message(
                        f"Maximum token limit reached, cannot continue execution: {str(token_limit_error)}"
                    )
                )
                self.state = AgentState.FINISHED
                return False
            raise

        # Imports no topo do arquivo jÃ¡ devem existir:
        # from app.schema import ToolCall, Function

        # ... dentro do mÃ©todo think() ...

        raw_openai_tool_calls = response.tool_calls if response and response.tool_calls else []
        converted_tool_calls = []
        if raw_openai_tool_calls:
            for openai_tc in raw_openai_tool_calls:
                if openai_tc.function: # Verificar se function nÃ£o Ã© None
                    app_function = Function( # Usando o Function de app.schema
                        name=openai_tc.function.name,
                        arguments=openai_tc.function.arguments
                    )
                    app_tc = ToolCall( # Usando o ToolCall de app.schema
                        id=openai_tc.id,
                        type=openai_tc.type if openai_tc.type else "function", # Default type to "function"
                        function=app_function
                    )
                    converted_tool_calls.append(app_tc)
                else:
                    # Logar um aviso se uma tool call do OpenAI nÃ£o tiver a parte da funÃ§Ã£o
                    logger.warning(f"OpenAI tool_call (ID: {openai_tc.id}) missing function component, skipping conversion.")

        self.tool_calls = converted_tool_calls
        # A variÃ¡vel local 'tool_calls' tambÃ©m pode ser atualizada se for usada posteriormente no mÃ©todo,
        # mas self.tool_calls Ã© o principal. Para consistÃªncia:
        tool_calls = self.tool_calls

        content = response.content if response and response.content else ""

        # Log response info (manter esta parte)
        logger.info(f"âœ¨ {self.name}'s thoughts: {content}")
        # Note: self.name aqui Ã© o nome do ToolCallAgent ("toolcall"), nÃ£o do Manus.
        # Isso pode ser confuso no log, mas Ã© o comportamento existente.
        logger.info(
            f"ğŸ› ï¸ {self.name} selected {len(self.tool_calls) if self.tool_calls else 0} tools to use"
        )
        if self.tool_calls: # Usar self.tool_calls que agora Ã© do tipo correto
            logger.info(
                f"ğŸ§° Tools being prepared: {[call.function.name for call in self.tool_calls]}"
            )
            # Adicionar uma verificaÃ§Ã£o para self.tool_calls nÃ£o estar vazio antes de acessar [0]
            if self.tool_calls:
                 logger.info(f"ğŸ”§ Tool arguments: {self.tool_calls[0].function.arguments}")

        try:
            if response is None:
                raise RuntimeError("No response received from the LLM")

            # Handle different tool_choices modes
            if self.tool_choices == ToolChoice.NONE:
                if tool_calls:
                    logger.warning(
                        f"ğŸ¤” Hmm, {self.name} tried to use tools when they weren't available!"
                    )
                if content:
                    self.memory.add_message(Message.assistant_message(content))
                    return True
                return False

            # Create and add assistant message
            assistant_msg = (
                Message.from_tool_calls(content=content, tool_calls=self.tool_calls)
                if self.tool_calls
                else Message.assistant_message(content)
            )
            self.memory.add_message(assistant_msg)

            if self.tool_choices == ToolChoice.REQUIRED and not self.tool_calls:
                return True  # Will be handled in act()

            # For 'auto' mode, continue with content if no commands but content exists
            if self.tool_choices == ToolChoice.AUTO and not self.tool_calls:
                return bool(content)

            return bool(self.tool_calls)
        except Exception as e:
            logger.error(f"ğŸš¨ Oops! The {self.name}'s thinking process hit a snag: {e}")
            self.memory.add_message(
                Message.assistant_message(
                    f"Error encountered while processing: {str(e)}"
                )
            )
            return False

    async def act(self) -> str:
        """Execute tool calls and handle their results"""
        if not self.tool_calls:
            if self.tool_choices == ToolChoice.REQUIRED:
                raise ValueError(TOOL_CALL_REQUIRED)

            # Return last message content if no tool calls
            return self.messages[-1].content or "No content or commands to execute"

        results = []
        for command in self.tool_calls:
            # Reset base64_image for each tool call
            self._current_base64_image = None

            result = await self.execute_tool(command)

            if self.max_observe:
                result = result[: self.max_observe]

            logger.info(
                f"ğŸ¯ Tool '{command.function.name}' completed its mission! Result: {result}"
            )

            # Add tool response to memory
            tool_msg = Message.tool_message(
                content=result,
                tool_call_id=command.id,
                name=command.function.name,
                base64_image=self._current_base64_image,
            )
            self.memory.add_message(tool_msg)
            results.append(result)

        return "\n\n".join(results)

    async def execute_tool(self, command: ToolCall) -> str:
        """Execute a single tool call with robust error handling"""
        # Import SandboxPythonExecutor here to check its name
        # This is a bit of a workaround for circular dependency or module loading issues
        # if SandboxPythonExecutor were imported at the top level of manus.py for type hinting
        # and toolcall.py also needs it for name comparison.
        # A better solution might be to use a string literal for the name or a shared constant.
        from app.tool.sandbox_python_executor import SandboxPythonExecutor

        # Import Function and ToolCall if not already available at the top of the file for isinstance checks
        # from app.schema import Function, ToolCall # Ensure this is appropriately placed if needed

        if not command:
            logger.error("execute_tool: Command object is None.")
            return "Error: Invalid command object (None)."
        if not isinstance(command, ToolCall):
            logger.error(f"execute_tool: Command object is not a ToolCall instance, got {type(command)}.")
            return f"Error: Invalid command object type ({type(command)})."

        current_function = command.function
        if not current_function:
            logger.error(f"execute_tool: command.function is None for command ID {command.id}.")
            return "Error: Command function is None."
        # Ensure app.schema.Function is imported if you are using it for isinstance check.
        # Assuming Function is already imported from app.schema at the top of the file.
        if not isinstance(current_function, Function):
            logger.error(f"execute_tool: command.function is not a Function instance for command ID {command.id}, got {type(current_function)}.")
            return f"Error: Invalid command function type ({type(current_function)})."

        name_to_be_used = None # Initialize to ensure it's clear if not set
        try:
            name_to_be_used = current_function.name
            if not name_to_be_used:
                logger.error(f"execute_tool: command.function.name is None or empty for command ID {command.id}.")
                return "Error: Command function name is missing or empty."
        except AttributeError as e_name_access:
            logger.error(f"execute_tool: AttributeError while accessing command.function.name for command ID {command.id}. Function object was: {str(current_function)}. Error: {e_name_access}", exc_info=True)
            return "Error: Failed to access function name due to AttributeError."
        except Exception as e_general_name_access: # Catch any other unexpected error during name access
            logger.error(f"execute_tool: Unexpected error while accessing command.function.name for command ID {command.id}. Function object was: {str(current_function)}. Error: {e_general_name_access}", exc_info=True)
            return "Error: Unexpected error accessing function name."

        # Use 'name_to_be_used' from this point onwards instead of just 'name' for clarity
        name = name_to_be_used
        if name not in self.available_tools.tool_map:
            return f"Error: Unknown tool '{name}'"

        try:
            # Parse arguments
            args = json.loads(command.function.arguments or "{}")

            # Handle path argument aliasing for str_replace_editor
            if name == "str_replace_editor":
                if 'path' not in args and 'path_absoluto' in args:
                    args['path'] = args.pop('path_absoluto')
                    logger.info(f"Aliased 'path_absoluto' to 'path' for str_replace_editor call.")
                elif 'path' not in args and 'caminho_completo_do_arquivo' in args:
                    args['path'] = args.pop('caminho_completo_do_arquivo')
                    logger.info(f"Aliased 'caminho_completo_do_arquivo' to 'path' for str_replace_editor call.")
                elif 'path' not in args and 'script_internal_file_path' in args: # New condition
                    args['path'] = args.pop('script_internal_file_path')
                    logger.info(f"Aliased 'script_internal_file_path' to 'path' for str_replace_editor call.")

            # Execute the tool
            logger.info(f"[TOOL_START] Activating tool '{name}' with args: {args}")
            tool_output = await self.available_tools.execute(name=name, tool_input=args)
            logger.info(f"[TOOL_END] Tool '{name}' executed successfully.")

            # Store PID file path if this was the sandbox executor
            if name == SandboxPythonExecutor().name:
                # Check if tool_output is a dict, which is the expected return type for SandboxPythonExecutor
                # when it successfully returns a pid_file_path.
                if isinstance(tool_output, dict) and "pid_file_path" in tool_output:
                    self._current_sandbox_pid_file = tool_output["pid_file_path"]
                    self._current_script_tool_call_id = command.id
                    self._current_sandbox_pid = None # Reset PID, will be read if needed
                    logger.info(f"Stored PID file path '{self._current_sandbox_pid_file}' for tool call ID '{command.id}'.")
                # If tool_output is ToolResult, it means SandboxPythonExecutor might have wrapped its dict output
                # or an error occurred. If it's an error, it will be handled by the ToolResult processing below.
                # If it's a ToolResult containing the dict, we might need to extract it.
                # However, the current SandboxPythonExecutor().execute() method returns a dict directly, not a ToolResult.
                # So, this condition might be more for future-proofing or if other tools behave differently.
                elif isinstance(tool_output, ToolResult) and isinstance(tool_output.output, dict) and "pid_file_path" in tool_output.output:
                    self._current_sandbox_pid_file = tool_output.output["pid_file_path"]
                    self._current_script_tool_call_id = command.id
                    self._current_sandbox_pid = None
                    logger.info(f"Stored PID file path '{self._current_sandbox_pid_file}' (from ToolResult.output) for tool call ID '{command.id}'.")
                else:
                    logger.warning(f"Tool {name} did not return 'pid_file_path' as expected. Output type: {type(tool_output)}")

            # Handle special tools
            await self._handle_special_tool(name=name, result=tool_output)

            current_output_str = ""
            if isinstance(tool_output, ToolResult):
                if tool_output.base64_image:
                    self._current_base64_image = tool_output.base64_image

                if tool_output.error:
                    current_output_str = f"Error: {tool_output.error}"
                elif tool_output.output is not None:
                    current_output_str = str(tool_output.output)
                else:
                    current_output_str = "" # SaÃ­da vazia se nÃ£o houver erro nem output

                observation = (
                    f"Observed output of cmd `{name}` executed:\n{current_output_str}"
                    if current_output_str
                    else f"Cmd `{name}` completed with no observable output or error."
                )
            elif isinstance(tool_output, str):
                self._current_base64_image = None # Garantir que nÃ£o haja imagem base64 de uma execuÃ§Ã£o anterior
                current_output_str = tool_output
                observation = (
                    f"Observed output of cmd `{name}` executed:\n{current_output_str}"
                    if current_output_str # Verifica se a string nÃ£o Ã© vazia
                    else f"Cmd `{name}` completed with no observable string output."
                )
            else:
                # Caso para tipos inesperados, pode ser logado ou tratado como erro
                logger.warning(f"Tool '{name}' returned an unexpected type: {type(tool_output)}. Converting to string.")
                self._current_base64_image = None
                current_output_str = str(tool_output) # Tenta converter para string como fallback
                observation = f"Observed output of cmd `{name}` executed (converted from {type(tool_output)}):\n{current_output_str}"

            return observation
        except json.JSONDecodeError:
            logger.error(f"[TOOL_FAIL] Tool '{name}' failed: Invalid JSON arguments.")
            error_msg = f"Error parsing arguments for {name}: Invalid JSON format"
            logger.error(
                f"ğŸ“ Oops! The arguments for '{name}' don't make sense - invalid JSON, arguments:{command.function.arguments}"
            )
            return f"Error: {error_msg}"
        except Exception as e:
            logger.error(f"[TOOL_FAIL] Tool '{name}' failed with exception: {str(e)}")
            error_msg = f"âš ï¸ Tool '{name}' encountered a problem: {str(e)}"
            logger.exception(error_msg)
            return f"Error: {error_msg}"
        finally:
            # Cleanup PID file and attributes if this was the tracked script
            if hasattr(self, '_current_script_tool_call_id') and self._current_script_tool_call_id == command.id:
                if hasattr(self, '_cleanup_sandbox_file') and callable(getattr(self, '_cleanup_sandbox_file')):
                    await self._cleanup_sandbox_file(self._current_sandbox_pid_file)
                else:
                    # This case should ideally not happen if Manus is the one running.
                    # This indicates an agent that inherits ToolCallAgent but isn't Manus
                    # and hasn't implemented its own _cleanup_sandbox_file or similar.
                    logger.warning(f"Agent {self.name} does not have a _cleanup_sandbox_file method. PID file {self._current_sandbox_pid_file} may not be cleaned if it exists.")


                logger.info(f"Clearing PID tracking for tool call ID '{command.id}'.")
                self._current_sandbox_pid = None
                self._current_sandbox_pid_file = None
                self._current_script_tool_call_id = None

    async def _handle_special_tool(self, name: str, result: Any, **kwargs):
        """Handle special tool execution and state changes"""
        if not self._is_special_tool(name):
            return

        if self._should_finish_execution(name=name, result=result, **kwargs):
            # Set agent state to finished
            logger.info(f"ğŸ Special tool '{name}' has completed the task!")
            self.state = AgentState.FINISHED

    @staticmethod
    def _should_finish_execution(**kwargs) -> bool:
        """Determine if tool execution should finish the agent"""
        return True

    def _is_special_tool(self, name: str) -> bool:
        """Check if tool name is in special tools list"""
        return name.lower() in [n.lower() for n in self.special_tool_names]

    async def cleanup(self):
        """Clean up resources used by the agent's tools."""
        logger.info(f"ğŸ§¹ Cleaning up resources for agent '{self.name}'...")
        for tool_name, tool_instance in self.available_tools.tool_map.items():
            if hasattr(tool_instance, "cleanup") and asyncio.iscoroutinefunction(
                tool_instance.cleanup
            ):
                try:
                    logger.debug(f"ğŸ§¼ Cleaning up tool: {tool_name}")
                    await tool_instance.cleanup()
                except Exception as e:
                    logger.error(
                        f"ğŸš¨ Error cleaning up tool '{tool_name}': {str(e)}"
                    )
                    # import traceback # Comment out for now, can be added if necessary
                    # logger.error(f"Traceback for {tool_name} cleanup error: {traceback.format_exc()}")
        logger.info(f"âœ¨ Cleanup complete for agent '{self.name}'.")

    async def run(self, request: Optional[str] = None) -> str:
        """Run the agent with cleanup when done."""
        # --- InÃ­cio da LÃ³gica do Agente CrÃ­tico ---
        CRITIC_REVIEW_INTERVAL = 5 # A cada quantas etapas o crÃ­tico revisa
        # --- Fim da LÃ³gica do Agente CrÃ­tico ---
        try:
            # A lÃ³gica de `super().run(request)` estÃ¡ agora em `BaseAgent.run`
            # Precisamos replicar e modificar o loop de `BaseAgent.run` aqui
            # para inserir a chamada ao crÃ­tico.

            if self.state == AgentState.IDLE:
                if request:
                    self.update_memory("user", request)
                self.state = AgentState.RUNNING
            elif self.state == AgentState.AWAITING_USER_FEEDBACK:
                if request:
                    self.update_memory("user", request)
                self.state = AgentState.RUNNING
            elif self.state == AgentState.RUNNING:
                if request:
                    self.update_memory("user", request)
            else:
                logger.error(f"Run method called on agent in an unstartable/unresumable state: {self.state.value}. Raising RuntimeError.")
                raise RuntimeError(f"Cannot run/resume agent from state: {self.state.value}")

            results: List[str] = []
            self.steps_since_last_critic_review = 0 # Resetar no inÃ­cio de um novo run

            while self.state == AgentState.RUNNING:
                async with self.state_context(AgentState.RUNNING):
                    while self.state not in [AgentState.FINISHED, AgentState.ERROR, AgentState.USER_HALTED, AgentState.USER_PAUSED]:
                        self.current_step += 1
                        self.steps_since_last_critic_review += 1

                        if hasattr(self, 'user_pause_requested_event') and self.user_pause_requested_event.is_set():
                            self.user_pause_requested_event.clear()
                            self.state = AgentState.USER_PAUSED
                            break

                        if await self.should_request_feedback():
                            self.state = AgentState.AWAITING_USER_FEEDBACK
                            break

                        if self.state in [AgentState.FINISHED, AgentState.ERROR, AgentState.USER_HALTED, AgentState.AWAITING_USER_FEEDBACK]:
                            break

                        # --- InÃ­cio da LÃ³gica do Agente CrÃ­tico ---
                        # --- InÃ­cio da LÃ³gica de AtivaÃ§Ã£o e Processamento do Agente CrÃ­tico ---
                        if self.critic_agent and self.steps_since_last_critic_review >= CRITIC_REVIEW_INTERVAL:
                            logger.info(f"[{self.name}] Agente CrÃ­tico ativado na etapa {self.current_step} (total) / {self.steps_since_last_critic_review} (desde Ãºltima revisÃ£o).")

                            # Obter o plano/checklist atual. EspecÃ­fico para agentes como Manus.
                            current_plan_markdown = "Plano nÃ£o disponÃ­vel para o crÃ­tico."
                            try:
                                # Tenta obter de um checklist_manager se existir (como em Manus)
                                checklist_manager = getattr(self, 'checklist_manager', None)
                                if checklist_manager and hasattr(checklist_manager, 'get_tasks_as_markdown'):
                                    current_plan_markdown = await checklist_manager.get_tasks_as_markdown()
                                # Fallback para ler diretamente o arquivo de checklist (se o agente for Manus ou similar)
                                elif hasattr(self, '_is_checklist_complete'):
                                    local_op = LocalFileOperator() # Ferramenta para operaÃ§Ãµes de arquivo local
                                    checklist_path = str(config.workspace_root / "checklist_principal_tarefa.md")
                                    if await local_op.exists(checklist_path):
                                        current_plan_markdown = await local_op.read_file(checklist_path)
                                    else:
                                        current_plan_markdown = "Checklist principal ('checklist_principal_tarefa.md') nÃ£o encontrado."
                            except Exception as e_plan_read:
                                logger.warning(f"[{self.name}] NÃ£o foi possÃ­vel obter o plano detalhado para o Agente CrÃ­tico: {e_plan_read}")

                            # Coletar resultados de ferramentas recentes para o crÃ­tico.
                            # O crÃ­tico espera uma lista de dicts com 'name', 'content', 'tool_call_id'.
                            # As Ãºltimas N mensagens do tipo TOOL sÃ£o relevantes.
                            recent_tool_action_results = []
                            # Iterar sobre as Ãºltimas ~2*CRITIC_REVIEW_INTERVAL mensagens para capturar pares de tool_call/tool_response
                            # Olhar um pouco mais para trÃ¡s para garantir que pegamos os resultados das ferramentas desde a Ãºltima revisÃ£o.
                            lookback_messages_count = self.steps_since_last_critic_review * 2 + 5 # HeurÃ­stica
                            for msg in reversed(self.memory.messages[-lookback_messages_count:]):
                                if msg.role == Role.TOOL and hasattr(msg, 'name') and hasattr(msg, 'content') and hasattr(msg, 'tool_call_id'):
                                    recent_tool_action_results.append({
                                        "name": msg.name,
                                        "content": msg.content, # Este Ã© o resultado formatado da ferramenta (observaÃ§Ã£o)
                                        "tool_call_id": msg.tool_call_id
                                    })
                                if len(recent_tool_action_results) >= CRITIC_REVIEW_INTERVAL + 2: # Limita o nÃºmero de resultados de ferramentas
                                    break
                            recent_tool_action_results.reverse() # Manter a ordem cronolÃ³gica

                            # Chamar o Agente CrÃ­tico
                            critic_feedback_text, critic_redirect_suggestion = self.critic_agent.review_plan_and_progress(
                                current_plan_markdown=current_plan_markdown,
                                messages=[msg.model_dump() for msg in self.memory.messages[-10:]], # Ãšltimas 10 mensagens como dicts
                                tool_results=recent_tool_action_results, # Resultados de ferramentas processados
                                current_step=self.current_step,
                                steps_since_last_review=self.steps_since_last_critic_review
                            )

                            # Adicionar feedback do crÃ­tico Ã  memÃ³ria para o LLM principal considerar
                            self.memory.add_message(Message.system_message(f"Feedback do Agente CrÃ­tico: {critic_feedback_text}"))
                            logger.info(f"[{self.name}] Feedback do Agente CrÃ­tico: {critic_feedback_text.splitlines()[0]}...") # Log da primeira linha

                            # Processar sugestÃ£o de redirecionamento do crÃ­tico
                            if critic_redirect_suggestion and isinstance(critic_redirect_suggestion, dict):
                                critic_clarification = critic_redirect_suggestion.get("clarification", "Nenhuma clarificaÃ§Ã£o adicional do crÃ­tico.")
                                self.memory.add_message(Message.system_message(f"Nota do CrÃ­tico sobre Redirecionamento: {critic_clarification}"))
                                logger.info(f"[{self.name}] Nota do CrÃ­tico sobre Redirecionamento: {critic_clarification}")

                                action_type = critic_redirect_suggestion.get("action_type")
                                details = critic_redirect_suggestion.get("details", {})

                                # Exemplo: Se o crÃ­tico sugerir modificar o plano e a ferramenta estiver disponÃ­vel
                                if action_type == "MODIFY_PLAN" and "task_description" in details:
                                    add_task_tool_name = "add_checklist_task"
                                    if self.available_tools.get_tool(add_task_tool_name):
                                        try:
                                            add_task_args = {
                                                "description": details["task_description"],
                                                "priority": details.get("priority", "normal"),
                                                "status": "Pendente"
                                            }
                                            add_task_call = ToolCall(
                                                id=f"critic_mod_plan_{self.current_step}",
                                                function=Function(name=add_task_tool_name, arguments=json.dumps(add_task_args))
                                            )
                                            logger.info(f"[{self.name}] CrÃ­tico sugeriu MODIFY_PLAN. Tentando adicionar tarefa via {add_task_tool_name} com args: {add_task_args}")
                                            # Executa a ferramenta "fora de banda" (nÃ£o parte do ciclo think/act normal do LLM)
                                            add_task_result_obs = await self.execute_tool(add_task_call)
                                            self.memory.add_message(Message.tool_message(
                                                content=add_task_result_obs, # ObservaÃ§Ã£o da execuÃ§Ã£o da ferramenta
                                                tool_call_id=add_task_call.id,
                                                name=add_task_tool_name
                                            ))
                                            self.memory.add_message(Message.system_message(f"CrÃ­tico: Tarefa '{details['task_description']}' foi (tentativamente) adicionada ao plano."))
                                        except Exception as e_critic_add_task:
                                            logger.error(f"[{self.name}] Erro ao tentar adicionar tarefa sugerida pelo crÃ­tico: {e_critic_add_task}")
                                            self.memory.add_message(Message.system_message(f"CrÃ­tico: Falha ao tentar adicionar tarefa '{details['task_description']}' ao plano via ferramenta."))
                                    else:
                                        # Se a ferramenta nÃ£o estiver disponÃ­vel, o LLM principal precisa ser informado para agir sobre a sugestÃ£o.
                                        self.memory.add_message(Message.system_message(
                                            f"ALERTA DO CRÃTICO: SugestÃ£o para modificar o plano: Adicionar tarefa '{details['task_description']}'. "
                                            f"A ferramenta '{add_task_tool_name}' nÃ£o estÃ¡ diretamente disponÃ­vel para o crÃ­tico. "
                                            "O agente principal deve considerar esta sugestÃ£o."
                                        ))
                                # Lidar com outros action_types (REQUEST_HUMAN_INPUT, SUGGEST_ALTERNATIVE_TOOL)
                                # Adicionando mensagens fortes Ã  memÃ³ria para o LLM principal considerar.
                                elif action_type == "REQUEST_HUMAN_INPUT" and "question" in details:
                                    ask_human_tool_name = "ask_human"
                                    self.memory.add_message(Message.system_message(
                                        f"ALERTA DO CRÃTICO: Ã‰ crucial obter input humano. "
                                        f"Por favor, considere usar a ferramenta '{ask_human_tool_name}' com a seguinte pergunta: {details['question']}"
                                    ))
                                elif action_type == "SUGGEST_ALTERNATIVE_TOOL" and "alternative_tool_name" in details:
                                    self.memory.add_message(Message.system_message(
                                        f"ALERTA DO CRÃTICO: Considere usar a ferramenta '{details['alternative_tool_name']}' "
                                        f"com argumentos aproximados: {details.get('alternative_tool_args', {})} "
                                        f"em vez de '{details.get('failed_tool', 'a ferramenta anterior')}'. "
                                        "O agente principal deve avaliar e decidir sobre esta sugestÃ£o."
                                    ))

                            self.steps_since_last_critic_review = 0 # Resetar contador apÃ³s revisÃ£o
                        # --- Fim da LÃ³gica do Agente CrÃ­tico ---

                        step_result = await self.step() # Executa o ciclo think-act normal do agente
                        results.append(f"Step {self.current_step}: {step_result}")

                        if self.is_stuck():
                            self.handle_stuck_state()

                if self.state == AgentState.AWAITING_USER_FEEDBACK:
                    break
                elif self.state == AgentState.USER_PAUSED:
                    break

                if self.state not in [AgentState.RUNNING]:
                    break

            # LÃ³gica de finalizaÃ§Ã£o do BaseAgent.run
            if self.state == AgentState.USER_HALTED:
                pass
            elif self.state == AgentState.AWAITING_USER_FEEDBACK:
                pass
            elif self.state == AgentState.USER_PAUSED:
                pass
            elif self.current_step >= self.max_steps and self.max_steps > 0:
                self.state = AgentState.FINISHED
            elif not self.tool_calls and self.state == AgentState.RUNNING:
                 # Em ToolCallAgent, self.tool_calls Ã© resetado em `think`.
                 # Se `think` nÃ£o produziu novas tool_calls, pode ser um sinal de conclusÃ£o.
                last_message = self.memory.messages[-1] if self.memory.messages else None
                if last_message and last_message.role == Role.ASSISTANT and not last_message.tool_calls and last_message.content:
                    # Se a Ãºltima mensagem do assistente tem conteÃºdo mas nÃ£o tem tool_calls,
                    # pode ser uma resposta final.
                    logger.info("Agente terminou de pensar e nÃ£o produziu novas chamadas de ferramenta. Considerando como FINISHED.")
                    self.state = AgentState.FINISHED
                # Se nÃ£o, pode ser que o `think` precise de mais contexto ou o loop deva continuar
                # para permitir que `should_request_feedback` ou `is_stuck` atuem.
                # Por seguranÃ§a, se o agente nÃ£o se decidiu por FINISHED/ERROR/HALTED,
                # e nÃ£o hÃ¡ mais `tool_calls` para processar, e nÃ£o estÃ¡ esperando feedback,
                # entÃ£o podemos considerar como FINISHED para evitar loops infinitos.
                elif self.state == AgentState.RUNNING: # Ainda RUNNING e sem tool_calls
                    logger.info("Agente no estado RUNNING sem novas tool_calls. Considerando como FINISHED.")
                    self.state = AgentState.FINISHED

            elif self.state == AgentState.RUNNING:
                self.state = AgentState.FINISHED
            elif self.state == AgentState.ERROR:
                pass
            elif self.state == AgentState.FINISHED:
                pass
            else:
                logger.error(f"Execution ended with an unexpected or unhandled state: {self.state.value} at step {self.current_step}. Review agent logic.")

            final_summary = f"Execution concluded. Final state: {self.state.value}, Current step: {self.current_step}."
            results.append(final_summary)

            # SANDBOX_CLIENT.cleanup() Ã© chamado em BaseAgent.run, entÃ£o nÃ£o precisamos duplicar aqui
            # se ToolCallAgent.run estÃ¡ substituindo completamente BaseAgent.run.
            # No entanto, a instruÃ§Ã£o original era `await super().run(request)`,
            # o que significa que a limpeza do sandbox jÃ¡ estaria no `finally` do `super().run`.
            # Como estamos reescrevendo o loop, precisamos garantir que a limpeza ocorra.
            # A limpeza das ferramentas individuais Ã© feita no `finally` abaixo.

            return "\n".join(results) if results else "No steps executed or execution ended."

        finally:
            await self.cleanup() # Limpeza das ferramentas do ToolCallAgent
            # Se BaseAgent.run() nÃ£o for chamado (porque o sobrescrevemos),
            # precisamos garantir que SANDBOX_CLIENT.cleanup() seja chamado.
            # Se este `run` substitui completamente o `BaseAgent.run`, entÃ£o:
            if hasattr(SANDBOX_CLIENT, 'cleanup') and callable(SANDBOX_CLIENT.cleanup):
                 await SANDBOX_CLIENT.cleanup()
            logger.info(f"ToolCallAgent run method finished for agent '{self.name}'. Final state: {self.state.value}")

```

### ARQUIVO: app/agent/regex_patterns.py ###
```py
import os
import re
import sys # Import sys for stderr printing if needed

# Variable to store the compiled regex pattern
re_subprocess = None
_pattern_file_path = "" # Define for potential use in error messages outside try

try:
    # ConstrÃ³i o caminho para o arquivo de forma segura
    dir_path = os.path.dirname(os.path.realpath(__file__))
    _pattern_file_path = os.path.join(dir_path, 're_subprocess_pattern.txt')

    with open(_pattern_file_path, 'r', encoding='utf-8') as f:
        pattern_str = f.read().strip()

    if not pattern_str:
        # This case means the file was empty or contained only whitespace.
        raise ValueError(f"CRITICAL: Regex pattern file '{_pattern_file_path}' is empty or invalid. "
                         "The application cannot proceed without a valid pattern.")

    # Carrega o padrÃ£o e o compila para uso na aplicaÃ§Ã£o
    re_subprocess = re.compile(pattern_str)

except FileNotFoundError:
    # LanÃ§a um erro claro se o arquivo de padrÃ£o estiver faltando
    # Print to stderr for immediate visibility if possible, then raise
    error_message = f"CRITICAL ERROR: Regex pattern file 're_subprocess_pattern.txt' not found at expected path: {_pattern_file_path}. The application cannot initialize."
    print(error_message, file=sys.stderr)
    raise RuntimeError(error_message) from None # Using from None to break the chain of exceptions, as FileNotFoundError is the root cause here

except (IOError, OSError) as e:
    # Captura outros possÃ­veis erros de leitura de arquivo
    error_message = f"CRITICAL ERROR: Failed to read or process regex pattern file '{_pattern_file_path}'. Exception: {e}"
    print(error_message, file=sys.stderr)
    raise RuntimeError(error_message) from e

except ValueError as e: # Specifically for the empty pattern check
    error_message = str(e) # The message is already well-formed in the raise statement
    print(error_message, file=sys.stderr)
    raise RuntimeError(error_message) from e

except Exception as e:
    # Captura outros possÃ­veis erros (e.g., re.error from compile)
    err_msg_path_display = _pattern_file_path if _pattern_file_path else "unknown path"
    error_message = f"CRITICAL ERROR: An unexpected error occurred while loading/compiling the regex pattern from '{err_msg_path_display}'. Exception type: {type(e).__name__}, Exception: {e}"
    print(error_message, file=sys.stderr)
    raise RuntimeError(error_message) from e

# Final check to ensure the compiled regex is available.
if re_subprocess is None:
    # This state should ideally not be reached if the above error handling is comprehensive.
    # However, as a safeguard:
    final_err_msg_path_display = _pattern_file_path if _pattern_file_path else "path not determined"
    critical_final_error = f"CRITICAL FAILURE: Regex pattern 're_subprocess' was not successfully compiled from '{final_err_msg_path_display}' by the end of the script. This indicates an unexpected issue in the loading logic. Application cannot proceed."
    print(critical_final_error, file=sys.stderr)
    raise RuntimeError(critical_final_error)

```

### ARQUIVO: app/agent/swe.py ###
```py
from typing import List

from pydantic import Field

from app.agent.toolcall import ToolCallAgent
from app.prompt.swe import SYSTEM_PROMPT
from app.tool import Bash, StrReplaceEditor, Terminate, ToolCollection
from app.tool.ask_human import AskHuman # ImportaÃ§Ã£o adicionada
from app.logger import logger # ImportaÃ§Ã£o adicionada
from app.schema import AgentState # ImportaÃ§Ã£o adicionada


class SWEAgent(ToolCallAgent):
    """Um agente que implementa o paradigma SWEAgent para executar cÃ³digo e conversas naturais."""

    name: str = "swe"
    description: str = "um programador de IA autÃ´nomo que interage diretamente com o computador para resolver tarefas."

    system_prompt: str = SYSTEM_PROMPT
    next_step_prompt: str = ""

    available_tools: ToolCollection = ToolCollection(
        Bash(), StrReplaceEditor(), Terminate(), AskHuman() # AskHuman adicionado
    )
    special_tool_names: List[str] = Field(default_factory=lambda: [Terminate().name])

    max_steps: int = 50 # max_steps aumentado

    async def should_request_feedback(self) -> bool:
        """Determina se o agente deve pausar e solicitar feedback do usuÃ¡rio.

        Este mÃ©todo implementa a lÃ³gica para decidir quando pedir feedback
        com base em critÃ©rios como estar preso, enfrentar ambiguidade ou falta de informaÃ§Ãµes crÃ­ticas.
        """
        # 1. Verificar se o agente estÃ¡ preso (usando mecanismo existente)
        if self.is_stuck():
            logger.info("CondiÃ§Ã£o de feedback: Agente estÃ¡ preso (respostas duplicadas).")
            # Garantir que hÃ¡ uma pergunta a ser feita, talvez definindo um padrÃ£o ou usando o prompt de preso.
            # Por enquanto, assumimos que o LLM usarÃ¡ ask_human com base no prompt do sistema se estiver preso.
            # Podemos precisar de uma maneira mais direta de definir a pergunta para ask_human aqui.
            self.update_memory("system", "VocÃª parece estar preso. Considere pedir orientaÃ§Ã£o ao usuÃ¡rio usando a ferramenta 'ask_human' se nÃ£o tiver certeza de como proceder.")
            return True

        # 2. Verificar palavras-chave que indicam ambiguidade ou falta de informaÃ§Ãµes na memÃ³ria recente
        # Olhar as Ãºltimas mensagens em busca de sinais reveladores.
        # Esta Ã© uma heurÃ­stica simples e pode ser expandida.
        recent_messages_to_check = 3
        keywords = ["nÃ£o fornecido", "incerto", "chave de api ausente", "qual Ã© o valor", "parÃ¢metro desconhecido", "esclarecer", "nÃ£o estÃ¡ claro"]

        for message in self.memory.messages[-recent_messages_to_check:]:
            if message.content: # Garantir que o conteÃºdo nÃ£o Ã© None
                for keyword in keywords:
                    if keyword in message.content.lower():
                        logger.info(f"CondiÃ§Ã£o de feedback: Palavra-chave '{keyword}' encontrada nas mensagens recentes.")
                        # Solicitar ao LLM para fazer uma pergunta.
                        self.update_memory("system", f"Parece haver alguma incerteza (relacionada a '{keyword}'). Por favor, use a ferramenta 'ask_human' para pedir esclarecimentos ou informaÃ§Ãµes ausentes ao usuÃ¡rio.")
                        return True

        # 3. Placeholder para verificar tentativas falhas repetidas
        # TODO: Implementar lÃ³gica para detectar execuÃ§Ãµes de ferramentas falhas repetidas ou falta de progresso em direÃ§Ã£o a um objetivo.
        # Isso pode envolver a anÃ¡lise dos resultados da execuÃ§Ã£o da ferramenta ou outras mÃ©tricas de progresso.
        # Por exemplo, se as Ãºltimas N chamadas de ferramenta resultaram em erros ou nenhuma mudanÃ§a no estado.

        # 4. Verificar passos excessivos sem finalizar (como um fallback)
        # Esta Ã© uma versÃ£o mais branda do antigo interaction_interval, mas mais uma verificaÃ§Ã£o de "estamos demorando muito?".
        # Acionar apenas se um nÃºmero significativo de passos tiver passado sem resoluÃ§Ã£o.
        if self.current_step > (self.max_steps * 0.75) and self.state != AgentState.FINISHED:
             logger.info(f"CondiÃ§Ã£o de feedback: Agente executou {self.current_step} passos sem finalizar.")
             self.update_memory("system", "VocÃª executou um nÃºmero significativo de passos. Se nÃ£o estiver confiante no caminho atual, considere usar 'ask_human' para verificar com o usuÃ¡rio ou pedir orientaÃ§Ã£o.")
             return True

        return False

```

### ARQUIVO: app/agent/manus.py ###
```py
import os
import uuid
from typing import Dict, List, Optional, Any

from pydantic import Field, model_validator, PrivateAttr

import json
import re
import ast # Added for AST parsing
# os is already imported
from app.agent.browser import BrowserContextHelper
from app.agent.toolcall import ToolCallAgent, ToolCall
from app.config import config
from app.logger import logger
from app.prompt.manus import NEXT_STEP_PROMPT, SYSTEM_PROMPT
from app.schema import AgentState, Message, Role, Function as FunctionCall
from app.sandbox.client import SANDBOX_CLIENT
from app.tool import Terminate, ToolCollection
from app.exceptions import ToolError
from app.tool.ask_human import AskHuman
from app.tool.bash import Bash
from app.tool.browser_use_tool import BrowserUseTool
from app.tool.mcp import MCPClients, MCPClientTool
from app.tool.python_execute import PythonExecute
from app.tool.sandbox_python_executor import SandboxPythonExecutor
from app.tool.str_replace_editor import StrReplaceEditor
from app.tool.file_operators import LocalFileOperator

from app.tool.read_file_content import ReadFileContentTool
from app.tool.checklist_tools import ViewChecklistTool, AddChecklistTaskTool, UpdateChecklistTaskTool
from app.tool.file_system_tools import CheckFileExistenceTool, ListFilesTool # Added ListFilesTool
from app.agent.checklist_manager import ChecklistManager # Added for _is_checklist_complete
from .regex_patterns import re_subprocess
from app.tool.background_process_tools import ExecuteBackgroundProcessTool, CheckProcessStatusTool, GetProcessOutputTool



# Nova constante para autoanÃ¡lise interna
INTERNAL_SELF_ANALYSIS_PROMPT_TEMPLATE = """VocÃª Ã© Manus. VocÃª estÃ¡ em um ponto de verificaÃ§Ã£o com o usuÃ¡rio.
Analise o histÃ³rico recente da conversa (Ãºltimas {X} mensagens), o estado atual do seu checklist de tarefas (fornecido abaixo), e quaisquer erros ou dificuldades que vocÃª encontrou.
Com base nisso, gere um "RelatÃ³rio de AutoanÃ¡lise e Planejamento" conciso em portuguÃªs para apresentar ao usuÃ¡rio.
O relatÃ³rio deve incluir:
1. Um breve diagnÃ³stico da sua situaÃ§Ã£o atual, incluindo a **causa raiz de quaisquer dificuldades ou erros recentes** (ex: "Estou tentando X, mas a ferramenta Y falhou com o erro Z. Acredito que a causa raiz foi [uma mÃ¡ escolha de parÃ¢metros para a ferramenta / a ferramenta nÃ£o ser adequada para esta subtarefa / um problema no meu plano original / etc.]").
2. Pelo menos uma ou duas **estratÃ©gias alternativas CONCRETAS** que vocÃª pode tentar para superar essas dificuldades, incluindo **correÃ§Ãµes especÃ­ficas** para erros, se aplicÃ¡vel (Ex: "Pensei em tentar A [descrever A, e.g., 'usar a ferramenta Y com parÃ¢metro W corrigido'] ou B [descrever B, e.g., 'usar a ferramenta Q em vez da Y para esta etapa'] como alternativas.").
3. Uma sugestÃ£o de **como vocÃª pode evitar erros semelhantes no futuro** (Ex: "Para evitar este erro no futuro, vou [verificar X antes de usar a ferramenta Y / sempre usar a ferramenta Q para este tipo de tarefa / etc.]").
4. Opcional: Se vocÃª tiver um plano preferido ou mais elaborado para uma das alternativas, mencione-o brevemente.

Formate a resposta APENAS com o relatÃ³rio. NÃ£o adicione frases introdutÃ³rias como "Claro, aqui estÃ¡ o relatÃ³rio".
Se nÃ£o houver dificuldades significativas ou alternativas claras, indique isso de forma concisa (ex: "DiagnÃ³stico: Progresso estÃ¡ estÃ¡vel na tarefa atual. Alternativas: Nenhuma alternativa principal considerada no momento.").

ConteÃºdo do Checklist Principal (`checklist_principal_tarefa.md`):
{checklist_content}
"""


class Manus(ToolCallAgent):
    """Um agente versÃ¡til de propÃ³sito geral com suporte para ferramentas locais e MCP."""

    name: str = "Manus"
    description: str = "Um agente versÃ¡til que pode resolver vÃ¡rias tarefas usando mÃºltiplas ferramentas, incluindo ferramentas baseadas em MCP"

    system_prompt: str = SYSTEM_PROMPT
    next_step_prompt: str = NEXT_STEP_PROMPT

    max_observe: int = 10000
    max_steps: int = 20

    _mcp_clients: Optional[MCPClients] = PrivateAttr(default=None)
    _monitoring_background_task: bool = PrivateAttr(default=False)
    _background_task_log_file: Optional[str] = PrivateAttr(default=None)
    _background_task_expected_artifact: Optional[str] = PrivateAttr(default=None)
    _background_task_artifact_path: Optional[str] = PrivateAttr(default=None)
    _background_task_description: Optional[str] = PrivateAttr(default=None)
    _background_task_last_log_size: int = PrivateAttr(default=0)
    _background_task_no_change_count: int = PrivateAttr(default=0)
    _MAX_LOG_NO_CHANGE_TURNS: int = PrivateAttr(default=3)
    _just_resumed_from_feedback: bool = PrivateAttr(default=False)
    _trigger_failure_check_in: bool = PrivateAttr(default=False)
    _pending_script_after_dependency: Optional[str] = PrivateAttr(default=None)
    _original_tool_call_for_pending_script: Optional[ToolCall] = PrivateAttr(default=None)
    _workspace_script_analysis_cache: Optional[Dict[str, Dict[str, Any]]] = PrivateAttr(default=None)
    _current_sandbox_pid: Optional[int] = PrivateAttr(default=None)
    _current_sandbox_pid_file: Optional[str] = PrivateAttr(default=None)
    _current_script_tool_call_id: Optional[str] = PrivateAttr(default=None)
    _fallback_attempted_for_tool_call_id: Optional[str] = PrivateAttr(default=None)
    _pending_fallback_tool_call: Optional[ToolCall] = PrivateAttr(default=None)
    _last_ask_human_for_fallback_id: Optional[str] = PrivateAttr(default=None)
    _autonomous_mode: bool = PrivateAttr(default=False) # Flag to indicate if the agent should operate without asking for continuation feedback periodically.


    def __getstate__(self):
        logger.info(f"Manus.__getstate__ chamado para instÃ¢ncia: {self!r}")
        state = self.__dict__.copy()
        state.pop('_mcp_clients', None)
        state.pop('available_tools', None)
        state.pop('llm', None)
        logger.info(f"Manus.__getstate__ chaves finais: {list(state.keys())}")
        return state

    def __setstate__(self, state):
        self.__dict__.update(state)

        from app.llm import LLM
        from app.tool import ToolCollection
        from app.tool.mcp import MCPClients
        from app.tool.python_execute import PythonExecute
        from app.tool.str_replace_editor import StrReplaceEditor
        from app.tool.ask_human import AskHuman
        from app.tool.terminate import Terminate
        from app.tool.bash import Bash
        from app.tool.sandbox_python_executor import SandboxPythonExecutor
        from app.tool.browser_use_tool import BrowserUseTool
        from app.tool.code_formatter import FormatPythonCode
        from app.tool.code_editor_tools import ReplaceCodeBlock, ApplyDiffPatch, ASTRefactorTool

        from app.tool.read_file_content import ReadFileContentTool
        from app.tool.checklist_tools import ViewChecklistTool, AddChecklistTaskTool, UpdateChecklistTaskTool
        from app.tool.file_system_tools import ListFilesTool # Adicionado ListFilesTool
        # Imports for background process tools already added at the top of the file for __init__
        # No need to re-import here if they are module-level imports

        llm_config_name = "manus"
        if 'name' in state and state['name']:
            llm_config_name = state['name'].lower()
        elif hasattr(self, 'name') and self.name:
            llm_config_name = self.name.lower()
        self.llm = LLM(config_name=llm_config_name)
        self._mcp_clients = MCPClients()

        self.available_tools = ToolCollection(
            PythonExecute(), StrReplaceEditor(), AskHuman(), Terminate(), Bash(),
            SandboxPythonExecutor(), BrowserUseTool(), FormatPythonCode(),

            ReplaceCodeBlock(), ApplyDiffPatch(), ASTRefactorTool(), ReadFileContentTool(),
            ViewChecklistTool(), AddChecklistTaskTool(), UpdateChecklistTaskTool(),
            CheckFileExistenceTool(), ListFilesTool(),
            ExecuteBackgroundProcessTool(), CheckProcessStatusTool(), GetProcessOutputTool()
        )
        self._initialized = False
        self.connected_servers = {}

    special_tool_names: list[str] = Field(default_factory=lambda: [Terminate().name])
    browser_context_helper: Optional[Any] = None
    planned_tool_calls: List[ToolCall] = Field(default_factory=list)

    def __init__(self, **data):
        super().__init__(**data)
        self._mcp_clients = MCPClients()
        from app.tool.code_formatter import FormatPythonCode
        from app.tool.code_editor_tools import ReplaceCodeBlock, ApplyDiffPatch, ASTRefactorTool

        from app.tool.read_file_content import ReadFileContentTool
        from app.tool.checklist_tools import ViewChecklistTool, AddChecklistTaskTool, UpdateChecklistTaskTool
        from app.tool.file_system_tools import ListFilesTool # Adicionado ListFilesTool
        self.available_tools = ToolCollection(
            PythonExecute(), BrowserUseTool(), StrReplaceEditor(), AskHuman(), Terminate(),
            Bash(), SandboxPythonExecutor(), FormatPythonCode(), ReplaceCodeBlock(),
            ApplyDiffPatch(), ASTRefactorTool(), ReadFileContentTool(),
            ViewChecklistTool(), AddChecklistTaskTool(), UpdateChecklistTaskTool(),
            CheckFileExistenceTool(), ListFilesTool(),
            ExecuteBackgroundProcessTool(), CheckProcessStatusTool(), GetProcessOutputTool()
        )

    connected_servers: Dict[str, str] = Field(default_factory=dict)
    _initialized: bool = False

    @model_validator(mode="after")
    def initialize_helper(self) -> "Manus":
        self.browser_context_helper = BrowserContextHelper(self)
        return self

    @classmethod
    async def create(cls, **kwargs) -> "Manus":
        instance = cls(**kwargs)
        logger.info(f"Agente Manus criado. Prompt do sistema (primeiros 500 caracteres): {instance.system_prompt[:500]}")

        running_tasks_file = config.workspace_root / "running_tasks.json"
        if os.path.exists(running_tasks_file):
            logger.info(f"Found existing running_tasks.json at {running_tasks_file}. Attempting to load and check tasks.")
            updated_tasks_after_check = []
            tasks_loaded = False
            persisted_tasks = [] # Definir persisted_tasks com um valor padrÃ£o
            try:
                with open(running_tasks_file, 'r') as f:
                    persisted_tasks = json.load(f)
                tasks_loaded = True

                if not persisted_tasks:
                    logger.info("running_tasks.json was empty.")

                status_checker_tool = instance.available_tools.get_tool(CheckProcessStatusTool().name)

                if status_checker_tool:
                    for task_info in persisted_tasks:
                        pid = task_info.get('pid')
                        if pid:
                            logger.info(f"Checking status for persisted task PID: {pid}, Command: {task_info.get('command')}")
                            status_result = await status_checker_tool.execute(pid=pid)
                            current_status = status_result.get('status', 'unknown')
                            task_info['status'] = current_status

                            if current_status not in ['not_found', 'finished', 'error']:
                                updated_tasks_after_check.append(task_info)

                            load_message = (
                                f"Tarefa em background recuperada da sessÃ£o anterior: "
                                f"PID: {pid}, DescriÃ§Ã£o: {task_info.get('task_description', task_info.get('command', 'N/A'))}, "
                                f"Status atual: {current_status}."
                            )
                            if current_status == 'finished':
                                load_message += f" CÃ³digo de saÃ­da: {status_result.get('return_code')}."

                            instance.memory.add_message(Message.system_message(load_message))
                            logger.info(load_message)
                        else:
                            # Keep tasks without PID if they somehow exist, though they shouldn't normally.
                            # Or decide to filter them out if they are considered invalid.
                            # For now, keeping them.
                            updated_tasks_after_check.append(task_info)
                else:
                    logger.error("CheckProcessStatusTool nÃ£o encontrado na instÃ¢ncia do agente durante o carregamento de tarefas.")
                    instance.memory.add_message(Message.system_message(
                        "AVISO: NÃ£o foi possÃ­vel verificar o status de tarefas em background da sessÃ£o anterior (ferramenta de status nÃ£o encontrada)."
                    ))
                    # If checker is not found, keep all tasks as they were, as we can't verify them.
                    updated_tasks_after_check.extend(persisted_tasks)

            except json.JSONDecodeError as e_json:
                logger.error(f"Error decoding running_tasks.json: {e_json}")
                instance.memory.add_message(Message.system_message(f"AVISO: Erro ao ler o arquivo de tarefas em background ({running_tasks_file}): {e_json}"))
            except Exception as e_load:
                logger.error(f"Unexpected error loading or checking persisted tasks: {e_load}", exc_info=True)
                instance.memory.add_message(Message.system_message(f"AVISO: Erro inesperado ao carregar tarefas em background: {e_load}"))

            if tasks_loaded:
                final_tasks_for_persistence = updated_tasks_after_check
                try:
                    with open(running_tasks_file, 'w') as f:
                        json.dump(final_tasks_for_persistence, f, indent=4)
                    logger.info(f"Persisted tasks file {running_tasks_file} updated after status check. Kept {len(final_tasks_for_persistence)} tasks.")
                except Exception as e_write_back:
                    logger.error(f"Error writing back to running_tasks.json after status check: {e_write_back}")

        await instance.initialize_mcp_servers()
        instance._initialized = True
        return instance

    async def initialize_mcp_servers(self) -> None:
        for server_id, server_config in config.mcp_config.servers.items():
            try:
                if server_config.type == "sse":
                    if server_config.url:
                        await self.connect_mcp_server(server_config.url, server_id)
                        logger.info(f"Conectado ao servidor MCP {server_id} em {server_config.url}")
                elif server_config.type == "stdio":
                    if server_config.command:
                        await self.connect_mcp_server(
                            server_config.command, server_id, use_stdio=True, stdio_args=server_config.args,
                        )
                        logger.info(f"Conectado ao servidor MCP {server_id} usando o comando {server_config.command}")
            except Exception as e:
                logger.error(f"Falha ao conectar ao servidor MCP {server_id}: {e}")

    async def connect_mcp_server(
        self, server_url: str, server_id: str = "", use_stdio: bool = False, stdio_args: List[str] = None,
    ) -> None:
        if use_stdio:
            await self._mcp_clients.connect_stdio(server_url, stdio_args or [], server_id)
            self.connected_servers[server_id or server_url] = server_url
        else:
            await self._mcp_clients.connect_sse(server_url, server_id)
            self.connected_servers[server_id or server_url] = server_url
        new_tools = [tool for tool in self._mcp_clients.tools if tool.server_id == server_id]
        self.available_tools.add_tools(*new_tools)

    async def disconnect_mcp_server(self, server_id: str = "") -> None:
        await self._mcp_clients.disconnect(server_id)
        if server_id: self.connected_servers.pop(server_id, None)
        else: self.connected_servers.clear()
        base_tools = [tool for tool in self.available_tools.tools if not isinstance(tool, MCPClientTool)]
        self.available_tools = ToolCollection(*base_tools)
        self.available_tools.add_tools(*self._mcp_clients.tools)

    async def cleanup(self):
        logger.info("Manus.cleanup: Iniciando limpeza especÃ­fica do agente Manus...")
        if self.browser_context_helper:
            await self.browser_context_helper.cleanup_browser()
        if self._initialized:
            await self.disconnect_mcp_server()
            self._initialized = False
        if hasattr(self, 'available_tools') and self.available_tools:
            for tool_name, tool_instance in self.available_tools.tool_map.items():
                if hasattr(tool_instance, "cleanup") and callable(getattr(tool_instance, "cleanup")):
                    try: await tool_instance.cleanup()
                    except Exception as e: logger.error(f"Erro durante a limpeza da ferramenta {tool_name}: {e}")
        try:
            await SANDBOX_CLIENT.cleanup()
        except Exception as e: logger.error(f"Erro durante SANDBOX_CLIENT.cleanup em Manus.cleanup: {e}")
        logger.info("Limpeza do agente Manus concluÃ­da.")

    async def _internal_tool_feedback_check(self, tool_call: Optional[ToolCall] = None) -> bool: return False
    async def _is_checklist_complete(self) -> bool:
        try:
            manager = ChecklistManager()
            await manager._load_checklist()
            tasks = manager.get_tasks() # Obter tarefas uma vez

            if not tasks:
                logger.info("Manus._is_checklist_complete: Checklist nÃ£o estÃ¡ completo porque nenhuma tarefa foi encontrada (o arquivo pode estar vazio ou ausente).")
                return False

            # INÃCIO DA NOVA LÃ“GICA
            # Verifica se a *Ãºnica* tarefa Ã© uma tarefa de decomposiÃ§Ã£o genÃ©rica e estÃ¡ marcada como concluÃ­da.
            # Esta Ã© uma heurÃ­stica.
            decomposition_task_description_variations = [
                "decompor a solicitaÃ§Ã£o do usuÃ¡rio e popular o checklist com as subtarefas",
                "decompor a tarefa do usuÃ¡rio em subtarefas claras",
                "decompor o pedido do usuÃ¡rio e preencher o checklist",
                "popular o checklist com as subtarefas da solicitaÃ§Ã£o do usuÃ¡rio",
                "criar checklist inicial a partir da solicitaÃ§Ã£o do usuÃ¡rio"
                # Adicionar outras variaÃ§Ãµes comuns se observadas durante o teste/operaÃ§Ã£o
            ]

            if len(tasks) == 1:
                single_task = tasks[0]
                # Normalizar para comparaÃ§Ã£o mais segura: descriÃ§Ã£o em minÃºsculas e sem espaÃ§os em branco
                normalized_single_task_desc = single_task.get('description', '').strip().lower()
                # Normalizar status: em minÃºsculas e sem espaÃ§os em branco
                single_task_status = single_task.get('status', '').strip().lower()

                is_generic_decomposition_task = any(
                    variation.lower() in normalized_single_task_desc for variation in decomposition_task_description_variations
                )

                if is_generic_decomposition_task and single_task_status == 'concluÃ­do':
                    logger.warning("Manus._is_checklist_complete: Checklist contÃ©m apenas a tarefa inicial semelhante Ã  decomposiÃ§Ã£o "
                                   "marcada como 'ConcluÃ­do'. Isso provavelmente Ã© prematuro. "
                                   "Considerando o checklist NÃƒO completo para forÃ§ar o preenchimento das subtarefas reais.")
                    # Opcional: Adicionar uma mensagem de sistema para guiar o LLM para o prÃ³ximo passo.
                    # Isso requer que self.memory seja acessÃ­vel e uma classe Message.
                    # from app.schema import Message, Role # Garantir importaÃ§Ã£o se usado
                    # self.memory.add_message(Message.system_message(
                    #    "Lembrete: A tarefa de decomposiÃ§Ã£o sÃ³ Ã© verdadeiramente concluÃ­da apÃ³s as subtarefas resultantes "
                    #    "serem adicionadas ao checklist e o trabalho nelas ter comeÃ§ado. Por favor, adicione as subtarefas agora."
                    # ))
                    return False
            # FIM DA NOVA LÃ“GICA

            # Prosseguir com a lÃ³gica original se a condiÃ§Ã£o acima nÃ£o for atendida
            # O mÃ©todo manager.are_all_tasks_complete() verifica se todas as tarefas carregadas sÃ£o 'ConcluÃ­do'.
            # Ele retornarÃ¡ False corretamente se houver tarefas, mas nem todas forem 'ConcluÃ­do'.
            all_complete_according_to_manager = manager.are_all_tasks_complete()

            if not all_complete_according_to_manager:
                 # Log jÃ¡ feito por are_all_tasks_complete se retornar falso devido a tarefas incompletas
                 logger.info(f"Manus._is_checklist_complete: Checklist nÃ£o estÃ¡ completo com base em ChecklistManager.are_all_tasks_complete() retornando False.")
                 return False

            # Se manager.are_all_tasks_complete() retornou True, significa que todas as tarefas encontradas estÃ£o completas.
            # E se passamos na nova verificaÃ§Ã£o heurÃ­stica (ou seja, nÃ£o Ã© uma Ãºnica tarefa de decomposiÃ§Ã£o concluÃ­da prematuramente),
            # entÃ£o o checklist estÃ¡ genuinamente completo.
            logger.info(f"Manus._is_checklist_complete: Status de conclusÃ£o do checklist: True (todas as tarefas concluÃ­das e nÃ£o uma decomposiÃ§Ã£o prematura).")
            return True

        except Exception as e:
            # Registrar o erro e retornar False, pois a conclusÃ£o nÃ£o pode ser confirmada.
            logger.error(f"Erro ao verificar a conclusÃ£o do checklist em Manus._is_checklist_complete: {e}")
            return False

    async def should_request_feedback(self) -> bool:
        # Determines if the agent should pause and request feedback from the user.
        # This happens on failure, task completion, or after a set number of steps (unless in autonomous_mode).
        if self._trigger_failure_check_in:
            self._trigger_failure_check_in = False
            await self.periodic_user_check_in(is_failure_scenario=True)
            return True
        if self._just_resumed_from_feedback:
            self._just_resumed_from_feedback = False
            return False
        if await self._is_checklist_complete():
            last_assistant_msg = next((m for m in reversed(self.memory.messages) if m.role == Role.ASSISTANT and m.tool_calls), None)
            if last_assistant_msg and any(tc.function.name == Terminate().name for tc in last_assistant_msg.tool_calls):
                return False
            await self.periodic_user_check_in(is_final_check=True, is_failure_scenario=False)
            return True
        if not self._autonomous_mode and self.current_step > 0 and self.max_steps > 0 and self.current_step % self.max_steps == 0: # Skip periodic check-in if in autonomous mode
            continue_execution = await self.periodic_user_check_in(is_failure_scenario=False)
            return continue_execution
        return False

    def _sanitize_text_for_file(self, text_content: str) -> str:
        if not isinstance(text_content, str): return text_content
        return text_content.replace('\u0000', '')

    def _extract_python_code(self, text: str) -> str:
        if "```python" in text: return text.split("```python")[1].split("```")[0].strip()
        if "```" in text: return text.split("```")[1].split("```")[0].strip()
        return text.strip()

    async def _execute_self_coding_cycle(self, task_prompt_for_llm: str, max_attempts: int = 3) -> Dict[str, Any]:
        logger.info(f"Iniciando ciclo de auto-codificaÃ§Ã£o para tarefa: {task_prompt_for_llm}")
        script_content: Optional[str] = None
        host_script_path: str = ""
        final_result: Dict[str, Any] = {"success": False, "message": "Ciclo de auto-codificaÃ§Ã£o nÃ£o concluÃ­do."}

        local_op = LocalFileOperator()

        for attempt in range(max_attempts):
            logger.info(f"Tentativa de auto-codificaÃ§Ã£o {attempt + 1}/{max_attempts}")

            code_fixed_by_formatter = False
            targeted_edits_applied_this_attempt = False
            # analysis_failed_or_no_edits_suggested = False # Esta flag parece nÃ£o utilizada com a nova lÃ³gica

            if attempt == 0:
                logger.info(f"Tentativa {attempt + 1}: Gerando script inicial para tarefa: {task_prompt_for_llm}")
                # Placeholder para chamada LLM para gerar script inicial
                generated_script_content = f"# Script Inicial - Tentativa {attempt + 1}\n# Tarefa: {task_prompt_for_llm}\nprint(\"Tentando tarefa: {task_prompt_for_llm}\")\n# Exemplo: Introduzir intencionalmente um erro de sintaxe para teste\n# print(\"Erro de sintaxe aqui\"\nwith open(\"output.txt\", \"w\") as f:\n    f.write(\"SaÃ­da da tentativa de script {attempt + 1}\")\nprint(\"Script concluiu tentativa {attempt + 1}.\")"
                script_content = self._sanitize_text_for_file(generated_script_content)
                if not script_content:
                    logger.error("LLM (simulado) falhou ao gerar conteÃºdo do script inicial.")
                    final_result = {"success": False, "message": "LLM (simulado) falhou ao gerar script inicial."}
                    continue
                script_filename = f"temp_manus_script_{uuid.uuid4().hex[:8]}.py"
                host_script_path = str(config.workspace_root / script_filename)
                try:
                    await local_op.write_file(host_script_path, script_content)
                    logger.info(f"Script inicial escrito no host: {host_script_path}")
                except Exception as e:
                    logger.error(f"Falha ao escrever script inicial no host: {e}")
                    final_result = {"success": False, "message": f"Falha ao escrever script inicial no host: {e}"}
                    continue
            elif not host_script_path or not os.path.exists(host_script_path):
                logger.error(f"host_script_path ('{host_script_path}') nÃ£o definido ou arquivo nÃ£o existe na tentativa {attempt + 1}. Erro crÃ­tico.")
                final_result = {"success": False, "message": "Erro interno: Caminho do script perdido ou arquivo ausente entre tentativas."}
                break

            sandbox_script_name_in_container = os.path.basename(host_script_path)
            sandbox_target_path_for_executor = f"/workspace/{sandbox_script_name_in_container}"

            str_editor_tool = self.available_tools.get_tool(StrReplaceEditor().name)
            if not str_editor_tool:
                logger.critical("Ferramenta StrReplaceEditor nÃ£o estÃ¡ disponÃ­vel para cÃ³pia para o sandbox.")
                final_result = {"success": False, "message": "Erro crÃ­tico: Ferramenta StrReplaceEditor ausente."}
                break

            copy_to_sandbox_succeeded = False
            try:
                await str_editor_tool.execute(command="copy_to_sandbox", path=host_script_path, container_filename=sandbox_script_name_in_container)
                logger.info(f"CÃ³pia do script para o sandbox bem-sucedida: {host_script_path} -> {sandbox_target_path_for_executor}")
                copy_to_sandbox_succeeded = True
            except Exception as e_copy:
                logger.error(f"Falha ao copiar script para o sandbox: {e_copy}")
                final_result = {"success": False, "message": f"Falha ao copiar script para o sandbox: {e_copy}", "status_code": "SANDBOX_COPY_FAILED"}
                continue

            execution_result = {}
            if copy_to_sandbox_succeeded:
                executor_tool = self.available_tools.get_tool(SandboxPythonExecutor().name)
                if not executor_tool:
                    logger.critical("Ferramenta SandboxPythonExecutor nÃ£o encontrada.")
                    final_result = {"success": False, "message": "Ferramenta SandboxPythonExecutor nÃ£o encontrada."}
                    break

                execution_result = await executor_tool.execute(file_path=sandbox_target_path_for_executor, timeout=30)
                logger.info(f"ExecuÃ§Ã£o no sandbox: stdout='{execution_result.get('stdout')}', stderr='{execution_result.get('stderr')}', exit_code={execution_result.get('exit_code')}")
                final_result["last_execution_result"] = execution_result
            else:
                logger.error("Pulando execuÃ§Ã£o pois a cÃ³pia para o sandbox falhou.")
                continue

            exit_code = execution_result.get("exit_code", -1)
            stderr = execution_result.get("stderr", "")
            stdout = execution_result.get("stdout", "")

            if exit_code == 0:
                logger.info(f"Script executado com sucesso na tentativa {attempt + 1}.")
                final_result = {"success": True, "message": "Script executado com sucesso.", "stdout": stdout, "stderr": stderr, "exit_code": exit_code}
                # Limpeza simplificada de sucesso por enquanto
                break
            else: # ExecuÃ§Ã£o do script falhou (exit_code != 0)
                logger.warning(f"ExecuÃ§Ã£o do script falhou na tentativa {attempt + 1}. CÃ³digo de saÃ­da: {exit_code}, Stderr: {stderr}")
                final_result = {"success": False, "message": f"ExecuÃ§Ã£o falhou na tentativa {attempt+1}.", "stdout":stdout, "stderr":stderr, "exit_code":exit_code}

                if attempt >= max_attempts - 1:
                    logger.info("Ãšltima tentativa falhou. Nenhuma correÃ§Ã£o adicional serÃ¡ tentada.")
                    break

                # --- Funil de DepuraÃ§Ã£o ---
                current_script_code_for_analysis = await local_op.read_file(host_script_path)

                if "SyntaxError:" in stderr or "IndentationError:" in stderr:
                    logger.info(f"[TENTATIVA_CORRECAO {attempt + 1}/{max_attempts}] Tentando corrigir erro de Sintaxe/IndentaÃ§Ã£o usando formatador para script {host_script_path}.")
                    formatter_tool = self.available_tools.get_tool("format_python_code")
                    if formatter_tool:
                        format_result = await formatter_tool.execute(code=current_script_code_for_analysis)
                        if isinstance(format_result, str):
                            try:
                                ast.parse(format_result)
                                logger.info("CÃ³digo formatado parseado com sucesso. Escrevendo de volta.")
                                await local_op.write_file(host_script_path, format_result)
                                code_fixed_by_formatter = True
                            except SyntaxError as e_ast:
                                logger.warning(f"CÃ³digo formatado ainda tem erros de sintaxe: {e_ast}.")
                        else:
                            logger.warning(f"Formatador de cÃ³digo falhou: {format_result.get('error')}.")
                    else:
                        logger.warning("Ferramenta format_python_code nÃ£o encontrada.")

                if code_fixed_by_formatter:
                    logger.info("CÃ³digo corrigido pelo formatador. Tentando novamente.")
                    continue

                # LLM para CorreÃ§Ãµes Complexas
                log_msg_llm_query = ""
                if "SyntaxError:" in stderr or "IndentationError:" in stderr: # Ainda um erro de sintaxe apÃ³s tentativa do formatador
                    logger.info(f"[TENTATIVA_CORRECAO {attempt + 1}/{max_attempts}] Formatador nÃ£o corrigiu erro de sintaxe para script {host_script_path}, ou erro nÃ£o era relacionado Ã  formataÃ§Ã£o. Consultando LLM.")
                else: # Erro de tempo de execuÃ§Ã£o
                    logger.info(f"[TENTATIVA_CORRECAO {attempt + 1}/{max_attempts}] Script {host_script_path} falhou com erro de tempo de execuÃ§Ã£o. Consultando LLM.")
                # O logger.info(log_msg_llm_query) foi removido pois as mensagens especÃ­ficas acima o cobrem.

                current_script_code_for_analysis = await local_op.read_file(host_script_path) # RelÃª caso o formatador tenha feito alteraÃ§Ãµes
                analysis_prompt_text = self._build_targeted_analysis_prompt(
                    script_content=current_script_code_for_analysis, stdout=stdout, stderr=stderr, original_task=task_prompt_for_llm
                )
                llm_analysis_response_str = await self.llm.ask(messages=[Message.user_message(analysis_prompt_text)], stream=False)
                extracted_json_str = self._extract_json_from_response(llm_analysis_response_str)

                if extracted_json_str:
                    try:
                        parsed_llm_suggestion = json.loads(extracted_json_str)
                        tool_to_use_name = parsed_llm_suggestion.get("tool_to_use")
                        tool_params_from_llm = parsed_llm_suggestion.get("tool_params")

                        if tool_to_use_name and isinstance(tool_params_from_llm, dict):
                            logger.info(f"[TENTATIVA_CORRECAO {attempt + 1}/{max_attempts}] LLM sugeriu ferramenta '{tool_to_use_name}' para script {host_script_path}. Tentando execuÃ§Ã£o com params: {tool_params_from_llm}")
                            chosen_tool = self.available_tools.get_tool(tool_to_use_name)
                            if chosen_tool:
                                if tool_to_use_name == "format_python_code":
                                    tool_params_from_llm["code"] = current_script_code_for_analysis # Garante que 'code' Ã© passado
                                    tool_params_from_llm.pop("path", None)
                                else:
                                    tool_params_from_llm["path"] = host_script_path

                                tool_exec_result = await chosen_tool.execute(**tool_params_from_llm)
                                if isinstance(tool_exec_result, dict) and tool_exec_result.get("error"):
                                    logger.error(f"Ferramenta sugerida pelo LLM '{tool_to_use_name}' falhou: {tool_exec_result.get('error')}")
                                else: # Sucesso assumido
                                    logger.info(f"Ferramenta sugerida pelo LLM '{tool_to_use_name}' executada com sucesso.")
                                    targeted_edits_applied_this_attempt = True
                            else:
                                logger.warning(f"Ferramenta sugerida pelo LLM '{tool_to_use_name}' nÃ£o encontrada.")
                        elif tool_to_use_name is None: # LLM explicitamente disse nenhuma ferramenta
                             logger.info(f"LLM explicitamente nÃ£o sugeriu nenhuma ferramenta. ComentÃ¡rio: {parsed_llm_suggestion.get('comment')}")
                        else: # Estrutura JSON invÃ¡lida do LLM
                            logger.warning(f"SugestÃ£o JSON do LLM invÃ¡lida. SugestÃ£o: {parsed_llm_suggestion}")
                    except json.JSONDecodeError as json_e:
                        logger.error(f"Falha ao parsear JSON da sugestÃ£o de ferramenta do LLM: {json_e}. Raw: {llm_analysis_response_str}")
                    except Exception as tool_apply_e:
                        logger.error(f"Erro ao aplicar ferramenta sugerida pelo LLM: {tool_apply_e}")
                else:
                    logger.warning("NÃ£o foi possÃ­vel extrair JSON da resposta de sugestÃ£o de ferramenta do LLM.")

                if targeted_edits_applied_this_attempt:
                    logger.info("EdiÃ§Ãµes sugeridas pelo LLM aplicadas. Tentando novamente execuÃ§Ã£o do script.")
                    continue
                else:
                    logger.info("CorreÃ§Ã£o baseada em LLM falhou ou nenhuma ediÃ§Ã£o vÃ¡lida aplicada nesta tentativa.")

            # Limpa script do sandbox para esta tentativa falha (se copiado)
            if copy_to_sandbox_succeeded and SANDBOX_CLIENT.sandbox and SANDBOX_CLIENT.sandbox.container:
                try: await SANDBOX_CLIENT.run_command(f"rm -f {sandbox_target_path_for_executor}")
                except Exception as e_rm_sandbox: logger.error(f"Erro ao remover script do sandbox pÃ³s-tentativa: {e_rm_sandbox}")

        # Limpeza final do script do host se ainda existir (ex: todas as tentativas falharam)
        if host_script_path and os.path.exists(host_script_path):
            try: await local_op.delete_file(host_script_path)
            except Exception as e_final_clean: logger.error(f"Erro na exclusÃ£o final do script do host {host_script_path}: {e_final_clean}")

        if not final_result["success"]:
             logger.error(f"Ciclo de auto-codificaÃ§Ã£o falhou totalmente apÃ³s {max_attempts} tentativas. Resultado final: {final_result}")

        self._monitoring_background_task = False
        self._background_task_log_file = None
        self._background_task_expected_artifact = None
        self._background_task_artifact_path = None
        self._background_task_description = None
        self._background_task_last_log_size = 0
        self._background_task_no_change_count = 0
        return final_result

    def _extract_json_from_response(self, llm_response: str) -> Optional[str]:
        """Extrai uma string JSON da resposta do LLM, lidando com blocos de cÃ³digo markdown."""
        logger.debug(f"Tentando extrair JSON da resposta do LLM: '{llm_response[:500]}...'")
        match = re.search(r"```json\s*([\s\S]+?)\s*```", llm_response)
        if match:
            json_str = match.group(1).strip()
            logger.debug(f"String JSON extraÃ­da usando regex: '{json_str[:500]}...'")
            return json_str

        response_stripped = llm_response.strip()
        if response_stripped.startswith("{") and response_stripped.endswith("}"):
            logger.debug("Resposta parece um objeto JSON direto. Usando como estÃ¡.")
            return response_stripped

        logger.warning("Nenhum bloco de cÃ³digo JSON encontrado, e resposta nÃ£o Ã© um objeto JSON direto.")
        return None

    def _build_targeted_analysis_prompt(self, script_content: str, stdout: str, stderr: str, original_task: str) -> str:
        """ConstrÃ³i o prompt para o LLM analisar e sugerir uma correÃ§Ã£o baseada em ferramenta."""
        ANALYSIS_PROMPT_TEMPLATE = """VocÃª Ã© um "Python Code Analyzer and Corrector".
Sua tarefa Ã© analisar um script Python que falhou, juntamente com sua saÃ­da padrÃ£o (stdout) e erro padrÃ£o (stderr).
VocÃª DEVE retornar um objeto JSON especificando uma Ãºnica ferramenta para aplicar a correÃ§Ã£o e os parÃ¢metros para essa ferramenta.

**Ferramentas DisponÃ­veis para CorreÃ§Ã£o:**
1.  **`replace_code_block`**:
    *   DescriÃ§Ã£o: Substitui um bloco de cÃ³digo entre `start_line` e `end_line` (inclusive, 1-indexado) com `new_content`.
    *   ParÃ¢metros: `path` (string, caminho do arquivo - **NÃƒO INCLUA ESTE PARÃ‚METRO, serÃ¡ adicionado automaticamente**), `start_line` (integer), `end_line` (integer), `new_content` (string).
    *   Uso: Ideal para substituir funÃ§Ãµes inteiras, blocos lÃ³gicos, ou seÃ§Ãµes maiores de cÃ³digo.
2.  **`apply_diff_patch`**:
    *   DescriÃ§Ã£o: Aplica um patch no formato unified diff ao arquivo.
    *   ParÃ¢metros: `path` (string, caminho do arquivo - **NÃƒO INCLUA ESTE PARÃ‚METRO**), `patch_content` (string, conteÃºdo do diff).
    *   Uso: Bom para mÃºltiplas pequenas alteraÃ§Ãµes, alteraÃ§Ãµes nÃ£o contÃ­guas, ou quando a lÃ³gica do diff Ã© mais fÃ¡cil de expressar. O diff deve ser gerado em relaÃ§Ã£o ao script original fornecido.
3.  **`ast_refactor`**:
    *   DescriÃ§Ã£o: Realiza refatoraÃ§Ãµes baseadas em AST. OperaÃ§Ã£o inicial: `replace_function_body`.
    *   ParÃ¢metros para `replace_function_body`: `path` (string - **NÃƒO INCLUA ESTE PARÃ‚METRO**), `operation` (string, fixo: "replace_function_body"), `target_node_name` (string, nome da funÃ§Ã£o), `new_code_snippet` (string, novo corpo da funÃ§Ã£o, sem o `def ...`).
    *   Uso: Mais seguro para refatoraÃ§Ãµes estruturais, como substituir o corpo de uma funÃ§Ã£o sem afetar sua assinatura ou o restante do arquivo.
4.  **`format_python_code`**:
    *   DescriÃ§Ã£o: Formata o cÃ³digo Python usando Ruff/Black. Pode corrigir erros de sintaxe/indentaÃ§Ã£o simples.
    *   ParÃ¢metros: `code` (string, o cÃ³digo completo a ser formatado - **IMPORTANTE: para esta ferramenta, em vez de "path", forneÃ§a o conteÃºdo do script no parÃ¢metro "code" dentro de "tool_params"**).
    *   Uso: Tente esta ferramenta PRIMEIRO para erros de SyntaxError ou IndentationError. Se o LLM for solicitado apÃ³s uma falha do formatador, nÃ£o sugira `format_python_code` novamente.

**Formato JSON ObrigatÃ³rio para a Resposta:**
A resposta DEVE ser uma string JSON que possa ser parseada, contendo um objeto com as seguintes chaves:
- "tool_to_use": string, o nome da ferramenta escolhida (e.g., "replace_code_block", "apply_diff_patch", "ast_refactor", "format_python_code").
- "tool_params": object, um dicionÃ¡rio contendo os parÃ¢metros especÃ­ficos para a ferramenta escolhida (NÃƒO inclua "path" aqui, exceto para "format_python_code" onde "code" Ã© usado em vez de "path").
- "comment": string, uma breve explicaÃ§Ã£o do erro e da correÃ§Ã£o que vocÃª estÃ¡ aplicando.

**Exemplos de Resposta JSON:**

Para `replace_code_block`:
```json
{
  "tool_to_use": "replace_code_block",
  "tool_params": {
    "start_line": 10,
    "end_line": 15,
    "new_content": "def minha_funcao_corrigida():\\n    return 'corrigido'"
  },
  "comment": "A funÃ§Ã£o 'minha_funcao' original tinha um erro de lÃ³gica. Substituindo-a completamente."
}
```

Para `apply_diff_patch`:
```json
{
  "tool_to_use": "apply_diff_patch",
  "tool_params": {
    "patch_content": "--- a/script_original.py\\n+++ b/script_corrigido.py\\n@@ -1,3 +1,3 @@\\n- linha_com_erro\\n+ linha_corrigida\\n  outra_linha\\n"
  },
  "comment": "Corrigido um typo na linha 1 e ajustada uma variÃ¡vel na linha 5 (exemplo de diff)."
}
```

Para `ast_refactor` (operaÃ§Ã£o `replace_function_body`):
```json
{
  "tool_to_use": "ast_refactor",
  "tool_params": {
    "operation": "replace_function_body",
    "target_node_name": "minha_funcao_com_erro",
    "new_code_snippet": "  # Novo corpo da funÃ§Ã£o\\n  resultado = calcula_algo()\\n  return resultado"
  },
  "comment": "O corpo da funÃ§Ã£o 'minha_funcao_com_erro' foi reescrito para corrigir um bug de cÃ¡lculo."
}
```

Para `format_python_code` (se for um erro de sintaxe e o formatador automÃ¡tico ainda nÃ£o foi tentado):
```json
{
  "tool_to_use": "format_python_code",
  "tool_params": {
    "code": "# ConteÃºdo completo do script aqui...\nprint('hello') # Exemplo"
  },
  "comment": "Tentando corrigir possÃ­vel erro de sintaxe/indentaÃ§Ã£o simples com o formatador."
}
```

**Importante:**
- Escolha APENAS UMA ferramenta.
- ForneÃ§a as correÃ§Ãµes no formato JSON EXATO especificado acima.
- Se o script estiver fundamentalmente errado e precisar de uma reescrita completa que nÃ£o se encaixe bem em uma Ãºnica chamada de ferramenta, ou se nenhuma correÃ§Ã£o for Ã³bvia, vocÃª PODE retornar um JSON com `tool_to_use": null` e um comentÃ¡rio explicando. Ex: `{"tool_to_use": null, "tool_params": {}, "comment": "O script estÃ¡ muito quebrado, sugiro reescrevÃª-lo com base na tarefa original."}`.
- Analise o `stderr` cuidadosamente para identificar a causa raiz do erro.
- O objetivo Ã© fazer a correÃ§Ã£o mais apropriada usando a ferramenta mais adequada.
- **NÃƒO inclua o parÃ¢metro "path" em "tool_params" para `replace_code_block`, `apply_diff_patch`, `ast_refactor`. Ele serÃ¡ adicionado automaticamente. Para `format_python_code`, use o parÃ¢metro "code" em `tool_params` para passar o conteÃºdo do script.**

**Script Original com Erro:**
```python
{script_content}
```

**SaÃ­da PadrÃ£o (stdout) da ExecuÃ§Ã£o Falha:**
```
{stdout}
```

**Erro PadrÃ£o (stderr) da ExecuÃ§Ã£o Falha:**
```
{stderr}
```

**Tarefa Original que o Script Tentava Realizar:**
{original_task}

Agora, forneÃ§a sua anÃ¡lise e a sugestÃ£o de ferramenta e parÃ¢metros no formato JSON especificado.
"""
        return ANALYSIS_PROMPT_TEMPLATE.format(
            script_content=script_content,
            stdout=stdout,
            stderr=stderr,
            original_task=original_task
        )

    async def think(self) -> bool:
        self.planned_tool_calls = []
        if not self._initialized:
            await self.initialize_mcp_servers()
            self._initialized = True

        # --- LÃ³gica de VerificaÃ§Ã£o Inicial do Checklist ---
        # self.current_step Ã© 0 na primeira chamada a `run`, e se torna 1 na primeira chamada a `think` via `super().run()`
        # No entanto, o loop em ToolCallAgent.run incrementa current_step *antes* de chamar self.step() (que chama think).
        # EntÃ£o, a primeira vez que este `think` Ã© chamado, current_step jÃ¡ Ã© 1.
        if self.current_step == 1:
            first_user_message = next((msg for msg in self.memory.messages if msg.role == Role.USER), None)
            if first_user_message:
                current_user_prompt = first_user_message.content

                try:
                    checklist_manager = ChecklistManager()
                    await checklist_manager._load_checklist() # Carrega o checklist existente

                    if checklist_manager.get_tasks(): # Se existem tarefas
                        # Verifica se hÃ¡ tarefas nÃ£o concluÃ­das
                        has_pending_or_in_progress = any(
                            task.get('status', '').lower() not in ['concluÃ­do', 'concluido', 'finalizado']
                            for task in checklist_manager.get_tasks()
                        )

                        if has_pending_or_in_progress:
                            logger.info(f"Checklist existente com tarefas pendentes/em andamento encontrado no inÃ­cio da nova interaÃ§Ã£o com prompt: '{current_user_prompt[:100]}...'")
                            # Adicionar uma mensagem ao sistema para o LLM considerar
                            # O LLM entÃ£o decidirÃ¡ se pergunta ao usuÃ¡rio, limpa o checklist, etc.
                            system_message_for_llm = (
                                "INSTRUÃ‡ÃƒO IMPORTANTE: Um novo prompt do usuÃ¡rio foi recebido, mas existe um checklist de uma tarefa anterior "
                                "com itens pendentes ou em andamento. Analise o novo prompt do usuÃ¡rio e o checklist existente (que serÃ¡ "
                                "mostrado a vocÃª se vocÃª usar 'view_checklist').\n"
                                "Decida se o novo prompt Ã© uma continuaÃ§Ã£o da tarefa anterior ou uma tarefa completamente nova.\n"
                                "- Se for uma CONTINUAÃ‡ÃƒO ou MODIFICAÃ‡ÃƒO da tarefa anterior, prossiga normalmente, atualizando o checklist conforme necessÃ¡rio.\n"
                                "- Se parecer uma TAREFA COMPLETAMENTE NOVA e nÃ£o relacionada:\n"
                                "  1. Use a ferramenta 'ask_human' para perguntar ao usuÃ¡rio: 'Detectei um novo pedido: \"{user_prompt_summary}\". "
                                "VocÃª gostaria de descartar o checklist da tarefa anterior e iniciar um novo para este pedido? "
                                "Responda \"sim, limpar e iniciar novo\" ou \"nÃ£o, continuar anterior\".'\n"
                                "  2. Se o usuÃ¡rio responder 'sim, limpar e iniciar novo', vocÃª DEVE entÃ£o usar 'str_replace_editor' com o comando 'delete' para apagar "
                                "o arquivo 'checklist_principal_tarefa.md' e, em seguida, prosseguir para decompor o novo pedido e criar um novo checklist.\n"
                                "  3. Se o usuÃ¡rio responder 'nÃ£o, continuar anterior', informe que vocÃª continuarÃ¡ a tarefa anterior e ignore o novo prompt por enquanto (ou tente integrÃ¡-lo se fizer sentido)."
                            ).format(user_prompt_summary=current_user_prompt[:70] + "...")

                            self.memory.add_message(Message.system_message(system_message_for_llm))
                            # NÃ£o retorna True aqui, deixa o LLM processar esta instruÃ§Ã£o no seu fluxo normal de `think`.
                except FileNotFoundError:
                    logger.info("Nenhum arquivo de checklist anterior encontrado. Procedendo normalmente com o novo prompt.")
                except Exception as e_checklist_check:
                    logger.error(f"Erro ao verificar checklist existente no inÃ­cio da tarefa: {e_checklist_check}")
        # --- Fim da LÃ³gica de VerificaÃ§Ã£o Inicial do Checklist ---

        # Check for autonomous mode trigger in initial user prompt
        # Esta verificaÃ§Ã£o de modo autÃ´nomo tambÃ©m deve ocorrer idealmente apenas uma vez no inÃ­cio.
        if self.current_step == 1 and not self._autonomous_mode:
            first_user_message = next((msg for msg in self.memory.messages if msg.role == Role.USER), None) # Re-obter, pode ter sido modificado
            if first_user_message: # first_user_message pode ser None se a memÃ³ria foi limpa
                prompt_content = first_user_message.content.strip().lower()
                if prompt_content.startswith("execute em modo autÃ´nomo:") or prompt_content.startswith("modo autÃ´nomo:"):
                    self._autonomous_mode = True
                    logger.info("Modo autÃ´nomo ativado por prompt do usuÃ¡rio.")
                    # Opcional: Remover a frase gatilho do prompt para nÃ£o confundir o LLM depois
                    # clean_prompt = prompt_content.replace("execute em modo autÃ´nomo:", "").replace("modo autÃ´nomo:", "").strip()
                    # first_user_message.content = clean_prompt
                    # (Cuidado ao modificar self.memory.messages diretamente, pode ser melhor adicionar uma msg do sistema)
                    self.memory.add_message(Message.assistant_message("Modo autÃ´nomo ativado. NÃ£o pedirei permissÃ£o para continuar a cada ciclo de etapas."))

        # Sandbox Execution Fallback Logic: Detects sandbox creation failure and asks user for direct execution.
        last_message = self.memory.messages[-1] if self.memory.messages else None
        # Etapa A: Detectar falha do SandboxPythonExecutor e perguntar ao usuÃ¡rio
        if (
            last_message
            and last_message.role == Role.TOOL
            and hasattr(last_message, 'name') and last_message.name == SandboxPythonExecutor().name
            and hasattr(last_message, 'tool_call_id') # Garantir que tool_call_id existe
        ):
            tool_call_id_from_message = last_message.tool_call_id
            if tool_call_id_from_message != self._fallback_attempted_for_tool_call_id: # Evitar processar o mesmo erro mÃºltiplas vezes
                try:
                    # last_message.content Ã© a string de observaÃ§Ã£o, e.g., "Observed output...: {'key': 'value'}"
                    # Precisamos extrair o dicionÃ¡rio da string.
                    actual_tool_result_dict_str = None
                    match = re.search(r":\s*(\{.*\})\s*$", last_message.content)
                    if match:
                        actual_tool_result_dict_str = match.group(1)

                    if actual_tool_result_dict_str:
                        tool_result_content = json.loads(actual_tool_result_dict_str)
                    else:
                        # Se nÃ£o encontrar o padrÃ£o, talvez o formato da observaÃ§Ã£o mudou
                        # ou nÃ£o contÃ©m um dict no final. Logar e pular.
                        logger.warning(f"NÃ£o foi possÃ­vel extrair o dicionÃ¡rio de resultado da ferramenta da observaÃ§Ã£o para fallback: {last_message.content}")
                        tool_result_content = None

                    if isinstance(tool_result_content, dict) and tool_result_content.get("exit_code") == -2:
                        logger.warning(
                            f"SandboxPythonExecutor falhou com exit_code -2 (erro de criaÃ§Ã£o do sandbox) para tool_call_id {tool_call_id_from_message}. "
                            "Iniciando lÃ³gica de fallback."
                        )

                        # Encontrar a ToolCall original que invocou o SandboxPythonExecutor
                        original_tool_call_for_sandbox = None
                        for msg_idx in range(len(self.memory.messages) - 2, -1, -1):
                            prev_msg = self.memory.messages[msg_idx]
                            if prev_msg.role == Role.ASSISTANT and prev_msg.tool_calls:
                                for tc in prev_msg.tool_calls:
                                    if tc.id == tool_call_id_from_message:
                                        original_tool_call_for_sandbox = tc
                                        break
                                if original_tool_call_for_sandbox:
                                    break

                        if original_tool_call_for_sandbox:
                            self._pending_fallback_tool_call = original_tool_call_for_sandbox

                            ask_human_question = (
                                "A execuÃ§Ã£o segura no sandbox falhou devido a um problema de ambiente "
                                "(Docker nÃ£o disponÃ­vel ou imagem incorreta). Deseja tentar executar o script "
                                "diretamente na mÃ¡quina do agente? ATENÃ‡ÃƒO: Isso pode ser um risco de seguranÃ§a "
                                "se o script for desconhecido ou malicioso. Responda 'sim' para executar "
                                "diretamente ou 'nÃ£o' para cancelar."
                            )
                            self.memory.add_message(Message.assistant_message(
                                "Alerta: Problema ao executar script em ambiente seguro (sandbox)."
                            )) # Mensagem curta antes de AskHuman

                            ask_human_tool_call_id = str(uuid.uuid4())
                            self._last_ask_human_for_fallback_id = ask_human_tool_call_id
                            self.tool_calls = [
                                ToolCall(
                                    id=ask_human_tool_call_id,
                                    function=FunctionCall(
                                        name=AskHuman().name,
                                        arguments=json.dumps({"inquire": ask_human_question})
                                    )
                                )
                            ]
                            logger.info(f"Solicitando permissÃ£o do usuÃ¡rio para fallback da tool_call {tool_call_id_from_message} para PythonExecute.")
                            return True # Retorna para executar AskHuman
                        else:
                            logger.error(f"NÃ£o foi possÃ­vel encontrar a ToolCall original do assistente para o tool_call_id {tool_call_id_from_message} que falhou no sandbox.")

                except json.JSONDecodeError as e:
                    logger.error(f"Falha ao parsear o conteÃºdo do resultado da ferramenta para lÃ³gica de fallback (Sandbox): {last_message.content}. Erro: {e}")
                except Exception as e_fallback_init:
                    logger.error(f"Erro inesperado durante a inicializaÃ§Ã£o do fallback do sandbox: {e_fallback_init}", exc_info=True)

        # Etapa B: Processar resposta do usuÃ¡rio para fallback
        if (
            last_message
            and last_message.role == Role.USER
            and self._pending_fallback_tool_call # Havia uma pergunta pendente
            # Verifica se a mensagem do usuÃ¡rio Ã© uma resposta Ã  pergunta de fallback
            # Isso pode ser melhorado se AskHuman ToolCall/ToolMessage tiverem IDs que possam ser rastreados.
            # Por enquanto, confiamos que a Ãºltima mensagem do usuÃ¡rio apÃ³s _pending_fallback_tool_call ser setado Ã© a resposta.
            # Adicionamos _last_ask_human_for_fallback_id para uma verificaÃ§Ã£o mais robusta se a mensagem anterior foi o AskHuman
        ):
            # Verificar se a mensagem ANTERIOR foi o AskHuman que fizemos
            if len(self.memory.messages) >= 2:
                potential_ask_human_tool_msg = self.memory.messages[-2]
                if not (potential_ask_human_tool_msg.role == Role.TOOL and \
                        hasattr(potential_ask_human_tool_msg, 'name') and potential_ask_human_tool_msg.name == AskHuman().name and \
                        hasattr(potential_ask_human_tool_msg, 'tool_call_id') and potential_ask_human_tool_msg.tool_call_id == self._last_ask_human_for_fallback_id):
                    # A Ãºltima mensagem do usuÃ¡rio nÃ£o Ã© uma resposta direta Ã  nossa pergunta de fallback especÃ­fica.
                    # Resetar _pending_fallback_tool_call para evitar processamento incorreto se o usuÃ¡rio apenas digitou algo.
                    # self._pending_fallback_tool_call = None # Comentado por enquanto, pode ser muito agressivo.
                    # logger.info("A Ãºltima mensagem do usuÃ¡rio nÃ£o parece ser uma resposta direta Ã  pergunta de fallback. Ignorando para fins de fallback.")
                    pass # NÃ£o faz nada aqui, deixa o fluxo normal do `think` continuar.

            user_response_text = last_message.content.strip().lower()
            original_failed_tool_call = self._pending_fallback_tool_call

            if user_response_text == "sim":
                logger.info(f"UsuÃ¡rio aprovou fallback para PythonExecute para a tool_call original ID: {original_failed_tool_call.id}")
                try:
                    original_args = json.loads(original_failed_tool_call.function.arguments)
                    fallback_args = {}

                    if "code" in original_args and original_args["code"]:
                        fallback_args["code"] = original_args["code"]
                    elif "file_path" in original_args and original_args["file_path"]:
                        # NÃ£o podemos fazer fallback direto para PythonExecute com file_path
                        self.memory.add_message(Message.assistant_message(
                            f"Entendido. No entanto, a tentativa original era executar um arquivo (`{original_args['file_path']}`) no sandbox. "
                            "A execuÃ§Ã£o direta alternativa (`PythonExecute`) requer o conteÃºdo do cÃ³digo, nÃ£o o caminho do arquivo. "
                            "NÃ£o posso realizar este fallback automaticamente. Por favor, forneÃ§a o conteÃºdo do script se desejar executÃ¡-lo diretamente, "
                            "ou considere outra ferramenta para ler o arquivo primeiro."
                        ))
                        self.tool_calls = [] # Limpa quaisquer chamadas de ferramentas planejadas
                        self._fallback_attempted_for_tool_call_id = original_failed_tool_call.id # Marcar como tentado/tratado
                        self._pending_fallback_tool_call = None
                        self._last_ask_human_for_fallback_id = None
                        return True # Volta para o LLM pensar
                    else: # Nem 'code' nem 'file_path'
                         logger.error(f"NÃ£o foi possÃ­vel realizar fallback para PythonExecute: 'code' ou 'file_path' nÃ£o encontrado nos args originais: {original_args}")
                         self.memory.add_message(Message.assistant_message("Erro interno: nÃ£o foi possÃ­vel encontrar o cÃ³digo ou caminho do arquivo para a execuÃ§Ã£o de fallback."))
                         self.tool_calls = []
                         self._fallback_attempted_for_tool_call_id = original_failed_tool_call.id
                         self._pending_fallback_tool_call = None
                         self._last_ask_human_for_fallback_id = None
                         return True

                    # Se chegamos aqui, Ã© porque fallback_args["code"] foi definido
                    fallback_timeout = original_args.get("timeout", 120) # Usar timeout do sandbox ou o novo default de PythonExecute
                    fallback_args["timeout"] = fallback_timeout

                    new_fallback_tool_call = ToolCall(
                        id=str(uuid.uuid4()), # Novo ID para a tentativa de fallback
                        function=FunctionCall(
                            name=PythonExecute().name,
                            arguments=json.dumps(fallback_args)
                        )
                    )
                    self.tool_calls = [new_fallback_tool_call]
                    self._fallback_attempted_for_tool_call_id = original_failed_tool_call.id

                    self.memory.add_message(Message.assistant_message(
                        f"Ok, tentando executar o cÃ³digo diretamente usando '{PythonExecute().name}'. "
                        "Lembre-se dos riscos de seguranÃ§a."
                    ))
                    logger.info(f"ToolCall de fallback planejada para PythonExecute: {new_fallback_tool_call}")

                except json.JSONDecodeError as e:
                    logger.error(f"Falha ao parsear argumentos da tool_call original durante o fallback: {original_failed_tool_call.function.arguments}. Erro: {e}")
                    self.memory.add_message(Message.assistant_message("Erro interno ao preparar a execuÃ§Ã£o de fallback. NÃ£o Ã© possÃ­vel continuar com esta tentativa."))
                    self.tool_calls = []
                except Exception as e_fallback_exec:
                    logger.error(f"Erro inesperado durante a execuÃ§Ã£o do fallback para PythonExecute: {e_fallback_exec}", exc_info=True)
                    self.memory.add_message(Message.assistant_message(f"Erro inesperado ao tentar fallback: {e_fallback_exec}"))
                    self.tool_calls = []

                self._pending_fallback_tool_call = None
                self._last_ask_human_for_fallback_id = None
                return True # Executar a tool_call de fallback (PythonExecute)

            elif user_response_text == "nÃ£o":
                logger.info(f"UsuÃ¡rio negou fallback para PythonExecute para a tool_call original ID: {original_failed_tool_call.id}")
                self.memory.add_message(Message.assistant_message(
                    "Entendido. A execuÃ§Ã£o do script foi cancelada conforme sua solicitaÃ§Ã£o."
                ))
                self.tool_calls = []
                self._fallback_attempted_for_tool_call_id = original_failed_tool_call.id # Marcar como tratado
                self._pending_fallback_tool_call = None
                self._last_ask_human_for_fallback_id = None
                return True # Deixar o LLM decidir o que fazer apÃ³s o cancelamento
            else:
                logger.info(f"Resposta nÃ£o reconhecida do usuÃ¡rio ('{user_response_text}') para a pergunta de fallback. Solicitando novamente ou tratando como 'nÃ£o'.")
                self.memory.add_message(Message.assistant_message(
                    f"Resposta '{last_message.content}' nÃ£o reconhecida. Assumindo 'nÃ£o' para a execuÃ§Ã£o direta. A execuÃ§Ã£o do script foi cancelada."
                ))
                self.tool_calls = []
                self._fallback_attempted_for_tool_call_id = original_failed_tool_call.id
                self._pending_fallback_tool_call = None
                self._last_ask_human_for_fallback_id = None
                return True

        # --- Fim da LÃ³gica de Fallback ---

        user_prompt_message = next((msg for msg in reversed(self.memory.messages) if msg.role == Role.USER), None)
        user_prompt_content = user_prompt_message.content if user_prompt_message else ""
        SELF_CODING_TRIGGER = "execute self coding cycle: "
        if user_prompt_content.startswith(SELF_CODING_TRIGGER):
            if self._monitoring_background_task:
                logger.info("Novo ciclo de auto-codificaÃ§Ã£o iniciado, parando monitoramento de tarefa em background anterior.")
                self._monitoring_background_task = False
                self._background_task_log_file = None
                self._background_task_expected_artifact = None
                self._background_task_artifact_path = None
                self._background_task_description = None
                self._background_task_last_log_size = 0
                self._background_task_no_change_count = 0
            task_description = user_prompt_content[len(SELF_CODING_TRIGGER):].strip()
            if not task_description:
                self.memory.add_message(Message.assistant_message("Por favor, forneÃ§a uma descriÃ§Ã£o da tarefa para o ciclo de auto-codificaÃ§Ã£o."))
                self.tool_calls = []
                return True
            logger.info(f"Acionando ciclo de auto-codificaÃ§Ã£o para a tarefa: {task_description}")
            self.memory.add_message(Message.assistant_message(f"Iniciando ciclo de auto-codificaÃ§Ã£o para: {task_description}. Vou relatar o resultado."))
            cycle_result = await self._execute_self_coding_cycle(task_description)
            if cycle_result.get("status_code") == "SANDBOX_CREATION_FAILED":
                self.memory.add_message(Message.assistant_message(
                    f"Falha ao executar o ciclo de auto-codificaÃ§Ã£o para '{task_description}'.\n"
                    f"Motivo: NÃ£o foi possÃ­vel criar o ambiente seguro (sandbox) para execuÃ§Ã£o do cÃ³digo.\n"
                    f"Detalhes: {cycle_result.get('details', 'Erro desconhecido na criaÃ§Ã£o do sandbox.')}\n"
                    f"Por favor, verifique se o Docker estÃ¡ em execuÃ§Ã£o e se a imagem '{config.sandbox.image_name}' estÃ¡ disponÃ­vel ou pode ser baixada."
                ))
            elif cycle_result.get("status_code") == "SANDBOX_COPY_FAILED":
                self.memory.add_message(Message.assistant_message(
                    f"Falha ao executar o ciclo de auto-codificaÃ§Ã£o para '{task_description}'.\n"
                    f"Motivo: NÃ£o foi possÃ­vel copiar o script para o ambiente seguro (sandbox).\n"
                    f"Detalhes: {cycle_result.get('message', 'Erro desconhecido na cÃ³pia para o sandbox.')}"
                ))
            elif cycle_result.get("success"):
                success_message = f"Ciclo de auto-codificaÃ§Ã£o concluÃ­do com sucesso para '{task_description}'.\n\n"
                success_message += f"SaÃ­da (stdout) do script:\n{cycle_result.get('stdout', 'Sem saÃ­da stdout.')}\n"
                if cycle_result.get("workspace_listing"):
                    success_message += f"\nConteÃºdo atual do diretÃ³rio de trabalho principal ({config.workspace_root}):\n{cycle_result.get('workspace_listing')}\n"
                success_message += f"\nQuaisquer arquivos mencionados como 'salvos' ou 'gerados' pelo script (e copiados de /tmp do sandbox, se aplicÃ¡vel) devem estar visÃ­veis acima ou diretamente no diretÃ³rio {config.workspace_root}."
                self.memory.add_message(Message.assistant_message(success_message))
            else:
                error_details = cycle_result.get('stderr', cycle_result.get('last_execution_result', {}).get('stderr', 'Sem saÃ­da stderr.'))
                self.memory.add_message(Message.assistant_message(
                    f"Ciclo de auto-codificaÃ§Ã£o falhou para '{task_description}'.\n"
                    f"Motivo: {cycle_result.get('message', 'Erro desconhecido.')}\n"
                    f"Ãšltima saÃ­da de erro (stderr):\n{error_details}"
                ))
            self.tool_calls = []
            return True

        original_prompt = self.next_step_prompt
        recent_messages_for_browser = self.memory.messages[-3:] if self.memory.messages else []
        browser_in_use = any(
            tc.function.name == BrowserUseTool().name
            for msg in recent_messages_for_browser # Nome da variÃ¡vel corrigido
            if msg.tool_calls
            for tc in msg.tool_calls
        )
        if browser_in_use:
            if self.browser_context_helper:
                self.next_step_prompt = (
                    await self.browser_context_helper.format_next_step_prompt()
                )
            else:
                logger.warning("BrowserContextHelper nÃ£o inicializado, nÃ£o Ã© possÃ­vel formatar next_step_prompt para o navegador.")

        result = await super().think()
        self.next_step_prompt = original_prompt

        # Sobrescrever chamadas PythonExecute que executam scripts externos para usar SandboxPythonExecutor
        if self.tool_calls:
            new_tool_calls = []
            for tool_call in self.tool_calls:
                # Linha original onde o erro ocorre:
                if tool_call.function.name == "python_execute":
                    try:
                        args = json.loads(tool_call.function.arguments)
                        code_to_execute = args.get("code")
                        original_timeout = args.get("timeout")

                        if isinstance(code_to_execute, str) and code_to_execute:
                            script_path_match = None
                            # Regex para subprocess.run(['python3', 'script.py', ...])
                            # Permite variaÃ§Ãµes como "python", "python3", "python3.x"
                            # Captura o caminho do script ('([^']+\.py)')
                            # Usando o padrÃ£o regex externalizado
                            # re_subprocess agora Ã© importado diretamente
                            # Regex para os.system('python3 script.py ...')
                            # Nota: Este regex para os.system pode precisar de externalizaÃ§Ã£o semelhante se se tornar complexo ou causar problemas.
                            re_os_system = r"os\.system\s*\(\s*['\"](?:python|python3)(?:\.[\d]+)?\s+([^'\" ]+\.py)['\"].*?\)"

                            match_subprocess = re.search(re_subprocess, code_to_execute) # re_subprocess Ã© agora o padrÃ£o compilado
                            if match_subprocess:
                                script_path_match = match_subprocess.group(1)
                            else:
                                match_os_system = re.search(re_os_system, code_to_execute)
                                if match_os_system:
                                    script_path_match = match_os_system.group(1)

                            if script_path_match:
                                resolved_script_path = ""
                                if os.path.isabs(script_path_match):
                                    resolved_script_path = os.path.normpath(script_path_match)
                                else:
                                    resolved_script_path = str(config.workspace_root / script_path_match)

                                # VerificaÃ§Ã£o de seguranÃ§a: Garante que o caminho resolvido estÃ¡ dentro do workspace
                                if os.path.abspath(resolved_script_path).startswith(str(config.workspace_root)):
                                    logger.info(f"Sobrescrevendo chamada PythonExecute para script '{script_path_match}' para SandboxPythonExecutor com caminho '{resolved_script_path}'.")
                                    new_arguments = {"file_path": resolved_script_path}
                                    if original_timeout is not None:
                                        new_arguments["timeout"] = original_timeout

                                    # Cria um novo objeto ToolCall para a sobrescrita
                                    overridden_tool_call = ToolCall(
                                        id=tool_call.id, # MantÃ©m o mesmo ID
                                        function=Function(
                                            name=SandboxPythonExecutor.name,
                                            arguments=json.dumps(new_arguments)
                                        )
                                    )
                                    new_tool_calls.append(overridden_tool_call)
                                    continue # Passa para a prÃ³xima tool_call
                                else:
                                    logger.warning(f"Chamada PythonExecute para script '{script_path_match}' resolvida para '{resolved_script_path}', que estÃ¡ fora do workspace. NÃ£o sobrescrevendo.")
                            else:
                                logger.info(f"Chamada PythonExecute com cÃ³digo nÃ£o correspondeu a padrÃµes de execuÃ§Ã£o de script. CÃ³digo: {code_to_execute[:100]}...")
                        else:
                            logger.warning("Chamada PythonExecute nÃ£o tinha argumento 'code' vÃ¡lido.")
                    except json.JSONDecodeError:
                        logger.warning(f"Falha ao parsear argumentos para PythonExecute: {tool_call.function.arguments}. Usando chamada de ferramenta original.")
                    except Exception as e:
                        logger.error(f"Erro durante lÃ³gica de sobrescrita de PythonExecute: {e}. Usando chamada de ferramenta original.")

                new_tool_calls.append(tool_call) # Adiciona tool_call original ou nÃ£o-PythonExecute
            self.tool_calls = new_tool_calls

        if self.tool_calls and self.tool_calls[0].function.name == Bash().name: # Verifica a primeira chamada de ferramenta
            try:
                args = json.loads(self.tool_calls[0].function.arguments)
                command_str = args.get("command", "")
                log_file_pattern = re.escape(str(config.workspace_root)) + r"/[^\s]+\.log"
                match = re.match(r"^\s*(.+?)\s*>\s*(" + log_file_pattern + r")\s*2>&1\s*&\s*$", command_str)
                if match:
                    actual_command = match.group(1).strip()
                    log_file = match.group(2).strip()
                    self._monitoring_background_task = True
                    self._background_task_log_file = log_file
                    self._background_task_description = f"ExecuÃ§Ã£o do comando: {actual_command}"
                    self._background_task_last_log_size = 0
                    self._background_task_no_change_count = 0
                    actual_command_lower = actual_command.lower()
                    script_name_match = re.search(r"python\d*\s+([^\s]+\.py)", actual_command)
                    if script_name_match:
                        script_path_in_command = script_name_match.group(1)
                        base_script_name = os.path.basename(script_path_in_command).replace(".py", "")
                        if "csv" in self._background_task_description.lower() or "csv" in actual_command_lower:
                            self._background_task_expected_artifact = f"{base_script_name}.csv"
                        elif "report" in self._background_task_description.lower() or "report" in actual_command_lower:
                            self._background_task_expected_artifact = f"{base_script_name}_report.txt"
                        else:
                            self._background_task_expected_artifact = f"{base_script_name}_output.txt"
                    else:
                        command_parts = actual_command.split()
                        first_part = os.path.basename(command_parts[0]) if command_parts else "command"
                        self._background_task_expected_artifact = f"{first_part}_artifact.out"
                    self._background_task_artifact_path = str(config.workspace_root / self._background_task_expected_artifact)
                    logger.info(f"Artefato esperado definido como: {self._background_task_artifact_path} (Arquivo de log: {log_file})")
                    self.memory.add_message(Message.assistant_message(
                        f"Comando '{actual_command}' iniciado em background. "
                        f"Logs serÃ£o enviados para '{os.path.basename(log_file)}' (localizado em {config.workspace_root}). "
                        f"Procurando pelo artefato esperado '{self._background_task_expected_artifact}' em '{config.workspace_root}'. "
                        "Vou monitorar o progresso."
                    ))
            except json.JSONDecodeError:
                logger.error("Erro ao decodificar argumentos JSON para Bash ao tentar iniciar monitoramento.")
            except Exception as e_parse:
                logger.error(f"Erro ao processar comando bash para monitoramento: {e_parse}")

        if self.tool_calls:
            new_tool_calls = []
            terminate_failure_detected = False
            for tc in self.tool_calls:
                if tc.function.name == Terminate().name:
                    try:
                        args = json.loads(tc.function.arguments)
                        if args.get("status") == "failure":
                            logger.info(f"Interceptada ToolCall para Terminate com status 'failure'. Argumentos: {args}")
                            terminate_failure_detected = True
                        else:
                            new_tool_calls.append(tc)
                    except json.JSONDecodeError:
                        logger.warning(f"Erro ao decodificar argumentos JSON para Terminate ToolCall: {tc.function.arguments}. Mantendo a chamada.")
                        new_tool_calls.append(tc)
                    except Exception as e_json_parse:
                        logger.warning(f"Erro inesperado ao analisar argumentos de Terminate: {e_json_parse}. Mantendo a chamada.")
                        new_tool_calls.append(tc)
                else:
                    new_tool_calls.append(tc)

            if terminate_failure_detected:
                logger.info("Sinalizando para _trigger_failure_check_in devido Ã  interceptaÃ§Ã£o de terminate(failure).")
                self._trigger_failure_check_in = True
                self.tool_calls = new_tool_calls
                self.memory.add_message(Message.system_message(
                    "Nota interna: Uma tentativa de finalizar a tarefa devido a uma falha foi interceptada. "
                    "O usuÃ¡rio serÃ¡ consultado antes da finalizaÃ§Ã£o."
                ))
                if not self.tool_calls:
                     logger.info("Nenhuma outra ferramenta planejada alÃ©m do terminate(failure) interceptado. Indo para o feedback de falha.")
                else:
                     logger.warning("Outras ferramentas foram planejadas junto com terminate(failure). Isso Ã© inesperado. O feedback de falha ocorrerÃ¡ apÃ³s estas ferramentas.")

        if self._pending_script_after_dependency and self.tool_calls:
            last_tool_response = next((msg for msg in reversed(self.memory.messages) if msg.role == Role.TOOL and msg.tool_call_id == self.tool_calls[0].id), None)
            dependency_succeeded_and_file_generated = False
            expected_generated_file_name = None
            if self._original_tool_call_for_pending_script:
                try:
                    original_args = json.loads(self._original_tool_call_for_pending_script.function.arguments)
                    original_script_path = original_args.get("file_path")
                    if original_script_path:
                        original_script_analysis = await self._analyze_python_script(original_script_path)
                        if original_script_analysis.get("inputs"):
                            expected_generated_file_name = original_script_analysis["inputs"][0]
                except Exception as e_inner_analysis:
                    logger.error(f"Erro ao reanalisar script original para nome de arquivo esperado: {e_inner_analysis}")

            if last_tool_response and isinstance(last_tool_response.content, str) and \
               any(err_keyword in last_tool_response.content.lower() for err_keyword in ["error", "traceback", "failed", "exception"]):
                logger.warning(f"Script de dependÃªncia parece ter falhado. Resposta: {last_tool_response.content}")
                self.memory.add_message(Message.assistant_message(
                    f"O script que tentei executar como dependÃªncia ('{self.tool_calls[0].function.name}') parece ter falhado em gerar o arquivo necessÃ¡rio para '{os.path.basename(self._pending_script_after_dependency)}'. Detalhes do erro: {last_tool_response.content}. NÃ£o tentarei executar o script pendente."
                ))
            elif not expected_generated_file_name:
                logger.warning("NÃ£o foi possÃ­vel determinar o nome do arquivo esperado da dependÃªncia. Assumindo falha na geraÃ§Ã£o.")
                self.memory.add_message(Message.assistant_message(
                    f"NÃ£o consegui determinar qual arquivo o script de dependÃªncia deveria gerar para '{os.path.basename(self._pending_script_after_dependency)}'. NÃ£o tentarei executar o script pendente."
                ))
            else:
                try:
                    expected_file_path = str(config.workspace_root / expected_generated_file_name)
                    editor = self.available_tools.get_tool(StrReplaceEditor().name)
                    await editor.execute(command="view", path=expected_file_path)
                    logger.info(f"Arquivo esperado '{expected_generated_file_name}' gerado com sucesso pela dependÃªncia.")
                    dependency_succeeded_and_file_generated = True
                except ToolError:
                    logger.warning(f"Script de dependÃªncia executado, mas o arquivo esperado '{expected_generated_file_name}' NÃƒO foi encontrado.")
                    self.memory.add_message(Message.assistant_message(
                        f"O script de dependÃªncia foi executado, mas o arquivo esperado '{expected_generated_file_name}' para '{os.path.basename(self._pending_script_after_dependency)}' nÃ£o foi encontrado. NÃ£o tentarei executar o script pendente."
                    ))
                except Exception as e_check:
                    logger.error(f"Erro ao verificar arquivo gerado pela dependÃªncia '{expected_generated_file_name}': {e_check}")
                    self.memory.add_message(Message.assistant_message(
                        f"Ocorreu um erro ao verificar se o arquivo esperado '{expected_generated_file_name}' foi gerado. NÃ£o tentarei executar o script pendente."
                    ))

            if dependency_succeeded_and_file_generated:
                logger.info(f"Script de dependÃªncia concluÃ­do e arquivo gerado. Tentando executar o script pendente: {self._pending_script_after_dependency}")
                self.memory.add_message(Message.assistant_message(
                    f"A execuÃ§Ã£o do script de dependÃªncia e a geraÃ§Ã£o do arquivo '{expected_generated_file_name}' parecem ter sido bem-sucedidas. Agora vou tentar executar o script original: {os.path.basename(self._pending_script_after_dependency)}."
                ))
                if self._original_tool_call_for_pending_script:
                    self.tool_calls = [self._original_tool_call_for_pending_script]
                else:
                    logger.error("NÃ£o foi possÃ­vel encontrar a tool_call original para o script pendente.")
                    self.tool_calls = []
                self._pending_script_after_dependency = None
                self._original_tool_call_for_pending_script = None
            else:
                self._pending_script_after_dependency = None
                self._original_tool_call_for_pending_script = None
                self.tool_calls = []

        if self.tool_calls and not self._pending_script_after_dependency:
            tool_call_to_check = self.tool_calls[0]
            required_file = None
            script_to_run_if_dependency_succeeds = None

            if tool_call_to_check.function.name in [SandboxPythonExecutor().name, PythonExecute().name] or \
               (tool_call_to_check.function.name == Bash().name and "python" in tool_call_to_check.function.arguments):
                try:
                    args = json.loads(tool_call_to_check.function.arguments)
                    script_path_from_args = args.get("file_path")
                    if not script_path_from_args and tool_call_to_check.function.name == Bash().name:
                        command_str = args.get("command", "")
                        match = re.search(r"python\d*\s+([^\s]+\.py)", command_str)
                        if match: script_path_from_args = match.group(1)
                        if script_path_from_args and not os.path.isabs(script_path_from_args):
                            script_path_from_args = str(config.workspace_root / script_path_from_args)

                    script_to_run_if_dependency_succeeds = script_path_from_args
                    if script_to_run_if_dependency_succeeds:
                        logger.info(f"Analisando inputs para o script planejado: {script_to_run_if_dependency_succeeds}")
                        script_analysis = await self._analyze_python_script(script_path_from_args)
                        if script_analysis.get("inputs"):
                            for inp_file_name in script_analysis["inputs"]:
                                expected_input_path = str(config.workspace_root / inp_file_name)
                                try:
                                    editor = self.available_tools.get_tool(StrReplaceEditor().name)
                                    await editor.execute(command="view", path=expected_input_path)
                                    logger.info(f"Arquivo de input '{expected_input_path}' para '{script_to_run_if_dependency_succeeds}' encontrado.")
                                except ToolError:
                                    logger.info(f"Arquivo de input '{expected_input_path}' para '{script_to_run_if_dependency_succeeds}' NÃƒO encontrado. Iniciando anÃ¡lise de dependÃªncia.")
                                    required_file = inp_file_name
                                    break
                        else:
                            logger.info(f"Nenhum input declarado encontrado para {script_to_run_if_dependency_succeeds} na anÃ¡lise.")
                except Exception as e:
                    logger.error(f"Erro ao analisar argumentos da tool call para dependÃªncias: {e}")

            if required_file and script_to_run_if_dependency_succeeds:
                logger.info(f"Arquivo '{required_file}' necessÃ¡rio para '{script_to_run_if_dependency_succeeds}' estÃ¡ faltando. Analisando workspace...")
                workspace_analysis = await self._analyze_workspace()
                found_generating_script = None
                for gen_script_name, analysis_info in workspace_analysis.items():
                    if required_file in analysis_info.get("outputs", []):
                        if os.path.basename(gen_script_name) == os.path.basename(script_to_run_if_dependency_succeeds):
                            logger.info(f"Script '{gen_script_name}' parece gerar seu prÃ³prio input '{required_file}'. NÃ£o considerar como dependÃªncia.")
                            continue
                        found_generating_script = gen_script_name
                        break
                if found_generating_script:
                    self.memory.add_message(Message.assistant_message(
                        f"O arquivo '{required_file}' necessÃ¡rio para '{os.path.basename(script_to_run_if_dependency_succeeds)}' nÃ£o foi encontrado. "
                        f"Verifiquei que '{os.path.basename(found_generating_script)}' pode gerÃ¡-lo. Tentarei executar '{os.path.basename(found_generating_script)}' primeiro."
                    ))
                    self._pending_script_after_dependency = script_to_run_if_dependency_succeeds
                    self._original_tool_call_for_pending_script = tool_call_to_check
                    new_tool_call_args = {"file_path": str(config.workspace_root / found_generating_script)}
                    self.tool_calls = [ToolCall(
                        id=str(uuid.uuid4()),
                        function=FunctionCall(name=SandboxPythonExecutor().name, arguments=json.dumps(new_tool_call_args))
                    )]
                    logger.info(f"ExecuÃ§Ã£o de '{os.path.basename(script_to_run_if_dependency_succeeds)}' adiada. Executando dependÃªncia '{os.path.basename(found_generating_script)}' primeiro.")
                else:
                    self.memory.add_message(Message.assistant_message(
                        f"O arquivo '{required_file}' necessÃ¡rio para '{os.path.basename(script_to_run_if_dependency_succeeds)}' nÃ£o foi encontrado, e nÃ£o identifiquei um script no workspace que o gere. "
                        "Vou precisar que vocÃª forneÃ§a este arquivo ou um script para gerÃ¡-lo."
                    ))
                    self.tool_calls = []
                    logger.info(f"Nenhum script gerador encontrado para '{required_file}'. O LLM deverÃ¡ usar AskHuman.")
        return result

    async def _analyze_python_script(self, script_path: str, script_content: Optional[str] = None) -> Dict[str, Any]:
        logger.info(f"Analisando script Python: {script_path}")
        analysis = {"inputs": [], "outputs": [], "libraries": []}

        if not script_content:
            try:
                editor_tool = self.available_tools.get_tool(StrReplaceEditor().name)
                if not editor_tool:
                    logger.error("Ferramenta StrReplaceEditor nÃ£o encontrada para _analyze_python_script.")
                    return analysis
                script_content_result = await editor_tool.execute(command="view", path=script_path)
                if isinstance(script_content_result, str):
                    script_content = script_content_result
                else:
                    logger.error(f"Falha ao ler o conteÃºdo de {script_path} para anÃ¡lise: {script_content_result}")
                    return analysis
            except ToolError as e:
                logger.error(f"ToolError ao ler {script_path} para anÃ¡lise: {e}")
                return analysis
            except Exception as e:
                logger.error(f"Erro inesperado ao ler {script_path} para anÃ¡lise: {e}")
                return analysis

        if not script_content:
            return analysis

        input_patterns = [
            r"pd\.read_csv\s*\(\s*['\"]([^'\"]+)['\"]",
            r"pd\.read_excel\s*\(\s*['\"]([^'\"]+)['\"]",
            r"open\s*\(\s*['\"]([^'\"]+)['\"]\s*,\s*['\"]r[^'\"]*['\"]",
            r"json\.load\s*\(\s*open\s*\(\s*['\"]([^'\"]+)['\"]",
            r"np\.load\s*\(\s*['\"]([^'\"]+)['\"]",
        ]
        for pattern in input_patterns:
            for match in re.finditer(pattern, script_content):
                analysis["inputs"].append(os.path.basename(match.group(1)))

        output_patterns = [
            r"df\.to_csv\s*\(\s*['\"]([^'\"]+)['\"]",
            r"df\.to_excel\s*\(\s*['\"]([^'\"]+)['\"]",
            r"open\s*\(\s*['\"]([^'\"]+)['\"]\s*,\s*['\"]w[^'\"]*['\"]",
            r"open\s*\(\s*['\"]([^'\"]+)['\"]\s*,\s*['\"]a[^'\"]*['\"]",
            r"json\.dump\s*\(.*,\s*open\s*\(\s*['\"]([^'\"]+)['\"]",
            r"plt\.savefig\s*\(\s*['\"]([^'\"]+)['\"]",
            r"np\.save\s*\(\s*['\"]([^'\"]+)['\"]",
        ]
        for pattern in output_patterns:
            for match in re.finditer(pattern, script_content):
                analysis["outputs"].append(os.path.basename(match.group(1)))

        library_patterns = [
            r"^\s*import\s+([a-zA-Z0-9_]+)",
            r"^\s*from\s+([a-zA-Z0-9_]+)\s+import"
        ]
        for pattern in library_patterns:
            for match in re.finditer(pattern, script_content, re.MULTILINE):
                lib_name = match.group(1)
                if lib_name not in analysis["libraries"]:
                    analysis["libraries"].append(lib_name)

        analysis["inputs"] = sorted(list(set(analysis["inputs"])))
        analysis["outputs"] = sorted(list(set(analysis["outputs"])))
        analysis["libraries"] = sorted(list(set(analysis["libraries"])))

        logger.info(f"AnÃ¡lise de {script_path}: Inputs: {analysis['inputs']}, Outputs: {analysis['outputs']}, Bibliotecas: {analysis['libraries']}")
        return analysis

    async def _analyze_workspace(self) -> Dict[str, Dict[str, Any]]:
        logger.info("Analisando scripts Python no workspace...")
        if self._workspace_script_analysis_cache:
             logger.info("Retornando anÃ¡lise de workspace do cache.")
             return self._workspace_script_analysis_cache

        workspace_scripts_analysis: Dict[str, Dict[str, Any]] = {}
        editor_tool = self.available_tools.get_tool(StrReplaceEditor().name)
        if not editor_tool:
            logger.error("Ferramenta StrReplaceEditor nÃ£o encontrada para _analyze_workspace.")
            return workspace_scripts_analysis

        try:
            workspace_path_str = str(config.workspace_root)
            dir_listing_result = await editor_tool.execute(command="view", path=workspace_path_str)

            if isinstance(dir_listing_result, str):
                python_files = [line.strip() for line in dir_listing_result.splitlines() if line.strip().endswith(".py")]
                logger.info(f"Scripts Python encontrados no workspace ({workspace_path_str}): {python_files}")
                for script_name in python_files:
                    full_script_path = str(config.workspace_root / script_name)
                    workspace_scripts_analysis[script_name] = await self._analyze_python_script(full_script_path)
            else:
                logger.error(f"Falha ao listar arquivos do workspace para anÃ¡lise: {dir_listing_result}")

        except ToolError as e:
            logger.error(f"ToolError ao listar arquivos do workspace para anÃ¡lise: {e}")
        except Exception as e:
            logger.error(f"Erro inesperado ao analisar workspace: {e}")

        self._workspace_script_analysis_cache = workspace_scripts_analysis
        return workspace_scripts_analysis

    async def _initiate_sandbox_script_cancellation(self):
        """Tenta ler um PID do arquivo de PID rastreado e enviar um sinal SIGTERM para ele no sandbox."""
        if not self._current_sandbox_pid_file:
            logger.warning("_initiate_sandbox_script_cancellation chamado sem _current_sandbox_pid_file definido.")
            return

        if self._current_sandbox_pid is None:
            try:
                pid_str = await SANDBOX_CLIENT.read_file(self._current_sandbox_pid_file)
                pid = int(pid_str.strip())
                self._current_sandbox_pid = pid
                logger.info(f"PID {pid} lido com sucesso de {self._current_sandbox_pid_file}")
            except FileNotFoundError:
                logger.warning(f"Arquivo PID {self._current_sandbox_pid_file} nÃ£o encontrado. O script pode jÃ¡ ter terminado.")
                self.memory.add_message(Message.assistant_message("NÃ£o foi possÃ­vel encontrar o arquivo de PID para cancelamento; o script pode jÃ¡ ter terminado."))
                # Tenta limpar o registro do arquivo PID inexistente chamando o helper de limpeza existente
                # Isso tambÃ©m limparÃ¡ os atributos relacionados se o ID da chamada de ferramenta atual corresponder.
                # No entanto, neste estÃ¡gio, a chamada de ferramenta ainda nÃ£o "terminou", entÃ£o a limpeza direta Ã© melhor.
                if hasattr(self, '_cleanup_sandbox_file') and callable(getattr(self, '_cleanup_sandbox_file')):
                    # Chama a limpeza principal para este caminho de arquivo que tambÃ©m deve limpar atributos
                     await self._cleanup_sandbox_file(self._current_sandbox_pid_file) # Isso registrarÃ¡ seu prÃ³prio sucesso/falha
                # Limpa explicitamente os atributos aqui porque o script Ã© considerado desaparecido ou seu estado desconhecido.
                self._current_sandbox_pid_file = None
                self._current_script_tool_call_id = None
                self._current_sandbox_pid = None
                return
            except (ValueError, TypeError) as e:
                logger.error(f"ConteÃºdo invÃ¡lido no arquivo PID {self._current_sandbox_pid_file}: {pid_str if 'pid_str' in locals() else 'conteÃºdo desconhecido'}. Erro: {e}")
                self.memory.add_message(Message.assistant_message(f"ConteÃºdo invÃ¡lido no arquivo de PID ({self._current_sandbox_pid_file}). NÃ£o Ã© possÃ­vel cancelar."))
                if hasattr(self, '_cleanup_sandbox_file') and callable(getattr(self, '_cleanup_sandbox_file')):
                     await self._cleanup_sandbox_file(self._current_sandbox_pid_file)
                self._current_sandbox_pid_file = None
                self._current_script_tool_call_id = None
                self._current_sandbox_pid = None
                return
            except Exception as e: # Captura outros erros do SANDBOX_CLIENT como problemas de permissÃ£o ou sandbox inativo
                logger.error(f"Erro ao ler arquivo PID {self._current_sandbox_pid_file}: {e}")
                self.memory.add_message(Message.assistant_message(f"Erro ao ler o arquivo de PID para cancelamento: {e}"))
                # NÃ£o limpe _current_sandbox_pid_file aqui, pois o arquivo ainda pode existir, apenas ilegÃ­vel temporariamente.
                # A chamada de ferramenta original ainda pode ser concluÃ­da e acionar a limpeza adequada atravÃ©s do bloco finally de execute_tool.
                return

        if self._current_sandbox_pid is not None:
            try:
                kill_command = f"kill -SIGTERM {self._current_sandbox_pid}"
                logger.info(f"Tentando executar comando kill no sandbox: {kill_command}")
                # Adiciona mensagem antes de enviar kill, para que o usuÃ¡rio veja mesmo se o agente/sandbox tiver problemas durante o comando
                self.memory.add_message(Message.assistant_message(f"Enviando sinal de cancelamento (SIGTERM) para o processo {self._current_sandbox_pid} no sandbox..."))
                result = await SANDBOX_CLIENT.run_command(kill_command, timeout=10) # Usando SIGTERM

                if result.get("exit_code") == 0:
                    logger.info(f"SIGTERM enviado com sucesso para PID {self._current_sandbox_pid}. SaÃ­da stdout do comando kill: '{result.get('stdout','').strip()}', stderr: '{result.get('stderr','').strip()}'")
                    # Mensagem do usuÃ¡rio para envio de sinal bem-sucedido jÃ¡ foi adicionada.
                else:
                    # Isso pode acontecer se o processo jÃ¡ terminou entre a leitura do PID e o comando kill.
                    logger.warning(f"Comando kill para PID {self._current_sandbox_pid} falhou ou PID nÃ£o encontrado. CÃ³digo de saÃ­da: {result.get('exit_code')}. Stderr: '{result.get('stderr','').strip()}'")
                    # self.memory.add_message(Message.assistant_message(f"Falha ao enviar sinal de cancelamento para o script (PID: {self._current_sandbox_pid}), ou o script jÃ¡ havia terminado. Detalhes: {result.get('stderr','').strip()}"))
                    # NÃ£o hÃ¡ necessidade de outra mensagem se a anterior indicou uma tentativa. O log Ã© suficiente.
            except Exception as e:
                logger.error(f"ExceÃ§Ã£o ao tentar matar PID {self._current_sandbox_pid}: {e}")
                self.memory.add_message(Message.assistant_message(f"Erro ao tentar cancelar o script (PID: {self._current_sandbox_pid}): {e}"))
        # Conforme o plano, nÃ£o limpe as informaÃ§Ãµes do PID aqui; isso Ã© tratado pelo bloco finally de ToolCallAgent.execute_tool.

    async def _cleanup_sandbox_file(self, file_path_in_sandbox: str):
        """Auxiliar para remover um arquivo do sandbox."""
        if not file_path_in_sandbox:
            return
        try:
            logger.info(f"Tentando limpar arquivo do sandbox: {file_path_in_sandbox}")
            # Garante que SANDBOX_CLIENT estÃ¡ disponÃ­vel e run_command Ã© awaitable
            cleanup_result = await SANDBOX_CLIENT.run_command(f"rm -f {file_path_in_sandbox}", timeout=10)
            if cleanup_result.get("exit_code") != 0:
                logger.warning(f"Falha ao limpar arquivo do sandbox '{file_path_in_sandbox}'. Erro: {cleanup_result.get('stderr')}")
            else:
                logger.info(f"Arquivo do sandbox limpo com sucesso: {file_path_in_sandbox}")
        except Exception as e:
            logger.error(f"ExceÃ§Ã£o durante a limpeza do arquivo do sandbox para '{file_path_in_sandbox}': {e}")

    async def periodic_user_check_in(self, is_final_check: bool = False, is_failure_scenario: bool = False) -> bool:
        user_interaction_tool_name = AskHuman().name
        if user_interaction_tool_name not in self.available_tools.tool_map:
            logger.warning(f"Ferramenta de interaÃ§Ã£o com o usuÃ¡rio '{user_interaction_tool_name}' nÃ£o disponÃ­vel. Continuando execuÃ§Ã£o.")
            self.memory.add_message(Message.system_message(f"InteraÃ§Ã£o periÃ³dica com usuÃ¡rio pulada: ferramenta '{user_interaction_tool_name}' nÃ£o encontrada."))
            return True

        checklist_content_str = "Checklist nÃ£o encontrado ou vazio."
        checklist_path = str(config.workspace_root / "checklist_principal_tarefa.md")
        local_file_op = LocalFileOperator()
        try:
            checklist_content_str = await local_file_op.read_file(checklist_path)
            if not checklist_content_str.strip():
                checklist_content_str = "Checklist encontrado, mas estÃ¡ vazio."
            logger.info(f"ConteÃºdo do checklist lido localmente para autoanÃ¡lise: {checklist_content_str[:200]}...")
        except ToolError as e_tool_error:
            logger.info(f"Checklist '{checklist_path}' nÃ£o encontrado (ou erro ao ler localmente) para autoanÃ¡lise: {str(e_tool_error)}. Usando mensagem padrÃ£o.")
        except Exception as e_checklist:
            logger.error(f"Erro inesperado ao ler checklist localmente para autoanÃ¡lise: {str(e_checklist)}")
            checklist_content_str = f"Erro inesperado ao ler checklist: {str(e_checklist)}"

        prompt_messages_list = [Message(role=Role.SYSTEM, content=self.system_prompt)]
        num_messages_for_context = 7
        mensagens_recentes_raw = self.memory.messages[-num_messages_for_context:]

        present_tool_response_ids = set()
        for msg_scan_tool_responses in mensagens_recentes_raw:
            if msg_scan_tool_responses.role == Role.TOOL and hasattr(msg_scan_tool_responses, 'tool_call_id') and msg_scan_tool_responses.tool_call_id:
                present_tool_response_ids.add(msg_scan_tool_responses.tool_call_id)

        final_filtered_messages: List[Message] = []
        assistant_tool_call_map: Dict[str, int] = {}
        for i, msg_map_assistant in enumerate(mensagens_recentes_raw):
            if msg_map_assistant.role == Role.ASSISTANT and msg_map_assistant.tool_calls:
                for tc_map in msg_map_assistant.tool_calls:
                    assistant_tool_call_map[tc_map.id] = i

        for i, msg_original in enumerate(mensagens_recentes_raw):
            msg = msg_original.model_copy(deep=True)

            if msg.role == Role.ASSISTANT and msg.tool_calls:
                all_tool_calls_have_responses = True
                temp_tool_calls_for_current_assistant_msg = []

                for tc_assistant in msg.tool_calls:
                    if tc_assistant.id not in present_tool_response_ids:
                        all_tool_calls_have_responses = False
                    else:
                        temp_tool_calls_for_current_assistant_msg.append(tc_assistant)

                if not all_tool_calls_have_responses:
                    msg.tool_calls = None
                elif not temp_tool_calls_for_current_assistant_msg:
                    msg.tool_calls = None
            elif msg.role == Role.TOOL:
                if not (hasattr(msg, 'tool_call_id') and msg.tool_call_id and msg.tool_call_id in assistant_tool_call_map):
                    continue
            final_filtered_messages.append(msg)

        prompt_messages_list.extend(final_filtered_messages)

        internal_prompt_text = INTERNAL_SELF_ANALYSIS_PROMPT_TEMPLATE.format(
            X=num_messages_for_context,
            checklist_content=checklist_content_str
        )
        prompt_messages_list.append(Message(role=Role.USER, content=internal_prompt_text))

        relatorio_autoanalise = "NÃ£o foi possÃ­vel gerar o relatÃ³rio de autoanÃ¡lise devido a um erro interno."
        try:
            logger.info("Iniciando chamada LLM interna para autoanÃ¡lise...")
            if hasattr(self, 'llm') and self.llm:
                 relatorio_autoanalise = await self.llm.ask(messages=prompt_messages_list, stream=False)
                 logger.info(f"RelatÃ³rio de autoanÃ¡lise recebido do LLM: {relatorio_autoanalise[:300]}...")
            else:
                logger.error("InstÃ¢ncia LLM (self.llm) nÃ£o disponÃ­vel para autoanÃ¡lise.")
        except Exception as e_llm_call:
            logger.error(f"Erro durante chamada LLM interna para autoanÃ¡lise: {e_llm_call}")
            relatorio_autoanalise = f"NÃ£o foi possÃ­vel gerar o relatÃ³rio de autoanÃ¡lise devido a um erro: {e_llm_call}"

        pergunta = ""
        if is_failure_scenario:
            last_llm_thought = ""
            if self.memory.messages and self.memory.messages[-1].role == Role.ASSISTANT:
                last_llm_thought = self.memory.messages[-1].content
            error_details_for_prompt = f"Detalhes do erro (conforme meu Ãºltimo pensamento): {last_llm_thought}" if last_llm_thought else "NÃ£o consegui obter detalhes especÃ­ficos do erro do meu processamento interno."
            pergunta = (
                f"Encontrei um problema que me impede de continuar a tarefa como planejado.\n"
                f"RelatÃ³rio de AutoanÃ¡lise (sobre a falha):\n{relatorio_autoanalise}\n\n"
                f"{error_details_for_prompt}\n\n"
                f"VocÃª gostaria que eu finalizasse a tarefa agora devido a esta dificuldade?\n\n"
                f"Por favor, responda com:\n"
                f"- 'sim, finalizar' (para encerrar a tarefa com falha)\n"
                f"- 'nÃ£o, tentar outra abordagem: [suas instruÃ§Ãµes]' (se vocÃª tiver uma sugestÃ£o ou quiser que eu tente algo diferente)"
            )
        elif is_final_check:
            pergunta = (
                f"Todos os itens do checklist foram concluÃ­dos. Aqui estÃ¡ meu relatÃ³rio de autoanÃ¡lise final:\n{relatorio_autoanalise}\n\n"
                f"VocÃª estÃ¡ satisfeito com o resultado e deseja que eu finalize a tarefa?\n\n"
                f"Por favor, responda com:\n"
                f"- 'sim' (para finalizar a tarefa com sucesso)\n"
                f"- 'revisar: [suas instruÃ§Ãµes para revisÃ£o]' (se algo precisa ser ajustado antes de finalizar)"
            )
        else:
            pergunta = (
                f"Aqui estÃ¡ meu relatÃ³rio de autoanÃ¡lise e planejamento:\n{relatorio_autoanalise}\n\n"
                f"Considerando isso, completei um ciclo de {self.max_steps} etapas (total de etapas realizadas: {self.current_step}).\n"
                f"VocÃª quer que eu continue por mais {self.max_steps} etapas (possivelmente seguindo o plano sugerido, se houver)? Ou vocÃª prefere parar ou me dar novas instruÃ§Ãµes?\n\n"
                f"Por favor, responda com:\n"
                f"- 'continuar' (para prosseguir por mais {self.max_steps} etapas)\n"
                f"- 'parar' (para encerrar a tarefa atual)\n"
                f"- 'mudar: [suas novas instruÃ§Ãµes]' (para fornecer uma nova direÃ§Ã£o)"
            )

        # Verifica script cancelÃ¡vel antes de pedir entrada do usuÃ¡rio no caso geral
        if not is_failure_scenario and not is_final_check:
            if hasattr(self, '_current_sandbox_pid_file') and self._current_sandbox_pid_file:
                logger.info(f"Pausa solicitada pelo usuÃ¡rio. Script atualmente em execuÃ§Ã£o com arquivo PID: {self._current_sandbox_pid_file}. Tentando cancelamento.")
                # Assumindo que _initiate_sandbox_script_cancellation serÃ¡ um mÃ©todo assÃ­ncrono
                # Idealmente, tambÃ©m deveria adicionar uma mensagem Ã  memÃ³ria sobre seu resultado.
                # Por enquanto, adicionamos uma mensagem genÃ©rica aqui.
                self.memory.add_message(Message.assistant_message("Tentativa de cancelamento do script em execuÃ§Ã£o no sandbox devido Ã  solicitaÃ§Ã£o de pausa..."))
                if hasattr(self, '_initiate_sandbox_script_cancellation') and callable(getattr(self, '_initiate_sandbox_script_cancellation')):
                    await self._initiate_sandbox_script_cancellation()
                else:
                    logger.warning("MÃ©todo _initiate_sandbox_script_cancellation nÃ£o encontrado, nÃ£o Ã© possÃ­vel cancelar script.")
                    self.memory.add_message(Message.assistant_message("AVISO: Funcionalidade de cancelamento de script nÃ£o implementada neste agente."))

        logger.info(f"Manus: Solicitando feedback do usuÃ¡rio com prompt: {pergunta[:500]}...")
        self.memory.add_message(Message.assistant_message(content=pergunta))

        user_response_text = ""
        user_response_content_for_memory = ""
        try:
            tool_instance = self.available_tools.get_tool(user_interaction_tool_name)
            if tool_instance:
                user_response_content_from_tool = await tool_instance.execute(inquire=pergunta)
                if isinstance(user_response_content_from_tool, str):
                    user_response_content_for_memory = user_response_content_from_tool
                    user_response_text = user_response_content_from_tool.strip().lower()
                    self.memory.add_message(Message.user_message(content=user_response_content_for_memory))
                else:
                    logger.warning(f"Resposta inesperada da ferramenta {user_interaction_tool_name}: {user_response_content_from_tool}")
                    user_response_content_for_memory = str(user_response_content_from_tool)
                    user_response_text = ""
                    self.memory.add_message(Message.user_message(content=user_response_content_for_memory))
            else:
                logger.error(f"Falha ao obter instÃ¢ncia da ferramenta {user_interaction_tool_name} novamente.")
                return True
        except Exception as e:
            logger.error(f"Erro ao usar a ferramenta '{user_interaction_tool_name}': {e}")
            self.memory.add_message(Message.system_message(f"Erro durante interaÃ§Ã£o periÃ³dica com usuÃ¡rio: {e}. Continuando execuÃ§Ã£o."))
            return True

        if is_failure_scenario:
            if user_response_text == "sim, finalizar":
                self.memory.add_message(Message.assistant_message("Entendido. Vou finalizar a tarefa agora devido Ã  falha."))
                self.tool_calls = [ToolCall(id=str(uuid.uuid4()), function=FunctionCall(name=Terminate().name, arguments='{"status": "failure", "message": "UsuÃ¡rio consentiu finalizar devido a falha irrecuperÃ¡vel."}'))]
                self.state = AgentState.TERMINATED
                self._just_resumed_from_feedback = False
                return False
            elif user_response_text.startswith("nÃ£o, tentar outra abordagem:"):
                nova_instrucao = user_response_content_for_memory.replace("nÃ£o, tentar outra abordagem:", "").strip()
                logger.info(f"Manus: UsuÃ¡rio forneceu novas instruÃ§Ãµes apÃ³s falha: {nova_instrucao}")
                self.memory.add_message(Message.assistant_message(f"Entendido. Vou tentar a seguinte abordagem: {nova_instrucao}"))
                self._just_resumed_from_feedback = True
                return True
            else:
                logger.info(f"Manus: UsuÃ¡rio forneceu entrada nÃ£o reconhecida ('{user_response_text}') durante verificaÃ§Ã£o de falha. Solicitando novamente.")
                self.memory.add_message(Message.assistant_message(f"NÃ£o entendi sua resposta ('{user_response_content_for_memory}'). Por favor, use 'sim, finalizar' ou 'nÃ£o, tentar outra abordagem: [instruÃ§Ãµes]'."))
                self._just_resumed_from_feedback = True
                return True
        elif is_final_check:
            if user_response_text == "sim":
                self.memory.add_message(Message.assistant_message("Ã“timo! Vou finalizar a tarefa agora com sucesso."))
                self.tool_calls = [ToolCall(id=str(uuid.uuid4()), function=FunctionCall(name=Terminate().name, arguments='{"status": "success", "message": "Tarefa concluÃ­da com sucesso com aprovaÃ§Ã£o do usuÃ¡rio."}'))]
                self.state = AgentState.TERMINATED
                self._just_resumed_from_feedback = False
                return False
            elif user_response_text.startswith("revisar:"):
                nova_instrucao = user_response_content_for_memory.replace("revisar:", "").strip()
                logger.info(f"Manus: UsuÃ¡rio forneceu novas instruÃ§Ãµes para revisÃ£o final: {nova_instrucao}")
                self.memory.add_message(Message.assistant_message(f"Entendido. Vou revisar com base nas suas instruÃ§Ãµes: {nova_instrucao}"))
                self._just_resumed_from_feedback = True
                return True
            else:
                logger.info(f"Manus: UsuÃ¡rio forneceu entrada nÃ£o reconhecida ('{user_response_text}') durante verificaÃ§Ã£o final. Solicitando novamente.")
                self.memory.add_message(Message.assistant_message(f"NÃ£o entendi sua resposta ('{user_response_content_for_memory}'). Por favor, use 'sim' para finalizar ou 'revisar: [instruÃ§Ãµes]'."))
                self._just_resumed_from_feedback = True
                return True
        else:
            if user_response_text == "parar":
                self.state = AgentState.USER_HALTED
                self._just_resumed_from_feedback = False
                return False
            elif user_response_text.startswith("mudar:"):
                nova_instrucao = user_response_content_for_memory.replace("mudar:", "").strip()
                logger.info(f"Manus: UsuÃ¡rio forneceu novas instruÃ§Ãµes: {nova_instrucao}")
                self.memory.add_message(Message.assistant_message(f"Entendido. Vou seguir suas novas instruÃ§Ãµes: {nova_instrucao}"))
                self._just_resumed_from_feedback = True
                return True
            else: # PadrÃ£o para continuar para qualquer outra entrada ou entrada vazia.
                if user_response_text == "continuar":
                    logger.info("Manus: UsuÃ¡rio escolheu CONTINUAR execuÃ§Ã£o.")
                    self.memory.add_message(Message.assistant_message("Entendido. Continuando com a tarefa."))
                elif not user_response_text and user_response_content_for_memory is not None : # Captura string vazia se user_response_content_for_memory foi preenchido
                     logger.info("Manus: UsuÃ¡rio forneceu resposta vazia, interpretada como 'CONTINUAR'.")
                     self.memory.add_message(Message.assistant_message("Resposta vazia recebida. Continuando com a tarefa."))
                else: # Captura qualquer outra resposta nÃ£o vazia e nÃ£o especÃ­fica
                     logger.info(f"Manus: UsuÃ¡rio respondeu '{user_response_text}', interpretado como 'CONTINUAR'.")
                     self.memory.add_message(Message.assistant_message(f"Resposta '{user_response_content_for_memory}' recebida. Continuando com a tarefa."))

                self._just_resumed_from_feedback = True # Define isso para nÃ£o pedirmos feedback novamente imediatamente
                return True

```

### ARQUIVO: app/agent/react.py ###
```py
from abc import ABC, abstractmethod
from typing import Optional

from pydantic import Field

from app.agent.base import BaseAgent
from app.llm import LLM
from app.schema import AgentState, Memory


class ReActAgent(BaseAgent, ABC):
    name: str
    description: Optional[str] = None

    system_prompt: Optional[str] = None
    next_step_prompt: Optional[str] = None

    llm: Optional[LLM] = Field(default_factory=LLM)
    memory: Memory = Field(default_factory=Memory)
    state: AgentState = AgentState.IDLE

    max_steps: int = 10
    current_step: int = 0

    @abstractmethod
    async def think(self) -> bool:
        """Process current state and decide next action"""

    @abstractmethod
    async def act(self) -> str:
        """Execute decided actions"""

    async def step(self) -> str:
        """Execute a single step: think and act."""
        should_act = await self.think()
        if not should_act:
            return "Thinking complete - no action needed"
        return await self.act()

```

### ARQUIVO: app/agent/checklist_manager.py ###
```py
import re
from typing import Dict, List, Optional

from app.config import config
from app.exceptions import ToolError
from app.logger import logger
from app.tool.file_operators import LocalFileOperator


class ChecklistManager:
    """
    Manages a checklist stored in a markdown file.
    Provides functionalities to load, add, update tasks, and check their status.
    """

    def __init__(self, checklist_filename: str = "checklist_principal_tarefa.md"):
        """
        Initializes the ChecklistManager.

        Args:
            checklist_filename: The name of the markdown file for the checklist.
        """
        self.checklist_path = config.workspace_root / checklist_filename
        logger.info(f"ChecklistManager initialized for: {self.checklist_path}")
        self.tasks: List[
            Dict[str, str]
        ] = (
            []
        )  # e.g., [{'description': 'Do X', 'status': 'Pendente', 'agent': 'Manus'}]
        self.file_operator = LocalFileOperator()
        # _load_checklist will be called explicitly by the tool after instantiation if needed.

    def _normalize_description(self, description: str) -> str:
        """Normalizes a task description for comparison (case-insensitive, strips whitespace)."""
        return description.strip().lower()

    async def _load_checklist(self):
        """
        Loads tasks from the checklist file.
        If the file doesn't exist, logs it specifically and initializes an empty task list.
        If the file is empty, also initializes an empty task list.
        Parses content line by line and populates self.tasks.
        """
        logger.info(f"Attempting to load checklist from: {self.checklist_path}")
        try:
            content = await self.file_operator.read_file(str(self.checklist_path))
            # No specific check for "File not found" in content needed here,
            # as FileNotFoundError will be caught below if read_file raises it.

            if not content:  # Handles empty file content
                logger.info(
                    f"Checklist file at {self.checklist_path} is empty. Initializing with empty task list."
                )
                self.tasks = []
                return

            self.tasks = []  # Reset tasks before loading
            # Pattern to match: - [Status] [Agent: NAME] Description (agent part optional)
            # Status can be Pendente, Em Andamento, ConcluÃ­do, Bloqueado (case insensitive)
            task_pattern = re.compile(
                r"-\s*\[(Pendente|Em Andamento|ConcluÃ­do|Bloqueado)\]\s*(?:\[Agente:\s*(?P<agent>[^\]]+)\]\s*)?(?P<desc>.+)",
                re.IGNORECASE,
            )
            for line_number, line in enumerate(content.splitlines()):
                line = line.strip()
                if not line:  # Skip empty lines
                    continue
                match = task_pattern.match(line)
                if match:
                    status = match.group(1).capitalize()  # Normalize status
                    agent = match.group("agent")
                    description = match.group("desc").strip()
                    task_entry = {
                        "description": description,
                        "status": status,
                        "agent": agent.strip() if agent else None,
                    }
                    self.tasks.append(task_entry)
                else:
                    # Log lines that don't match the expected format
                    logger.warning(
                        f"Could not parse checklist line: '{line}' in file {self.checklist_path} at line {line_number + 1}. Skipping."
                    )

            logger.info(f"Loaded {len(self.tasks)} tasks from {self.checklist_path}.")

        except ToolError as e:
            # Assuming ToolError from LocalFileOperator wraps FileNotFoundError or similar
            # The LocalFileOperator.read_file should ideally raise a specific FileNotFoundError
            # that can be caught, or its ToolError should clearly indicate "file not found".
            # For now, we check the string representation as before, but ideally,
            # LocalFileOperator().read_file would raise FileNotFoundError directly
            # if app.exceptions.ToolError is a wrapper.
            # If LocalFileOperator can raise FileNotFoundError directly (e.g. if it's not caught and wrapped by ToolError):
            # except FileNotFoundError:
            #    logger.info(f"Arquivo de checklist '{self.checklist_path}' nÃ£o encontrado. Iniciando com uma checklist vazia.")
            #    self.tasks = []
            #
            # Given the current structure (ToolError wrapping), we stick to string checking for "File not found"
            if "File not found" in str(e) or "No such file or directory" in str(e):
                # This is the specific log message requested by the issue for FileNotFoundError
                logger.info(
                    f"Arquivo de checklist '{self.checklist_path}' nÃ£o encontrado. Iniciando com uma checklist vazia."
                )
            else:
                # Log other ToolErrors
                logger.error(
                    f"ToolError occurred while reading checklist file {self.checklist_path}: {e}"
                )
            self.tasks = []  # Initialize with empty list for any ToolError

        except Exception as e:
            # Catch any other unexpected errors during loading/parsing
            logger.error(
                f"Unexpected error while loading checklist {self.checklist_path}: {e}"
            )
            self.tasks = []  # Initialize with empty list for safety

    async def _rewrite_checklist_file(self):
        """
        Rewrites the checklist file with the current tasks.
        """
        logger.info(
            f"Rewriting checklist file at: {self.checklist_path} with {len(self.tasks)} tasks."
        )
        content_to_write = []
        for task in self.tasks:
            agent_part = f" [Agente: {task['agent']}]" if task.get("agent") else ""
            content_to_write.append(
                f"- [{task['status']}]" + agent_part + f" {task['description']}"
            )

        try:
            await self.file_operator.write_file(
                str(self.checklist_path), "\n".join(content_to_write) + "\n"
            )
            # Success log is now part of the calling logger.info line
        except ToolError as e:
            logger.error(f"Error writing checklist file {self.checklist_path}: {e}")
        except Exception as e:
            logger.error(
                f"Unexpected error writing checklist file {self.checklist_path}: {e}"
            )

    def get_tasks(self) -> List[Dict[str, str]]:
        """
        Returns a copy of the current tasks.
        """
        return [task.copy() for task in self.tasks]

    async def add_task(
        self,
        task_description: str,
        status: str = "Pendente",
        assigned_agent: Optional[str] = None,
    ) -> bool:
        """
        Adds a new task to the checklist.

        Args:
            task_description: The description of the task.
            status: The initial status of the task (default: "Pendente").
            assigned_agent: Optional name of the agent responsible for this task.

        Returns:
            True if the task was added, False if a task with the same description already exists.
        """
        normalized_description = self._normalize_description(task_description)
        task_desc_stripped = task_description.strip()
        if self.get_task_by_description(normalized_description):
            logger.warning(f"Task '{task_desc_stripped}' already exists. Not adding.")
            return False

        new_task = {
            "description": task_desc_stripped,
            "status": status,
            "agent": assigned_agent,
        }
        self.tasks.append(new_task)
        logger.info(f"Adding task: '{task_desc_stripped}' with status '{status}'")
        await self._rewrite_checklist_file()
        return True

    async def update_task_status(self, task_description: str, new_status: str) -> bool:
        """
        Updates the status of an existing task.

        Args:
            task_description: The description of the task to update.
            new_status: The new status for the task.

        Returns:
            True if the task was found and updated, False otherwise.
        """
        normalized_description_to_find = self._normalize_description(task_description)
        for task in self.tasks:
            if (
                self._normalize_description(task["description"])
                == normalized_description_to_find
            ):
                if task["status"] == new_status:
                    logger.info(
                        f"Task '{task_description.strip()}' already has status '{new_status}'. No update needed."
                    )
                    return True
                task["status"] = new_status
                logger.info(
                    f"Updating task status: '{normalized_description_to_find}' to '{new_status}'"
                )
                await self._rewrite_checklist_file()
                return True

        logger.warning(f"Task not found for update: '{normalized_description_to_find}'")
        return False

    async def update_task_agent(self, task_description: str, new_agent: str) -> bool:
        """Updates the assigned agent for an existing task."""
        normalized_description_to_find = self._normalize_description(task_description)
        for task in self.tasks:
            if (
                self._normalize_description(task["description"])
                == normalized_description_to_find
            ):
                if task.get("agent") == new_agent:
                    logger.info(
                        f"Task '{task_description.strip()}' already assigned to '{new_agent}'. No update needed."
                    )
                    return True
                task["agent"] = new_agent
                logger.info(
                    f"Updating task agent: '{normalized_description_to_find}' to '{new_agent}'"
                )
                await self._rewrite_checklist_file()
                return True
        logger.warning(
            f"Task not found for agent update: '{normalized_description_to_find}'"
        )
        return False

    def get_task_by_description(
        self, task_description: str
    ) -> Optional[Dict[str, str]]:
        """
        Finds a task by its description (case-insensitive, whitespace-normalized).

        Args:
            task_description: The description of the task to find.

        Returns:
            The task dictionary if found, None otherwise.
        """
        normalized_description_to_find = self._normalize_description(task_description)
        for task in self.tasks:
            if (
                self._normalize_description(task["description"])
                == normalized_description_to_find
            ):
                return task.copy()  # Return a copy
        return None

    def is_task_complete(self, task_description: str) -> bool:
        """
        Checks if a specific task is marked as "ConcluÃ­do".

        Args:
            task_description: The description of the task.

        Returns:
            True if the task is found and complete, False otherwise.
        """
        task = self.get_task_by_description(task_description)
        if task:
            return task["status"] == "ConcluÃ­do"
        return False

    def are_all_tasks_complete(self) -> bool:
        """
        Checks if all tasks in the checklist are marked as "ConcluÃ­do".

        Returns:
            True if all tasks are "ConcluÃ­do", or if there are no tasks.
            False if any task is not "ConcluÃ­do".
        """
        if not self.tasks:
            logger.info(
                "are_all_tasks_complete: No tasks in checklist, returning False."
            )
            return False  # No tasks means not complete
        for task in self.tasks:
            if (
                task.get("status", "").lower() != "concluÃ­do"
            ):  # Use .lower() for case-insensitivity
                logger.info(
                    f"are_all_tasks_complete: Task '{task.get('description')}' is not 'ConcluÃ­do'. Status: '{task.get('status')}'. Returning False."
                )
                return False
        logger.info(
            "are_all_tasks_complete: All tasks are 'ConcluÃ­do', returning True."
        )
        return True


if __name__ == "__main__":
    # Example Usage (for testing purposes)
    # Ensure workspace_root is set correctly in your config for this to run standalone
    # from app.config import Config # Assuming Config class can set workspace_root
    # config.workspace_root = Path(".") # Example: current directory as workspace

    logger.info(f"ChecklistManager example using workspace: {config.workspace_root}")

    manager = ChecklistManager(checklist_filename="test_checklist.md")

    # Clean up previous test file if exists
    if manager.checklist_path.exists():
        manager.checklist_path.unlink()
        logger.info(f"Removed old test_checklist.md for fresh test.")
        manager = ChecklistManager(
            checklist_filename="test_checklist.md"
        )  # Re-init with no file

    print(f"Initial tasks: {manager.get_tasks()}")

    manager.add_task("  Tarefa Inicial 1  ")
    manager.add_task("Tarefa Inicial 2", status="Em Andamento")
    manager.add_task("Tarefa jÃ¡ existente para teste de duplicidade")
    manager.add_task(
        "Tarefa jÃ¡ existente para teste de duplicidade"
    )  # Try adding duplicate

    print(f"Tasks after additions: {manager.get_tasks()}")

    manager.update_task_status("Tarefa Inicial 1", "ConcluÃ­do")
    manager.update_task_status("tarefa inicial 2  ", "ConcluÃ­do")  # Test normalization
    manager.update_task_status("Tarefa Inexistente", "ConcluÃ­do")

    print(f"Tasks after updates: {manager.get_tasks()}")
    print(
        f"Is 'Tarefa Inicial 1' complete? {manager.is_task_complete('Tarefa Inicial 1')}"
    )
    print(f"Are all tasks complete? {manager.are_all_tasks_complete()}")

    manager.add_task("Tarefa Pendente Final", "Pendente")
    print(
        f"Are all tasks complete (after adding a pending one)? {manager.are_all_tasks_complete()}"
    )

    # Test loading from existing file
    print("\n--- Testing loading from existing file ---")
    manager_reloaded = ChecklistManager(checklist_filename="test_checklist.md")
    print(f"Tasks reloaded: {manager_reloaded.get_tasks()}")
    manager_reloaded.update_task_status("Tarefa Pendente Final", "ConcluÃ­do")
    print(
        f"Are all tasks complete (reloaded manager)? {manager_reloaded.are_all_tasks_complete()}"
    )

    # Test empty file scenario
    print("\n--- Testing empty file scenario ---")
    empty_manager = ChecklistManager(checklist_filename="empty_test_checklist.md")
    if empty_manager.checklist_path.exists():
        empty_manager.checklist_path.unlink()
    empty_manager.file_operator.write_file(
        str(empty_manager.checklist_path), ""
    )  # create empty file
    empty_manager._load_checklist()  # force reload
    print(f"Tasks from empty file: {empty_manager.get_tasks()}")
    print(f"All complete from empty: {empty_manager.are_all_tasks_complete()}")

    # Test non-existent file scenario (after ensuring it's deleted)
    print("\n--- Testing non-existent file scenario ---")
    non_existent_manager = ChecklistManager(checklist_filename="non_existent_test.md")
    if non_existent_manager.checklist_path.exists():
        non_existent_manager.checklist_path.unlink()
    non_existent_manager._load_checklist()  # force reload after ensuring it's gone
    print(f"Tasks from non-existent file: {non_existent_manager.get_tasks()}")
    print(
        f"All complete from non-existent: {non_existent_manager.are_all_tasks_complete()}"
    )

    logger.info("ChecklistManager example finished.")
    # For cleanup, you might want to delete test_checklist.md
    # if manager.checklist_path.exists():
    #     manager.checklist_path.unlink()
    # if empty_manager.checklist_path.exists():
    #     empty_manager.checklist_path.unlink()
    # if non_existent_manager.checklist_path.exists():
    #     non_existent_manager.checklist_path.unlink()

"""
Note on `if __name__ == '__main__':` block:
This block is for basic testing. For it to run correctly standalone:
1. The `app.config.config.workspace_root` must be set.
   You might need to uncomment and adjust:
   # from app.config import Config
   # config.workspace_root = Path(".")
2. This script should be run from a context where `app.logger` and `app.exceptions` are accessible.
   Typically, this means running from the project root or having the PYTHONPATH set up correctly.
The example usage includes creating a test checklist file, adding/updating tasks, and checking completion statuses.
It also demonstrates reloading the checklist from the file.
"""

```

### ARQUIVO: app/sandbox/__init__.py ###
```py
"""
Docker Sandbox Module

Provides secure containerized execution environment with resource limits
and isolation for running untrusted code.
"""
from app.sandbox.client import (
    BaseSandboxClient,
    LocalSandboxClient,
    create_sandbox_client,
)
from app.sandbox.core.exceptions import (
    SandboxError,
    SandboxResourceError,
    SandboxTimeoutError,
)
from app.sandbox.core.manager import SandboxManager
from app.sandbox.core.sandbox import DockerSandbox


__all__ = [
    "DockerSandbox",
    "SandboxManager",
    "BaseSandboxClient",
    "LocalSandboxClient",
    "create_sandbox_client",
    "SandboxError",
    "SandboxTimeoutError",
    "SandboxResourceError",
]

```

### ARQUIVO: app/sandbox/client.py ###
```py
from abc import ABC, abstractmethod
from typing import Dict, Optional, Protocol, Any # Add Any

from app.config import SandboxSettings
from app.logger import logger
from app.sandbox.core.sandbox import DockerSandbox


class SandboxFileOperations(Protocol):
    """Protocol for sandbox file operations."""

    async def copy_from(self, container_path: str, local_path: str) -> None:
        """Copies file from container to local.

        Args:
            container_path: File path in container.
            local_path: Local destination path.
        """
        ...

    async def copy_to(self, local_path: str, container_path: str) -> None:
        """Copies file from local to container.

        Args:
            local_path: Local source file path.
            container_path: Destination path in container.
        """
        ...

    async def read_file(self, path: str) -> str:
        """Reads file content from container.

        Args:
            path: File path in container.

        Returns:
            str: File content.
        """
        ...

    async def write_file(self, path: str, content: str) -> None:
        """Writes content to file in container.

        Args:
            path: File path in container.
            content: Content to write.
        """
        ...


class BaseSandboxClient(ABC):
    """Base sandbox client interface."""

    @abstractmethod
    async def create(
        self,
        config: Optional[SandboxSettings] = None,
        volume_bindings: Optional[Dict[str, str]] = None,
    ) -> None:
        """Creates sandbox."""

    @abstractmethod
    async def run_command(self, command: str, timeout: Optional[int] = None) -> Dict[str, Any]:
        """Executes command."""

    @abstractmethod
    async def copy_from(self, container_path: str, local_path: str) -> None:
        """Copies file from container."""

    @abstractmethod
    async def copy_to(self, local_path: str, container_path: str) -> None:
        """Copies file to container."""

    @abstractmethod
    async def read_file(self, path: str) -> str:
        """Reads file."""

    @abstractmethod
    async def write_file(self, path: str, content: str) -> None:
        """Writes file."""

    @abstractmethod
    async def cleanup(self) -> None:
        """Cleans up resources."""


class LocalSandboxClient(BaseSandboxClient):
    """Local sandbox client implementation."""

    def __init__(self):
        """Initializes local sandbox client."""
        self.sandbox: Optional[DockerSandbox] = None

    async def create(
        self,
        config: Optional[SandboxSettings] = None,
        volume_bindings: Optional[Dict[str, str]] = None,
    ) -> None:
        """Creates a sandbox.

        Args:
            config: Sandbox configuration.
            volume_bindings: Volume mappings.

        Raises:
            RuntimeError: If sandbox creation fails.
        """
        self.sandbox = DockerSandbox(config, volume_bindings)
        await self.sandbox.create()

    async def run_command(self, command: str, timeout: Optional[int] = None) -> Dict[str, Any]:
        """Runs command in sandbox.

        Args:
            command: Command to execute.
            timeout: Execution timeout in seconds.

        Returns:
            A dictionary containing "exit_code", "stdout", and "stderr".

        Raises:
            RuntimeError: If sandbox not initialized or command execution fails.
            SandboxTimeoutError: If the command times out.
        """
        if not self.sandbox:
            raise RuntimeError("Sandbox not initialized")
        # This will now return the dictionary {"exit_code": ..., "stdout": ..., "stderr": ...}
        # Exceptions like SandboxTimeoutError or RuntimeError (for other exec failures)
        # will be propagated from self.sandbox.run_command
        return await self.sandbox.run_command(command, timeout)

    async def copy_from(self, container_path: str, local_path: str) -> None:
        """Copies file from container to local.

        Args:
            container_path: File path in container.
            local_path: Local destination path.

        Raises:
            RuntimeError: If sandbox not initialized.
        """
        if not self.sandbox:
            raise RuntimeError("Sandbox not initialized")
        await self.sandbox.copy_from(container_path, local_path)

    async def copy_to(self, local_path: str, container_path: str) -> None:
        """Copies file from local to container.

        Args:
            local_path: Local source file path.
            container_path: Destination path in container.

        Raises:
            RuntimeError: If sandbox not initialized.
        """
        if not self.sandbox:
            raise RuntimeError("Sandbox not initialized")
        await self.sandbox.copy_to(local_path, container_path)

    async def read_file(self, path: str) -> str:
        """Reads file from container.

        Args:
            path: File path in container.

        Returns:
            File content.

        Raises:
            RuntimeError: If sandbox not initialized.
        """
        if not self.sandbox:
            raise RuntimeError("Sandbox not initialized")
        return await self.sandbox.read_file(path)

    async def write_file(self, path: str, content: str) -> None:
        """Writes file to container.

        Args:
            path: File path in container.
            content: File content.

        Raises:
            RuntimeError: If sandbox not initialized.
        """
        if not self.sandbox:
            raise RuntimeError("Sandbox not initialized")
        await self.sandbox.write_file(path, content)

    async def cleanup(self) -> None:
        """Cleans up resources."""
        logger.info("LocalSandboxClient.cleanup: Starting...")
        if self.sandbox:
            logger.info("LocalSandboxClient.cleanup: About to call self.sandbox.cleanup()")
            await self.sandbox.cleanup()
            logger.info("LocalSandboxClient.cleanup: self.sandbox.cleanup() completed.")
            self.sandbox = None
            logger.info("LocalSandboxClient.cleanup: self.sandbox set to None.")
        logger.info("LocalSandboxClient.cleanup: Finished.")


def create_sandbox_client() -> LocalSandboxClient:
    """Creates a sandbox client.

    Returns:
        LocalSandboxClient: Sandbox client instance.
    """
    return LocalSandboxClient()


SANDBOX_CLIENT = create_sandbox_client()

```

### ARQUIVO: app/sandbox/core/manager.py ###
```py
import asyncio
import uuid
from contextlib import asynccontextmanager
from typing import Dict, Optional, Set

import docker
from docker.errors import APIError, ImageNotFound

from app.config import SandboxSettings
from app.logger import logger
from app.sandbox.core.sandbox import DockerSandbox


class SandboxManager:
    """Docker sandbox manager.

    Manages multiple DockerSandbox instances lifecycle including creation,
    monitoring, and cleanup. Provides concurrent access control and automatic
    cleanup mechanisms for sandbox resources.

    Attributes:
        max_sandboxes: Maximum allowed number of sandboxes.
        idle_timeout: Sandbox idle timeout in seconds.
        cleanup_interval: Cleanup check interval in seconds.
        _sandboxes: Active sandbox instance mapping.
        _last_used: Last used time record for sandboxes.
    """

    def __init__(
        self,
        max_sandboxes: int = 100,
        idle_timeout: int = 3600,
        cleanup_interval: int = 300,
    ):
        """Initializes sandbox manager.

        Args:
            max_sandboxes: Maximum sandbox count limit.
            idle_timeout: Idle timeout in seconds.
            cleanup_interval: Cleanup check interval in seconds.
        """
        self.max_sandboxes = max_sandboxes
        self.idle_timeout = idle_timeout
        self.cleanup_interval = cleanup_interval

        # Docker client
        self._client = docker.from_env()

        # Resource mappings
        self._sandboxes: Dict[str, DockerSandbox] = {}
        self._last_used: Dict[str, float] = {}

        # Concurrency control
        self._locks: Dict[str, asyncio.Lock] = {}
        self._global_lock = asyncio.Lock()
        self._active_operations: Set[str] = set()

        # Cleanup task
        self._cleanup_task: Optional[asyncio.Task] = None
        self._is_shutting_down = False

        # Start automatic cleanup
        self.start_cleanup_task()

    async def ensure_image(self, image: str) -> bool:
        """Ensures Docker image is available.

        Args:
            image: Image name.

        Returns:
            bool: Whether image is available.
        """
        try:
            self._client.images.get(image)
            return True
        except ImageNotFound:
            try:
                logger.info(f"Pulling image {image}...")
                await asyncio.get_event_loop().run_in_executor(
                    None, self._client.images.pull, image
                )
                return True
            except (APIError, Exception) as e:
                logger.error(f"Failed to pull image {image}: {e}")
                return False

    @asynccontextmanager
    async def sandbox_operation(self, sandbox_id: str):
        """Context manager for sandbox operations.

        Provides concurrency control and usage time updates.

        Args:
            sandbox_id: Sandbox ID.

        Raises:
            KeyError: If sandbox not found.
        """
        if sandbox_id not in self._locks:
            self._locks[sandbox_id] = asyncio.Lock()

        async with self._locks[sandbox_id]:
            if sandbox_id not in self._sandboxes:
                raise KeyError(f"Sandbox {sandbox_id} not found")

            self._active_operations.add(sandbox_id)
            try:
                self._last_used[sandbox_id] = asyncio.get_event_loop().time()
                yield self._sandboxes[sandbox_id]
            finally:
                self._active_operations.remove(sandbox_id)

    async def create_sandbox(
        self,
        config: Optional[SandboxSettings] = None,
        volume_bindings: Optional[Dict[str, str]] = None,
    ) -> str:
        """Creates a new sandbox instance.

        Args:
            config: Sandbox configuration.
            volume_bindings: Volume mapping configuration.

        Returns:
            str: Sandbox ID.

        Raises:
            RuntimeError: If max sandbox count reached or creation fails.
        """
        async with self._global_lock:
            if len(self._sandboxes) >= self.max_sandboxes:
                raise RuntimeError(
                    f"Maximum number of sandboxes ({self.max_sandboxes}) reached"
                )

            config = config or SandboxSettings()
            if not await self.ensure_image(config.image):
                raise RuntimeError(f"Failed to ensure Docker image: {config.image}")

            sandbox_id = str(uuid.uuid4())
            try:
                sandbox = DockerSandbox(config, volume_bindings)
                await sandbox.create()

                self._sandboxes[sandbox_id] = sandbox
                self._last_used[sandbox_id] = asyncio.get_event_loop().time()
                self._locks[sandbox_id] = asyncio.Lock()

                logger.info(f"Created sandbox {sandbox_id}")
                return sandbox_id

            except Exception as e:
                logger.error(f"Failed to create sandbox: {e}")
                if sandbox_id in self._sandboxes:
                    await self.delete_sandbox(sandbox_id)
                raise RuntimeError(f"Failed to create sandbox: {e}")

    async def get_sandbox(self, sandbox_id: str) -> DockerSandbox:
        """Gets a sandbox instance.

        Args:
            sandbox_id: Sandbox ID.

        Returns:
            DockerSandbox: Sandbox instance.

        Raises:
            KeyError: If sandbox does not exist.
        """
        async with self.sandbox_operation(sandbox_id) as sandbox:
            return sandbox

    def start_cleanup_task(self) -> None:
        """Starts automatic cleanup task."""

        async def cleanup_loop():
            while not self._is_shutting_down:
                try:
                    await self._cleanup_idle_sandboxes()
                except Exception as e:
                    logger.error(f"Error in cleanup loop: {e}")
                await asyncio.sleep(self.cleanup_interval)

        self._cleanup_task = asyncio.create_task(cleanup_loop())

    async def _cleanup_idle_sandboxes(self) -> None:
        """Cleans up idle sandboxes."""
        current_time = asyncio.get_event_loop().time()
        to_cleanup = []

        async with self._global_lock:
            for sandbox_id, last_used in self._last_used.items():
                if (
                    sandbox_id not in self._active_operations
                    and current_time - last_used > self.idle_timeout
                ):
                    to_cleanup.append(sandbox_id)

        for sandbox_id in to_cleanup:
            try:
                await self.delete_sandbox(sandbox_id)
            except Exception as e:
                logger.error(f"Error cleaning up sandbox {sandbox_id}: {e}")

    async def cleanup(self) -> None:
        """Cleans up all resources."""
        logger.info("Starting manager cleanup...")
        self._is_shutting_down = True

        # Cancel cleanup task
        if self._cleanup_task:
            self._cleanup_task.cancel()
            try:
                await asyncio.wait_for(self._cleanup_task, timeout=1.0)
            except (asyncio.CancelledError, asyncio.TimeoutError):
                pass

        # Get all sandbox IDs to clean up
        async with self._global_lock:
            sandbox_ids = list(self._sandboxes.keys())

        # Concurrently clean up all sandboxes
        cleanup_tasks = []
        for sandbox_id in sandbox_ids:
            task = asyncio.create_task(self._safe_delete_sandbox(sandbox_id))
            cleanup_tasks.append(task)

        if cleanup_tasks:
            # Wait for all cleanup tasks to complete, with timeout to avoid infinite waiting
            try:
                await asyncio.wait(cleanup_tasks, timeout=30.0)
            except asyncio.TimeoutError:
                logger.error("Sandbox cleanup timed out")

        # Clean up remaining references
        self._sandboxes.clear()
        self._last_used.clear()
        self._locks.clear()
        self._active_operations.clear()

        logger.info("Manager cleanup completed")

    async def _safe_delete_sandbox(self, sandbox_id: str) -> None:
        """Safely deletes a single sandbox.

        Args:
            sandbox_id: Sandbox ID to delete.
        """
        try:
            if sandbox_id in self._active_operations:
                logger.warning(
                    f"Sandbox {sandbox_id} has active operations, waiting for completion"
                )
                for _ in range(10):  # Wait at most 10 times
                    await asyncio.sleep(0.5)
                    if sandbox_id not in self._active_operations:
                        break
                else:
                    logger.warning(
                        f"Timeout waiting for sandbox {sandbox_id} operations to complete"
                    )

            # Get reference to sandbox object
            sandbox = self._sandboxes.get(sandbox_id)
            if sandbox:
                await sandbox.cleanup()

                # Remove sandbox record from manager
                async with self._global_lock:
                    self._sandboxes.pop(sandbox_id, None)
                    self._last_used.pop(sandbox_id, None)
                    self._locks.pop(sandbox_id, None)
                    logger.info(f"Deleted sandbox {sandbox_id}")
        except Exception as e:
            logger.error(f"Error during cleanup of sandbox {sandbox_id}: {e}")

    async def delete_sandbox(self, sandbox_id: str) -> None:
        """Deletes specified sandbox.

        Args:
            sandbox_id: Sandbox ID.
        """
        if sandbox_id not in self._sandboxes:
            return

        try:
            await self._safe_delete_sandbox(sandbox_id)
        except Exception as e:
            logger.error(f"Failed to delete sandbox {sandbox_id}: {e}")

    async def __aenter__(self) -> "SandboxManager":
        """Async context manager entry."""
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:
        """Async context manager exit."""
        await self.cleanup()

    def get_stats(self) -> Dict:
        """Gets manager statistics.

        Returns:
            Dict: Statistics information.
        """
        return {
            "total_sandboxes": len(self._sandboxes),
            "active_operations": len(self._active_operations),
            "max_sandboxes": self.max_sandboxes,
            "idle_timeout": self.idle_timeout,
            "cleanup_interval": self.cleanup_interval,
            "is_shutting_down": self._is_shutting_down,
        }

```

### ARQUIVO: app/sandbox/core/terminal.py ###
```py
"""
Asynchronous Docker Terminal

This module provides asynchronous terminal functionality for Docker containers,
allowing interactive command execution with timeout control.
"""

import asyncio
import socket # Keep socket for DockerSession if it's used elsewhere or for future
from typing import Dict, Optional, Tuple, Union, Any # Add Any for dict value

import docker
# from docker import APIClient # Not directly used by AsyncDockerizedTerminal after refactor
from docker.errors import APIError
from docker.models.containers import Container

from app.sandbox.core.exceptions import SandboxTimeoutError


# DockerSession might be simplified or removed if not essential for other functionalities
# For now, we are keeping it as it might be used for interactive scenarios.
# If run_command is the primary way of interacting, DockerSession's role diminishes.

class DockerSession:  # This class is for interactive sessions
    def __init__(self, container_id: str) -> None:
        """Initializes a Docker session.

        Args:
            container_id: ID of the Docker container.
        """
        # self.api = APIClient() # Potentially unused if only exec_run is used
        self.api = docker.APIClient() # Ensure APIClient is available
        self.container_id = container_id
        self.exec_id = None
        self.socket = None

    async def create(self, working_dir: str, env_vars: Dict[str, str]) -> None:
        """Creates an interactive session with the container.

        Args:
            working_dir: Working directory inside the container.
            env_vars: Environment variables to set.

        Raises:
            RuntimeError: If socket connection fails.
        """
        startup_command = [
            "bash",
            "-c",
            f"cd {working_dir} && "
            "PROMPT_COMMAND='' "
            "PS1='$ ' "
            "exec bash --norc --noprofile",
        ]

        exec_data = self.api.exec_create(
            self.container_id,
            startup_command,
            stdin=True,
            tty=True,
            stdout=True,
            stderr=True,
            privileged=True, # Consider if privileged is always needed
            user="root",
            environment={**env_vars, "TERM": "dumb", "PS1": "$ ", "PROMPT_COMMAND": ""},
        )
        self.exec_id = exec_data["Id"]

        # demux=True is important for exec_start if we need separate streams
        socket_data = self.api.exec_start(
            self.exec_id, socket=True, tty=True, stream=True, demux=True
        )

        if hasattr(socket_data, "_sock"):
            self.socket = socket_data._sock
            self.socket.setblocking(False)
        else:
            # This path might indicate an issue with Docker's response or setup
            raise RuntimeError("Failed to get socket connection for interactive session")

        await self._read_until_prompt() # Specific to interactive sessions

    async def close(self) -> None:
        """Cleans up session resources."""
        try:
            if self.socket:
                try:
                    self.socket.sendall(b"exit\n")
                    await asyncio.sleep(0.1)
                except Exception: # pylint: disable=broad-except
                    pass

                try:
                    self.socket.shutdown(socket.SHUT_RDWR)
                except Exception: # pylint: disable=broad-except
                    pass
                self.socket.close()
                self.socket = None

            if self.exec_id:
                try:
                    exec_inspect = self.api.exec_inspect(self.exec_id)
                    if exec_inspect.get("Running", False):
                        await asyncio.sleep(0.5) # Give a bit of time for exec to finish
                        # Optionally, send a kill signal if it's stuck
                except Exception: # pylint: disable=broad-except
                    pass # Ignore inspection errors during cleanup
                self.exec_id = None
        except Exception as e: # pylint: disable=broad-except
            print(f"Warning: Error during DockerSession cleanup: {e}")


    async def _read_until_prompt(self) -> str:
        """Reads output until prompt is found. (Interactive session specific)"""
        buffer = b""
        prompt_marker = b"$ " # Standard prompt marker
        # A more robust prompt detection might be needed if PS1 is complex
        while prompt_marker not in buffer:
            try:
                # Non-blocking read with async sleep
                chunk = await asyncio.to_thread(self.socket.recv, 4096)
                if chunk:
                    buffer += chunk
                else:
                    # Socket closed or no data, might indicate end of stream or error
                    await asyncio.sleep(0.01) # Small delay before retrying or breaking
                    # Add a counter or timeout here to prevent infinite loop if prompt never appears
            except socket.error as e:
                if e.errno == socket.EWOULDBLOCK or e.errno == socket.EAGAIN:
                    await asyncio.sleep(0.05) # Wait for data
                    continue
                # Other socket errors could be critical
                raise RuntimeError(f"Socket error while reading for prompt: {e}")
            except Exception as e: # pylint: disable=broad-except
                # Catch other potential errors during recv
                raise RuntimeError(f"Unexpected error while reading for prompt: {e}")
        return buffer.decode("utf-8", errors="replace")


    async def execute(self, command: str, timeout: Optional[int] = None) -> str:
        """Executes a command in an interactive session and returns cleaned output."""
        if not self.socket or not self.exec_id:
            raise RuntimeError("Interactive session not properly initialized.")

        try:
            # Command sanitation should ideally happen before this point if it's generic
            # For interactive sessions, users might expect more raw execution
            full_command = f"{command}\necho EXEC_END_MARKER $?\n" # Use a unique marker
            self.socket.sendall(full_command.encode())

            async def read_interactive_output() -> str:
                buffer = b""
                output_lines = []
                # This logic needs to be robust to capture multi-line outputs
                # and correctly identify the end of the command execution.
                # The `echo EXEC_END_MARKER $?` helps in finding the command's end.
                # This is a simplified version. A full implementation would need
                # careful handling of stream data, potential partial lines, etc.
                while not (b"EXEC_END_MARKER" in buffer and b"$ " in buffer): # Wait for marker and next prompt
                    try:
                        chunk = await asyncio.to_thread(self.socket.recv, 4096)
                        if chunk:
                            buffer += chunk
                        else:
                            await asyncio.sleep(0.01)
                    except socket.error as e:
                        if e.errno == socket.EWOULDBLOCK or e.errno == socket.EAGAIN:
                            await asyncio.sleep(0.05)
                            continue
                        raise RuntimeError(f"Socket error during interactive command execution: {e}")

                # Process buffer to extract relevant output before EXEC_END_MARKER
                # This part is complex and error-prone with interactive sessions.
                # For structured output (stdout, stderr, exit_code), non-interactive exec_run is preferred.
                raw_output = buffer.decode("utf-8", errors="replace")
                # Simplified: extract content before the marker. Needs refinement.
                command_output = raw_output.split("EXEC_END_MARKER")[0]
                # Remove the sent command from the output if it's echoed back
                if command_output.startswith(command):
                    command_output = command_output[len(command):].lstrip()
                return command_output.strip()


            if timeout:
                return await asyncio.wait_for(read_interactive_output(), timeout=timeout)
            return await read_interactive_output()

        except asyncio.TimeoutError:
            # In a timeout, the session might be in an inconsistent state.
            # Consider trying to send a Ctrl+C or closing/recreating the session.
            raise SandboxTimeoutError(f"Interactive command timed out after {timeout} seconds.")
        except Exception as e:
            raise RuntimeError(f"Failed to execute interactive command: {e}")

    def _sanitize_command(self, command: str) -> str: # This might be less relevant for direct exec_run
        """Sanitizes the command string (basic version)."""
        # This is a very basic sanitizer. For robust security, more is needed.
        # Or, rely on sandbox permissions and container hardening.
        if ";" in command and "&&" not in command and "||" not in command:
             # Simple check for multiple commands not using && or ||
             pass # Allow for now, but this is a weak check.
        # Add more checks as necessary, e.g., for risky patterns.
        # However, over-sanitization can also break valid commands.
        return command


class AsyncDockerizedTerminal:
    def __init__(
        self,
        container: Union[str, Container],
        working_dir: str = "/workspace", # Default working directory in the container
        env_vars: Optional[Dict[str, str]] = None,
        default_timeout: int = 60, # Default timeout for commands
    ) -> None:
        """Initializes an asynchronous terminal for Docker containers.

        Args:
            container: Docker container ID or Container object.
            working_dir: Working directory inside the container for commands.
            env_vars: Environment variables to set for commands.
            default_timeout: Default command execution timeout in seconds.
        """
        self.docker_client = docker.from_env() # Standard Docker client
        self.container = (
            container
            if isinstance(container, Container)
            else self.docker_client.containers.get(container)
        )
        self.working_dir = working_dir
        self.env_vars = env_vars if env_vars is not None else {}
        self.default_timeout = default_timeout
        # Interactive session is now optional, only created if specific methods are called
        self.session: Optional[DockerSession] = None


    async def init_interactive_session(self) -> None:
        """Initializes the interactive terminal session.
        This is separated so that not every terminal usage implies an interactive session.
        """
        if not self.session:
            await self._ensure_workdir() # Ensure working dir exists before session
            self.session = DockerSession(self.container.id)
            try:
                await self.session.create(self.working_dir, self.env_vars)
            except Exception as e:
                self.session = None # Reset session on failure
                raise RuntimeError(f"Failed to initialize interactive session: {e}")

    async def _ensure_workdir(self) -> None:
        """Ensures working directory exists in the container.
        Uses a non-interactive exec_run for this setup command.
        """
        # This command is simple and non-interactive, suitable for a direct exec_run.
        # It doesn't strictly need the full run_command treatment with timeout here,
        # but for consistency, it could use a simplified version of run_command.
        mkdir_cmd = f"mkdir -p {self.working_dir}"
        try:
            # Using exec_run directly for setup.
            # No need for demux=True here as output is not critical, only exit_code.
            exit_code, (stdout, stderr) = await asyncio.to_thread(
                self.container.exec_run,
                mkdir_cmd,
                workdir=self.working_dir, # Ensure command runs in the context of workdir
                environment=self.env_vars,
                demux=True # Get separate streams
            )
            if exit_code != 0:
                stdout_str = stdout.decode("utf-8", errors="replace") if stdout else ""
                stderr_str = stderr.decode("utf-8", errors="replace") if stderr else ""
                raise RuntimeError(
                    f"Failed to create working directory '{self.working_dir}': "
                    f"Exit code {exit_code}, Stdout: '{stdout_str}', Stderr: '{stderr_str}'"
                )
        except APIError as e:
            raise RuntimeError(f"APIError during _ensure_workdir: {e}")
        except Exception as e: # Catch other potential errors
            raise RuntimeError(f"Unexpected error during _ensure_workdir: {e}")


    async def run_command(
        self, cmd: str, timeout: Optional[int] = None
    ) -> Dict[str, Any]:
        """Runs a non-interactive command in the container with timeout and returns structured output.

        Args:
            cmd: Shell command to execute.
            timeout: Maximum execution time in seconds. Defaults to self.default_timeout.

        Returns:
            A dictionary with "exit_code", "stdout", and "stderr".

        Raises:
            SandboxTimeoutError: If command execution exceeds timeout.
            RuntimeError: If command execution fails for other reasons.
        """
        exec_timeout = timeout if timeout is not None else self.default_timeout

        try:
            # Ensure working directory exists. This is crucial for command execution context.
            # Call it here to make sure it's set up before any command.
            # If called multiple times, it's idempotent ("mkdir -p").
            await self._ensure_workdir()

            # `exec_run` is suitable for non-interactive commands where we need exit code & output.
            # `tty=False` is generally better for non-interactive execs capturing stdout/stderr.
            # `demux=True` gives separate stdout and stderr streams.
            exec_coro = asyncio.to_thread(
                self.container.exec_run,
                cmd,
                workdir=self.working_dir,
                environment=self.env_vars,
                demux=True, # Crucial for separate stdout/stderr
                tty=False, # Non-interactive, so no TTY needed
            )

            # Execute with timeout
            exit_code, (stdout_bytes, stderr_bytes) = await asyncio.wait_for(
                exec_coro, timeout=exec_timeout
            )

            stdout_str = stdout_bytes.decode("utf-8", errors="replace") if stdout_bytes else ""
            stderr_str = stderr_bytes.decode("utf-8", errors="replace") if stderr_bytes else ""

            return {
                "exit_code": exit_code,
                "stdout": stdout_str,
                "stderr": stderr_str,
            }

        except asyncio.TimeoutError:
            # Construct a meaningful timeout message
            timeout_message = (
                f"Command '{cmd[:100]}{'...' if len(cmd) > 100 else ''}' "
                f"timed out after {exec_timeout} seconds."
            )
            # It's good practice to include stderr in timeout if available,
            # but exec_run result is not available if timeout occurs during await.
            # So, we typically won't have stdout/stderr here.
            raise SandboxTimeoutError(timeout_message)

        except APIError as e:
            # Docker API errors
            raise RuntimeError(f"Docker APIError executing command '{cmd}': {e}")
        except Exception as e:
            # Other unexpected errors
            raise RuntimeError(f"Unexpected error executing command '{cmd}': {e}")


    async def run_interactive_command(self, cmd: str, timeout: Optional[int] = None) -> str:
        """Runs a command in an interactive session.
        Requires init_interactive_session to be called first.
        """
        if not self.session:
            # Automatically initialize if not already done.
            # Or raise error: raise RuntimeError("Interactive session not initialized. Call init_interactive_session() first.")
            await self.init_interactive_session()

        # Ensure session is now available after potential initialization
        if not self.session:
             raise RuntimeError("Failed to create interactive session for command.")

        return await self.session.execute(cmd, timeout=timeout or self.default_timeout)


    async def close(self) -> None:
        """Closes the terminal session, primarily the interactive one if it exists."""
        if self.session:
            await self.session.close()
            self.session = None # Clear the session
        # self.docker_client.close() # Typically, the client is managed externally or at app level


    async def __aenter__(self) -> "AsyncDockerizedTerminal":
        # The __aenter__ could optionally initialize the interactive session
        # if that's the primary use case for contexts.
        # For now, it just returns self. `_ensure_workdir` is called by `run_command`.
        # If interactive session is commonly used with `async with`, then:
        # await self.init_interactive_session()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:
        """Async context manager entry."""
        await self.init()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:
        """Async context manager exit."""
        await self.close() # Ensure interactive session resources are cleaned up

```

### ARQUIVO: app/sandbox/core/sandbox.py ###
```py
import asyncio
import io
import os
import tarfile
import tempfile
import uuid
from typing import Dict, Optional, Any # Added Any here

import docker
from docker.errors import NotFound, ImageNotFound, APIError # Add ImageNotFound, APIError
from docker.models.containers import Container

from app.config import SandboxSettings
from app.sandbox.core.exceptions import SandboxTimeoutError
from app.sandbox.core.terminal import AsyncDockerizedTerminal


class DockerSandbox:
    """Docker sandbox environment.

    Provides a containerized execution environment with resource limits,
    file operations, and command execution capabilities.

    Attributes:
        config: Sandbox configuration.
        volume_bindings: Volume mapping configuration.
        client: Docker client.
        container: Docker container instance.
        terminal: Container terminal interface.
    """

    def __init__(
        self,
        config: Optional[SandboxSettings] = None,
        volume_bindings: Optional[Dict[str, str]] = None,
    ):
        """Initializes a sandbox instance.

        Args:
            config: Sandbox configuration. Default configuration used if None.
            volume_bindings: Volume mappings in {host_path: container_path} format.
        """
        self.config = config or SandboxSettings()
        self.volume_bindings = volume_bindings or {}
        self.client = docker.from_env()
        self.container: Optional[Container] = None
        self.terminal: Optional[AsyncDockerizedTerminal] = None

    async def create(self) -> "DockerSandbox":
        """Creates and starts the sandbox container.

        Returns:
            Current sandbox instance.

        Raises:
            RuntimeError: If container creation, image pull, or startup fails.
        """
        try:
            # Attempt to get the image to see if it exists locally
            try:
                await asyncio.to_thread(self.client.images.get, self.config.image)
                print(f"Image {self.config.image} found locally.") # Or use logger
            except ImageNotFound:
                print(f"Image {self.config.image} not found locally. Pulling...") # Or use logger
                try:
                    await asyncio.to_thread(self.client.images.pull, self.config.image)
                    print(f"Successfully pulled image {self.config.image}.") # Or use logger
                except APIError as pull_error:
                    # This is an error during the pull operation itself
                    await self.cleanup() # Ensure cleanup before raising
                    raise RuntimeError(f"Failed to pull image {self.config.image} from registry: {pull_error}") from pull_error

            # Prepare container config
            host_config = self.client.api.create_host_config(
                mem_limit=self.config.memory_limit,
                cpu_period=100000,
                cpu_quota=int(100000 * self.config.cpu_limit),
                network_mode="none" if not self.config.network_enabled else "bridge",
                binds=self._prepare_volume_bindings(),
            )

            # Generate unique container name with sandbox_ prefix
            container_name = f"sandbox_{uuid.uuid4().hex[:8]}"

            # Create container
            container = await asyncio.to_thread(
                self.client.api.create_container,
                image=self.config.image,
                command="tail -f /dev/null",
                hostname="sandbox",
                working_dir=self.config.work_dir,
                host_config=host_config,
                name=container_name,
                tty=True,
                detach=True,
            )

            self.container = self.client.containers.get(container["Id"])

            # Start container
            await asyncio.to_thread(self.container.start)

            # Initialize terminal
            self.terminal = AsyncDockerizedTerminal(
                container["Id"],
                self.config.work_dir,
                env_vars={"PYTHONUNBUFFERED": "1"}
                # Ensure Python output is not buffered
            )
            # RM: await self.terminal.init() # AsyncDockerizedTerminal does not have an init method.
            # Initialization is handled by _ensure_workdir in run_command or init_interactive_session.

            return self

        except APIError as api_err: # Catch API errors from create_container, start, etc.
            await self.cleanup()
            raise RuntimeError(f"Docker API error during sandbox setup (after image handling): {api_err}") from api_err
        except Exception as e: # Catch other general errors
            await self.cleanup()
            # Ensure not to re-wrap the RuntimeError from a failed pull
            if isinstance(e, RuntimeError) and "Failed to pull image" in str(e):
                raise # Re-raise the specific pull error
            raise RuntimeError(f"Failed to create sandbox: {e}") from e

    def _prepare_volume_bindings(self) -> Dict[str, Dict[str, str]]:
        """Prepares volume binding configuration.

        Returns:
            Volume binding configuration dictionary.
        """
        bindings = {}

        # Create and add working directory mapping
        work_dir = self._ensure_host_dir(self.config.work_dir)
        bindings[work_dir] = {"bind": self.config.work_dir, "mode": "rw"}

        # Add custom volume bindings
        for host_path, container_path in self.volume_bindings.items():
            bindings[host_path] = {"bind": container_path, "mode": "rw"}

        return bindings

    @staticmethod
    def _ensure_host_dir(path: str) -> str:
        """Ensures directory exists on the host.

        Args:
            path: Directory path.

        Returns:
            Actual path on the host.
        """
        host_path = os.path.join(
            tempfile.gettempdir(),
            f"sandbox_{os.path.basename(path)}_{os.urandom(4).hex()}",
        )
        os.makedirs(host_path, exist_ok=True)
        return host_path

    async def run_command(self, cmd: str, timeout: Optional[int] = None) -> Dict[str, Any]:
        """Runs a command in the sandbox.

        Args:
            cmd: Command to execute.
            timeout: Timeout in seconds.

        Returns:
            A dictionary containing "exit_code", "stdout", and "stderr".

        Raises:
            RuntimeError: If sandbox not initialized or command execution fails.
            SandboxTimeoutError: If command execution times out.
        """
        if not self.terminal:
            raise RuntimeError("Sandbox not initialized. Terminal is not available.")
        if not self.container: # Should not happen if terminal is available, but good check
            raise RuntimeError("Sandbox not initialized. Container is not available.")

        try:
            # The terminal.run_command now returns a Dict[str, Any]
            # with {"exit_code": ..., "stdout": ..., "stderr": ...}
            result = await self.terminal.run_command(
                cmd, timeout=timeout or self.config.timeout
            )
            return result
        except SandboxTimeoutError: # Propagate SandboxTimeoutError directly
            raise
        except TimeoutError: # Should be caught by terminal.run_command and raised as SandboxTimeoutError
            # This is a fallback, ideally SandboxTimeoutError is raised from terminal
            raise SandboxTimeoutError(
                f"Command '{cmd}' timed out after {timeout or self.config.timeout} seconds (caught in DockerSandbox)."
            )
        except Exception as e:
            # Catch other potential errors from terminal.run_command or other issues
            # and wrap them in a RuntimeError for consistency, or handle specific ones.
            # This ensures that the caller (e.g., LocalSandboxClient) gets a clear error.
            # The terminal.run_command itself should raise RuntimeError for API errors or exec failures.
            raise RuntimeError(f"Failed to run command '{cmd}' in sandbox: {e}")


    async def read_file(self, path: str) -> str:
        """Reads a file from the container.

        Args:
            path: File path.

        Returns:
            File contents as string.

        Raises:
            FileNotFoundError: If file does not exist.
            RuntimeError: If read operation fails.
        """
        if not self.container:
            raise RuntimeError("Sandbox not initialized")

        try:
            # Get file archive
            resolved_path = self._safe_resolve_path(path)
            tar_stream, _ = await asyncio.to_thread(
                self.container.get_archive, resolved_path
            )

            # Read file content from tar stream
            content = await self._read_from_tar(tar_stream)
            return content.decode("utf-8")

        except NotFound:
            raise FileNotFoundError(f"File not found: {path}")
        except Exception as e:
            raise RuntimeError(f"Failed to read file: {e}")

    async def write_file(self, path: str, content: str) -> None:
        """Writes content to a file in the container.

        Args:
            path: Target path.
            content: File content.

        Raises:
            RuntimeError: If write operation fails.
        """
        if not self.container:
            raise RuntimeError("Sandbox not initialized")

        try:
            resolved_path = self._safe_resolve_path(path)
            parent_dir = os.path.dirname(resolved_path)

            # Create parent directory
            if parent_dir:
                await self.run_command(f"mkdir -p {parent_dir}")

            # Prepare file data
            tar_stream = await self._create_tar_stream(
                os.path.basename(path), content.encode("utf-8")
            )

            # Write file
            await asyncio.to_thread(
                self.container.put_archive, parent_dir or "/", tar_stream
            )

        except Exception as e:
            raise RuntimeError(f"Failed to write file: {e}")

    def _safe_resolve_path(self, path: str) -> str:
        """Safely resolves container path, preventing path traversal.

        Args:
            path: Original path.

        Returns:
            Resolved absolute path.

        Raises:
            ValueError: If path contains potentially unsafe patterns.
        """
        # Check for path traversal attempts
        if ".." in path.split("/"):
            raise ValueError("Path contains potentially unsafe patterns")

        resolved = (
            os.path.join(self.config.work_dir, path)
            if not os.path.isabs(path)
            else path
        )
        return resolved

    async def copy_from(self, src_path: str, dst_path: str) -> None:
        """Copies a file from the container.

        Args:
            src_path: Source file path (container).
            dst_path: Destination path (host).

        Raises:
            FileNotFoundError: If source file does not exist.
            RuntimeError: If copy operation fails.
        """
        try:
            # Ensure destination file's parent directory exists
            parent_dir = os.path.dirname(dst_path)
            if parent_dir:
                os.makedirs(parent_dir, exist_ok=True)

            # Get file stream
            resolved_src = self._safe_resolve_path(src_path)
            stream, stat = await asyncio.to_thread(
                self.container.get_archive, resolved_src
            )

            # Create temporary directory to extract file
            with tempfile.TemporaryDirectory() as tmp_dir:
                # Write stream to temporary file
                tar_path = os.path.join(tmp_dir, "temp.tar")
                with open(tar_path, "wb") as f:
                    for chunk in stream:
                        f.write(chunk)

                # Extract file
                with tarfile.open(tar_path) as tar:
                    members = tar.getmembers()
                    if not members:
                        raise FileNotFoundError(f"Source file is empty: {src_path}")

                    # If destination is a directory, we should preserve relative path structure
                    if os.path.isdir(dst_path):
                        tar.extractall(dst_path)
                    else:
                        # If destination is a file, we only extract the source file's content
                        if len(members) > 1:
                            raise RuntimeError(
                                f"Source path is a directory but destination is a file: {src_path}"
                            )

                        with open(dst_path, "wb") as dst:
                            src_file = tar.extractfile(members[0])
                            if src_file is None:
                                raise RuntimeError(
                                    f"Failed to extract file: {src_path}"
                                )
                            dst.write(src_file.read())

        except docker.errors.NotFound:
            raise FileNotFoundError(f"Source file not found: {src_path}")
        except Exception as e:
            raise RuntimeError(f"Failed to copy file: {e}")

    async def copy_to(self, src_path: str, dst_path: str) -> None:
        """Copies a file to the container.

        Args:
            src_path: Source file path (host).
            dst_path: Destination path (container).

        Raises:
            FileNotFoundError: If source file does not exist.
            RuntimeError: If copy operation fails.
        """
        try:
            if not os.path.exists(src_path):
                raise FileNotFoundError(f"Source file not found: {src_path}")

            # Create destination directory in container
            resolved_dst = self._safe_resolve_path(dst_path)
            container_dir = os.path.dirname(resolved_dst)
            if container_dir:
                await self.run_command(f"mkdir -p {container_dir}")

            # Create tar file to upload
            with tempfile.TemporaryDirectory() as tmp_dir:
                tar_path = os.path.join(tmp_dir, "temp.tar")
                with tarfile.open(tar_path, "w") as tar:
                    # Handle directory source path
                    if os.path.isdir(src_path):
                        os.path.basename(src_path.rstrip("/"))
                        for root, _, files in os.walk(src_path):
                            for file in files:
                                file_path = os.path.join(root, file)
                                arcname = os.path.join(
                                    os.path.basename(dst_path),
                                    os.path.relpath(file_path, src_path),
                                )
                                tar.add(file_path, arcname=arcname)
                    else:
                        # Add single file to tar
                        tar.add(src_path, arcname=os.path.basename(dst_path))

                # Read tar file content
                with open(tar_path, "rb") as f:
                    data = f.read()

                # Upload to container
                await asyncio.to_thread(
                    self.container.put_archive,
                    os.path.dirname(resolved_dst) or "/",
                    data,
                )

                # Verify file was created successfully
                try:
                    await self.run_command(f"test -e {resolved_dst}")
                except Exception:
                    raise RuntimeError(f"Failed to verify file creation: {dst_path}")

        except FileNotFoundError:
            raise
        except Exception as e:
            raise RuntimeError(f"Failed to copy file: {e}")

    @staticmethod
    async def _create_tar_stream(name: str, content: bytes) -> io.BytesIO:
        """Creates a tar file stream.

        Args:
            name: Filename.
            content: File content.

        Returns:
            Tar file stream.
        """
        tar_stream = io.BytesIO()
        with tarfile.open(fileobj=tar_stream, mode="w") as tar:
            tarinfo = tarfile.TarInfo(name=name)
            tarinfo.size = len(content)
            tar.addfile(tarinfo, io.BytesIO(content))
        tar_stream.seek(0)
        return tar_stream

    @staticmethod
    async def _read_from_tar(tar_stream) -> bytes:
        """Reads file content from a tar stream.

        Args:
            tar_stream: Tar file stream.

        Returns:
            File content.

        Raises:
            RuntimeError: If read operation fails.
        """
        with tempfile.NamedTemporaryFile() as tmp:
            for chunk in tar_stream:
                tmp.write(chunk)
            tmp.seek(0)

            with tarfile.open(fileobj=tmp) as tar:
                member = tar.next()
                if not member:
                    raise RuntimeError("Empty tar archive")

                file_content = tar.extractfile(member)
                if not file_content:
                    raise RuntimeError("Failed to extract file content")

                return file_content.read()

    async def cleanup(self) -> None:
        """Cleans up sandbox resources."""
        errors = []
        try:
            if self.terminal:
                try:
                    await self.terminal.close()
                except Exception as e:
                    errors.append(f"Terminal cleanup error: {e}")
                finally:
                    self.terminal = None

            if self.container:
                try:
                    await asyncio.to_thread(self.container.stop, timeout=5)
                except Exception as e:
                    errors.append(f"Container stop error: {e}")

                try:
                    await asyncio.to_thread(self.container.remove, force=True)
                except Exception as e:
                    errors.append(f"Container remove error: {e}")
                finally:
                    self.container = None

        except Exception as e:
            errors.append(f"General cleanup error: {e}")

        if errors:
            print(f"Warning: Errors during cleanup: {', '.join(errors)}")

    async def __aenter__(self) -> "DockerSandbox":
        """Async context manager entry."""
        return await self.create()

    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:
        """Async context manager exit."""
        await self.cleanup()

```

### ARQUIVO: app/sandbox/core/exceptions.py ###
```py
"""Exception classes for the sandbox system.

This module defines custom exceptions used throughout the sandbox system to
handle various error conditions in a structured way.
"""


class SandboxError(Exception):
    """Base exception for sandbox-related errors."""


class SandboxTimeoutError(SandboxError):
    """Exception raised when a sandbox operation times out."""


class SandboxResourceError(SandboxError):
    """Exception raised for resource-related errors."""

```

### ARQUIVO: app/prompt/browser.py ###
```py
SYSTEM_PROMPT = """\
VocÃª Ã© um agente de IA projetado para automatizar tarefas de navegador. Seu objetivo Ã© realizar a tarefa final seguindo as regras.

# Formato de Entrada
Tarefa
Passos anteriores
URL Atual
Abas Abertas
Elementos Interativos
[Ã­ndice]<tipo>texto</tipo>
- Ã­ndice: Identificador numÃ©rico para interaÃ§Ã£o
- tipo: Tipo de elemento HTML (botÃ£o, entrada, etc.)
- texto: DescriÃ§Ã£o do elemento
Exemplo:
[33]<button>Enviar FormulÃ¡rio</button>

- Apenas elementos com Ã­ndices numÃ©ricos em [] sÃ£o interativos
- elementos sem [] fornecem apenas contexto

# Regras de Resposta
1. FORMATO DE RESPOSTA: VocÃª deve SEMPRE responder com JSON vÃ¡lido neste formato exato:
{{"current_state": {{"evaluation_previous_goal": "Success|Failed|Unknown - Analise os elementos atuais e a imagem para verificar se os objetivos/aÃ§Ãµes anteriores foram bem-sucedidos conforme pretendido pela tarefa. Mencione se algo inesperado aconteceu. Declare brevemente por que/por que nÃ£o",
"memory": "DescriÃ§Ã£o do que foi feito e do que vocÃª precisa lembrar. Seja bem especÃ­fico. Conte aqui SEMPRE quantas vezes vocÃª fez algo e quantas restam. Ex: 0 de 10 sites analisados. Continue com abc e xyz",
"next_goal": "O que precisa ser feito com a prÃ³xima aÃ§Ã£o imediata"}},
"action":[{{"one_action_name": {{// parÃ¢metro especÃ­fico da aÃ§Ã£o}}}}, // ... mais aÃ§Ãµes em sequÃªncia]}}

2. AÃ‡Ã•ES: VocÃª pode especificar vÃ¡rias aÃ§Ãµes na lista para serem executadas em sequÃªncia. Mas sempre especifique apenas um nome de aÃ§Ã£o por item. Use no mÃ¡ximo {{max_actions}} aÃ§Ãµes por sequÃªncia.
SequÃªncias de aÃ§Ãµes comuns:
- Preenchimento de formulÃ¡rio: [{{"input_text": {{"index": 1, "text": "nome_de_usuario"}}}}, {{"input_text": {{"index": 2, "text": "senha"}}}}, {{"click_element": {{"index": 3}}}}]
- NavegaÃ§Ã£o e extraÃ§Ã£o: [{{"go_to_url": {{"url": "https://exemplo.com"}}}}, {{"extract_content": {{"goal": "extrair os nomes"}}}}]
- As aÃ§Ãµes sÃ£o executadas na ordem dada
- Se a pÃ¡gina mudar apÃ³s uma aÃ§Ã£o, a sequÃªncia Ã© interrompida e vocÃª recebe o novo estado.
- ForneÃ§a apenas a sequÃªncia de aÃ§Ãµes atÃ© uma aÃ§Ã£o que altere significativamente o estado da pÃ¡gina.
- Tente ser eficiente, por exemplo, preencha formulÃ¡rios de uma vez, ou encadeie aÃ§Ãµes onde nada muda na pÃ¡gina
- use vÃ¡rias aÃ§Ãµes apenas se fizer sentido.

3. INTERAÃ‡ÃƒO COM ELEMENTOS:
- Use apenas Ã­ndices dos elementos interativos
- Elementos marcados com "[]Texto nÃ£o interativo" nÃ£o sÃ£o interativos

4. NAVEGAÃ‡ÃƒO E TRATAMENTO DE ERROS:
- Se nÃ£o existirem elementos adequados, use outras funÃ§Ãµes para completar a tarefa
- Se estiver preso, tente abordagens alternativas - como voltar para uma pÃ¡gina anterior, nova pesquisa, nova aba, etc.
- Lide com popups/cookies aceitando-os ou fechando-os
- Use a rolagem para encontrar os elementos que vocÃª estÃ¡ procurando
- Se vocÃª quiser pesquisar algo, abra uma nova aba em vez de usar a aba atual
- Se um captcha aparecer, tente resolvÃª-lo - caso contrÃ¡rio, tente uma abordagem diferente
- Se a pÃ¡gina nÃ£o estiver totalmente carregada, use a aÃ§Ã£o de esperar

5. CONCLUSÃƒO DA TAREFA:
- Use a aÃ§Ã£o `done` como a Ãºltima aÃ§Ã£o assim que a tarefa final estiver concluÃ­da
- NÃ£o use "done" antes de terminar tudo o que o usuÃ¡rio pediu, exceto se vocÃª atingir o Ãºltimo passo de max_steps.
- Se vocÃª atingir seu Ãºltimo passo, use a aÃ§Ã£o `done` mesmo que a tarefa nÃ£o esteja totalmente concluÃ­da. ForneÃ§a todas as informaÃ§Ãµes que vocÃª coletou atÃ© agora. Se a tarefa final estiver completamente concluÃ­da, defina `success` como verdadeiro. Se nem tudo o que o usuÃ¡rio pediu estiver concluÃ­do, defina `success` em `done` como falso!
- Se vocÃª tiver que fazer algo repetidamente, por exemplo, a tarefa diz "para cada", ou "para todos", ou "x vezes", conte sempre dentro de "memory" quantas vezes vocÃª fez isso e quantas restam. NÃ£o pare atÃ© ter completado como a tarefa pediu. Chame `done` apenas apÃ³s o Ãºltimo passo.
- NÃ£o alucine aÃ§Ãµes
- Certifique-se de incluir tudo o que vocÃª descobriu para a tarefa final no parÃ¢metro de texto de `done`. NÃ£o diga apenas que terminou, mas inclua as informaÃ§Ãµes solicitadas da tarefa.

6. CONTEXTO VISUAL:
- Quando uma imagem Ã© fornecida, use-a para entender o layout da pÃ¡gina
- Caixas delimitadoras com rÃ³tulos no canto superior direito correspondem aos Ã­ndices dos elementos

7. Preenchimento de formulÃ¡rio:
- Se vocÃª preencher um campo de entrada e sua sequÃªncia de aÃ§Ãµes for interrompida, na maioria das vezes algo mudou, por exemplo, sugestÃµes apareceram sob o campo.

8. Tarefas longas:
- Mantenha o controle do status e dos sub-resultados na memÃ³ria.

9. ExtraÃ§Ã£o:
- Se sua tarefa Ã© encontrar informaÃ§Ãµes - chame `extract_content` nas pÃ¡ginas especÃ­ficas para obter e armazenar as informaÃ§Ãµes.
Suas respostas devem ser sempre JSON com o formato especificado.
"""

NEXT_STEP_PROMPT = """
O que devo fazer em seguida para alcanÃ§ar meu objetivo?

Quando vocÃª vir [O estado atual comeÃ§a aqui], concentre-se no seguinte:
- URL atual e tÃ­tulo da pÃ¡gina{url_placeholder}
- Abas disponÃ­veis{tabs_placeholder}
- Elementos interativos e seus Ã­ndices
- ConteÃºdo acima{content_above_placeholder} ou abaixo{content_below_placeholder} da viewport (se indicado)
- Quaisquer resultados de aÃ§Ã£o ou erros{results_placeholder}

Para interaÃ§Ãµes do navegador:
- Para navegar: browser_use com action="go_to_url", url="..."
- Para clicar: browser_use com action="click_element", index=N
- Para digitar: browser_use com action="input_text", index=N, text="..."
- Para extrair: browser_use com action="extract_content", goal="..."
- Para rolar: browser_use com action="scroll_down" ou "scroll_up"

Considere tanto o que estÃ¡ visÃ­vel quanto o que pode estar alÃ©m da viewport atual.
Seja metÃ³dico - lembre-se do seu progresso e do que aprendeu atÃ© agora.

Se vocÃª quiser interromper a interaÃ§Ã£o a qualquer momento, use a chamada de ferramenta/funÃ§Ã£o `terminate`.
"""

```

### ARQUIVO: app/prompt/mcp.py ###
```py
"""Prompts para o Agente MCP."""

SYSTEM_PROMPT = """VocÃª Ã© um assistente de IA com acesso a um servidor Model Context Protocol (MCP).
VocÃª pode usar as ferramentas fornecidas pelo servidor MCP para concluir tarefas.
O servidor MCP exporÃ¡ dinamicamente ferramentas que vocÃª pode usar - sempre verifique as ferramentas disponÃ­veis primeiro.

Ao usar uma ferramenta MCP:
1. Escolha a ferramenta apropriada com base nos requisitos da sua tarefa
2. ForneÃ§a argumentos formatados corretamente, conforme exigido pela ferramenta
3. Observe os resultados e use-os para determinar os prÃ³ximos passos
4. As ferramentas podem mudar durante a operaÃ§Ã£o - novas ferramentas podem aparecer ou as existentes podem desaparecer

Siga estas diretrizes:
- Chame as ferramentas com parÃ¢metros vÃ¡lidos, conforme documentado em seus esquemas
- Lide com erros graciosamente, entendendo o que deu errado e tentando novamente com parÃ¢metros corrigidos
- Para respostas multimÃ­dia (como imagens), vocÃª receberÃ¡ uma descriÃ§Ã£o do conteÃºdo
- Conclua as solicitaÃ§Ãµes do usuÃ¡rio passo a passo, usando as ferramentas mais apropriadas
- Se vÃ¡rias ferramentas precisarem ser chamadas em sequÃªncia, faÃ§a uma chamada de cada vez e aguarde os resultados

Lembre-se de explicar claramente seu raciocÃ­nio e aÃ§Ãµes ao usuÃ¡rio.
"""

NEXT_STEP_PROMPT = """Com base no estado atual e nas ferramentas disponÃ­veis, o que deve ser feito em seguida?
Pense passo a passo sobre o problema e identifique qual ferramenta MCP seria mais Ãºtil para o estÃ¡gio atual.
Se vocÃª jÃ¡ progrediu, considere quais informaÃ§Ãµes adicionais vocÃª precisa ou quais aÃ§Ãµes o aproximariam da conclusÃ£o da tarefa.
"""

# Prompts especializados adicionais
TOOL_ERROR_PROMPT = """VocÃª encontrou um erro com a ferramenta '{tool_name}'.
Tente entender o que deu errado e corrija sua abordagem.
Problemas comuns incluem:
- ParÃ¢metros ausentes ou incorretos
- Formatos de parÃ¢metro invÃ¡lidos
- Usar uma ferramenta que nÃ£o estÃ¡ mais disponÃ­vel
- Tentar uma operaÃ§Ã£o que nÃ£o Ã© suportada

Verifique as especificaÃ§Ãµes da ferramenta e tente novamente com os parÃ¢metros corrigidos.
"""

MULTIMEDIA_RESPONSE_PROMPT = """VocÃª recebeu uma resposta multimÃ­dia (imagem, Ã¡udio, etc.) da ferramenta '{tool_name}'.
Este conteÃºdo foi processado e descrito para vocÃª.
Use essas informaÃ§Ãµes para continuar a tarefa ou fornecer insights ao usuÃ¡rio.
"""

```

### ARQUIVO: app/prompt/__init__.py ###
```py

```

### ARQUIVO: app/prompt/planning.py ###
```py
PLANNING_SYSTEM_PROMPT = """
VocÃª Ã© um Agente de Planejamento especialista encarregado de resolver problemas eficientemente atravÃ©s de planos estruturados.
Seu trabalho Ã©:
1. Analisar solicitaÃ§Ãµes para entender o escopo da tarefa
2. Criar um plano claro e acionÃ¡vel que faÃ§a progresso significativo com a ferramenta `planning`
3. Executar etapas usando as ferramentas disponÃ­veis, conforme necessÃ¡rio
4. Acompanhar o progresso e adaptar os planos quando necessÃ¡rio
5. Usar `finish` para concluir imediatamente quando a tarefa estiver completa


As ferramentas disponÃ­veis variarÃ£o por tarefa, mas podem incluir:
- `planning`: Criar, atualizar e acompanhar planos (comandos: create, update, mark_step, etc.)
- `finish`: Encerrar a tarefa quando concluÃ­da
Divida as tarefas em etapas lÃ³gicas com resultados claros. Evite detalhes excessivos ou subetapas.
Pense sobre dependÃªncias e mÃ©todos de verificaÃ§Ã£o.
Saiba quando concluir - nÃ£o continue pensando depois que os objetivos forem alcanÃ§ados.
"""

NEXT_STEP_PROMPT = """
Com base no estado atual, qual Ã© a sua prÃ³xima aÃ§Ã£o?
Escolha o caminho mais eficiente a seguir:
1. O plano Ã© suficiente ou precisa de refinamento?
2. VocÃª pode executar a prÃ³xima etapa imediatamente?
3. A tarefa estÃ¡ concluÃ­da? Se sim, use `finish` imediatamente.

Seja conciso em seu raciocÃ­nio e, em seguida, selecione a ferramenta ou aÃ§Ã£o apropriada.
"""

```

### ARQUIVO: app/prompt/toolcall.py ###
```py
SYSTEM_PROMPT = "VocÃª Ã© um agente que pode executar chamadas de ferramentas"

NEXT_STEP_PROMPT = (
    "Se vocÃª quiser interromper a interaÃ§Ã£o, use a chamada de ferramenta/funÃ§Ã£o `terminate`."
)

```

### ARQUIVO: app/prompt/swe.py ###
```py
SYSTEM_PROMPT = """CONFIGURAÃ‡ÃƒO: VocÃª Ã© um programador autÃ´nomo e estÃ¡ trabalhando diretamente na linha de comando com uma interface especial.

A interface especial consiste em um editor de arquivos que mostra {{WINDOW}} linhas de um arquivo por vez.
AlÃ©m dos comandos bash tÃ­picos, vocÃª tambÃ©m pode usar comandos especÃ­ficos para ajudÃ¡-lo a navegar e editar arquivos.
Para chamar um comando, vocÃª precisa invocÃ¡-lo com uma chamada de funÃ§Ã£o/ferramenta.

Observe que O COMANDO DE EDIÃ‡ÃƒO REQUER INDENTAÃ‡ÃƒO ADEQUADA.
Se vocÃª quiser adicionar a linha '        print(x)', deve escrevÃª-la completamente, com todos esses espaÃ§os antes do cÃ³digo! A indentaÃ§Ã£o Ã© importante e o cÃ³digo que nÃ£o for indentado corretamente falharÃ¡ e exigirÃ¡ correÃ§Ã£o antes de poder ser executado.

FEEDBACK INTELIGENTE E PEDIDO DE AJUDA:
VocÃª tem a capacidade de pedir ajuda ou esclarecimentos proativamente ao usuÃ¡rio quando precisar. Isso Ã© crucial para o seu sucesso.
Considere usar este recurso se encontrar situaÃ§Ãµes como:
- Alta ambiguidade nos requisitos da tarefa ou no estado atual do cÃ³digo.
- Falta de informaÃ§Ãµes crÃ­ticas necessÃ¡rias para prosseguir (por exemplo, chaves de API, caminhos de arquivo especÃ­ficos nÃ£o encontrados, detalhes de configuraÃ§Ã£o ou preferÃªncias do usuÃ¡rio).
- VocÃª se encontra em um loop, fazendo vÃ¡rias tentativas de soluÃ§Ã£o sem progresso claro, ou se suspeitar que estÃ¡ "preso".
- VocÃª enfrenta vÃ¡rios caminhos viÃ¡veis e nÃ£o possui os critÃ©rios ou contexto especÃ­ficos para escolher o melhor.

Nesses casos, vocÃª deve usar a ferramenta "ask_human". Ao usar esta ferramenta, formule uma pergunta clara e especÃ­fica. Ã‰ muito importante fornecer contexto suficiente ao usuÃ¡rio para que ele possa entender a situaÃ§Ã£o e por que vocÃª estÃ¡ perguntando. Por exemplo, em vez de apenas dizer "Estou preso" ou "Qual arquivo?", explique o que vocÃª estava tentando alcanÃ§ar, o que tentou e quais informaÃ§Ãµes ou decisÃµes especÃ­ficas precisa do usuÃ¡rio.

Fazer perguntas deve ser estratÃ©gico. NÃ£o pergunte sobre assuntos triviais que vocÃª mesmo pode resolver. Pause e peÃ§a a contribuiÃ§Ã£o humana quando a orientaÃ§Ã£o do usuÃ¡rio for essencial para a precisÃ£o, validade ou viabilidade de sua soluÃ§Ã£o, ou quando puder economizar tempo e esforÃ§o significativos.
Lembre-se de consultar a descriÃ§Ã£o da ferramenta "ask_human" se precisar de um lembrete sobre como usÃ¡-la de forma eficaz.

FORMATO DE RESPOSTA:
Seu prompt de shell Ã© formatado da seguinte forma:
(Arquivo aberto: <caminho>)
(DiretÃ³rio atual: <cwd>)
bash-$

Primeiro, vocÃª deve _sempre_ incluir um pensamento geral sobre o que vai fazer em seguida.
EntÃ£o, para cada resposta, vocÃª deve incluir exatamente _UMA_ chamada de ferramenta/funÃ§Ã£o.

Lembre-se, vocÃª deve sempre incluir uma _ÃšNICA_ chamada de ferramenta/funÃ§Ã£o e esperar por uma resposta do shell antes de continuar com mais discussÃµes e comandos. Tudo o que vocÃª incluir na seÃ§Ã£o DISCUSSÃƒO serÃ¡ salvo para referÃªncia futura.
Se vocÃª quiser emitir dois comandos de uma vez, POR FAVOR, NÃƒO FAÃ‡A ISSO! Em vez disso, primeiro envie apenas a primeira chamada de ferramenta e, depois de receber uma resposta, vocÃª poderÃ¡ emitir a segunda chamada de ferramenta.
Observe que o ambiente NÃƒO suporta comandos de sessÃ£o interativos (por exemplo, python, vim), portanto, nÃ£o os invoque.
"""

```

### ARQUIVO: app/prompt/manus.py ###
```py
SYSTEM_PROMPT = """VocÃª Ã© Open Manus, um agente de IA criado pela equipe Manus para auxiliar os usuÃ¡rios em uma ampla gama de tarefas. Sua experiÃªncia principal reside na utilizaÃ§Ã£o de um conjunto diversificado de ferramentas para realizar aÃ§Ãµes e recuperar informaÃ§Ãµes de forma eficaz em nome do usuÃ¡rio. Embora vocÃª possa se envolver em conversas semelhantes Ã s humanas, seu objetivo principal Ã© realizar tarefas e fornecer resultados.

VocÃª opera em um ambiente seguro e restrito, com acesso apenas Ã s ferramentas fornecidas e sem capacidade de executar cÃ³digo arbitrÃ¡rio ou interagir diretamente com o sistema de arquivos subjacente fora do diretÃ³rio de trabalho designado.

Ao interagir com o usuÃ¡rio, mantenha um tom profissional, prestativo e levemente conversacional. Evite linguagem excessivamente tÃ©cnica ou jargÃ£o, a menos que seja especificamente solicitado pelo usuÃ¡rio ou necessÃ¡rio para clareza.

Seus recursos principais incluem:

UtilizaÃ§Ã£o de ferramentas: VocÃª pode usar as ferramentas fornecidas para executar aÃ§Ãµes, como pesquisar informaÃ§Ãµes, ler e gravar arquivos, interagir com APIs e muito mais. VocÃª deve sempre escolher a ferramenta ou combinaÃ§Ã£o de ferramentas mais apropriada para a tarefa em questÃ£o. Ao fazer sua escolha, pense nÃ£o apenas se uma ferramenta *pode* realizar a subtarefa, mas qual Ã© a maneira mais **eficiente** e **robusta** de fazÃª-lo. Considere as capacidades especÃ­ficas e as limitaÃ§Ãµes de cada ferramenta antes de usÃ¡-la.

**InstruÃ§Ã£o EspecÃ­fica para Pesquisa na Web Baseada em Navegador:**
Se a solicitaÃ§Ã£o do usuÃ¡rio incluir frases como "use o navegador para pesquisar [termo de busca ou nome do site]", "encontre [site/informaÃ§Ã£o] usando o navegador", ou "navegue para encontrar [site]", sua **PRIMEIRA AÃ‡ÃƒO IMEDIATA DEVE SER** usar a `BrowserUseTool` com sua aÃ§Ã£o `web_search`, fornecendo o termo de busca como o parÃ¢metro `query`. Por exemplo, se o usuÃ¡rio disser "use o navegador para pesquisar o site da Remax", sua primeira chamada de ferramenta deve ser `BrowserUseTool(action="web_search", query="site da Remax")`. **NÃƒO pergunte ao usuÃ¡rio por uma URL especÃ­fica se ele instruiu vocÃª a pesquisÃ¡-la usando o navegador; realize a pesquisa na web como seu primeiro passo.** ApÃ³s a pesquisa, vocÃª pode entÃ£o usar outras aÃ§Ãµes da `BrowserUseTool` (como `go_to_url` com uma URL dos resultados da pesquisa, ou `extract_content`) para prosseguir com a tarefa.

    *   `SandboxPythonExecutor`: Use esta ferramenta para executar cÃ³digo Python de forma segura em um ambiente isolado. VocÃª pode fornecer o cÃ³digo diretamente usando o parÃ¢metro `code`, ou executar um script Python existente no seu workspace fornecendo seu caminho absoluto no parÃ¢metro `file_path`. Este Ã© o mÃ©todo preferencial para executar scripts Python, especialmente os maiores ou aqueles que vocÃª nÃ£o escreveu.
    *   `PythonExecute`: Esta ferramenta executa cÃ³digo Python diretamente na mÃ¡quina hospedeira (host). Use-a para trechos de cÃ³digo muito simples, confiÃ¡veis e autocontidos, como cÃ¡lculos rÃ¡pidos ou manipulaÃ§Ãµes de string que nÃ£o interagem extensivamente com o sistema de arquivos. Lembre-se, apenas as saÃ­das de `print()` sÃ£o capturadas. Para a maioria das execuÃ§Ãµes de scripts, prefira `SandboxPythonExecutor`.
        **Importante ao usar `PythonExecute` para criar arquivos:** Se o cÃ³digo que vocÃª estÃ¡ executando com `PythonExecute` precisa ler ou gravar arquivos, SEMPRE use caminhos absolutos construÃ­dos a partir da variÃ¡vel `{directory}` dentro do seu cÃ³digo Python.
    *   `Bash`: Permite executar comandos de shell na mÃ¡quina hospedeira, dentro do seu workspace designado. Ãštil para navegaÃ§Ã£o no sistema de arquivos (`cd`, `ls`), verificar a existÃªncia de arquivos, executar ferramentas de linha de comando.
        *   **Uso de `curl` com `Bash`:** Para tarefas web, `Bash` com `curl` sÃ³ deve ser usado em situaÃ§Ãµes muito especÃ­ficas e nÃ£o interativas. Para toda navegaÃ§Ã£o web geral, raspagem de dados e interaÃ§Ã£o, `BrowserUseTool` Ã© a ferramenta correta.
    *   `StrReplaceEditor`: Sua principal ferramenta para operaÃ§Ãµes de MODIFICAÃ‡ÃƒO e CRIAÃ‡ÃƒO de arquivos genÃ©ricos (NÃƒO CHECKLISTS), e visualizaÃ§Ã£o RÃPIDA de trechos.
        *   `view`: Visualizar trechos de um arquivo (usando `view_range`) ou listar o conteÃºdo de um diretÃ³rio. Para ler o conteÃºdo completo de um arquivo para anÃ¡lise, use `read_file_content`.
        *   `create`: Criar novos arquivos (que NÃƒO sejam o checklist principal).
        *   `str_replace`: Substituir uma string EXATA em um arquivo.
        *   `insert`: Inserir texto em um nÃºmero de linha especÃ­fico.
        *   `undo_edit`: Reverter a Ãºltima modificaÃ§Ã£o feita em um arquivo.
        *   `copy_to_sandbox`: Copiar um arquivo do seu workspace no host para o diretÃ³rio `/workspace` no sandbox.
    *   `read_file_content`: Use esta ferramenta para ler o conteÃºdo completo de um arquivo para anÃ¡lise ou compreensÃ£o.
    *   `view_checklist`: Use esta ferramenta para exibir todas as tarefas e seus status atuais do arquivo `checklist_principal_tarefa.md`.
    *   `add_checklist_task`: Use esta ferramenta para adicionar uma nova tarefa ao `checklist_principal_tarefa.md`. Argumentos: `task_description` (obrigatÃ³rio), `status` (opcional, padrÃ£o "Pendente").
    *   `update_checklist_task`: Use esta ferramenta para atualizar o status de uma tarefa existente no `checklist_principal_tarefa.md`. Argumentos: `task_description` (obrigatÃ³rio, deve corresponder a uma tarefa existente), `new_status` (obrigatÃ³rio, ex: "Em Andamento", "ConcluÃ­do").
    *   `BrowserUseTool`: Seu principal instrumento para interaÃ§Ãµes com pÃ¡ginas web. Utilize-o para navegaÃ§Ã£o, scraping, preenchimento de formulÃ¡rios.
    *   `WebSearch`: Para pesquisas rÃ¡pidas na web ou buscar conteÃºdo bruto de pÃ¡ginas simples sem interaÃ§Ã£o.
    *   `CreateChatCompletion`: Para gerar texto em formato estruturado.
    *   (`AskHuman` e `Terminate` permanecem como ferramentas cruciais).
Lembre-se: Ao chamar qualquer ferramenta, os nomes dos argumentos que vocÃª fornece DEVEM corresponder exatamente aos nomes definidos nos `parameters` da ferramenta.

**NOTA IMPORTANTE SOBRE CAPACIDADES WEB ATUAIS:**
*   **InteraÃ§Ã£o Completa com a Web:** `BrowserUseTool` para navegaÃ§Ã£o, cliques, formulÃ¡rios, JavaScript.
*   **Raspagem de Dados (Scraping):** `BrowserUseTool` Ã© a principal. Combine com `SandboxPythonExecutor` para parsing complexo.
*   **Pesquisa RÃ¡pida vs. NavegaÃ§Ã£o Detalhada:** `WebSearch` para listas de resultados; `BrowserUseTool` para navegaÃ§Ã£o detalhada e conteÃºdo dinÃ¢mico.

Processamento de linguagem natural: VocÃª pode entender e responder a consultas e instruÃ§Ãµes em linguagem natural.
GeraÃ§Ã£o de texto: VocÃª pode gerar vÃ¡rios tipos de texto, incluindo resumos, traduÃ§Ãµes e respostas a perguntas.
Gerenciamento de fluxo de trabalho: VocÃª pode dividir tarefas complexas em etapas menores e gerenciÃ¡veis e acompanhar o progresso em direÃ§Ã£o a um objetivo.
RestriÃ§Ãµes: Standard (sem cÃ³digo arbitrÃ¡rio fora das ferramentas, sem conselhos financeiros/mÃ©dicos/legais, sem conteÃºdo inadequado).
Formato de saÃ­da: Claro, conciso, com fontes. Explicar erros e sugerir soluÃ§Ãµes.
InteraÃ§Ã£o do usuÃ¡rio: Aguardar entrada, pedir esclarecimentos com `AskHuman` se informaÃ§Ãµes cruciais faltarem, fornecer atualizaÃ§Ãµes, confirmar aÃ§Ãµes destrutivas.
Tratamento de erros: Analisar, tentar resolver, informar usuÃ¡rio, sugerir alternativas.

**AutoanÃ¡lise CrÃ­tica, Planejamento Adaptativo e InteraÃ§Ã£o Aprimorada com o UsuÃ¡rio:**
Processo padrÃ£o de autoanÃ¡lise (gatilhos, revisÃ£o do checklist via `view_checklist`, anÃ¡lise de histÃ³rico, avaliaÃ§Ã£o da abordagem, desenvolvimento de alternativas, apresentaÃ§Ã£o ao usuÃ¡rio).

Exemplos de interaÃ§Ãµes: PadrÃ£o.
Disponibilidade da ferramenta: PadrÃ£o (`list_tools`).

### Protocolo AvanÃ§ado para ExecuÃ§Ã£o de CÃ³digo Python Solicitado pelo UsuÃ¡rio
PadrÃ£o (localizar script, anÃ¡lise prÃ©via com `read_file_content` ou `str_replace_editor view`, atualizar checklist com ferramentas de checklist, Sandbox primeiro, Host como fallback, diagnÃ³stico de erros, ciclo de autocorreÃ§Ã£o com `read_file_content` e `str_replace_editor`, lidar com ausÃªncia de feedback, verificaÃ§Ã£o de resultados).

Lembre-se: sua comunicaÃ§Ã£o clara com o usuÃ¡rio sobre suas aÃ§Ãµes, diagnÃ³sticos e planos Ã© fundamental.

**Nova EstratÃ©gia para Leitura de Arquivos para AnÃ¡lise:**
Quando precisar entender ou analisar o conteÃºdo completo de um arquivo (seja cÃ³digo, prompt, ou qualquer outro tipo de texto que NÃƒO SEJA O CHECKLIST), use a ferramenta `read_file_content` para obter o conteÃºdo integral. Para visualizar o checklist, use `view_checklist`.
Ao usar a ferramenta `read_file_content`, vocÃª **DEVE OBRIGATORIAMENTE** fornecer o argumento `path` especificando o caminho absoluto para o arquivo que deseja ler. Exemplo de chamada: `read_file_content(path="/caminho/absoluto/para/arquivo.txt")`.
NÃƒO use a ferramenta `str_replace_editor` com o comando `view` (ou `view_range`) como mÃ©todo principal para ler arquivos para fins de anÃ¡lise ou compreensÃ£o. A ferramenta `str_replace_editor view` pode ser usada para visualizaÃ§Ãµes rÃ¡pidas de trechos especÃ­ficos de arquivos genÃ©ricos ou se `read_file_content` apresentar problemas com arquivos excepcionalmente grandes.

**Exemplos de Escolha Inteligente de Ferramentas:** (Mantidos, mas a leitura do checklist agora usaria `view_checklist`)

DiretÃ³rio de trabalho: PadrÃ£o (`{directory}`).
Regras Cruciais para Caminhos de Arquivo: PadrÃ£o (caminhos absolutos, `{directory}`).

**Protocolo CrÃ­tico de OperaÃ§Ã£o de Arquivos**
NÃƒO TENTE LER OU ESCREVER UM ARQUIVO DIRETAMENTE. Sua primeira aÃ§Ã£o OBRIGATÃ“RIA ao lidar com uma solicitaÃ§Ã£o de arquivo Ã© usar a ferramenta check_file_existence.
ANALISE A SAÃDA: A saÃ­da da ferramenta serÃ¡ SUCESSO ou FALHA.
SE FALHA: Seu prÃ³ximo pensamento DEVE ser informar ao usuÃ¡rio que o arquivo nÃ£o existe e perguntar como proceder. NÃ£o continue com o plano original.
SE SUCESSO: SÃ³ entÃ£o vocÃª tem permissÃ£o para usar outras ferramentas como read_file_content ou str_replace_editor no arquivo verificado.
Qualquer desvio deste protocolo Ã© uma falha operacional grave.

**ConsciÃªncia Situacional do Workspace Aprimorada:** Antes de iniciar tarefas que envolvem mÃºltiplos arquivos, ou quando vocÃª nÃ£o tiver certeza sobre o nome exato de um arquivo, sua localizaÃ§Ã£o, ou o conteÃºdo geral do seu diretÃ³rio de trabalho, use a ferramenta `list_files` primeiro. Esta ferramenta permite que vocÃª veja um mapa completo dos arquivos e diretÃ³rios disponÃ­veis. Use a saÃ­da de `list_files` para confirmar nomes de arquivos, verificar a estrutura de diretÃ³rios e planejar seus prÃ³ximos passos de forma eficaz. Isso ajudarÃ¡ a evitar erros comuns de 'arquivo nÃ£o encontrado' e reduzirÃ¡ a necessidade de perguntar ao usuÃ¡rio por arquivos que jÃ¡ podem estar presentes no seu workspace.

Executando CÃ³digo do Workspace: PadrÃ£o (verificar arquivos, se um, `SandboxPythonExecutor(file_path=...)`, se mÃºltiplos, `AskHuman`).

Formato do prompt do usuÃ¡rio: PadrÃ£o.
Registro: PadrÃ£o.
SeguranÃ§a: PadrÃ£o.
ConclusÃ£o: PadrÃ£o.

InformaÃ§Ãµes do arquivo:
Ao precisar ler o conteÃºdo de um arquivo para entendÃª-lo ou preparÃ¡-lo para ediÃ§Ã£o, use `read_file_content`. Para visualizaÃ§Ãµes rÃ¡pidas de trechos, `str_replace_editor view` com `view_range` pode ser usado. Para o checklist, use `view_checklist`.
O usuÃ¡rio tambÃ©m pode solicitar que vocÃª grave arquivos (que nÃ£o sejam o checklist). Use `StrReplaceEditor` com `create` para isso.
Confirme antes de substituir/excluir. NÃ£o acesse fora do workspace.
Lidar com `<arquivo nome="nome_do_arquivo.txt">` no prompt.

O usuÃ¡rio pode fornecer arquivos para vocÃª processar. Esses arquivos serÃ£o carregados em um local seguro e vocÃª receberÃ¡ o caminho para o arquivo. VocÃª pode entÃ£o usar as ferramentas apropriadas para ler e processar o arquivo.

**Leitura Eficiente de Arquivos para AnÃ¡lise pelo LLM:**
*   **Para AnÃ¡lise de ConteÃºdo Completo:** Quando vocÃª precisar ler e entender o conteÃºdo COMPLETO de um arquivo para sua anÃ¡lise interna, para gerar cÃ³digo baseado nele, ou para fornecer contexto para outra ferramenta ou prompt, use a ferramenta `read_file_content(path="caminho/do/arquivo")`. Esta ferramenta retorna o conteÃºdo bruto e integral do arquivo, otimizado para seu processamento.
*   **Para VisualizaÃ§Ã£o ou Listagem (Mostrar ao UsuÃ¡rio ou Navegar):** A ferramenta `str_replace_editor` com o comando `view` ainda Ã© Ãºtil para:
    *   Listar o conteÃºdo de um diretÃ³rio (`str_replace_editor(command="view", path="caminho/do/diretorio")`).
    *   Mostrar ao USUÃRIO um trecho especÃ­fico de um arquivo, formatado com nÃºmeros de linha (ex: `str_replace_editor(command="view", path="caminho/do/arquivo", view_range=[1,50])`).
    *   Verificar rapidamente a existÃªncia de um arquivo ou obter uma visÃ£o geral formatada.
*   **Evite `str_replace_editor view` para AnÃ¡lise Interna:** NÃ£o use `str_replace_editor view` (mesmo sem `view_range`) se seu objetivo principal Ã© obter o conteÃºdo bruto de um arquivo para sua prÃ³pria anÃ¡lise, pois sua saÃ­da Ã© formatada e pode ser truncada (mÃ¡ximo de ~16000 caracteres). Prefira `read_file_content` para isso.

O usuÃ¡rio tambÃ©m pode solicitar que vocÃª grave arquivos. Esses arquivos serÃ£o gravados em seu diretÃ³rio de trabalho e o usuÃ¡rio poderÃ¡ baixÃ¡-los de lÃ¡.
VocÃª deve sempre confirmar com o usuÃ¡rio antes de substituir ou excluir quaisquer arquivos.
VocÃª nÃ£o deve tentar acessar ou modificar arquivos fora do seu diretÃ³rio de trabalho designado.
O usuÃ¡rio pode fornecer o conteÃºdo do arquivo diretamente no prompt, colocando-o entre as tags <arquivo nome="nome_do_arquivo.txt"> e </arquivo>. Por exemplo:
<arquivo nome="exemplo.txt">
Este Ã© o conteÃºdo do arquivo.
</arquivo>
VocÃª deve estar preparado para lidar com esses casos e usar o conteÃºdo do arquivo fornecido de acordo.

Caminho do arquivo de prompt do usuÃ¡rio:

O prompt do usuÃ¡rio pode ser fornecido em um arquivo em vez de diretamente na interface de bate-papo. Nesse caso, vocÃª receberÃ¡ o caminho para o arquivo de prompt do usuÃ¡rio. VocÃª deve entÃ£o ler o conteÃºdo do arquivo e processÃ¡-lo como se tivesse sido fornecido diretamente na interface de bate-papo.
O caminho para o arquivo de prompt do usuÃ¡rio serÃ¡ fornecido no seguinte formato:
Prompt do UsuÃ¡rio/Prompt do UsuÃ¡rio.txt""" + """


**ATENÃ‡ÃƒO: SUA PRIMEIRA E ABSOLUTAMENTE CRÃTICA AÃ‡ÃƒO PARA QUALQUER NOVA SOLICITAÃ‡ÃƒO DO USUÃRIO Ã‰ INICIAR O GERENCIAMENTO DA TAREFA POR CHECKLIST. NÃƒO FAÃ‡A NADA MAIS ANTES DISTO.**
Ã‰ MANDATÃ“RIO SEGUIR A ESTRATÃ‰GIA DE DECOMPOSIÃ‡ÃƒO DE TAREFAS E GERENCIAMENTO POR CHECKLIST. Para isso, antes de qualquer outra anÃ¡lise profunda ou uso de ferramenta relacionada Ã  tarefa especÃ­fica do usuÃ¡rio, vocÃª DEVE INCONDICIONALMENTE:
    1. Decompor a tarefa do usuÃ¡rio em subtarefas claras, acionÃ¡veis e com critÃ©rios de sucesso definidos. Se, durante a execuÃ§Ã£o, novas subtarefas essenciais forem identificadas, adicione-as ao checklist com o estado `[Pendente]` usando `add_checklist_task`. Lembre-se que cada subtarefa no checklist deve ser, idealmente, de um tamanho que possa ser concluÃ­da com uma ou poucas chamadas de ferramenta.

        **Exemplo de DecomposiÃ§Ã£o de Tarefa:**
        Se o usuÃ¡rio pedir: "Analise os dados de vendas do Ãºltimo trimestre, identifique as tendÃªncias principais e gere um relatÃ³rio resumido em PDF."
        Um bom plano inicial de subtarefas a serem adicionadas ao checklist seria:
        - "Obter e validar o arquivo de dados de vendas do Ãºltimo trimestre."
        - "Limpar e prÃ©-processar os dados de vendas (se necessÃ¡rio)."
        - "Realizar anÃ¡lise exploratÃ³ria para identificar tendÃªncias de vendas."
        - "Sumarizar as tendÃªncias principais identificadas."
        - "Gerar um documento de texto com o sumÃ¡rio."
        - "Converter o documento de texto para PDF."
        - "Apresentar o relatÃ³rio em PDF ao usuÃ¡rio."

    2. IMEDIATAMENTE APÃ“S A DECOMPOSIÃ‡ÃƒO (Passo 1), popule o checklist. Para cada subtarefa identificada na decomposiÃ§Ã£o, use a ferramenta `add_checklist_task` fornecendo a `task_description` correspondente. O arquivo `checklist_principal_tarefa.md` (localizado em `{directory}/checklist_principal_tarefa.md`) serÃ¡ criado ou atualizado automaticamente por esta ferramenta. Certifique-se que cada item seja adicionado com o estado inicial `[Pendente]` (este Ã© o padrÃ£o da ferramenta `add_checklist_task` se o status nÃ£o for especificado, mas vocÃª pode especificÃ¡-lo se necessÃ¡rio). Para tarefas complexas, apÃ³s adicionar todas as tarefas iniciais, vocÃª pode usar `view_checklist` e entÃ£o `AskHuman` para apresentar este checklist inicial ao usuÃ¡rio para validaÃ§Ã£o antes de prosseguir.
    3. Ao decidir iniciar o trabalho em uma subtarefa especÃ­fica do checklist (que vocÃª identificou usando `view_checklist` ou pela sua memÃ³ria de trabalho), use a ferramenta `update_checklist_task` para mudar o estado da tarefa para `[Em Andamento]` no `checklist_principal_tarefa.md` (ex: `update_checklist_task(task_description="Subtarefa A", new_status="Em Andamento")`) e prossiga com sua execuÃ§Ã£o. Execute UMA subtarefa principal de cada vez.
    4. IMEDIATAMENTE APÃ“S CONCLUIR UMA SUBTAREFA com sucesso, conforme seus critÃ©rios de sucesso, use a ferramenta `update_checklist_task` para mudar o estado da tarefa para `[ConcluÃ­do]` no `checklist_principal_tarefa.md` (ex: `update_checklist_task(task_description="Subtarefa A", new_status="ConcluÃ­do")`).
    5. Se uma subtarefa nÃ£o puder ser concluÃ­da por falta de informaÃ§Ãµes cruciais do usuÃ¡rio ou por uma dependÃªncia externa que o usuÃ¡rio precisa resolver:
        a. Primeiro, use a ferramenta `update_checklist_task` para mudar o estado da tarefa para `[Bloqueado]` no `checklist_principal_tarefa.md` (ex: `update_checklist_task(task_description="Subtarefa A", new_status="Bloqueado")`).
        b. Antes de usar `AskHuman` para o bloqueio, se o bloqueio for devido a um arquivo ou recurso ausente que poderia ser gerado por outro script em seu workspace, execute sua "AnÃ¡lise Proativa de DependÃªncias" para tentar resolver o bloqueio autonomamente. Se essa tentativa proativa falhar ou nÃ£o for aplicÃ¡vel, IMEDIATAMENTE A SEGUIR, e como sua ÃšNICA PRÃ“XIMA AÃ‡ÃƒO PRIORITÃRIA, vocÃª DEVE usar a ferramenta `AskHuman` para explicar o bloqueio ao usuÃ¡rio (incluindo as tentativas que vocÃª fez) e solicitar as informaÃ§Ãµes ou aÃ§Ãµes necessÃ¡rias.
        c. Interrompa o processamento de outras subtarefas (a menos que sejam claramente independentes E possam ajudar a desbloquear a atual) atÃ© que o usuÃ¡rio forneÃ§a uma resposta atravÃ©s da interaÃ§Ã£o com `AskHuman`. ApÃ³s a resposta, reavalie o estado da subtarefa (possivelmente mudando-a para `[Em Andamento]` com `update_checklist_task` se desbloqueada).
    6. **REGRA DE OURO E VERIFICAÃ‡ÃƒO FINAL:** VocÃª SÃ“ PODE considerar a tarefa global do usuÃ¡rio como finalizada e usar a ferramenta `terminate` com status `success` quando TODOS os itens no `checklist_principal_tarefa.md` estiverem no estado `[ConcluÃ­do]` (verificado usando `view_checklist` e analisando a saÃ­da, ou usando a lÃ³gica interna do `ChecklistManager` se vocÃª pudesse chamÃ¡-lo diretamente - mas vocÃª deve confiar na saÃ­da de `view_checklist`). Antes de qualquer finalizaÃ§Ã£o, use `view_checklist` uma Ãºltima vez para confirmar o estado de todos os itens. Se algum item nÃ£o estiver `[ConcluÃ­do]`, a tarefa NÃƒO estÃ¡ finalizada e vocÃª deve continuar o trabalho ou a interaÃ§Ã£o com o usuÃ¡rio para os itens pendentes ou bloqueados.
    CRÃTICO: NUNCA use a ferramenta `terminate` se a tarefa estiver bloqueada ou paralisada por falta de informaÃ§Ã£o do usuÃ¡rio que poderia ser obtida com a ferramenta `AskHuman`. Sempre priorize obter a informaÃ§Ã£o necessÃ¡ria para concluir os itens do checklist. Use `terminate` apenas se o usuÃ¡rio explicitamente pedir para parar, se todos os itens do checklist estiverem `[ConcluÃ­do]`, ou se ocorrer um erro irrecuperÃ¡vel que impeÃ§a qualquer progresso mesmo com a ajuda do usuÃ¡rio.

As ferramentas `view_checklist`, `add_checklist_task`, e `update_checklist_task` sÃ£o a forma preferencial e mais robusta de interagir com o arquivo de checklist (`{directory}/checklist_principal_tarefa.md`), substituindo o uso direto de `str_replace_editor` para estas operaÃ§Ãµes especÃ­ficas de gerenciamento de checklist.
Esta Ã© a primeira e mais crucial fase do seu processo de pensamento e execuÃ§Ã£o. NÃƒO PULE ESTES PASSOS.

**Protocolo de FinalizaÃ§Ã£o ReforÃ§ado:** Lembre-se, a REGRA DE OURO Ã© crÃ­tica. A ferramenta `terminate` sÃ³ pode ser chamada se TODAS as seguintes condiÃ§Ãµes forem atendidas:
1. Todos os itens no `{directory}/checklist_principal_tarefa.md` estÃ£o marcados como `[ConcluÃ­do]` (verificado com `view_checklist`).
2. VocÃª explicitamente me perguntou (usando `AskHuman` dentro de `periodic_user_check_in`) se estou satisfeito com os resultados e se vocÃª pode finalizar a tarefa.
3. Eu dei consentimento explÃ­cito para finalizar em resposta a essa pergunta.
*ExceÃ§Ã£o para Falhas IrrecuperÃ¡veis:* (Mesmo procedimento, mas use `update_checklist_task` para marcar como `[Bloqueado]`).
Violar este protocolo de finalizaÃ§Ã£o Ã© uma falha grave.

VocÃª estÃ¡ operando em um ciclo de agente, completando tarefas iterativamente atravÃ©s destes passos:
1.  **ObservaÃ§Ã£o:** VocÃª recebe um prompt do usuÃ¡rio e o histÃ³rico da conversa. Se o arquivo de checklist (`{directory}/checklist_principal_tarefa.md`) existir, use a ferramenta `view_checklist` para revisar as tarefas e entender o progresso atual e a prÃ³xima subtarefa a ser executada.
2.  **Pensamento:** VocÃª analisa a tarefa, o histÃ³rico, o checklist (obtido via `view_checklist` se existir) e decide a prÃ³xima aÃ§Ã£o. Se nÃ£o houver um checklist ou ele estiver vazio, sua primeira aÃ§Ã£o DEVE SER decompor o prompt do usuÃ¡rio em subtarefas e adicionÃ¡-las usando `add_checklist_task` repetidamente.
3.  **AÃ§Ã£o:** VocÃª executa a aÃ§Ã£o escolhida (por exemplo, chamar uma ferramenta, responder ao usuÃ¡rio).
4.  **AtualizaÃ§Ã£o do Checklist e Gerenciamento de Estado:** ApÃ³s cada aÃ§Ã£o significativa, ou ao iniciar ou concluir uma subtarefa, atualize o `checklist_principal_tarefa.md` usando `add_checklist_task` ou `update_checklist_task` IMEDIATAMENTE. Mude o estado da subtarefa em foco para `[Em Andamento]`, `[ConcluÃ­do]`, ou `[Bloqueado]`, conforme o progresso e os resultados. Se um item for marcado como `[Bloqueado]`, siga o procedimento de interaÃ§Ã£o com o usuÃ¡rio (conforme detalhado no bloco ATENÃ‡ÃƒO, ponto 5).
5.  **VerificaÃ§Ã£o da Regra de Ouro:** Lembre-se da REGRA DE OURO: antes de usar 'terminate' com 'success', valide que todos os itens do checklist (vistos com `view_checklist`) estÃ£o '[ConcluÃ­do]'. Se nÃ£o estiverem, retorne ao Pensamento/AÃ§Ã£o para os itens restantes.

- Este checklist em `{directory}/checklist_principal_tarefa.md` complementa quaisquer planos do MÃ³dulo Planejador, focando no seu plano auto-derivado da decomposiÃ§Ã£o do prompt do usuÃ¡rio. VOCÃŠ DEVE SEGUIR ESTE CHECKLIST.
Lembre-se: a criaÃ§Ã£o e atualizaÃ§Ã£o rigorosa deste checklist (`{directory}/checklist_principal_tarefa.md`) usando as ferramentas `add_checklist_task` e `update_checklist_task`, incluindo o uso correto e imediato dos estados `[Pendente]`, `[Em Andamento]`, `[ConcluÃ­do]` e `[Bloqueado]` para cada item, sÃ£o fundamentais para o seu sucesso.
A sua tarefa SÃ“ Ã© considerada verdadeiramente concluÃ­da e pronta para finalizaÃ§Ã£o quando TODOS os itens no `checklist_principal_tarefa.md` estiverem marcados como `[ConcluÃ­do]` (verificado com `view_checklist`).
Se vocÃª acredita que o objetivo principal da tarefa foi alcanÃ§ado, mas ainda existem itens pendentes no checklist (ou seja, nÃ£o marcados como `[ConcluÃ­do]`), vocÃª DEVE priorizar a conclusÃ£o desses itens do checklist antes de qualquer outra aÃ§Ã£o de finalizaÃ§Ã£o.
A tarefa do usuÃ¡rio SÃ“ Ã‰ CONSIDERADA CONCLUÃDA para fins de finalizaÃ§Ã£o quando todos os itens do checklist estiverem marcados como `[ConcluÃ­do]`, apÃ³s verificaÃ§Ã£o explÃ­cita de cada item por vocÃª usando `view_checklist`.
ApÃ³s todos os itens do checklist serem marcados como `[ConcluÃ­do]`, vocÃª DEVE perguntar explicitamente ao usuÃ¡rio se ele estÃ¡ satisfeito e se vocÃª pode finalizar a tarefa (este Ã© o mecanismo de verificaÃ§Ã£o final de satisfaÃ§Ã£o).
A chamada Ã  ferramenta `terminate` SÃ“ Ã© permitida DEPOIS que todos os itens do checklist estiverem `[ConcluÃ­do]` E vocÃª tiver recebido a confirmaÃ§Ã£o explÃ­cita do usuÃ¡rio atravÃ©s deste mecanismo de verificaÃ§Ã£o final de satisfaÃ§Ã£o (onde vocÃª pergunta 'VocÃª estÃ¡ satisfeito com o resultado e deseja que eu finalize a tarefa?').
Tentar finalizar a tarefa (usar `terminate`) antes de todos os itens do checklist estarem `[ConcluÃ­do]` e sem a aprovaÃ§Ã£o explÃ­cita do usuÃ¡rio no passo final de verificaÃ§Ã£o Ã© uma falha e viola seu protocolo operacional.
""" + "\n\nThe initial directory is: {directory}"

NEXT_STEP_PROMPT = """
Com base nas necessidades do usuÃ¡rio, selecione proativamente a ferramenta ou combinaÃ§Ã£o de ferramentas mais apropriada. Para tarefas complexas, vocÃª pode dividir o problema e usar diferentes ferramentas passo a passo para resolvÃª-lo. ApÃ³s usar cada ferramenta, claramente
explique os resultados da execuÃ§Ã£o e sugira os prÃ³ximos passos.

Se vocÃª quiser interromper a interaÃ§Ã£o a qualquer momento, use a chamada de ferramenta/funÃ§Ã£o `terminate`.
"""

```

### ARQUIVO: app/prompt/visualization.py ###
```py
SYSTEM_PROMPT = """VocÃª Ã© um agente de IA projetado para tarefas de anÃ¡lise/visualizaÃ§Ã£o de dados. VocÃª tem vÃ¡rias ferramentas Ã  sua disposiÃ§Ã£o que pode chamar para concluir solicitaÃ§Ãµes complexas de forma eficiente.
# ObservaÃ§Ã£o:
1. O diretÃ³rio do espaÃ§o de trabalho Ã©: {directory}; Ler/escrever arquivo no espaÃ§o de trabalho
2. Gerar relatÃ³rio de conclusÃ£o da anÃ¡lise no final"""

NEXT_STEP_PROMPT = """Com base nas necessidades do usuÃ¡rio, divida o problema e use diferentes ferramentas passo a passo para resolvÃª-lo.
# ObservaÃ§Ã£o
1. Em cada etapa, selecione proativamente a ferramenta mais apropriada (APENAS UMA).
2. ApÃ³s usar cada ferramenta, explique claramente os resultados da execuÃ§Ã£o e sugira os prÃ³ximos passos.
3. Quando observar um Erro, revise e corrija-o."""

```

### ARQUIVO: app/tool/read_file_content.py ###
```py
import os
from pathlib import Path

from app.config import config
from app.exceptions import ToolError
from app.logger import logger
from app.tool.base import BaseTool, ToolResult
from app.tool.file_operators import LocalFileOperator
from app.tool.file_system_tools import ListFilesTool # Nova importaÃ§Ã£o


class ReadFileContentTool(BaseTool):
    """
    Reads the entire content of a specified file and returns it as a string.
    Use this to get the full context of a file for analysis or understanding.
    """

    name: str = "read_file_content"
    description: str = (
        "Reads the entire content of a specified file and returns it as a string. "
        "Use this to get the full context of a file for analysis or understanding."
    )
    args_schema: dict = {
        "type": "object",
        "properties": {
            "path": {"type": "string", "description": "Absolute path to the file."},
        },
        "required": ["path"],
    }

    async def execute(self, path: str) -> ToolResult:
        """
        Reads the entire content of a specified file and returns it as a string.

        Args:
            path: Absolute path to the file.

        Returns:
            The content of the file as a string.
        """
        absolute_path = Path(path)
        if not absolute_path.is_absolute():
            absolute_path = Path(config.workspace_root) / path

        logger.info(f"ReadFileContentTool: Attempting to read file: {absolute_path}")
        local_file_op = LocalFileOperator()

        try:
            # LocalFileOperator.read_file is async, so it needs to be awaited
            content = await local_file_op.read_file(str(absolute_path))
            logger.info(f"ReadFileContentTool: Successfully read file: {absolute_path}, content length: {len(content)}")
            return ToolResult(output=content)
        except FileNotFoundError as e:
            logger.error(f"ReadFileContentTool: FileNotFoundError reading file {absolute_path}: {e}")

            parent_dir_listing_str = "Could not list parent directory."
            try:
                parent_dir = absolute_path.parent
                # Ensure parent_dir is within workspace_root for security before listing
                if not str(parent_dir.resolve()).startswith(str(config.workspace_root.resolve())):
                    parent_dir_listing_str = f"Parent directory '{parent_dir}' is outside the allowed workspace. Cannot list."
                    logger.warning(f"Attempt to list parent directory '{parent_dir}' outside workspace denied.")
                else:
                    list_files_tool = ListFilesTool()
                    # Chamar execute com path e depth.
                    list_result = await list_files_tool.execute(path=str(parent_dir), depth=1)
                    if list_result.error:
                        parent_dir_listing_str = f"Error listing parent directory '{parent_dir}': {list_result.error}"
                    elif list_result.output:
                        # A saÃ­da de ListFilesTool Ã© uma string JSON.
                        # Para melhor legibilidade, podemos tentar parsear e formatar um pouco,
                        # mas usar diretamente tambÃ©m Ã© uma opÃ§Ã£o.
                        try:
                            parsed_listing = json.loads(list_result.output)
                            items_str = "\n".join([f"  - {item.get('path')} ({item.get('type')})" for item in parsed_listing.get('items', [])])
                            if not items_str:
                                items_str = "  (empty or no items found)"
                            parent_dir_listing_str = f"Listing of parent directory '{parent_dir}':\n{items_str}"
                        except json.JSONDecodeError:
                             parent_dir_listing_str = f"Listing of parent directory '{parent_dir}' (raw JSON):\n{list_result.output}"
                        except Exception as parse_fmt_e:
                            logger.error(f"ReadFileContentTool: Error parsing/formatting ListFilesTool output: {parse_fmt_e}")
                            parent_dir_listing_str = f"Listing of parent directory '{parent_dir}' (raw output, format error):\n{list_result.output}"

                    else:
                        parent_dir_listing_str = f"Parent directory '{parent_dir}' is empty or no output from list_files."

            except Exception as list_e:
                logger.error(f"ReadFileContentTool: Error when trying to list parent directory for {absolute_path}: {list_e}", exc_info=True)
                parent_dir_listing_str = f"Exception while trying to list parent directory: {list_e}"

            # Modificar a mensagem de erro para incluir a listagem
            error_message = (
                f"File not found: {absolute_path}.\n"
                f"{parent_dir_listing_str}"
            )
            raise ToolError(error_message)
        except IOError as e:
            logger.error(f"ReadFileContentTool: IOError reading file {absolute_path}: {e}")
            raise ToolError(f"Error reading file {absolute_path}: {e}")
        except Exception as e: # Catch-all for other unexpected errors during the read attempt itself
            logger.error(f"ReadFileContentTool: Unexpected error reading file {absolute_path}: {e}", exc_info=True)
            # Attempt to list parent directory even for other errors if absolute_path is defined
            parent_dir_listing_str = "Could not list parent directory due to earlier error."
            if 'absolute_path' in locals() and absolute_path:
                try:
                    parent_dir = absolute_path.parent
                    if not str(parent_dir.resolve()).startswith(str(config.workspace_root.resolve())):
                        parent_dir_listing_str = f"Parent directory '{parent_dir}' is outside the allowed workspace. Cannot list."
                    else:
                        list_files_tool = ListFilesTool()
                        list_result = await list_files_tool.execute(path=str(parent_dir), depth=1)
                        if list_result.error:
                            parent_dir_listing_str = f"Error listing parent directory '{parent_dir}' (during general error handling): {list_result.error}"
                        elif list_result.output:
                             parent_dir_listing_str = f"Parent directory '{parent_dir}' listing (during general error handling):\n{list_result.output}"
                        else:
                            parent_dir_listing_str = f"Parent directory '{parent_dir}' is empty or no output (during general error handling)."
                except Exception as list_e_general:
                    parent_dir_listing_str = f"Exception listing parent directory (during general error handling): {list_e_general}"

            raise ToolError(f"Unexpected error reading file {absolute_path}: {e}. {parent_dir_listing_str}")

```

### ARQUIVO: app/tool/file_system_tools.py ###
```py
import os
import asyncio
import json # Import json for structured output
from typing import List, Dict, Any, Optional # Optional is already here

from app.tool.base import BaseTool, ToolResult
from app.config import config # To access workspace_root
import aiofiles # For async file operations
import logging # For logging potential issues during the tool's execution

logger = logging.getLogger(__name__)

# Developer Note:
# The rich diagnostic output from this tool (when a file/directory is not found)
# is returned as a JSON string in ToolResult.output.
# An agent could parse this JSON and use the information for more intelligent error handling.
# For example:
# - Compare `checked_path_absolute` with user-provided paths to identify discrepancies.
# - Use `parent_directory_listing` to suggest alternative files if `checked_path_original`
#   seems like a typo (e.g., "Did you mean 'prompt.txt.bkp' instead of 'prompt.txt'?").
# - Log `current_working_directory` to help diagnose issues if the agent is not running
#   in the expected directory.
class CheckFileExistenceTool(BaseTool):
    name: str = "check_file_existence"
    description: str = (
        "Verifica se um arquivo ou diretÃ³rio existe no caminho especificado. "
        "Retorna SUCESSO se encontrado, ou FALHA com informaÃ§Ãµes de diagnÃ³stico detalhadas se nÃ£o encontrado, "
        "incluindo o caminho absoluto verificado, o diretÃ³rio de trabalho atual (CWD), "
        "e uma listagem do diretÃ³rio pai."
    )

    async def _get_path_details(self, path: str) -> tuple[str, str, list[str] | str]:
        """Helper function to get absolute path, CWD, and parent directory listing."""
        try:
            # Get absolute path
            absolute_path = await asyncio.to_thread(os.path.abspath, path)
        except Exception as e:
            logger.warning(f"Error getting absolute path for {path}: {e}")
            absolute_path = f"Erro ao obter caminho absoluto: {e}"

        try:
            # Get current working directory
            current_working_directory = await asyncio.to_thread(os.getcwd)
        except Exception as e:
            logger.warning(f"Error getting CWD: {e}")
            current_working_directory = f"Erro ao obter CWD: {e}"

        parent_directory_listing: list[str] | str = []
        try:
            parent_dir = await asyncio.to_thread(os.path.dirname, absolute_path if isinstance(absolute_path, str) and not absolute_path.startswith("Erro") else path)
            if not parent_dir: # Handle cases like root or relative paths without a clear parent in the input
                 parent_dir = current_working_directory # Default to CWD if parent_dir is empty

            if await asyncio.to_thread(os.path.exists, parent_dir):
                if await asyncio.to_thread(os.path.isdir, parent_dir):
                    parent_directory_listing = await asyncio.to_thread(os.listdir, parent_dir)
                else:
                    parent_directory_listing = f"O caminho pai '{parent_dir}' nÃ£o Ã© um diretÃ³rio."
            else:
                parent_directory_listing = f"O diretÃ³rio pai '{parent_dir}' nÃ£o foi encontrado."
        except Exception as e:
            logger.warning(f"Error listing parent directory for {path} (parent: {parent_dir if 'parent_dir' in locals() else 'N/A'}): {e}")
            parent_directory_listing = f"Erro ao listar o diretÃ³rio pai: {e}"

        return absolute_path, current_working_directory, parent_directory_listing

    async def execute(self, path: str) -> ToolResult:
        path_exists = False
        error_message = None
        absolute_path_checked = ""

        try:
            # Ensure path is a string
            if not isinstance(path, str):
                return ToolResult(error=f"Erro de tipo: o caminho fornecido '{path}' nÃ£o Ã© uma string.")

            # Attempt to get absolute path early for diagnostics, even if it fails
            try:
                absolute_path_checked = await asyncio.to_thread(os.path.abspath, path)
            except Exception as e:
                absolute_path_checked = f"NÃ£o foi possÃ­vel determinar o caminho absoluto para '{path}': {e}"
                logger.warning(f"Could not get abspath for {path} during execute: {e}")


            path_exists = await asyncio.to_thread(os.path.exists, path)

            if path_exists:
                output_data = {
                    "status": "SUCESSO",
                    "message": f"O arquivo ou diretÃ³rio em '{path}' foi encontrado.",
                    "checked_path_original": path,
                    "checked_path_absolute": absolute_path_checked
                }
                # Attempt to convert to JSON string for output, fallback to repr
                try:
                    output_str = json.dumps(output_data, ensure_ascii=False, indent=2)
                except Exception:
                    output_str = repr(output_data)
                return ToolResult(output=output_str)
            else:
                # If not found, gather diagnostic information
                abs_path_diag, cwd_diag, parent_listing_diag = await self._get_path_details(path)

                output_data = {
                    "status": "FALHA",
                    "message": f"O arquivo ou diretÃ³rio em '{path}' NÃƒO foi encontrado.",
                    "checked_path_original": path,
                    "checked_path_absolute": abs_path_diag, # Use the one from _get_path_details as it's more robustly attempted
                    "current_working_directory": cwd_diag,
                    "parent_directory_listing": parent_listing_diag
                }
                # Attempt to convert to JSON string for output, fallback to repr
                try:
                    output_str = json.dumps(output_data, ensure_ascii=False, indent=2)
                except Exception:
                    output_str = repr(output_data)
                return ToolResult(output=output_str)

        except Exception as e:
            logger.error(f"Erro inesperado na ferramenta CheckFileExistenceTool para o caminho '{path}': {e}", exc_info=True)
            # Gather diagnostic info even in case of an unexpected error during the check itself
            abs_path_diag, cwd_diag, parent_listing_diag = await self._get_path_details(path)

            error_output_data = {
                "status": "ERRO_INESPERADO",
                "message": f"Erro inesperado ao verificar a existÃªncia de '{path}': {str(e)}",
                "checked_path_original": path,
                "checked_path_absolute": abs_path_diag if abs_path_diag else absolute_path_checked,
                "current_working_directory": cwd_diag,
                "parent_directory_listing": parent_listing_diag
            }
            try:
                error_str = json.dumps(error_output_data, ensure_ascii=False, indent=2)
            except Exception:
                error_str = repr(error_output_data)
            return ToolResult(error=error_str)


class ListFilesTool(BaseTool):
    name: str = "list_files"
    description: str = (
        "Lista arquivos e diretÃ³rios em um caminho especificado, de forma recursiva atÃ© uma profundidade definida. "
        "Use esta ferramenta para obter consciÃªncia situacional do workspace ou para ver quais arquivos estÃ£o disponÃ­veis."
    )
    args_schema: dict = {
        "type": "object",
        "properties": {
            "path": {
                "type": "string", # Em JSON schema, 'null' pode ser um tipo ou usar anyOf para opcionalidade, mas aqui o campo Ã© opcional pela ausencia em 'required'
                "description": "O caminho do diretÃ³rio a ser listado. Se nÃ£o fornecido, lista o diretÃ³rio de trabalho atual do agente (config.workspace_root).",
            },
            "depth": {
                "type": "integer",
                "default": 1,
                "description": "Profundidade mÃ¡xima da listagem recursiva. 0 para profundidade ilimitada (use com cautela), 1 para listar apenas o conteÃºdo do diretÃ³rio especificado (sem recursÃ£o).",
            },
        },
        "required": [], # path e depth sÃ£o opcionais, seus defaults sÃ£o tratados na lÃ³gica da ferramenta
    }

    async def execute(self, path: Optional[str] = None, depth: int = 1) -> ToolResult:
        try:
            if path is None:
                start_path = str(config.workspace_root)
                logger.info(f"Nenhum caminho fornecido, usando o workspace_root: {start_path}")
            else:
                # Verificar se o caminho Ã© absoluto. Se nÃ£o, considerar relativo ao workspace_root.
                if not await asyncio.to_thread(os.path.isabs, path):
                    start_path = str(config.workspace_root / path)
                    logger.info(f"Caminho relativo fornecido '{path}', resolvido para: {start_path}")
                else:
                    start_path = path
                    logger.info(f"Caminho absoluto fornecido: {start_path}")

            # Validar se o start_path estÃ¡ dentro do workspace_root para seguranÃ§a
            # Convertendo ambos para caminhos absolutos resolvidos antes de comparar
            resolved_start_path = await asyncio.to_thread(os.path.realpath, start_path)
            resolved_workspace_root = await asyncio.to_thread(os.path.realpath, str(config.workspace_root))

            if not resolved_start_path.startswith(resolved_workspace_root):
                logger.warning(f"Tentativa de listar arquivos fora do workspace: {resolved_start_path}")
                return ToolResult(error=f"Erro: O caminho especificado '{path}' estÃ¡ fora do diretÃ³rio de trabalho permitido.")

            if not await asyncio.to_thread(os.path.exists, start_path):
                return ToolResult(error=f"Erro: O caminho '{start_path}' nÃ£o existe.")
            if not await asyncio.to_thread(os.path.isdir, start_path):
                return ToolResult(error=f"Erro: O caminho '{start_path}' nÃ£o Ã© um diretÃ³rio.")

            result_tree: Dict[str, Any] = {"path": os.path.basename(start_path), "type": "directory", "children": []}

            # Usar asyncio.to_thread para rodar os.walk em um thread separado
            # jÃ¡ que os.walk Ã© bloqueante.
            # A lÃ³gica de profundidade precisa ser gerenciada manualmente dentro do loop.

            # Normalizar start_path para garantir que a contagem de profundidade seja consistente
            normalized_start_path = await asyncio.to_thread(os.path.normpath, start_path)
            start_depth = normalized_start_path.count(os.sep)

            # Para evitar TimeoutError com asyncio.to_thread em operaÃ§Ãµes longas,
            # podemos precisar de uma abordagem mais granular ou um executor de threadpool customizado.
            # Para este caso, vamos confiar que os.walk nÃ£o serÃ¡ excessivamente longo para profundidades razoÃ¡veis.

            loop = asyncio.get_event_loop()
            # Precisamos coletar os resultados de os.walk, que Ã© um gerador.
            # O wrapper to_thread nÃ£o lida bem com geradores diretamente para consumo assÃ­ncrono.
            # Uma forma Ã© converter o gerador para uma lista dentro do thread.

            def walk_and_collect(root_dir, max_depth):
                collected_items = []
                for root, dirs, files in os.walk(root_dir, topdown=True):
                    current_rel_path = os.path.relpath(root, normalized_start_path)
                    current_depth = current_rel_path.count(os.sep) if current_rel_path != '.' else 0

                    if max_depth == 0 or current_depth < max_depth:
                        # Processa diretÃ³rios
                        dir_children_map = {d: [] for d in dirs}
                        # Processa arquivos
                        file_children = [{"path": f, "type": "file"} for f in files]

                        collected_items.append({
                            "root": root,
                            "dirs": dirs,
                            "files": files,
                            "current_depth": current_depth,
                            "rel_path": current_rel_path
                        })

                        # Controlar a recursÃ£o podando a lista dirs se a profundidade atual + 1 == max_depth
                        if max_depth > 0 and current_depth + 1 >= max_depth:
                            dirs[:] = [] # Modifica dirs in-place para parar a descida
                    elif current_depth >= max_depth and max_depth > 0 : # Se jÃ¡ estivermos na profundidade mÃ¡xima, nÃ£o desÃ§a mais
                        dirs[:] = []


                return collected_items

            collected_walk_results = await loop.run_in_executor(None, walk_and_collect, normalized_start_path, depth)

            # Agora, construa a Ã¡rvore JSON a partir dos resultados coletados
            # Esta parte Ã© um pouco complexa para reconstruir a Ã¡rvore a partir de uma lista plana de resultados de os.walk
            # Uma abordagem mais simples para a saÃ­da JSON pode ser uma lista de caminhos ou uma estrutura mais plana.
            # Por simplicidade, vamos retornar uma lista de caminhos por enquanto,
            # e podemos revisitar a estrutura de Ã¡rvore se necessÃ¡rio.

            output_list = []
            if not collected_walk_results and depth == 1: # Caso especial para profundidade 1 e sem subdiretÃ³rios
                # os.walk pode nÃ£o entrar no loop principal se o diretÃ³rio estiver vazio ou depth=1 e sÃ³ houver arquivos
                # Vamos listar manualmente para depth=1
                 try:
                    entries = await asyncio.to_thread(os.listdir, normalized_start_path)
                    for entry in entries:
                        entry_path = os.path.join(normalized_start_path, entry)
                        entry_type = "directory" if await asyncio.to_thread(os.path.isdir, entry_path) else "file"
                        output_list.append({"path": entry, "type": entry_type, "depth": 1})
                 except Exception as e_listdir:
                    logger.error(f"Erro ao listar manualmente {normalized_start_path} para depth=1: {e_listdir}")
                    return ToolResult(error=f"Erro ao listar diretÃ³rio: {e_listdir}")


            for item in collected_walk_results:
                # rel_path '.' significa o diretÃ³rio raiz que estÃ¡ sendo listado
                base_path_for_item = item['rel_path'] if item['rel_path'] != '.' else ''

                for d_name in item['dirs']:
                    # Adicionar apenas se a profundidade do diretÃ³rio em si estiver dentro do limite
                    # A poda em walk_and_collect jÃ¡ deve cuidar disso, mas uma verificaÃ§Ã£o dupla nÃ£o faz mal.
                    if depth == 0 or item['current_depth'] < depth:
                         output_list.append({
                            "path": os.path.join(base_path_for_item, d_name) if base_path_for_item else d_name,
                            "type": "directory",
                            "depth": item['current_depth'] + 1
                        })
                for f_name in item['files']:
                    if depth == 0 or item['current_depth'] < depth :
                        output_list.append({
                            "path": os.path.join(base_path_for_item, f_name) if base_path_for_item else f_name,
                            "type": "file",
                            "depth": item['current_depth'] + 1
                        })

            # Se depth Ã© 0 (ilimitado), e a lista estÃ¡ vazia, mas o diretÃ³rio existe (verificado no inÃ­cio),
            # isso significa que o diretÃ³rio estÃ¡ realmente vazio.
            # Se depth > 0 e a lista estÃ¡ vazia, tambÃ©m pode significar que o diretÃ³rio estÃ¡ vazio.
            if not output_list and await asyncio.to_thread(os.path.isdir, normalized_start_path):
                 # Verifica se o diretÃ³rio estÃ¡ realmente vazio
                if not await asyncio.to_thread(os.listdir, normalized_start_path):
                    return ToolResult(output=json.dumps({"path": os.path.basename(normalized_start_path), "type": "directory", "children": [], "message": "O diretÃ³rio estÃ¡ vazio."}, ensure_ascii=False, indent=2))


            # A estrutura de Ã¡rvore JSON Ã© mais complexa de construir iterativamente a partir de os.walk.
            # Vamos retornar uma lista achatada de arquivos e diretÃ³rios com seus caminhos relativos e tipos.
            # A profundidade tambÃ©m serÃ¡ incluÃ­da para cada item.
            # Ex: [{"path": "file.txt", "type": "file", "depth": 1}, {"path": "subdir/file2.txt", "type": "file", "depth": 2}]
            # Se output_list ainda estiver vazia aqui, significa que o diretÃ³rio pode estar vazio ou algo deu errado.
            # Mas as verificaÃ§Ãµes iniciais devem cobrir a existÃªncia do diretÃ³rio.

            # Se a lista de saÃ­da estiver vazia e o diretÃ³rio nÃ£o estiver (verificado por listdir anteriormente para depth=1),
            # pode indicar um problema na lÃ³gica de coleta. No entanto, se o diretÃ³rio estiver realmente vazio,
            # a mensagem de "O diretÃ³rio estÃ¡ vazio" jÃ¡ terÃ¡ sido retornada.

            final_output_structure = {
                "listed_path": os.path.basename(normalized_start_path),
                "base_path_absolute": normalized_start_path,
                "requested_depth": depth,
                "items": sorted(output_list, key=lambda x: (x['depth'], x['type'], x['path'])) # Ordenar para consistÃªncia
            }
            return ToolResult(output=json.dumps(final_output_structure, ensure_ascii=False, indent=2))

        except Exception as e:
            logger.error(f"Erro inesperado na ferramenta ListFilesTool para o caminho '{path}' e profundidade '{depth}': {e}", exc_info=True)
            return ToolResult(error=f"Erro inesperado ao listar arquivos: {str(e)}")

```

### ARQUIVO: app/tool/create_chat_completion.py ###
```py
from typing import Any, List, Optional, Type, Union, get_args, get_origin

from pydantic import BaseModel, Field

from app.tool import BaseTool


class CreateChatCompletion(BaseTool):
    name: str = "create_chat_completion"
    description: str = (
        "Creates a structured completion with specified output formatting."
    )

    # Type mapping for JSON schema
    type_mapping: dict = {
        str: "string",
        int: "integer",
        float: "number",
        bool: "boolean",
        dict: "object",
        list: "array",
    }
    response_type: Optional[Type] = None
    required: List[str] = Field(default_factory=lambda: ["response"])

    def __init__(self, response_type: Optional[Type] = str):
        """Initialize with a specific response type."""
        super().__init__()
        self.response_type = response_type
        self.parameters = self._build_parameters()

    def _build_parameters(self) -> dict:
        """Build parameters schema based on response type."""
        if self.response_type == str:
            return {
                "type": "object",
                "properties": {
                    "response": {
                        "type": "string",
                        "description": "The response text that should be delivered to the user.",
                    },
                },
                "required": self.required,
            }

        if isinstance(self.response_type, type) and issubclass(
            self.response_type, BaseModel
        ):
            schema = self.response_type.model_json_schema()
            return {
                "type": "object",
                "properties": schema["properties"],
                "required": schema.get("required", self.required),
            }

        return self._create_type_schema(self.response_type)

    def _create_type_schema(self, type_hint: Type) -> dict:
        """Create a JSON schema for the given type."""
        origin = get_origin(type_hint)
        args = get_args(type_hint)

        # Handle primitive types
        if origin is None:
            return {
                "type": "object",
                "properties": {
                    "response": {
                        "type": self.type_mapping.get(type_hint, "string"),
                        "description": f"Response of type {type_hint.__name__}",
                    }
                },
                "required": self.required,
            }

        # Handle List type
        if origin is list:
            item_type = args[0] if args else Any
            return {
                "type": "object",
                "properties": {
                    "response": {
                        "type": "array",
                        "items": self._get_type_info(item_type),
                    }
                },
                "required": self.required,
            }

        # Handle Dict type
        if origin is dict:
            value_type = args[1] if len(args) > 1 else Any
            return {
                "type": "object",
                "properties": {
                    "response": {
                        "type": "object",
                        "additionalProperties": self._get_type_info(value_type),
                    }
                },
                "required": self.required,
            }

        # Handle Union type
        if origin is Union:
            return self._create_union_schema(args)

        return self._build_parameters()

    def _get_type_info(self, type_hint: Type) -> dict:
        """Get type information for a single type."""
        if isinstance(type_hint, type) and issubclass(type_hint, BaseModel):
            return type_hint.model_json_schema()

        return {
            "type": self.type_mapping.get(type_hint, "string"),
            "description": f"Value of type {getattr(type_hint, '__name__', 'any')}",
        }

    def _create_union_schema(self, types: tuple) -> dict:
        """Create schema for Union types."""
        return {
            "type": "object",
            "properties": {
                "response": {"anyOf": [self._get_type_info(t) for t in types]}
            },
            "required": self.required,
        }

    async def execute(self, required: list | None = None, **kwargs) -> Any:
        """Execute the chat completion with type conversion.

        Args:
            required: List of required field names or None
            **kwargs: Response data

        Returns:
            Converted response based on response_type
        """
        required = required or self.required

        # Handle case when required is a list
        if isinstance(required, list) and len(required) > 0:
            if len(required) == 1:
                required_field = required[0]
                result = kwargs.get(required_field, "")
            else:
                # Return multiple fields as a dictionary
                return {field: kwargs.get(field, "") for field in required}
        else:
            required_field = "response"
            result = kwargs.get(required_field, "")

        # Type conversion logic
        if self.response_type == str:
            return result

        if isinstance(self.response_type, type) and issubclass(
            self.response_type, BaseModel
        ):
            return self.response_type(**kwargs)

        if get_origin(self.response_type) in (list, dict):
            return result  # Assuming result is already in correct format

        try:
            return self.response_type(result)
        except (ValueError, TypeError):
            return result

```

### ARQUIVO: app/tool/base.py ###
```py
from abc import ABC, abstractmethod
from typing import Any, Dict, Optional

from pydantic import BaseModel, Field


class BaseTool(ABC, BaseModel):
    name: str
    description: str
    parameters: Optional[dict] = None

    class Config:
        arbitrary_types_allowed = True

    async def __call__(self, **kwargs) -> Any:
        """Execute the tool with given parameters."""
        return await self.execute(**kwargs)

    @abstractmethod
    async def execute(self, **kwargs) -> Any:
        """Execute the tool with given parameters."""

    def to_param(self) -> Dict:
        """Convert tool to function call format."""
        return {
            "type": "function",
            "function": {
                "name": self.name,
                "description": self.description,
                "parameters": self.parameters,
            },
        }


class ToolResult(BaseModel):
    """Represents the result of a tool execution."""

    output: Any = Field(default=None)
    error: Optional[str] = Field(default=None)
    base64_image: Optional[str] = Field(default=None)
    system: Optional[str] = Field(default=None)

    class Config:
        arbitrary_types_allowed = True

    def __bool__(self):
        return any(getattr(self, field) for field in self.__fields__)

    def __add__(self, other: "ToolResult"):
        def combine_fields(
            field: Optional[str], other_field: Optional[str], concatenate: bool = True
        ):
            if field and other_field:
                if concatenate:
                    return field + other_field
                raise ValueError("Cannot combine tool results")
            return field or other_field

        return ToolResult(
            output=combine_fields(self.output, other.output),
            error=combine_fields(self.error, other.error),
            base64_image=combine_fields(self.base64_image, other.base64_image, False),
            system=combine_fields(self.system, other.system),
        )

    def __str__(self):
        return f"Error: {self.error}" if self.error else self.output

    def replace(self, **kwargs):
        """Returns a new ToolResult with the given fields replaced."""
        # return self.copy(update=kwargs)
        return type(self)(**{**self.dict(), **kwargs})


class CLIResult(ToolResult):
    """A ToolResult that can be rendered as a CLI output."""


class ToolFailure(ToolResult):
    """A ToolResult that represents a failure."""

```

### ARQUIVO: app/tool/file_reader.py ###
```py
import os
from typing import Dict, Union

from app.tool.base import BaseTool
from app.tool.file_operators import LocalFileOperator # To use for reading
from app.config import config # For workspace path resolution
from app.logger import logger
from app.exceptions import ToolError # For error handling

class ReadFileContent(BaseTool):
    name: str = "read_file_content"
    description: str = (
        "Reads and returns the entire raw content of a specified file. "
        "This tool should be used when the full context of a file is needed for analysis or processing. "
        "Relative paths are resolved from the agent's workspace root."
    )
    parameters: dict = {
        "type": "object",
        "properties": {
            "path": {
                "type": "string",
                "description": "The relative (from workspace root) or absolute path to the file to be read.",
            }
        },
        "required": ["path"],
    }

    _local_operator: LocalFileOperator = LocalFileOperator()

    async def execute(self, path: str) -> Union[str, Dict[str, str]]:
        """
        Reads and returns the full, raw, untruncated content of a file.

        Args:
            path (str): The path to the file.

        Returns:
            Union[str, Dict[str, str]]: The full file content as a string if successful,
                                         or a dictionary with an 'error' message if reading fails.
        """
        # Resolve the path relative to the workspace root if it's not absolute
        if not os.path.isabs(path):
            file_path = os.path.join(config.workspace_root, path)
        else:
            file_path = path

        # Normalize the path to handle potential ".." or "." segments and ensure it's an absolute path
        file_path = os.path.normpath(os.path.abspath(file_path))

        # Security check: Ensure the path is still within the workspace_root
        # This is important even for read operations to prevent arbitrary file access.
        if not file_path.startswith(os.path.normpath(os.path.abspath(config.workspace_root))):
            logger.error(f"Path traversal attempt detected for read_file_content. Original path: '{path}', Resolved path: '{file_path}' is outside workspace '{os.path.normpath(os.path.abspath(config.workspace_root))}'.")
            return {"error": f"Path is outside the allowed workspace: {path}"}

        # Check using os.path.isfile first, as LocalFileOperator.read_file might raise specific ToolErrors for not found
        # that we want to catch more generically here for this tool's specific error reporting.
        if not os.path.isfile(file_path):
            logger.error(f"File not found at path for read_file_content: {file_path} (original input: '{path}')")
            return {"error": f"File not found: {path} (resolved to: {file_path})"}

        try:
            # Use the instantiated LocalFileOperator
            content = await self._local_operator.read_file(file_path)
            logger.info(f"Successfully read {len(content)} characters from {file_path}.")
            return content
        except ToolError as e: # Catch specific ToolError from LocalFileOperator (e.g., if it has its own not found)
            logger.error(f"ToolError reading file {file_path} (original input: '{path}'): {e}")
            # Return the specific error from LocalFileOperator if available and informative
            return {"error": f"Failed to read file '{path}': {str(e)}"}
        except Exception as e:
            logger.error(f"Unexpected error reading file {file_path} (original input: '{path}'): {e}", exc_info=True)
            return {"error": f"An unexpected error occurred while reading file '{path}': {str(e)}"}

```

### ARQUIVO: app/tool/mcp.py ###
```py
from contextlib import AsyncExitStack
from typing import Dict, List, Optional

from mcp.client.sse import sse_client
from mcp.client.stdio import stdio_client
from mcp.types import ListToolsResult, TextContent

from app.logger import logger
from app.tool.base import BaseTool, ToolResult
from app.tool.tool_collection import ToolCollection
from mcp import ClientSession, StdioServerParameters


class MCPClientTool(BaseTool):
    """Represents a tool proxy that can be called on the MCP server from the client side."""

    session: Optional[ClientSession] = None
    server_id: str = ""  # Add server identifier
    original_name: str = ""

    async def execute(self, **kwargs) -> ToolResult:
        """Execute the tool by making a remote call to the MCP server."""
        if not self.session:
            return ToolResult(error="Not connected to MCP server")

        try:
            logger.info(f"Executing tool: {self.original_name}")
            result = await self.session.call_tool(self.original_name, kwargs)
            content_str = ", ".join(
                item.text for item in result.content if isinstance(item, TextContent)
            )
            return ToolResult(output=content_str or "No output returned.")
        except Exception as e:
            return ToolResult(error=f"Error executing tool: {str(e)}")


class MCPClients(ToolCollection):
    """
    A collection of tools that connects to multiple MCP servers and manages available tools through the Model Context Protocol.
    """

    sessions: Dict[str, ClientSession] = {}
    exit_stacks: Dict[str, AsyncExitStack] = {}
    description: str = "MCP client tools for server interaction"

    def __init__(self):
        super().__init__()  # Initialize with empty tools list
        self.name = "mcp"  # Keep name for backward compatibility

    async def connect_sse(self, server_url: str, server_id: str = "") -> None:
        """Connect to an MCP server using SSE transport."""
        if not server_url:
            raise ValueError("Server URL is required.")

        server_id = server_id or server_url

        # Always ensure clean disconnection before new connection
        if server_id in self.sessions:
            await self.disconnect(server_id)

        exit_stack = AsyncExitStack()
        self.exit_stacks[server_id] = exit_stack

        streams_context = sse_client(url=server_url)
        streams = await exit_stack.enter_async_context(streams_context)
        session = await exit_stack.enter_async_context(ClientSession(*streams))
        self.sessions[server_id] = session

        await self._initialize_and_list_tools(server_id)

    async def connect_stdio(
        self, command: str, args: List[str], server_id: str = ""
    ) -> None:
        """Connect to an MCP server using stdio transport."""
        if not command:
            raise ValueError("Server command is required.")

        server_id = server_id or command

        # Always ensure clean disconnection before new connection
        if server_id in self.sessions:
            await self.disconnect(server_id)

        exit_stack = AsyncExitStack()
        self.exit_stacks[server_id] = exit_stack

        server_params = StdioServerParameters(command=command, args=args)
        stdio_transport = await exit_stack.enter_async_context(
            stdio_client(server_params)
        )
        read, write = stdio_transport
        session = await exit_stack.enter_async_context(ClientSession(read, write))
        self.sessions[server_id] = session

        await self._initialize_and_list_tools(server_id)

    async def _initialize_and_list_tools(self, server_id: str) -> None:
        """Initialize session and populate tool map."""
        session = self.sessions.get(server_id)
        if not session:
            raise RuntimeError(f"Session not initialized for server {server_id}")

        await session.initialize()
        response = await session.list_tools()

        # Create proper tool objects for each server tool
        for tool in response.tools:
            original_name = tool.name
            # Always prefix with server_id to ensure uniqueness
            tool_name = f"mcp_{server_id}_{original_name}"

            server_tool = MCPClientTool(
                name=tool_name,
                description=tool.description,
                parameters=tool.inputSchema,
                session=session,
                server_id=server_id,
                original_name=original_name,
            )
            self.tool_map[tool_name] = server_tool

        # Update tools tuple
        self.tools = tuple(self.tool_map.values())
        logger.info(
            f"Connected to server {server_id} with tools: {[tool.name for tool in response.tools]}"
        )

    async def list_tools(self) -> ListToolsResult:
        """List all available tools."""
        tools_result = ListToolsResult(tools=[])
        for session in self.sessions.values():
            response = await session.list_tools()
            tools_result.tools += response.tools
        return tools_result

    async def disconnect(self, server_id: str = "") -> None:
        """Disconnect from a specific MCP server or all servers if no server_id provided."""
        if server_id:
            logger.info(f"MCPClients.disconnect: Starting disconnection for server_id: {server_id}")
            if server_id in self.sessions:
                try:
                    exit_stack = self.exit_stacks.get(server_id)

                    # Close the exit stack which will handle session cleanup
                    if exit_stack:
                        try:
                            logger.info(f"MCPClients.disconnect: About to call exit_stack.aclose() for server_id: {server_id}")
                            await exit_stack.aclose()
                            logger.info(f"MCPClients.disconnect: exit_stack.aclose() completed for server_id: {server_id}")
                        except RuntimeError as e:
                            logger.error(f"MCPClients.disconnect: Error during exit_stack.aclose() for server_id: {server_id}. Error: {e}")
                            if "cancel scope" in str(e).lower():
                                logger.warning(
                                    f"Cancel scope error during disconnect from {server_id}, continuing with cleanup: {e}"
                                )
                            else:
                                raise

                    # Clean up references
                    self.sessions.pop(server_id, None)
                    self.exit_stacks.pop(server_id, None)

                    # Remove tools associated with this server
                    self.tool_map = {
                        k: v
                        for k, v in self.tool_map.items()
                        if v.server_id != server_id
                    }
                    self.tools = tuple(self.tool_map.values())
                    logger.info(f"Disconnected from MCP server {server_id}")
                except Exception as e:
                    logger.error(f"Error disconnecting from server {server_id}: {e}")
            logger.info(f"MCPClients.disconnect: Finished disconnection for server_id: {server_id}")
        else:
            logger.info("MCPClients.disconnect: Starting disconnection for ALL servers.")
            # Disconnect from all servers in a deterministic order
            for sid in sorted(list(self.sessions.keys())):
                await self.disconnect(sid)
            self.tool_map = {}
            self.tools = tuple()
            logger.info("Disconnected from all MCP servers")
            logger.info("MCPClients.disconnect: Finished disconnection for ALL servers.")

```

### ARQUIVO: app/tool/checklist_tools.py ###
```py
from typing import Any, Dict, Optional

from app.agent.checklist_manager import ChecklistManager
from app.exceptions import ToolError
from app.logger import logger
from app.tool.base import BaseTool, ToolResult


class ViewChecklistTool(BaseTool):
    name: str = "view_checklist"
    description: str = "Displays all tasks, their current statuses and assigned agents from the main checklist."
    args_schema: Dict[str, Any] = {"type": "object", "properties": {}, "required": []}

    async def execute(self, **kwargs: Any) -> ToolResult:
        logger.info("ViewChecklistTool invoked.")
        try:
            manager = ChecklistManager()
            await manager._load_checklist()  # Load tasks explicitly
            tasks = manager.get_tasks()

            if not tasks:
                return ToolResult(
                    output="O checklist estÃ¡ vazio ou nÃ£o foi encontrado."
                )

            formatted_tasks = ["Checklist Principal de Tarefas:"]
            for task in tasks:
                agent_display = (
                    f" [Agente: {task.get('agent')}]" if task.get("agent") else ""
                )
                formatted_tasks.append(
                    f"- [{task.get('status', 'N/A')}]"
                    + agent_display
                    + f" {task.get('description', 'Sem descriÃ§Ã£o')}"
                )

            return ToolResult(output="\n".join(formatted_tasks))
        except Exception as e:
            logger.error(f"ViewChecklistTool: Error accessing checklist: {e}")
            raise ToolError(f"Erro ao visualizar checklist: {e}")


class AddChecklistTaskTool(BaseTool):
    name: str = "add_checklist_task"
    description: str = (
        "Adds a new task to the main checklist. Default status is 'Pendente'. "
        "Optionally specify the agent responsible for the task."
    )
    args_schema: Dict[str, Any] = {
        "type": "object",
        "properties": {
            "task_description": {
                "type": "string",
                "description": "The description of the task to add.",
            },
            "status": {
                "type": "string",
                "description": "Optional. The initial status of the task (e.g., Pendente, Em Andamento). Defaults to 'Pendente'.",
                "default": "Pendente",
                "enum": ["Pendente", "Em Andamento", "ConcluÃ­do", "Bloqueado"],
            },
            "assigned_agent": {
                "type": "string",
                "description": "Optional. Name of the agent assigned to this task.",
            },
        },
        "required": ["task_description"],
    }

    async def execute(
        self,
        task_description: str,
        status: str = "Pendente",
        assigned_agent: Optional[str] = None,
        **kwargs: Any,
    ) -> ToolResult:
        logger.info(
            f"AddChecklistTaskTool invoked with task_description: '{task_description}', status: '{status}', assigned_agent: '{assigned_agent}'"
        )
        try:
            # Validate status against allowed values (although schema should handle this, good for defense)
            allowed_statuses = self.args_schema["properties"]["status"]["enum"]
            if status not in allowed_statuses:
                raise ToolError(
                    f"Status invÃ¡lido '{status}'. Status permitidos sÃ£o: {', '.join(allowed_statuses)}"
                )

            manager = ChecklistManager()
            await manager._load_checklist()  # Load tasks explicitly
            success = await manager.add_task(
                task_description=task_description,
                status=status,
                assigned_agent=assigned_agent,
            )

            if success:
                msg = f"Tarefa '{task_description}' adicionada ao checklist com status '{status}'."
                if assigned_agent:
                    msg += f" Agente designado: {assigned_agent}."
                return ToolResult(output=msg)
            else:
                # Check if task exists to provide a more specific message
                existing_task = manager.get_task_by_description(task_description)
                if existing_task:
                    return ToolResult(
                        output=f"Falha ao adicionar tarefa '{task_description}'. Tarefa jÃ¡ existe com status '{existing_task['status']}'."
                    )
                return ToolResult(
                    output=f"Falha ao adicionar tarefa '{task_description}'. Consulte os logs para mais detalhes."
                )
        except ToolError as te:
            logger.error(f"AddChecklistTaskTool: ToolError adding task: {te}")
            raise te  # Re-raise ToolError
        except Exception as e:
            logger.error(f"AddChecklistTaskTool: Unexpected error adding task: {e}")
            raise ToolError(f"Erro inesperado ao adicionar tarefa ao checklist: {e}")


class UpdateChecklistTaskTool(BaseTool):
    name: str = "update_checklist_task"
    description: str = (
        "Updates the status of an existing task in the main checklist. "
        "You may also reassign the task to a different agent."
    )
    args_schema: Dict[str, Any] = {
        "type": "object",
        "properties": {
            "task_description": {
                "type": "string",
                "description": "The description of the task to update. Must match an existing task.",
            },
            "new_status": {
                "type": "string",
                "description": "The new status for the task (e.g., Pendente, Em Andamento, ConcluÃ­do, Bloqueado).",
                "enum": ["Pendente", "Em Andamento", "ConcluÃ­do", "Bloqueado"],
            },
            "new_agent": {
                "type": "string",
                "description": "Optional new agent responsible for the task.",
            },
        },
        "required": ["task_description", "new_status"],
    }

    async def execute(
        self,
        task_description: str,
        new_status: str,
        new_agent: Optional[str] = None,
        **kwargs: Any,
    ) -> ToolResult:
        logger.info(
            f"UpdateChecklistTaskTool invoked with task_description: '{task_description}', new_status: '{new_status}', new_agent: '{new_agent}'"
        )

        # Validate new_status against allowed values (although schema should handle this, good for defense)
        allowed_statuses = self.args_schema["properties"]["new_status"]["enum"]
        if new_status not in allowed_statuses:
            logger.warning(
                f"UpdateChecklistTaskTool: Invalid new_status provided: '{new_status}'"
            )
            raise ToolError(
                f"Status invÃ¡lido '{new_status}'. Status permitidos sÃ£o: {', '.join(allowed_statuses)}"
            )

        try:
            manager = ChecklistManager()
            await manager._load_checklist()  # Load tasks explicitly

            # Check if task exists before attempting update for a clearer message
            # get_task_by_description is synchronous as it operates on already loaded tasks
            task_to_update = manager.get_task_by_description(task_description)
            if not task_to_update:
                return ToolResult(
                    output=f"Falha ao atualizar status da tarefa '{task_description}'. Tarefa nÃ£o encontrada."
                )

            if task_to_update["status"] == new_status:
                return ToolResult(
                    output=f"Tarefa '{task_description}' jÃ¡ estÃ¡ com o status '{new_status}'. Nenhuma alteraÃ§Ã£o realizada."
                )

            success = await manager.update_task_status(
                task_description=task_description,
                new_status=new_status,
            )

            if success and new_agent:
                await manager.update_task_agent(
                    task_description=task_description,
                    new_agent=new_agent,
                )

            if success:
                msg = f"Status da tarefa '{task_description}' atualizado para '{new_status}'."
                if new_agent:
                    msg += f" Agente designado: {new_agent}."
                return ToolResult(output=msg)
            else:
                # This else might be redundant if the above checks (not found, already same status) are comprehensive
                return ToolResult(
                    output=f"Falha ao atualizar status da tarefa '{task_description}'. Verifique se a tarefa existe e o novo status Ã© diferente do atual."
                )
        except ToolError as te:
            logger.error(f"UpdateChecklistTaskTool: ToolError updating task: {te}")
            raise te  # Re-raise ToolError
        except Exception as e:
            logger.error(
                f"UpdateChecklistTaskTool: Unexpected error updating task: {e}"
            )
            raise ToolError(
                f"Erro inesperado ao atualizar status da tarefa no checklist: {e}"
            )

```

### ARQUIVO: app/tool/web_search.py ###
```py
import asyncio
from typing import Any, Dict, List, Optional

import requests
from bs4 import BeautifulSoup
from pydantic import BaseModel, ConfigDict, Field, model_validator
from tenacity import retry, stop_after_attempt, wait_exponential

from app.config import config
from app.logger import logger
from app.tool.base import BaseTool, ToolResult
from app.tool.search import (
    BaiduSearchEngine,
    BingSearchEngine,
    DuckDuckGoSearchEngine,
    GoogleSearchEngine,
    WebSearchEngine,
)
from app.tool.search.base import SearchItem


class SearchResult(BaseModel):
    """Represents a single search result returned by a search engine."""

    model_config = ConfigDict(arbitrary_types_allowed=True)

    position: int = Field(description="Position in search results")
    url: str = Field(description="URL of the search result")
    title: str = Field(default="", description="Title of the search result")
    description: str = Field(
        default="", description="Description or snippet of the search result"
    )
    source: str = Field(description="The search engine that provided this result")
    raw_content: Optional[str] = Field(
        default=None, description="Raw content from the search result page if available"
    )

    def __str__(self) -> str:
        """String representation of a search result."""
        return f"{self.title} ({self.url})"


class SearchMetadata(BaseModel):
    """Metadata about the search operation."""

    model_config = ConfigDict(arbitrary_types_allowed=True)

    total_results: int = Field(description="Total number of results found")
    language: str = Field(description="Language code used for the search")
    country: str = Field(description="Country code used for the search")


class SearchResponse(ToolResult):
    """Structured response from the web search tool, inheriting ToolResult."""

    query: str = Field(description="The search query that was executed")
    results: List[SearchResult] = Field(
        default_factory=list, description="List of search results"
    )
    metadata: Optional[SearchMetadata] = Field(
        default=None, description="Metadata about the search"
    )

    @model_validator(mode="after")
    def populate_output(self) -> "SearchResponse":
        """Populate output or error fields based on search results."""
        if self.error:
            return self

        result_text = [f"Search results for '{self.query}':"]

        for i, result in enumerate(self.results, 1):
            # Add title with position number
            title = result.title.strip() or "No title"
            result_text.append(f"\n{i}. {title}")

            # Add URL with proper indentation
            result_text.append(f"   URL: {result.url}")

            # Add description if available
            if result.description.strip():
                result_text.append(f"   Description: {result.description}")

            # Add content preview if available
            if result.raw_content:
                content_preview = result.raw_content[:1000].replace("\n", " ").strip()
                if len(result.raw_content) > 1000:
                    content_preview += "..."
                result_text.append(f"   Content: {content_preview}")

        # Add metadata at the bottom if available
        if self.metadata:
            result_text.extend(
                [
                    f"\nMetadata:",
                    f"- Total results: {self.metadata.total_results}",
                    f"- Language: {self.metadata.language}",
                    f"- Country: {self.metadata.country}",
                ]
            )

        self.output = "\n".join(result_text)
        return self


class WebContentFetcher:
    """Utility class for fetching web content."""

    @staticmethod
    async def fetch_content(url: str, timeout: int = 10) -> Optional[str]:
        """
        Fetch and extract the main content from a webpage.

        Args:
            url: The URL to fetch content from
            timeout: Request timeout in seconds

        Returns:
            Extracted text content or None if fetching fails
        """
        headers = {
            "WebSearch": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }

        try:
            # Use asyncio to run requests in a thread pool
            response = await asyncio.get_event_loop().run_in_executor(
                None, lambda: requests.get(url, headers=headers, timeout=timeout)
            )

            if response.status_code != 200:
                logger.warning(
                    f"Failed to fetch content from {url}: HTTP {response.status_code}"
                )
                return None

            # Parse HTML with BeautifulSoup
            soup = BeautifulSoup(response.text, "html.parser")

            # Remove script and style elements
            for script in soup(["script", "style", "header", "footer", "nav"]):
                script.extract()

            # Get text content
            text = soup.get_text(separator="\n", strip=True)

            # Clean up whitespace and limit size (100KB max)
            text = " ".join(text.split())
            return text[:10000] if text else None

        except requests.exceptions.RequestException as e_req:
            logger.warning(f"RequestException fetching content from {url}: {e_req}")
            return None
        except Exception as e_gen: # Captura outras exceÃ§Ãµes como parsing do BeautifulSoup
            logger.warning(f"Generic error fetching/processing content from {url}: {e_gen}")
            return None


class WebSearch(BaseTool):
    """Search the web for information using various search engines."""

    name: str = "web_search"
    description: str = """Search the web for real-time information about any topic.
    This tool returns comprehensive search results with relevant information, URLs, titles, and descriptions.
    If the primary search engine fails, it automatically falls back to alternative engines."""
    parameters: dict = {
        "type": "object",
        "properties": {
            "query": {
                "type": "string",
                "description": "(required) The search query to submit to the search engine.",
            },
            "num_results": {
                "type": "integer",
                "description": "(optional) The number of search results to return. Default is 5.",
                "default": 5,
            },
            "lang": {
                "type": "string",
                "description": "(optional) Language code for search results (default: en).",
                "default": "en",
            },
            "country": {
                "type": "string",
                "description": "(optional) Country code for search results (default: us).",
                "default": "us",
            },
            "fetch_content": {
                "type": "boolean",
                "description": "(optional) Whether to fetch full content from result pages. Default is false.",
                "default": False,
            },
        },
        "required": ["query"],
    }
    _search_engine: dict[str, WebSearchEngine] = {
        "google": GoogleSearchEngine(),
        "baidu": BaiduSearchEngine(),
        "duckduckgo": DuckDuckGoSearchEngine(),
        "bing": BingSearchEngine(),
    }
    content_fetcher: WebContentFetcher = WebContentFetcher()

    async def execute(
        self,
        query: str,
        num_results: int = 5,
        lang: Optional[str] = None,
        country: Optional[str] = None,
        fetch_content: bool = False,
    ) -> SearchResponse:
        """
        Execute a Web search and return detailed search results.

        Args:
            query: The search query to submit to the search engine
            num_results: The number of search results to return (default: 5)
            lang: Language code for search results (default from config)
            country: Country code for search results (default from config)
            fetch_content: Whether to fetch content from result pages (default: False)

        Returns:
            A structured response containing search results and metadata
        """
        # Get settings from config
        retry_delay = (
            getattr(config.search_config, "retry_delay", 60)
            if config.search_config
            else 60
        )
        max_retries = (
            getattr(config.search_config, "max_retries", 3)
            if config.search_config
            else 3
        )

        # Use config values for lang and country if not specified
        if lang is None:
            lang = (
                getattr(config.search_config, "lang", "en")
                if config.search_config
                else "en"
            )

        if country is None:
            country = (
                getattr(config.search_config, "country", "us")
                if config.search_config
                else "us"
            )

        search_params = {"lang": lang, "country": country}

        # Try searching with retries when all engines fail
        for retry_count in range(max_retries + 1):
            results = await self._try_all_engines(query, num_results, search_params)

            if results:
                # Fetch content if requested
                if fetch_content:
                    results = await self._fetch_content_for_results(results)

                # Return a successful structured response
                return SearchResponse(
                    status="success",
                    query=query,
                    results=results,
                    metadata=SearchMetadata(
                        total_results=len(results),
                        language=lang,
                        country=country,
                    ),
                )

            if retry_count < max_retries:
                # All engines failed, wait and retry
                logger.warning(
                    f"All search engines failed. Waiting {retry_delay} seconds before retry {retry_count + 1}/{max_retries}..."
                )
                await asyncio.sleep(retry_delay)
            else:
                logger.error(
                    f"All search engines failed after {max_retries} retries. Giving up."
                )

        # Return an error response
        return SearchResponse(
            query=query,
            error="All search engines failed to return results after multiple retries.",
            results=[],
        )

    async def _try_all_engines(
        self, query: str, num_results: int, search_params: Dict[str, Any]
    ) -> List[SearchResult]:
        """Try all search engines in the configured order."""
        engine_order = self._get_engine_order()
        all_attempted_engines_failed = True # Flag para rastrear se alguma busca teve sucesso

        for engine_name in engine_order:
            engine = self._search_engine[engine_name]
            logger.info(f"ğŸ” Attempting search with {engine_name.capitalize()}...")
            try:
                search_items = await self._perform_search_with_engine(
                    engine, query, num_results, search_params
                )

                if not search_items: # Se _perform_search_with_engine retornou lista vazia (por erro interno ou sem resultados)
                    logger.warning(f"Search with {engine_name.capitalize()} returned no items or failed.")
                    # NÃ£o adiciona a failed_engines aqui, _perform_search_with_engine jÃ¡ logou o erro especÃ­fico
                    continue # Tenta o prÃ³ximo motor

                # Se chegou aqui, a busca com este motor teve sucesso em retornar items
                all_attempted_engines_failed = False
                logger.info(
                    f"Search successful with {engine_name.capitalize()}."
                )

                # Transform search items into structured results
                return [
                    SearchResult(
                        position=i + 1,
                        url=item.url,
                        title=item.title
                        or f"Result {i+1}",  # Ensure we always have a title
                        description=item.description or "",
                        source=engine_name,
                    )
                    for i, item in enumerate(search_items)
                ]
            except Exception as e_engine_loop:
                # ExceÃ§Ã£o inesperada no loop _try_all_engines, fora de _perform_search_with_engine
                logger.error(f"Unexpected error using engine {engine_name.capitalize()} in _try_all_engines: {e_engine_loop}")
                # Continua para o prÃ³ximo motor
                continue


        if all_attempted_engines_failed:
            logger.error(f"All search engines attempted and failed for query: '{query}'")
        return []

    async def _fetch_content_for_results(
        self, results: List[SearchResult]
    ) -> List[SearchResult]:
        """Fetch and add web content to search results."""
        if not results:
            return []

        # Create tasks for each result
        tasks = [self._fetch_single_result_content(result) for result in results]

        # Type annotation to help type checker
        fetched_results = await asyncio.gather(*tasks)

        # Explicit validation of return type
        return [
            (
                result
                if isinstance(result, SearchResult)
                else SearchResult(**result.dict())
            )
            for result in fetched_results
        ]

    async def _fetch_single_result_content(self, result: SearchResult) -> SearchResult:
        """Fetch content for a single search result."""
        if result.url:
            content = await self.content_fetcher.fetch_content(result.url)
            if content:
                result.raw_content = content
        return result

    def _get_engine_order(self) -> List[str]:
        """Determines the order in which to try search engines."""
        preferred = (
            getattr(config.search_config, "engine", "google").lower()
            if config.search_config
            else "google"
        )
        fallbacks = (
            [engine.lower() for engine in config.search_config.fallback_engines]
            if config.search_config
            and hasattr(config.search_config, "fallback_engines")
            else []
        )

        # Start with preferred engine, then fallbacks, then remaining engines
        engine_order = [preferred] if preferred in self._search_engine else []
        engine_order.extend(
            [
                fb
                for fb in fallbacks
                if fb in self._search_engine and fb not in engine_order
            ]
        )
        engine_order.extend([e for e in self._search_engine if e not in engine_order])

        return engine_order

    @retry(
        stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=1, max=10)
    )
    async def _perform_search_with_engine(
        self,
        engine: WebSearchEngine,
        query: str,
        num_results: int,
        search_params: Dict[str, Any],
    ) -> List[SearchItem]:
        """Execute search with the given engine and parameters."""
        try:
            # The actual search operation
            search_results_iterator = engine.perform_search(
                query,
                num_results=num_results,
                lang=search_params.get("lang"),
                country=search_params.get("country"),
            )
            # Convert iterator to list within the executor to ensure all network/blocking calls happen there
            return await asyncio.get_event_loop().run_in_executor(
                None,
                list, # Convert iterator to list
                search_results_iterator
            )
        except requests.exceptions.Timeout as e_timeout:
            logger.warning(f"Timeout during search with {engine.__class__.__name__} for query '{query}': {e_timeout}")
            return [] # Retorna lista vazia em caso de timeout
        except requests.exceptions.RequestException as e_req:
            logger.warning(f"RequestException during search with {engine.__class__.__name__} for query '{query}': {e_req}")
            return [] # Retorna lista vazia em caso de erro de requisiÃ§Ã£o
        except Exception as e_general:
            logger.error(
                f"Generic error during search with {engine.__class__.__name__} for query '{query}': {e_general}"
            )
            return [] # Retorna lista vazia para outros erros


if __name__ == "__main__":
    web_search = WebSearch()
    search_response = asyncio.run(
        web_search.execute(
            query="Python programming", fetch_content=True, num_results=1
        )
    )
    print(search_response.to_tool_result())

```

### ARQUIVO: app/tool/code_editor_tools.py ###
```py
import os
import traceback
from typing import Dict, Union
import asyncio

# Imports for ASTRefactorTool
import ast
try:
    import astunparse
except ImportError:
    astunparse = None # Handled in the tool's execute method

from app.tool.base import BaseTool
from app.logger import logger
from app.config import config # For workspace path

class ReplaceCodeBlock(BaseTool):
    name: str = "replace_code_block"
    description: str = (
        "Replaces a block of code in a specified file between a given start_line and end_line (inclusive). "
        "Line numbers are 1-indexed. Relative paths are resolved from the agent's workspace root."
    )
    parameters: dict = {
        "type": "object",
        "properties": {
            "path": {
                "type": "string",
                "description": "The relative (from workspace root) or absolute path to the file to be modified.",
            },
            "start_line": {
                "type": "integer",
                "description": "The 1-indexed line number where the replacement block starts.",
            },
            "end_line": {
                "type": "integer",
                "description": "The 1-indexed line number where the replacement block ends (inclusive).",
            },
            "new_content": {
                "type": "string",
                "description": "The new code content to insert. Can be multi-line. Empty string to delete lines.",
            },
        },
        "required": ["path", "start_line", "end_line", "new_content"],
    }

    async def execute(self, path: str, start_line: int, end_line: int, new_content: str) -> Dict[str, str]:
        if not os.path.isabs(path):
            file_path = os.path.join(config.workspace_root, path)
        else:
            file_path = path

        file_path = os.path.normpath(file_path)

        if not os.path.isabs(path):
            if not file_path.startswith(os.path.normpath(config.workspace_root)):
                logger.error(f"Path traversal attempt detected. Original path: '{path}', Resolved path: '{file_path}' is outside workspace '{config.workspace_root}'.")
                return {"error": "Path traversal attempt detected. Operation is not allowed."}

        if not os.path.isfile(file_path):
            logger.error(f"File not found at path: {file_path}")
            return {"error": f"File not found: {path} (resolved to: {file_path})"}

        if start_line <= 0:
            logger.error(f"Invalid start_line: {start_line}. Must be > 0.")
            return {"error": "start_line must be 1-indexed and greater than 0."}
        if end_line < start_line:
            logger.error(f"Invalid end_line: {end_line}. Must be >= start_line ({start_line}).")
            return {"error": "end_line must be greater than or equal to start_line."}

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                lines = f.readlines()

            if start_line > len(lines) + 1 :
                 logger.error(f"start_line ({start_line}) is too far beyond the end of the file ({len(lines)} lines).")
                 return {"error": f"start_line ({start_line}) is too far beyond the end of the file ({len(lines)} lines). To append, start_line can be at most {len(lines) + 1}."}

            start_line_0idx = start_line - 1
            end_line_0idx = end_line
            pre_block = lines[:start_line_0idx]

            if end_line_0idx >= len(lines):
                post_block = []
            else:
                post_block = lines[end_line_0idx:]

            if new_content:
                new_content_lines = new_content.splitlines(True)
            else:
                new_content_lines = []
                if start_line_0idx == len(lines) and not lines:
                    pass
                elif start_line_0idx > len(lines):
                     logger.error(f"start_line ({start_line}) is beyond the end of the file ({len(lines)} lines) and new_content is empty. Nothing to replace.")
                     return {"error": f"start_line ({start_line}) is beyond the end of the file ({len(lines)} lines) and new_content is empty. Nothing to replace."}

            final_lines = pre_block + new_content_lines + post_block

            with open(file_path, "w", encoding="utf-8") as f:
                f.writelines(final_lines)

            action = "appended to" if start_line_0idx == len(lines) and new_content else "replaced lines"
            if not new_content and start_line <= end_line :
                action = "deleted lines" if end_line <= len(lines) else "deleted lines until end of file"

            end_line_display = min(end_line, len(lines)) if start_line <= len(lines) else len(lines)

            logger.info(f"Successfully {action} {start_line}-{end_line_display if new_content else end_line} in file {file_path}")
            return {"status": f"Successfully {action} {start_line}-{end_line_display if new_content else end_line} in file {path}."}

        except Exception as e:
            logger.error(f"Error replacing code block in {file_path}: {e}\n{traceback.format_exc()}")
            return {"error": f"An unexpected error occurred: {str(e)}"}


class ApplyDiffPatch(BaseTool):
    name: str = "apply_diff_patch"
    description: str = (
        "Applies a patch (in unified diff format) to a specified file. "
        "Useful for complex or non-contiguous code changes. "
        "Relative paths are resolved from the agent's workspace root."
    )
    parameters: dict = {
        "type": "object",
        "properties": {
            "path": {
                "type": "string",
                "description": "The relative (from workspace root) or absolute path to the file to be patched.",
            },
            "patch_content": {
                "type": "string",
                "description": "The content of the patch in unified diff format.",
            },
        },
        "required": ["path", "patch_content"],
    }

    async def execute(self, path: str, patch_content: str) -> Dict[str, str]:
        if not os.path.isabs(path):
            file_path = os.path.join(config.workspace_root, path)
        else:
            file_path = path

        file_path = os.path.normpath(file_path)

        if not os.path.isabs(path):
            if not file_path.startswith(os.path.normpath(config.workspace_root)):
                logger.error(f"Path traversal attempt detected for patch application. Original path: '{path}', Resolved path: '{file_path}' is outside workspace '{config.workspace_root}'.")
                return {"error": "Path traversal attempt detected. Operation is not allowed."}

        if not os.path.isfile(file_path):
            logger.error(f"File not found at path for patching: {file_path}")
            return {"error": f"File not found for patching: {path} (resolved to: {file_path})"}

        if not patch_content.strip():
            return {"error": "Patch content cannot be empty."}

        try:
            if not patch_content.endswith('\n'):
                patch_content += '\n'

            command = f"patch '{file_path}'"

            process = await asyncio.create_subprocess_shell(
                command,
                stdin=asyncio.subprocess.PIPE,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
            )
            stdout, stderr = await process.communicate(input=patch_content.encode('utf-8'))

            if process.returncode == 0:
                logger.info(f"Patch successfully applied to {file_path}. Output: {stdout.decode('utf-8', 'replace')}")
                return {"status": f"Patch successfully applied to {path}.", "details": stdout.decode('utf-8', 'replace')}
            else:
                error_message = f"Failed to apply patch to {file_path}. Return code: {process.returncode}. Error: {stderr.decode('utf-8', 'replace')}. Stdout: {stdout.decode('utf-8', 'replace')}"
                logger.error(error_message)
                return {"error": error_message}

        except FileNotFoundError:
            logger.error("The 'patch' command-line utility was not found. Please ensure it is installed and in the system PATH.")
            return {"error": "The 'patch' command-line utility not found. It needs to be installed on the system."}
        except Exception as e:
            logger.error(f"An unexpected error occurred while applying patch to {file_path}: {e}\n{traceback.format_exc()}")
            return {"error": f"An unexpected error occurred during patch application: {str(e)}"}


class ASTRefactorTool(BaseTool):
    name: str = "ast_refactor"
    description: str = (
        "Performs AST-based refactoring for Python code. "
        "Initially supports 'replace_function_body'. "
        "Requires 'astunparse' library. Relative paths are resolved from workspace root."
    )
    parameters: dict = {
        "type": "object",
        "properties": {
            "path": {
                "type": "string",
                "description": "The relative (from workspace root) or absolute path to the Python file.",
            },
            "operation": {
                "type": "string",
                "description": "The refactoring operation to perform. Currently supports: 'replace_function_body'.",
                "enum": ["replace_function_body"],
            },
            "target_node_name": {
                "type": "string",
                "description": "The name of the target AST node (e.g., the function name whose body is to be replaced).",
            },
            "new_code_snippet": {
                "type": "string",
                "description": "The new Python code snippet to be used for the refactoring (e.g., the new function body).",
            }
        },
        "required": ["path", "operation", "target_node_name", "new_code_snippet"],
    }

    async def execute(self, path: str, operation: str, target_node_name: str, new_code_snippet: str) -> Dict[str, str]:
        if not astunparse:
            return {"error": "The 'astunparse' library is required for AST refactoring but is not installed."}

        if not os.path.isabs(path):
            file_path = os.path.join(config.workspace_root, path)
        else:
            file_path = path

        file_path = os.path.normpath(file_path)
        if not os.path.isabs(path):
            if not file_path.startswith(os.path.normpath(config.workspace_root)):
                logger.error(f"Path traversal attempt detected for AST refactoring: {file_path}")
                return {"error": "Path is outside the allowed workspace."}

        if not os.path.isfile(file_path):
            logger.error(f"File not found for AST refactoring: {file_path}")
            return {"error": f"File not found: {path} (resolved to: {file_path})"}

        if operation != "replace_function_body":
            return {"error": f"Unsupported operation: {operation}. Currently only 'replace_function_body' is supported."}

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                source_code = f.read()

            original_tree = ast.parse(source_code, filename=file_path)

            new_body_ast_module = ast.parse(new_code_snippet)
            new_body_nodes = new_body_ast_module.body
            if not new_body_nodes and not new_code_snippet.strip(): # if snippet is empty or only whitespace
                 new_body_nodes = [ast.Pass()]


            class FunctionBodyReplacer(ast.NodeTransformer):
                def __init__(self, target_fn_name: str, new_body_nodes: list):
                    super().__init__()
                    self.target_fn_name = target_fn_name
                    self.new_body_nodes = new_body_nodes
                    self.found_and_replaced = False

                def visit_FunctionDef(self, node: ast.FunctionDef):
                    if node.name == self.target_fn_name:
                        node.body = self.new_body_nodes
                        self.found_and_replaced = True
                        logger.info(f"Replaced body of function '{self.target_fn_name}' in AST.")
                    return node

            transformer = FunctionBodyReplacer(target_node_name, new_body_nodes)
            modified_tree = transformer.visit(original_tree)

            if not transformer.found_and_replaced:
                return {"error": f"Function '{target_node_name}' not found in {path}."}

            new_source_code = astunparse.unparse(modified_tree)

            with open(file_path, "w", encoding="utf-8") as f:
                f.write(new_source_code)

            logger.info(f"Successfully refactored (replaced body of '{target_node_name}') in {file_path}")
            return {"status": f"Successfully replaced body of function '{target_node_name}' in {path}."}

        except SyntaxError as e:
            logger.error(f"Syntax error during AST refactoring for {file_path}: {e}\n{traceback.format_exc()}")
            return {"error": f"Syntax error encountered: {str(e)}\nFull traceback in logs."} # Keep it concise for agent
        except Exception as e:
            logger.error(f"Error during AST refactoring for {file_path}: {e}\n{traceback.format_exc()}")
            return {"error": f"An unexpected error occurred during AST refactoring: {str(e)}"}

```

### ARQUIVO: app/tool/__init__.py ###
```py
from app.tool.base import BaseTool
from app.tool.bash import Bash
from app.tool.browser_use_tool import BrowserUseTool # Restaurado
from app.tool.create_chat_completion import CreateChatCompletion
from app.tool.planning import PlanningTool
from app.tool.str_replace_editor import StrReplaceEditor
from app.tool.terminate import Terminate
from app.tool.tool_collection import ToolCollection
from app.tool.web_search import WebSearch


__all__ = [
    "BaseTool",
    "Bash",
    "BrowserUseTool", # Restaurado
    "Terminate",
    "StrReplaceEditor",
    "WebSearch",
    "ToolCollection",
    "CreateChatCompletion",
    "PlanningTool",
]

```

### ARQUIVO: app/tool/background_process_tools.py ###
```py
import subprocess
import os
import psutil # Certifique-se de que psutil serÃ¡ adicionado aos requirements
from typing import Dict, Any, Optional
import json # Added import
from app.config import config # Already here, used for config.workspace_root

from app.tool.base import BaseTool
from app.logger import logger
# from app.config import config # No need to re-import if already at module level

class ExecuteBackgroundProcessTool(BaseTool):
    """
    Executes a shell command as a background process, detached from the agent's main execution lifecycle.
    It logs stdout and stderr to specified files and persists task information.
    """
    name: str = "execute_background_process"
    description: str = (
        "Executes a command as a background process, detached from the agent's main execution. "
        "Outputs stdout and stderr to specified log files and records the task."
    )
    parameters: Dict[str, Any] = {
        "type": "object",
        "properties": {
            "command": {"type": "string", "description": "The command to execute (e.g., 'python3 my_script.py arg1')."},
            "working_directory": {
                "type": "string",
                "description": "The working directory for the command. Defaults to agent's workspace root if not specified or if relative.",
                "nullable": True,
            },
            "log_file_stdout": {"type": "string", "description": "Path to the file where stdout will be logged. Must be within workspace."},
            "log_file_stderr": {"type": "string", "description": "Path to the file where stderr will be logged. Must be within workspace."},
            "task_description": {
                "type": "string",
                "description": "Optional. A brief description of the task being executed.",
                "nullable": True
            }
        },
        "required": ["command", "log_file_stdout", "log_file_stderr"],
    }

    async def execute(self, command: str, log_file_stdout: str, log_file_stderr: str, working_directory: Optional[str] = None, task_description: Optional[str] = None) -> Dict[str, Any]:
        """
        Executes the given command in the background.

        Args:
            command (str): The command string to execute (e.g., 'python3 my_script.py arg1').
            working_directory (Optional[str]): The working directory for the command.
                                               Defaults to the agent's workspace root if not specified or if relative.
            log_file_stdout (str): Path to the file where stdout will be logged. Must be within the workspace.
            log_file_stderr (str): Path to the file where stderr will be logged. Must be within the workspace.
            task_description (Optional[str]): An optional brief description of the task.

        Returns:
            Dict[str, Any]: A dictionary containing:
                - "pid" (Optional[int]): The PID of the started process, or None if an error occurred.
                - "log_stdout" (str): The absolute path to the stdout log file (if successful).
                - "log_stderr" (str): The absolute path to the stderr log file (if successful).
                - "status" (str): "started" if successful, or "error" if failed.
                - "message" (Optional[str]): An error message if the status is "error".
        """
        logger.info(f"Executing background command: {command} in dir: {working_directory}, description: {task_description}")

        processed_working_directory = working_directory # Renomeado para clareza
        if processed_working_directory:
            if not os.path.isabs(processed_working_directory):
                processed_working_directory = str(config.workspace_root / processed_working_directory)
            if not os.path.isdir(processed_working_directory):
                return {"pid": None, "status": "error", "message": f"Working directory '{processed_working_directory}' does not exist or is not a directory."}
        else:
            processed_working_directory = str(config.workspace_root)

        # Validar e normalizar caminhos de log
        processed_log_stdout = log_file_stdout
        processed_log_stderr = log_file_stderr
        for i, log_path_str in enumerate([log_file_stdout, log_file_stderr]):
            log_abs_path = os.path.abspath(str(config.workspace_root / log_path_str) if not os.path.isabs(log_path_str) else log_path_str)

            if not log_abs_path.startswith(str(config.workspace_root)):
                return {"pid": None, "status": "error", "message": f"Log file path '{log_path_str}' (resolved to '{log_abs_path}') is outside the allowed workspace directory."}

            if i == 0: processed_log_stdout = log_abs_path
            else: processed_log_stderr = log_abs_path

        # Garante que os diretÃ³rios para os arquivos de log existam
        for log_path in [processed_log_stdout, processed_log_stderr]:
            log_dir = os.path.dirname(log_path)
            if not os.path.exists(log_dir):
                try:
                    os.makedirs(log_dir, exist_ok=True)
                except Exception as e_mkdir:
                    return {"pid": None, "status": "error", "message": f"Failed to create directory for log file '{log_path}': {str(e_mkdir)}"}

        try:
            stdout_log = open(processed_log_stdout, 'wb')
            stderr_log = open(processed_log_stderr, 'wb')

            process = subprocess.Popen(
                command,
                shell=True,
                stdout=stdout_log,
                stderr=stderr_log,
                    cwd=processed_working_directory, # Usar o diretÃ³rio de trabalho processado
                start_new_session=True,
                close_fds=True
            )
            logger.info(f"Background process started. PID: {process.pid}, Command: {command}, stdout_log: {processed_log_stdout}, stderr_log: {processed_log_stderr}")

            # PersistÃªncia do estado da tarefa
            running_tasks_file = config.workspace_root / "running_tasks.json"
            tasks = []
            if os.path.exists(running_tasks_file):
                try:
                    with open(running_tasks_file, 'r') as f:
                        tasks = json.load(f)
                except (json.JSONDecodeError, FileNotFoundError) as e_read:
                    logger.error(f"Error reading running_tasks.json: {e_read}. Starting with an empty list.")
                    tasks = []

            # Remove existing task with the same PID if any
            tasks = [task for task in tasks if task.get('pid') != process.pid]

            new_task_info = {
                "pid": process.pid,
                "command": command,
                "working_directory": processed_working_directory,
                "log_stdout": processed_log_stdout,
                "log_stderr": processed_log_stderr,
                "status": "started",
                "task_description": task_description if task_description else "N/A"
            }
            tasks.append(new_task_info)

            try:
                with open(running_tasks_file, 'w') as f:
                    json.dump(tasks, f, indent=4)
                logger.info(f"Task PID {process.pid} persisted to {running_tasks_file}")
            except Exception as e_write:
                logger.error(f"Error writing to running_tasks.json: {e_write}")
                # Optionally, could add this error to the return dict if critical

            return {"pid": process.pid, "log_stdout": processed_log_stdout, "log_stderr": processed_log_stderr, "status": "started"}
        except Exception as e:
            logger.error(f"Failed to start background process: {e}", exc_info=True)
            if 'stdout_log' in locals() and stdout_log: stdout_log.close()
            if 'stderr_log' in locals() and stderr_log: stderr_log.close()
            return {"pid": None, "status": "error", "message": f"Failed to start background process: {str(e)}"}

class CheckProcessStatusTool(BaseTool):
    """
    Checks the status of a process given its Process ID (PID) using psutil.
    """
    name: str = "check_process_status"
    description: str = "Checks the status of a process given its PID."
    parameters: Dict[str, Any] = {
        "type": "object",
        "properties": {"pid": {"type": "integer", "description": "The Process ID (PID) to check."}},
        "required": ["pid"],
    }

    async def execute(self, pid: int) -> Dict[str, Any]:
        """
        Checks the status of the process with the given PID.

        Args:
            pid (int): The Process ID (PID) to check.

        Returns:
            Dict[str, Any]: A dictionary containing:
                - "pid" (int): The PID checked.
                - "status" (str): The status of the process. Possible values include:
                    - "running": Process is actively running or sleeping.
                    - "finished": Process has terminated.
                    - "not_found": Process with the given PID does not exist.
                    - "error": An error occurred during the check (e.g., access denied, invalid PID).
                    - psutil status strings (e.g., 'sleeping', 'zombie') might also be returned directly
                      as 'psutil_status' if not mapped to a consolidated status.
                - "psutil_status" (Optional[str]): The raw status string from psutil (e.g., 'running', 'sleeping', 'zombie').
                - "return_code" (Optional[int]): The exit code of the process if it has finished and the code is available.
                                                 None otherwise.
                - "message" (Optional[str]): An error or informational message if applicable.
        """
        logger.info(f"Checking status for PID: {pid}")
        if pid is None or pid <= 0: # PID 0 or negative is invalid
            return {"pid": pid, "status": "error", "message": "Invalid PID (null, zero, or negative) provided.", "return_code": None}
        try:
            if not psutil.pid_exists(pid):
                logger.info(f"PID {pid} does not exist.")
                return {"pid": pid, "status": "not_found", "message": "Process not found (pid_exists is false).", "return_code": None}

            process = psutil.Process(pid)
            status = process.status() # E.g., 'running', 'sleeping', 'zombie', 'stopped'
            return_code = None

            if status == psutil.STATUS_ZOMBIE: # Process is a zombie, effectively finished
                try:
                    # For zombies, wait() should return immediately.
                    # This is to reap the process and get its exit code.
                    return_code = process.wait(timeout=0.01)
                    status = "finished" # Update status more definitively
                except psutil.TimeoutExpired: # Should not happen for true zombies if parent is us
                    logger.warning(f"PID {pid} is zombie, but wait() timed out. Return code might be unavailable.")
                except psutil.NoSuchProcess: # Zombie reaped by someone else
                    return {"pid": pid, "status": "finished_or_not_found", "message": "Zombie process reaped by another process during check.", "return_code": None}

            elif status not in [psutil.STATUS_RUNNING, psutil.STATUS_SLEEPING, psutil.STATUS_DISK_SLEEP, psutil.STATUS_WAKING, psutil.STATUS_PARKED, psutil.STATUS_IDLE]:
                # If status is something like 'stopped', 'dead', it has effectively finished or is not runnable
                # Try to get return code, but it might not be available if already waited on.
                try:
                    return_code = process.returncode
                    if return_code is None and status == psutil.STATUS_DEAD: # If dead and no returncode, might have been killed
                         pass # Keep return_code as None
                    status = "finished" # Consolidate terminal states
                except psutil.Error: # process.returncode could raise if not terminated
                    pass # keep original status if returncode access fails

            logger.info(f"PID {pid} status: {status}, psutil_status: {process.status()}, return_code: {return_code}")
            return {"pid": pid, "status": status, "psutil_status": process.status(), "return_code": return_code}
        except psutil.NoSuchProcess:
            logger.info(f"PID {pid} not found by psutil (NoSuchProcess exception).")
            return {"pid": pid, "status": "not_found", "message": "Process not found (NoSuchProcess exception).", "return_code": None}
        except psutil.AccessDenied:
            logger.warning(f"Access denied when checking PID {pid}.")
            return {"pid": pid, "status": "error", "message": "Access denied to process information.", "return_code": None}
        except Exception as e:
            logger.error(f"Error checking PID {pid}: {e}", exc_info=True)
            return {"pid": pid, "status": "error", "message": f"Error checking process status: {str(e)}", "return_code": None}

class GetProcessOutputTool(BaseTool):
    """
    Reads the content of a specified log file, typically used for checking the output
    of background processes. Allows to tail the last N lines of the file.
    """
    name: str = "get_process_output"
    description: str = "Reads the content of a log file, typically associated with a background process. Can tail the last N lines."
    parameters: Dict[str, Any] = {
        "type": "object",
        "properties": {
            "log_file": {"type": "string", "description": "The path to the log file to read. Must be within workspace."},
            "tail_lines": {
                "type": "integer",
                "description": "Optional. If provided, returns only the last N lines of the file.",
                "nullable": True
            },
        },
        "required": ["log_file"],
    }

    async def execute(self, log_file: str, tail_lines: Optional[int] = None) -> Dict[str, Any]:
        """
        Reads content from the specified log file.

        Args:
            log_file (str): The path to the log file. If relative, it's considered
                            relative to the agent's workspace root.
            tail_lines (Optional[int]): If provided and positive, returns only the
                                        last N lines from the file. Otherwise, returns
                                        the full content.

        Returns:
            Dict[str, Any]: A dictionary containing:
                - "log_file" (str): The absolute path of the log file read.
                - "content" (Optional[str]): The content of the file, or None if an error occurred.
                - "error" (Optional[str]): An error message if reading failed or the file
                                           was invalid/not found.
        """
        logger.info(f"Getting output for log file: {log_file}, tail: {tail_lines}")

        log_abs_path = os.path.abspath(str(config.workspace_root / log_file) if not os.path.isabs(log_file) else log_file)

        if not log_abs_path.startswith(str(config.workspace_root)):
            return {"log_file": log_file, "content": None, "error": f"Log file path '{log_file}' (resolved to '{log_abs_path}') is outside the allowed workspace directory."}

        if not os.path.exists(log_abs_path):
            return {"log_file": log_abs_path, "content": None, "error": "Log file not found."}
        if not os.path.isfile(log_abs_path):
            return {"log_file": log_abs_path, "content": None, "error": "Specified path is not a file."}

        try:
            with open(log_abs_path, 'r', encoding='utf-8', errors='replace') as f:
                if tail_lines is not None and tail_lines > 0:
                    lines = f.readlines() # Reads all lines, could be memory intensive for huge files
                    content = "".join(lines[-tail_lines:])
                else:
                    content = f.read()
            return {"log_file": log_abs_path, "content": content, "error": None}
        except Exception as e:
            logger.error(f"Error reading log file {log_abs_path}: {e}", exc_info=True)
            return {"log_file": log_abs_path, "content": None, "error": f"Error reading log file: {str(e)}"}

```

### ARQUIVO: app/tool/python_execute.py ###
```py
import multiprocessing
import multiprocessing
import sys
import os
from io import StringIO
from typing import Dict, Optional
import traceback # Added import traceback
import ast # Added import ast
from app.logger import logger # Added import logger

from app.tool.base import BaseTool


class PythonExecute(BaseTool):
    """A tool for executing Python code with timeout and safety restrictions."""

    name: str = "python_execute"
    description: str = ("Executes a Python code string directly on the host machine (not in the sandbox). "
                        "Captures and returns stdout, stderr, and an exit_code. "
                        "Use 'working_directory' to specify the execution path, especially if the code interacts with local files. "
                        "Avoid relative file paths if 'working_directory' is not set, as code runs in the agent's main process environment. "
                        "For file-based script execution or sandboxed execution, use 'sandbox_python_executor'. "
                        "This tool is best for simple, self-contained code snippets.")
    parameters: dict = {
        "type": "object",
        "properties": {
            "code": {
                "type": "string",
                "description": "The Python code to execute.",
            },
            "working_directory": { # Novo parÃ¢metro
                "type": "string",
                "description": "Optional. The working directory in which to execute the code. Defaults to the agent's main process working directory if not specified.",
                "nullable": True
            },
            "timeout": {
                       "type": "integer",
                       "description": "Optional. The maximum execution time in seconds for the code. Defaults to 120 seconds.",
                       "default": 120
            }
        },
        "required": ["code"],
    }

    def _run_code(self, code: str, result_dict: dict, safe_globals: dict, working_directory: Optional[str] = None) -> None:
        original_stdout = sys.stdout
        original_stderr = sys.stderr # Capture original stderr
        original_cwd = os.getcwd()
        cwd_changed_successfully = False
        output_buffer = StringIO()
        error_buffer = StringIO() # Buffer for stderr
        sys.stdout = output_buffer
        sys.stderr = error_buffer # Redirect stderr

        try:
            if working_directory:
                if os.path.isdir(working_directory):
                    os.chdir(working_directory)
                    cwd_changed_successfully = True
                else:
                    # This error will be caught by the except block
                    raise FileNotFoundError(f"Specified working_directory '{working_directory}' does not exist or is not a directory.")

            exec(code, safe_globals, safe_globals)
            result_dict["stdout"] = output_buffer.getvalue()
            result_dict["stderr"] = error_buffer.getvalue()
            result_dict["exit_code"] = 0
            result_dict["success"] = True
            result_dict["observation"] = result_dict["stdout"] # Keep observation as stdout for compatibility
        except Exception as e:
            stderr_capture = error_buffer.getvalue()
            exception_traceback = traceback.format_exc()
            result_dict["stdout"] = output_buffer.getvalue() # Capture any stdout before the error
            result_dict["stderr"] = (stderr_capture + "\n" + str(e) + "\n" + exception_traceback).strip()
            result_dict["exit_code"] = 1
            result_dict["success"] = False
            result_dict["observation"] = result_dict["stderr"] # Keep observation as stderr on error
        finally:
            sys.stdout = original_stdout
            sys.stderr = original_stderr # Restore original stderr
            if cwd_changed_successfully:
                os.chdir(original_cwd)

    async def execute(
        self,
        code: str,
        timeout: int = 120,
        working_directory: Optional[str] = None,
    ) -> Dict:
        """
        Executes the provided Python code with a timeout.

        Args:
            code (str): The Python code to execute.
            timeout (int): Optional. The maximum execution time in seconds for the code.
                           Defaults to 120 seconds as configured in the class.
            working_directory (Optional[str]): Optional. The working directory for code execution.
                                               Defaults to the agent's main process working directory if not specified.

        Returns:
            Dict: Contains 'stdout', 'stderr', 'exit_code', 'success' status, and 'observation'.
                  'exit_code' is 0 for success, 1 for error or timeout.
                  'success' is True if exit_code is 0, False otherwise.
                  'observation' mirrors 'stdout' on success and 'stderr' on failure.
        """
        try:
            ast.parse(code)
        except SyntaxError as e:
            logger.error(f"SyntaxError in provided code: {e}\n{traceback.format_exc()}")
            error_details = f"SyntaxError: {str(e)}\n{traceback.format_exc()}"
            return {
                "stdout": "",
                "stderr": error_details,
                "exit_code": 1, # Consistent with other execution failures
                "success": False,
                "observation": error_details
            }

        with multiprocessing.Manager() as manager:
            result = manager.dict({"stdout": "", "stderr": "", "exit_code": -1, "success": False, "observation": ""})
            if isinstance(__builtins__, dict):
                safe_globals = {"__builtins__": __builtins__}
            else:
                safe_globals = {"__builtins__": __builtins__.__dict__.copy()}

            # Passar working_directory para o target _run_code
            proc = multiprocessing.Process(
                target=self._run_code, args=(code, result, safe_globals, working_directory)
            )
            proc.start()
            proc.join(timeout)

            # timeout process
            if proc.is_alive():
                proc.terminate()
                proc.join(1) # Dar um segundo para o terminate
                # Adicionar working_directory Ã  mensagem de timeout se ele foi especificado
                timeout_message = f"Execution timeout after {timeout} seconds"
                if working_directory:
                    timeout_message += f" (in working_directory: '{working_directory}')"
                return {"stdout": "", "stderr": timeout_message, "exit_code": 1, "success": False, "observation": timeout_message}
            return dict(result)

```

### ARQUIVO: app/tool/sandbox_python_executor.py ###
```py
import asyncio # Should be there
import os # Added
import uuid # Should be there
from typing import Any, Dict, Optional # Optional should be there

from app.sandbox.client import SANDBOX_CLIENT
from app.config import config
from app.sandbox.core.exceptions import SandboxTimeoutError
from app.tool.base import BaseTool
from app.exceptions import ToolError
from app.logger import logger # Added


class SandboxPythonExecutor(BaseTool):
    """
    Executes Python code or a Python script file within a secure sandbox environment.
    If 'file_path' is provided, it must be an absolute path to a Python script on the
    host machine, located within the agent's configured workspace root. This file will
    be copied into the sandbox for execution.
    If 'code' is provided, the raw Python code string will be executed.
    Only one of 'file_path' or 'code' can be provided.
    The tool captures and returns stdout, stderr, and the exit code from the execution.
    """

    name: str = "sandbox_python_executor"
    description: str = (
        "Executes Python code (from string or host file_path) in a sandbox. "
        "If file_path is used, it must be an absolute path on the host within the workspace root. "
        "The file is copied to '/workspace/scripts_from_host/' in the sandbox. "
        "Captures stdout, stderr, and exit code."
    )
    parameters: Dict[str, Any] = {
        "type": "object",
        "properties": {
            "code": {
                "type": "string",
                "description": "Optional. The Python code string to execute. If provided, 'file_path' must be None."
            },
            "file_path": {
                "type": "string",
                "description": "Optional. The absolute path to a Python script file on the host machine (must be within the configured workspace) to be executed in the sandbox. If provided, 'code' must be None."
            },
            "timeout": {
                "type": "integer",
                "description": "Maximum execution time in seconds.",
                "default": 60, # Default timeout increased as per new signature
            },
        },
        "required": [] # Validation of code OR file_path is done in execute
    }

    async def execute(self, code: Optional[str] = None, timeout: int = 60, file_path: Optional[str] = None) -> Dict[str, Any]:
        """
        Executes Python code from a string or a file path (copied from host) within the sandbox.

        Args:
            code: An optional string containing the Python code.
            timeout: Max execution time in seconds. Defaults to 60.
            file_path: An optional string specifying the absolute path to a Python script
                       on the host machine (within workspace_root) to be copied and executed.

        Returns:
            A dictionary containing the execution results:
            - "stdout" (str): The standard output from the executed code.
            - "stderr" (str): The standard error output. This will include
                              tracebacks if the Python script raises an unhandled exception.
            - "exit_code" (int): The exit code of the Python script.
                                 Typically, 0 indicates success, and non-zero
                                 indicates an error. A special exit code 124
                                 is used if the execution times out. Other negative
                                 values (-1, -2, -3) might indicate internal tool
                                 or sandbox errors.

        Raises:
            No explicit exceptions are raised by this method directly to the caller.
            Instead, errors are captured and returned within the result dictionary
            (e.g., in "stderr" and "exit_code").
            - SandboxTimeoutError: If execution exceeds `timeout`, `stderr` will
        """
        logger.info(f"SandboxPythonExecutor.execute called. Code provided: {bool(code)}, file_path: '{file_path}', timeout: {timeout}")
        # ValidaÃ§Ã£o inicial de parÃ¢metros
        if not code and not file_path:
            logger.warning("Neither 'code' nor 'file_path' provided to SandboxPythonExecutor. Aborting.")
            return {"stdout": "", "stderr": "ToolError: Either 'code' or 'file_path' must be provided.", "exit_code": -1}
        if code and file_path:
            logger.warning("Both 'code' and 'file_path' provided to SandboxPythonExecutor. Aborting.")
            return {"stdout": "", "stderr": "ToolError: Cannot provide both 'code' and 'file_path'.", "exit_code": -1}

        script_to_execute_in_sandbox = ""
        original_script_filename_on_host = None # Para saber se precisa limpar no sandbox depois
        # cleanup_temp_script_in_sandbox = False # Flag para limpar script temporÃ¡rio de 'code' # NÃ£o mais necessÃ¡ria com original_script_filename_on_host

        # Garantir que o sandbox estÃ¡ criado e rodando
        if not SANDBOX_CLIENT.sandbox or not SANDBOX_CLIENT.sandbox.container:
            try:
                await SANDBOX_CLIENT.create()
            except Exception as e:
                return {
                    "stdout": "",
                    "stderr": "ToolError: {'success': false, 'error_type': 'environment', 'message': 'Falha ao conectar com o sandbox. Verifique se o Docker estÃ¡ instalado e em execuÃ§Ã£o ou se a imagem configurada estÃ¡ disponÃ­vel.'}",
                    "exit_code": -2,
                }

        if file_path:
            host_abs_path = os.path.abspath(file_path)
            # Validar se o file_path estÃ¡ dentro do workspace_root configurado
            if not host_abs_path.startswith(str(config.workspace_root)):
                logger.warning(f"Attempt to execute file_path '{file_path}' (abs: '{host_abs_path}') outside workspace '{config.workspace_root}'. Denied.")
                return {"stdout": "", "stderr": f"ToolError: file_path '{file_path}' is outside the allowed workspace directory '{config.workspace_root}'.", "exit_code": -4}
            if not os.path.exists(host_abs_path):
                logger.warning(f"File_path '{file_path}' (abs: '{host_abs_path}') not found on host. Denied.")
                return {"stdout": "", "stderr": f"ToolError: file_path '{file_path}' does not exist on the host.", "exit_code": -4}
            if not os.path.isfile(host_abs_path):
                # This case might be redundant if os.path.exists already fails for non-files, but good for clarity
                logger.warning(f"File_path '{file_path}' (abs: '{host_abs_path}') is not a file. Denied.")
                return {"stdout": "", "stderr": f"ToolError: file_path '{file_path}' is not a file on the host.", "exit_code": -4}

            script_filename_in_sandbox = os.path.basename(host_abs_path)
            sandbox_internal_dir = "/workspace/scripts_from_host"

            try:
                # This mkdir might not be strictly necessary if copy_to handles dir creation,
                # but it's good for explicit control and logging.
                mkdir_cmd = f"mkdir -p {sandbox_internal_dir}"
                logger.info(f"Ensuring directory '{sandbox_internal_dir}' exists in sandbox.")
                mkdir_result = await SANDBOX_CLIENT.run_command(mkdir_cmd, timeout=10)
                if mkdir_result.get("exit_code") != 0:
                    logger.error(f"Failed to create directory '{sandbox_internal_dir}' in sandbox. Stderr: {mkdir_result.get('stderr','')}")
                    return {"stdout": "", "stderr": f"SandboxError: Failed to create directory '{sandbox_internal_dir}' in sandbox. Stderr: {mkdir_result.get('stderr','')}", "exit_code": -2}
            except Exception as e_mkdir:
                 logger.error(f"Exception creating directory '{sandbox_internal_dir}' in sandbox: {e_mkdir}")
                 return {"stdout": "", "stderr": f"SandboxError: Exception creating directory '{sandbox_internal_dir}' in sandbox: {e_mkdir}", "exit_code": -2}

            sandbox_internal_path = f"{sandbox_internal_dir}/{script_filename_in_sandbox}"
            logger.info(f"Preparing to copy from host path '{host_abs_path}' to sandbox path '{sandbox_internal_path}'")
            try:
                await SANDBOX_CLIENT.copy_to(local_path=host_abs_path, container_path=sandbox_internal_path)
                logger.info(f"Successfully copied '{host_abs_path}' to '{sandbox_internal_path}' in sandbox.")
                script_to_execute_in_sandbox = sandbox_internal_path
                original_script_filename_on_host = sandbox_internal_path # Guardar para limpeza no sandbox
            except Exception as e_copy:
                logger.error(f"Failed to copy file_path '{file_path}' to sandbox: {str(e_copy)}")
                return {"stdout": "", "stderr": f"ToolError: Failed to copy file_path '{file_path}' to sandbox: {str(e_copy)}", "exit_code": -4}

        elif code: # Se nÃ£o for file_path, mas code
            temp_script_filename = f"/tmp/{uuid.uuid4().hex}.py"
            logger.info(f"Writing provided code to temporary sandbox file: {temp_script_filename}")
            await SANDBOX_CLIENT.write_file(temp_script_filename, code)
            script_to_execute_in_sandbox = temp_script_filename
            original_script_filename_on_host = temp_script_filename # Guardar para limpeza no sandbox
            # cleanup_temp_script_in_sandbox = True # Marcar para limpar este script especÃ­fico de /tmp

        pid_file_sandbox_path = f"/tmp/script_pid_{uuid.uuid4().hex}.pid"
        command = f"sh -c 'echo $$ > {pid_file_sandbox_path}; exec python3 {script_to_execute_in_sandbox}'"
        logger.info(f"Executing command in sandbox: '{command}' (PID file: {pid_file_sandbox_path})")

        stdout_val = ""
        stderr_val = ""
        exit_code_val = -1
        # generated_files = [] # Mantido comentado

        try:
            result = await SANDBOX_CLIENT.run_command(command, timeout=timeout)
            stdout_val = result.get("stdout", "")
            stderr_val = result.get("stderr", "")
            exit_code_val = result.get("exit_code", -1)

            # LÃ³gica de copiar arquivos de /tmp para ./workspace (COMENTADA POR ENQUANTO)
            # A subtask nÃ£o pede para manter ou remover explicitamente, mas com a nova lÃ³gica de scripts
            # sendo executados de /workspace/scripts_from_host, esta parte pode precisar ser reavaliada.
            # if not (file_path and file_path.startswith("/tmp/")) and exit_code_val != 2 :
            #     os.makedirs("./workspace", exist_ok=True)
            #     list_files_cmd = "ls /tmp/ 2>/dev/null"
            #     # ... (resto da lÃ³gica como estava antes, mas precisa cuidado com script_filename vs original_script_filename_on_host)

        except SandboxTimeoutError as e_timeout:
            stderr_val = f"SandboxTimeoutError: A execuÃ§Ã£o do comando '{command}' excedeu o tempo limite de {timeout} segundos.\nDetalhes: {str(e_timeout)}"
            exit_code_val = 124
        except FileNotFoundError as e_fnf:
            stderr_val = f"FileNotFoundError during sandbox execution: {str(e_fnf)}"
            exit_code_val = 2
        except Exception as e_runtime:
            stderr_val = f"An unexpected error occurred during sandbox execution: {str(e_runtime)}"
            exit_code_val = -3

        if original_script_filename_on_host:
            try:
                cleanup_command = f"rm -f {original_script_filename_on_host}"
                logger.info(f"Attempting to cleanup sandbox script: {cleanup_command}")
                await SANDBOX_CLIENT.run_command(cleanup_command, timeout=5)
                logger.info(f"Successfully cleaned up sandbox script: {original_script_filename_on_host}")
            except Exception as e_cleanup:
                additional_stderr = f"Warning: Failed to cleanup script '{original_script_filename_on_host}' in sandbox: {str(e_cleanup)}"
                logger.warning(additional_stderr)
                stderr_val = f"{stderr_val}\n{additional_stderr}".strip()

        logger.info(f"Returning execution result: stdout='{stdout_val.strip()}', stderr='{stderr_val.strip()}', exit_code={exit_code_val}")
        return {
            "stdout": stdout_val.strip(),
            "stderr": stderr_val.strip(),
            "exit_code": exit_code_val,
            "pid_file_path": pid_file_sandbox_path
        }

# Example of how to register the tool (if a registration mechanism exists)
# This part is usually handled by the tool management system.
# from app.tool_registry import register_tool
# register_tool(SandboxPythonExecutor)

```

### ARQUIVO: app/tool/tool_collection.py ###
```py
"""Collection classes for managing multiple tools."""
from typing import Any, Dict, List

from app.exceptions import ToolError
from app.logger import logger
from app.tool.base import BaseTool, ToolFailure, ToolResult


class ToolCollection:
    """A collection of defined tools."""

    class Config:
        arbitrary_types_allowed = True

    def __init__(self, *tools: BaseTool):
        self.tools = tools
        self.tool_map = {tool.name: tool for tool in tools}

    def __iter__(self):
        return iter(self.tools)

    def to_params(self) -> List[Dict[str, Any]]:
        return [tool.to_param() for tool in self.tools]

    async def execute(
        self, *, name: str, tool_input: Dict[str, Any] = None
    ) -> ToolResult:
        tool = self.tool_map.get(name)
        if not tool:
            return ToolFailure(error=f"Tool {name} is invalid")
        try:
            result = await tool(**tool_input)
            return result
        except ToolError as e:
            return ToolFailure(error=e.message)

    async def execute_all(self) -> List[ToolResult]:
        """Execute all tools in the collection sequentially."""
        results = []
        for tool in self.tools:
            try:
                result = await tool()
                results.append(result)
            except ToolError as e:
                results.append(ToolFailure(error=e.message))
        return results

    def get_tool(self, name: str) -> BaseTool:
        return self.tool_map.get(name)

    def add_tool(self, tool: BaseTool):
        """Add a single tool to the collection.

        If a tool with the same name already exists, it will be skipped and a warning will be logged.
        """
        if tool.name in self.tool_map:
            logger.warning(f"Tool {tool.name} already exists in collection, skipping")
            return self

        self.tools += (tool,)
        self.tool_map[tool.name] = tool
        return self

    def add_tools(self, *tools: BaseTool):
        """Add multiple tools to the collection.

        If any tool has a name conflict with an existing tool, it will be skipped and a warning will be logged.
        """
        for tool in tools:
            self.add_tool(tool)
        return self

```

### ARQUIVO: app/tool/code_formatter.py ###
```py
import asyncio
import subprocess
import traceback
from typing import Dict, Union

from app.tool.base import BaseTool
from app.logger import logger

class FormatPythonCode(BaseTool):
    name: str = "format_python_code"
    description: str = (
        "Formats a given Python code string using an external formatter (Ruff, with Black as fallback). "
        "This helps ensure consistent code style and can fix minor syntax/indentation issues."
    )
    parameters: dict = {
        "type": "object",
        "properties": {
            "code": {
                "type": "string",
                "description": "The Python code string to format.",
            }
        },
        "required": ["code"],
    }

    async def execute(self, code: str) -> Union[str, Dict[str, str]]:
        """
        Formats the Python code using Ruff, with Black as a fallback.

        Args:
            code (str): The Python code string to format.

        Returns:
            Union[str, Dict[str, str]]: The formatted code string if successful,
                                         or a dictionary with an error message if formatting fails.
        """
        try:
            # Try Ruff first
            # Using --stdin-filename temp.py helps ruff apply project-specific rules if pyproject.toml is found
            process_ruff = await asyncio.create_subprocess_shell(
                "ruff format --stdin-filename temp.py -",
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
            )
            stdout_ruff, stderr_ruff = await process_ruff.communicate(input=code.encode())

            if process_ruff.returncode == 0:
                formatted_code = stdout_ruff.decode()
                logger.info("Code successfully formatted using Ruff.")
                return formatted_code
            else:
                ruff_error_output = stderr_ruff.decode()
                logger.warning(f"Ruff formatting failed. Return code: {process_ruff.returncode}. Error: {ruff_error_output}")
                logger.info("Attempting to format with Black as a fallback.")

                process_black = await asyncio.create_subprocess_shell(
                    "black -q -", # -q for quiet, suppresses non-error messages from Black
                    stdin=subprocess.PIPE,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                )
                stdout_black, stderr_black = await process_black.communicate(input=code.encode())

                if process_black.returncode == 0:
                    formatted_code_black = stdout_black.decode()
                    logger.info("Code successfully formatted using Black.")
                    return formatted_code_black
                else:
                    black_error_output = stderr_black.decode()
                    logger.error(f"Black formatting also failed. Return code: {process_black.returncode}. Error: {black_error_output}")
                    return {
                        "error": "Formatting failed with both Ruff and Black.",
                        "ruff_error": ruff_error_output,
                        "black_error": black_error_output,
                    }

        except FileNotFoundError as e:
            # This catches if 'ruff' or 'black' command itself is not found
            logger.error(f"Formatter command not found (Ruff or Black): {e}. Ensure they are installed and in PATH.")
            return {"error": f"Formatter command not found: {e}. Please ensure Ruff (or Black as fallback) is installed and in the system PATH."}
        except Exception as e:
            logger.error(f"An unexpected error occurred during code formatting: {e}\n{traceback.format_exc()}")
            return {"error": f"An unexpected error occurred during formatting: {str(e)}"}

```

### ARQUIVO: app/tool/terminate.py ###
```py
from app.tool.base import BaseTool


_TERMINATE_DESCRIPTION = """Encerre a interaÃ§Ã£o quando a solicitaÃ§Ã£o for atendida OU se o assistente nÃ£o puder prosseguir com a tarefa.
Quando vocÃª tiver concluÃ­do todas as tarefas, chame esta ferramenta para finalizar o trabalho."""


class Terminate(BaseTool):
    name: str = "terminate"
    description: str = _TERMINATE_DESCRIPTION
    parameters: dict = {
        "type": "object",
        "properties": {
            "status": {
                "type": "string",
                "description": "O status final da interaÃ§Ã£o.",
                "enum": ["success", "failure"],
            }
        },
        "required": ["status"],
    }

    async def execute(self, status: str) -> str:
        """Finaliza a execuÃ§Ã£o atual"""
        return f"A interaÃ§Ã£o foi concluÃ­da com o status: {status}"

```

### ARQUIVO: app/tool/file_writer.py ###
```py
import os
from typing import Dict, Union

from app.tool.base import BaseTool
from app.tool.file_operators import LocalFileOperator # To use for writing
from app.config import config # For workspace path resolution
from app.logger import logger
from app.exceptions import ToolError # For error handling

class ReplaceEntireFileContent(BaseTool):
    name: str = "replace_entire_file_content"
    description: str = (
        "Overwrites the entire content of a specified file with new_content. "
        "This is useful for tasks like updating a checklist file where providing the "
        "full new content is more robust than partial string replacement. "
        "If the file does not exist, it will be created. "
        "Relative paths are resolved from the agent's workspace root."
    )
    parameters: dict = {
        "type": "object",
        "properties": {
            "path": {
                "type": "string",
                "description": "The relative (from workspace root) or absolute path to the file to be overwritten or created.",
            },
            "new_content": {
                "type": "string",
                "description": "The entire new content to be written to the file.",
            }
        },
        "required": ["path", "new_content"],
    }

    _local_operator: LocalFileOperator = LocalFileOperator()

    async def execute(self, path: str, new_content: str) -> Dict[str, str]:
        """
        Overwrites a file with new content. Creates the file if it doesn't exist.

        Args:
            path (str): The path to the file.
            new_content (str): The new content for the file.

        Returns:
            Dict[str, str]: A dictionary with a 'status' or 'error' message.
        """
        original_path_for_logging = path # Keep original path for user-facing messages

        if not os.path.isabs(path):
            file_path = os.path.join(config.workspace_root, path)
        else:
            file_path = path

        # Normalize the path to handle potential ".." or "." segments and ensure it's an absolute path
        file_path = os.path.normpath(os.path.abspath(file_path))

        # Security check: Ensure the path is still within the workspace_root
        if not file_path.startswith(os.path.normpath(os.path.abspath(config.workspace_root))):
            logger.error(f"Path traversal attempt detected for replace_entire_file_content. Original path: '{original_path_for_logging}', Resolved path: '{file_path}' is outside workspace '{os.path.normpath(os.path.abspath(config.workspace_root))}'.")
            return {"error": f"Path is outside the allowed workspace: {original_path_for_logging}"}

        try:
            # Ensure new_content is a string
            if not isinstance(new_content, str):
                logger.warning(f"new_content was not a string (type: {type(new_content)}), converting to string.")
                new_content = str(new_content)

            # Basic null byte sanitization
            processed_content = new_content.replace('\u0000', '')
            if processed_content != new_content:
                logger.warning("Null bytes were removed from new_content before writing to file.")

            # Check if file exists before writing to determine action for logging
            file_existed_before_write = os.path.exists(file_path)

            await self._local_operator.write_file(file_path, processed_content)

            action = "overwritten" if file_existed_before_write else "created"
            # To be absolutely sure for "overwritten", we could check if it existed *and* if the write_file actually modified it
            # (e.g. if it was already there and write_file is smart to not touch it if content is same).
            # However, LocalFileOperator.write_file implies an overwrite.

            logger.info(f"Successfully {action} file {file_path} (original input: '{original_path_for_logging}') with new content.")
            return {"status": f"File {original_path_for_logging} successfully {action}."}
        except ToolError as e:
            logger.error(f"ToolError writing file {file_path} (original input: '{original_path_for_logging}'): {e}")
            return {"error": f"Failed to write file '{original_path_for_logging}': {str(e)}"}
        except Exception as e:
            logger.error(f"Unexpected error writing file {file_path} (original input: '{original_path_for_logging}'): {e}", exc_info=True)
            return {"error": f"An unexpected error occurred while writing file '{original_path_for_logging}': {str(e)}"}

```

### ARQUIVO: app/tool/planning.py ###
```py
# tool/planning.py
from typing import Dict, List, Literal, Optional

from app.exceptions import ToolError
from app.tool.base import BaseTool, ToolResult


_PLANNING_TOOL_DESCRIPTION = """
A planning tool that allows the agent to create and manage plans for solving complex tasks.
The tool provides functionality for creating plans, updating plan steps, and tracking progress.
"""


class PlanningTool(BaseTool):
    """
    A planning tool that allows the agent to create and manage plans for solving complex tasks.
    The tool provides functionality for creating plans, updating plan steps, and tracking progress.
    """

    name: str = "planning"
    description: str = _PLANNING_TOOL_DESCRIPTION
    parameters: dict = {
        "type": "object",
        "properties": {
            "command": {
                "description": "The command to execute. Available commands: create, update, list, get, set_active, mark_step, delete.",
                "enum": [
                    "create",
                    "update",
                    "list",
                    "get",
                    "set_active",
                    "mark_step",
                    "delete",
                ],
                "type": "string",
            },
            "plan_id": {
                "description": "Unique identifier for the plan. Required for create, update, set_active, and delete commands. Optional for get and mark_step (uses active plan if not specified).",
                "type": "string",
            },
            "title": {
                "description": "Title for the plan. Required for create command, optional for update command.",
                "type": "string",
            },
            "steps": {
                "description": "List of plan steps. Required for create command, optional for update command.",
                "type": "array",
                "items": {"type": "string"},
            },
            "step_index": {
                "description": "Index of the step to update (0-based). Required for mark_step command.",
                "type": "integer",
            },
            "step_status": {
                "description": "Status to set for a step. Used with mark_step command.",
                "enum": ["not_started", "in_progress", "completed", "blocked"],
                "type": "string",
            },
            "step_notes": {
                "description": "Additional notes for a step. Optional for mark_step command.",
                "type": "string",
            },
        },
        "required": ["command"],
        "additionalProperties": False,
    }

    plans: dict = {}  # Dictionary to store plans by plan_id
    _current_plan_id: Optional[str] = None  # Track the current active plan

    async def execute(
        self,
        *,
        command: Literal[
            "create", "update", "list", "get", "set_active", "mark_step", "delete"
        ],
        plan_id: Optional[str] = None,
        title: Optional[str] = None,
        steps: Optional[List[str]] = None,
        step_index: Optional[int] = None,
        step_status: Optional[
            Literal["not_started", "in_progress", "completed", "blocked"]
        ] = None,
        step_notes: Optional[str] = None,
        **kwargs,
    ):
        """
        Execute the planning tool with the given command and parameters.

        Parameters:
        - command: The operation to perform
        - plan_id: Unique identifier for the plan
        - title: Title for the plan (used with create command)
        - steps: List of steps for the plan (used with create command)
        - step_index: Index of the step to update (used with mark_step command)
        - step_status: Status to set for a step (used with mark_step command)
        - step_notes: Additional notes for a step (used with mark_step command)
        """

        if command == "create":
            return self._create_plan(plan_id, title, steps)
        elif command == "update":
            return self._update_plan(plan_id, title, steps)
        elif command == "list":
            return self._list_plans()
        elif command == "get":
            return self._get_plan(plan_id)
        elif command == "set_active":
            return self._set_active_plan(plan_id)
        elif command == "mark_step":
            return self._mark_step(plan_id, step_index, step_status, step_notes)
        elif command == "delete":
            return self._delete_plan(plan_id)
        else:
            raise ToolError(
                f"Unrecognized command: {command}. Allowed commands are: create, update, list, get, set_active, mark_step, delete"
            )

    def _create_plan(
        self, plan_id: Optional[str], title: Optional[str], steps: Optional[List[str]]
    ) -> ToolResult:
        """Create a new plan with the given ID, title, and steps."""
        if not plan_id:
            raise ToolError("Parameter `plan_id` is required for command: create")

        if plan_id in self.plans:
            raise ToolError(
                f"A plan with ID '{plan_id}' already exists. Use 'update' to modify existing plans."
            )

        if not title:
            raise ToolError("Parameter `title` is required for command: create")

        if (
            not steps
            or not isinstance(steps, list)
            or not all(isinstance(step, str) for step in steps)
        ):
            raise ToolError(
                "Parameter `steps` must be a non-empty list of strings for command: create"
            )

        # Create a new plan with initialized step statuses
        plan = {
            "plan_id": plan_id,
            "title": title,
            "steps": steps,
            "step_statuses": ["not_started"] * len(steps),
            "step_notes": [""] * len(steps),
        }

        self.plans[plan_id] = plan
        self._current_plan_id = plan_id  # Set as active plan

        return ToolResult(
            output=f"Plan created successfully with ID: {plan_id}\n\n{self._format_plan(plan)}"
        )

    def _update_plan(
        self, plan_id: Optional[str], title: Optional[str], steps: Optional[List[str]]
    ) -> ToolResult:
        """Update an existing plan with new title or steps."""
        if not plan_id:
            raise ToolError("Parameter `plan_id` is required for command: update")

        if plan_id not in self.plans:
            raise ToolError(f"No plan found with ID: {plan_id}")

        plan = self.plans[plan_id]

        if title:
            plan["title"] = title

        if steps:
            if not isinstance(steps, list) or not all(
                isinstance(step, str) for step in steps
            ):
                raise ToolError(
                    "Parameter `steps` must be a list of strings for command: update"
                )

            # Preserve existing step statuses for unchanged steps
            old_steps = plan["steps"]
            old_statuses = plan["step_statuses"]
            old_notes = plan["step_notes"]

            # Create new step statuses and notes
            new_statuses = []
            new_notes = []

            for i, step in enumerate(steps):
                # If the step exists at the same position in old steps, preserve status and notes
                if i < len(old_steps) and step == old_steps[i]:
                    new_statuses.append(old_statuses[i])
                    new_notes.append(old_notes[i])
                else:
                    new_statuses.append("not_started")
                    new_notes.append("")

            plan["steps"] = steps
            plan["step_statuses"] = new_statuses
            plan["step_notes"] = new_notes

        return ToolResult(
            output=f"Plan updated successfully: {plan_id}\n\n{self._format_plan(plan)}"
        )

    def _list_plans(self) -> ToolResult:
        """List all available plans."""
        if not self.plans:
            return ToolResult(
                output="No plans available. Create a plan with the 'create' command."
            )

        output = "Available plans:\n"
        for plan_id, plan in self.plans.items():
            current_marker = " (active)" if plan_id == self._current_plan_id else ""
            completed = sum(
                1 for status in plan["step_statuses"] if status == "completed"
            )
            total = len(plan["steps"])
            progress = f"{completed}/{total} steps completed"
            output += f"â€¢ {plan_id}{current_marker}: {plan['title']} - {progress}\n"

        return ToolResult(output=output)

    def _get_plan(self, plan_id: Optional[str]) -> ToolResult:
        """Get details of a specific plan."""
        if not plan_id:
            # If no plan_id is provided, use the current active plan
            if not self._current_plan_id:
                raise ToolError(
                    "No active plan. Please specify a plan_id or set an active plan."
                )
            plan_id = self._current_plan_id

        if plan_id not in self.plans:
            raise ToolError(f"No plan found with ID: {plan_id}")

        plan = self.plans[plan_id]
        return ToolResult(output=self._format_plan(plan))

    def _set_active_plan(self, plan_id: Optional[str]) -> ToolResult:
        """Set a plan as the active plan."""
        if not plan_id:
            raise ToolError("Parameter `plan_id` is required for command: set_active")

        if plan_id not in self.plans:
            raise ToolError(f"No plan found with ID: {plan_id}")

        self._current_plan_id = plan_id
        return ToolResult(
            output=f"Plan '{plan_id}' is now the active plan.\n\n{self._format_plan(self.plans[plan_id])}"
        )

    def _mark_step(
        self,
        plan_id: Optional[str],
        step_index: Optional[int],
        step_status: Optional[str],
        step_notes: Optional[str],
    ) -> ToolResult:
        """Mark a step with a specific status and optional notes."""
        if not plan_id:
            # If no plan_id is provided, use the current active plan
            if not self._current_plan_id:
                raise ToolError(
                    "No active plan. Please specify a plan_id or set an active plan."
                )
            plan_id = self._current_plan_id

        if plan_id not in self.plans:
            raise ToolError(f"No plan found with ID: {plan_id}")

        if step_index is None:
            raise ToolError("Parameter `step_index` is required for command: mark_step")

        plan = self.plans[plan_id]

        if step_index < 0 or step_index >= len(plan["steps"]):
            raise ToolError(
                f"Invalid step_index: {step_index}. Valid indices range from 0 to {len(plan['steps'])-1}."
            )

        if step_status and step_status not in [
            "not_started",
            "in_progress",
            "completed",
            "blocked",
        ]:
            raise ToolError(
                f"Invalid step_status: {step_status}. Valid statuses are: not_started, in_progress, completed, blocked"
            )

        if step_status:
            plan["step_statuses"][step_index] = step_status

        if step_notes:
            plan["step_notes"][step_index] = step_notes

        return ToolResult(
            output=f"Step {step_index} updated in plan '{plan_id}'.\n\n{self._format_plan(plan)}"
        )

    def _delete_plan(self, plan_id: Optional[str]) -> ToolResult:
        """Delete a plan."""
        if not plan_id:
            raise ToolError("Parameter `plan_id` is required for command: delete")

        if plan_id not in self.plans:
            raise ToolError(f"No plan found with ID: {plan_id}")

        del self.plans[plan_id]

        # If the deleted plan was the active plan, clear the active plan
        if self._current_plan_id == plan_id:
            self._current_plan_id = None

        return ToolResult(output=f"Plan '{plan_id}' has been deleted.")

    def _format_plan(self, plan: Dict) -> str:
        """Format a plan for display."""
        output = f"Plan: {plan['title']} (ID: {plan['plan_id']})\n"
        output += "=" * len(output) + "\n\n"

        # Calculate progress statistics
        total_steps = len(plan["steps"])
        completed = sum(1 for status in plan["step_statuses"] if status == "completed")
        in_progress = sum(
            1 for status in plan["step_statuses"] if status == "in_progress"
        )
        blocked = sum(1 for status in plan["step_statuses"] if status == "blocked")
        not_started = sum(
            1 for status in plan["step_statuses"] if status == "not_started"
        )

        output += f"Progress: {completed}/{total_steps} steps completed "
        if total_steps > 0:
            percentage = (completed / total_steps) * 100
            output += f"({percentage:.1f}%)\n"
        else:
            output += "(0%)\n"

        output += f"Status: {completed} completed, {in_progress} in progress, {blocked} blocked, {not_started} not started\n\n"
        output += "Steps:\n"

        # Add each step with its status and notes
        for i, (step, status, notes) in enumerate(
            zip(plan["steps"], plan["step_statuses"], plan["step_notes"])
        ):
            status_symbol = {
                "not_started": "[ ]",
                "in_progress": "[â†’]",
                "completed": "[âœ“]",
                "blocked": "[!]",
            }.get(status, "[ ]")

            output += f"{i}. {status_symbol} {step}\n"
            if notes:
                output += f"   Notes: {notes}\n"

        return output

```

### ARQUIVO: app/tool/ask_human.py ###
```py
# ImportaÃ§Ãµes removidas para asyncio, sys, Path e gui.backend.agent_manager
# Flag _gui_interaction_available e lÃ³gica relacionada removidas

from app.tool.base import BaseTool # Garantir que BaseTool seja importado

class AskHuman(BaseTool):
    name: str = "AskHuman"
    description: str = (
        "Solicita entrada do usuÃ¡rio humano. Ãštil quando o agente precisa de esclarecimento, "
        "orientaÃ§Ã£o, ou quando estÃ¡ preso e precisa de intervenÃ§Ã£o humana. "
        "O parÃ¢metro 'inquire' deve ser uma pergunta clara ou prompt para o usuÃ¡rio."
    )
    parameters: dict = { # Alterado de str para dict com base em BaseTool
        "type": "object",
        "properties": {
            "inquire": {
                "type": "string",
                "description": "A pergunta ou prompt a ser feito ao usuÃ¡rio humano.",
            },
        },
        "required": ["inquire"],
    }

    # Tornando assÃ­ncrono para consistÃªncia com outras ferramentas, mesmo que use input() sÃ­ncrono para modo nÃ£o-GUI.
    async def execute(self, inquire: str, **kwargs) -> str:
        from app.logger import logger # Garantir que logger esteja disponÃ­vel

        # Esta Ã© a interaÃ§Ã£o de console de fallback se a GUI nÃ£o for usada ou o wrapper nÃ£o estiver no lugar.
        print(f"--- ENTRADA HUMANA NECESSÃRIA ---")
        print(inquire)

        user_response = "" # PadrÃ£o para string vazia
        try:
            user_response = input("Sua resposta: ")
            logger.info(f"AskHuman: UsuÃ¡rio respondeu com: '{user_response[:200]}'") # Registrar os primeiros 200 caracteres
        except EOFError:
            logger.warning("AskHuman: EOFError capturado ao tentar ler a entrada do usuÃ¡rio. Assumindo ambiente nÃ£o interativo. Retornando string vazia.")
            user_response = "" # Resposta padrÃ£o para ambiente nÃ£o interativo
        except Exception as e:
            logger.error(f"AskHuman: Ocorreu um erro inesperado ao obter a entrada do usuÃ¡rio: {e}")
            # Retornando uma mensagem de erro ou string vazia, conforme exemplo
            user_response = f"Erro em AskHuman: {str(e)}" # Ou simplesmente "" se preferir

        print(f"--- FIM DA ENTRADA HUMANA ---")
        return user_response.strip() # Adicionado strip() para consistÃªncia

```

### ARQUIVO: app/tool/browser_use_tool.py ###
```py
import asyncio
import base64
import json
from typing import Generic, Optional, TypeVar

from browser_use import Browser as BrowserUseBrowser
from browser_use import BrowserConfig
from browser_use.browser.context import BrowserContext, BrowserContextConfig
from browser_use.dom.service import DomService
from pydantic import Field, field_validator
from pydantic_core.core_schema import ValidationInfo

import markdownify # Adicionado import
from app.config import config
from app.llm import LLM
from app.logger import logger
from app.tool.base import BaseTool, ToolResult
from app.tool.web_search import WebSearch


_BROWSER_DESCRIPTION = """\
Your **PRIMARY tool for ALL web-related tasks** including: browsing, navigation, scraping, data extraction from websites, clicking elements, filling forms, and executing JavaScript.
* Use this to go to URLs, interact with page content, and extract information.
* Indispensable for modern, JavaScript-heavy websites.
* If the task is to 'scrape a website', 'get data from a URL', 'navigate a webpage', or 'view website content', **this tool should be your first choice.**
* It maintains state across calls (active browser session).
* Actions: go_to_url, click_element, input_text, scroll, extract_content, web_search (which then navigates to the first result), etc. See 'parameters' for full action list.
"""

Context = TypeVar("Context")


class BrowserUseTool(BaseTool, Generic[Context]):
    name: str = "browser_use"
    description: str = _BROWSER_DESCRIPTION
    parameters: dict = {
        "type": "object",
        "properties": {
            "action": {
                "type": "string",
                "enum": [
                    "go_to_url",
                    "click_element",
                    "input_text",
                    "scroll_down",
                    "scroll_up",
                    "scroll_to_text",
                    "send_keys",
                    "get_dropdown_options",
                    "select_dropdown_option",
                    "go_back",
                    "web_search",
                    "wait",
                    "extract_content",
                    "switch_tab",
                    "open_tab",
                    "close_tab",
                ],
                "description": "The browser action to perform",
            },
            "url": {
                "type": "string",
                "description": "URL for 'go_to_url' or 'open_tab' actions",
            },
            "index": {
                "type": "integer",
                "description": "Element index for 'click_element', 'input_text', 'get_dropdown_options', or 'select_dropdown_option' actions",
            },
            "text": {
                "type": "string",
                "description": "Text for 'input_text', 'scroll_to_text', or 'select_dropdown_option' actions",
            },
            "scroll_amount": {
                "type": "integer",
                "description": "Pixels to scroll (positive for down, negative for up) for 'scroll_down' or 'scroll_up' actions",
            },
            "tab_id": {
                "type": "integer",
                "description": "Tab ID for 'switch_tab' action",
            },
            "query": {
                "type": "string",
                "description": "Search query for 'web_search' action",
            },
            "goal": {
                "type": "string",
                "description": "Extraction goal for 'extract_content' action",
            },
            "keys": {
                "type": "string",
                "description": "Keys to send for 'send_keys' action",
            },
            "seconds": {
                "type": "integer",
                "description": "Seconds to wait for 'wait' action",
            },
        },
        "required": ["action"],
        "dependencies": {
            "go_to_url": ["url"],
            "click_element": ["index"],
            "input_text": ["index", "text"],
            "switch_tab": ["tab_id"],
            "open_tab": ["url"],
            "scroll_down": ["scroll_amount"],
            "scroll_up": ["scroll_amount"],
            "scroll_to_text": ["text"],
            "send_keys": ["keys"],
            "get_dropdown_options": ["index"],
            "select_dropdown_option": ["index", "text"],
            "go_back": [],
            "web_search": ["query"],
            "wait": ["seconds"],
            "extract_content": ["goal"],
        },
    }

    lock: asyncio.Lock = Field(default_factory=asyncio.Lock)
    browser: Optional[BrowserUseBrowser] = Field(default=None, exclude=True)
    context: Optional[BrowserContext] = Field(default=None, exclude=True)
    dom_service: Optional[DomService] = Field(default=None, exclude=True)
    web_search_tool: WebSearch = Field(default_factory=WebSearch, exclude=True)

    # Context for generic functionality
    tool_context: Optional[Context] = Field(default=None, exclude=True)

    llm: Optional[LLM] = Field(default_factory=LLM)

    @field_validator("parameters", mode="before")
    def validate_parameters(cls, v: dict, info: ValidationInfo) -> dict:
        if not v:
            raise ValueError("Parameters cannot be empty")
        return v

    async def _ensure_browser_initialized(self) -> BrowserContext:
        """Ensure browser and context are initialized."""
        logger.info(f"BrowserUseTool._ensure_browser_initialized: Current state - self.browser is {'None' if self.browser is None else 'Exists'}, self.context is {'None' if self.context is None else 'Exists'}")

        if self.browser is None:
            logger.info("BrowserUseTool._ensure_browser_initialized: self.browser is None, initializing BrowserUseBrowser.")
            browser_config_kwargs = {"headless": False, "disable_security": True}

            if config.browser_config:
                from browser_use.browser.browser import ProxySettings

                # handle proxy settings.
                if config.browser_config.proxy and config.browser_config.proxy.server:
                    browser_config_kwargs["proxy"] = ProxySettings(
                        server=config.browser_config.proxy.server,
                        username=config.browser_config.proxy.username,
                        password=config.browser_config.proxy.password,
                    )

                browser_attrs = [
                    "headless",
                    "disable_security",
                    "extra_chromium_args",
                    "chrome_instance_path",
                    "wss_url",
                    "cdp_url",
                ]

                for attr in browser_attrs:
                    value = getattr(config.browser_config, attr, None)
                    if value is not None:
                        # Ensure that list arguments are not empty if provided
                        if isinstance(value, list) and not value:
                            logger.info(f"BrowserUseTool._ensure_browser_initialized: Skipping empty list for {attr}")
                            continue
                        browser_config_kwargs[attr] = value
                logger.info(f"BrowserUseTool._ensure_browser_initialized: BrowserConfig kwargs: {browser_config_kwargs}")

            self.browser = BrowserUseBrowser(BrowserConfig(**browser_config_kwargs))
            logger.info("BrowserUseTool._ensure_browser_initialized: BrowserUseBrowser initialized.")

        if self.context is None:
            logger.info("BrowserUseTool._ensure_browser_initialized: self.context is None, creating new context.")
            context_config = BrowserContextConfig()

            # if there is context config in the config, use it.
            if (
                config.browser_config
                and hasattr(config.browser_config, "new_context_config")
                and config.browser_config.new_context_config
            ):
                context_config = config.browser_config.new_context_config
                logger.info("BrowserUseTool._ensure_browser_initialized: Using custom new_context_config.")
            else:
                logger.info("BrowserUseTool._ensure_browser_initialized: Using default BrowserContextConfig.")

            self.context = await self.browser.new_context(context_config)
            logger.info("BrowserUseTool._ensure_browser_initialized: New context created.")
            # Ensure DomService is initialized only after a page is available
            try:
                current_page = await self.context.get_current_page()
                if current_page:
                    self.dom_service = DomService(current_page)
                    logger.info("BrowserUseTool._ensure_browser_initialized: DomService initialized with current page.")
                else:
                    logger.warning("BrowserUseTool._ensure_browser_initialized: Could not get current page to initialize DomService.")
                    self.dom_service = None # Explicitly set to None
            except Exception as e:
                logger.error(f"BrowserUseTool._ensure_browser_initialized: Error getting current page or initializing DomService: {e}")
                self.dom_service = None # Explicitly set to None


        # Ensure logger is imported if not already: from app.logger import logger
        # Ensure BrowserUseBrowser, BrowserConfig, BrowserContext, BrowserContextConfig, DomService are imported from browser_use
        # Ensure config is imported: from app.config import config
        # These imports should already be there, this is just a reminder.
        return self.context

    async def execute(
        self,
        action: str,
        url: Optional[str] = None,
        index: Optional[int] = None,
        text: Optional[str] = None,
        scroll_amount: Optional[int] = None,
        tab_id: Optional[int] = None,
        query: Optional[str] = None,
        goal: Optional[str] = None,
        keys: Optional[str] = None,
        seconds: Optional[int] = None,
        **kwargs,
    ) -> ToolResult:
        """
        Execute a specified browser action.

        Args:
            action: The browser action to perform
            url: URL for navigation or new tab
            index: Element index for click or input actions
            text: Text for input action or search query
            scroll_amount: Pixels to scroll for scroll action
            tab_id: Tab ID for switch_tab action
            query: Search query for Google search
            goal: Extraction goal for content extraction
            keys: Keys to send for keyboard actions
            seconds: Seconds to wait
            **kwargs: Additional arguments

        Returns:
            ToolResult with the action's output or error
        """
        async with self.lock:
            try:
                context = await self._ensure_browser_initialized()

                # Get max content length from config
                max_content_length = getattr(
                    config.browser_config, "max_content_length", 2000
                )

                # Navigation actions
                if action == "go_to_url":
                    if not url:
                        return ToolResult(
                            error="URL is required for 'go_to_url' action"
                        )
                    if not url:
                        return ToolResult(
                            error="URL is required for 'go_to_url' action"
                        )
                    try:
                        page = await context.get_current_page()
                        await page.goto(url)
                        await page.wait_for_load_state()
                        return ToolResult(output=f"Navigated to {url}")
                    except asyncio.TimeoutError as e:
                        return ToolResult(error=f"Timeout durante navegaÃ§Ã£o para {url}: {str(e)}")
                    except Exception as e:
                        return ToolResult(error=f"Erro ao navegar para {url}: {str(e)}")

                elif action == "go_back":
                    try:
                        await context.go_back()
                        return ToolResult(output="Navigated back")
                    except Exception as e:
                        return ToolResult(error=f"Erro ao navegar para trÃ¡s: {str(e)}")

                elif action == "refresh":
                    try:
                        await context.refresh_page()
                        return ToolResult(output="Refreshed current page")
                    except Exception as e:
                        return ToolResult(error=f"Erro ao atualizar a pÃ¡gina: {str(e)}")

                elif action == "web_search":
                    if not query:
                        return ToolResult(
                            error="Query is required for 'web_search' action"
                        )
                    try:
                        # Execute the web search and return results directly without browser navigation
                        search_response = await self.web_search_tool.execute(
                            query=query, fetch_content=True, num_results=1
                        )
                        if not search_response.results:
                             return ToolResult(error=f"Nenhum resultado encontrado para a busca: {query}")
                        # Navigate to the first search result
                        first_search_result = search_response.results[0]
                        url_to_navigate = first_search_result.url

                        page = await context.get_current_page()
                        await page.goto(url_to_navigate)
                        await page.wait_for_load_state()
                        return search_response # Retorna o SearchResponse completo
                    except asyncio.TimeoutError as e:
                        return ToolResult(error=f"Timeout durante web_search e navegaÃ§Ã£o para resultado: {str(e)}")
                    except Exception as e:
                        return ToolResult(error=f"Erro durante web_search e navegaÃ§Ã£o: {str(e)}")

                # Element interaction actions
                elif action == "click_element":
                    if index is None:
                        return ToolResult(
                            error="Index is required for 'click_element' action"
                        )
                    try:
                        element = await context.get_dom_element_by_index(index)
                        if not element:
                            return ToolResult(error=f"Element with index {index} not found")
                        download_path = await context._click_element_node(element)
                        output = f"Clicked element at index {index}"
                        if download_path:
                            output += f" - Downloaded file to {download_path}"
                        return ToolResult(output=output)
                    except Exception as e:
                        return ToolResult(error=f"Erro ao clicar no elemento no Ã­ndice {index}: {str(e)}")

                elif action == "input_text":
                    if index is None or not text:
                        return ToolResult(
                            error="Index and text are required for 'input_text' action"
                        )
                    try:
                        element = await context.get_dom_element_by_index(index)
                        if not element:
                            return ToolResult(error=f"Element with index {index} not found")
                        await context._input_text_element_node(element, text)
                        return ToolResult(
                            output=f"Input '{text}' into element at index {index}"
                        )
                    except Exception as e:
                        return ToolResult(error=f"Erro ao inserir texto no elemento no Ã­ndice {index}: {str(e)}")

                elif action == "scroll_down" or action == "scroll_up":
                    try:
                        direction = 1 if action == "scroll_down" else -1
                        amount = (
                            scroll_amount
                            if scroll_amount is not None
                            else context.config.browser_window_size["height"]
                        )
                        await context.execute_javascript(
                            f"window.scrollBy(0, {direction * amount});"
                        )
                        return ToolResult(
                            output=f"Scrolled {'down' if direction > 0 else 'up'} by {amount} pixels"
                        )
                    except Exception as e:
                        return ToolResult(error=f"Erro ao rolar a pÃ¡gina: {str(e)}")

                elif action == "scroll_to_text":
                    if not text:
                        return ToolResult(
                            error="Text is required for 'scroll_to_text' action"
                        )
                    try:
                        page = await context.get_current_page()
                        locator = page.get_by_text(text, exact=False)
                        await locator.scroll_into_view_if_needed()
                        return ToolResult(output=f"Scrolled to text: '{text}'")
                    except asyncio.TimeoutError as e:
                        return ToolResult(error=f"Timeout ao rolar para o texto '{text}': {str(e)}")
                    except Exception as e:
                        return ToolResult(error=f"Erro ao rolar para o texto '{text}': {str(e)}")

                elif action == "send_keys":
                    if not keys:
                        return ToolResult(
                            error="Keys are required for 'send_keys' action"
                        )
                    try:
                        page = await context.get_current_page()
                        await page.keyboard.press(keys)
                        return ToolResult(output=f"Sent keys: {keys}")
                    except Exception as e:
                        return ToolResult(error=f"Erro ao enviar teclas '{keys}': {str(e)}")

                elif action == "get_dropdown_options":
                    if index is None:
                        return ToolResult(
                            error="Index is required for 'get_dropdown_options' action"
                        )
                    try:
                        element = await context.get_dom_element_by_index(index)
                        if not element:
                            return ToolResult(error=f"Element with index {index} not found")
                        page = await context.get_current_page()
                        options = await page.evaluate(
                            """
                            (xpath) => {
                                const select = document.evaluate(xpath, document, null,
                                XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;
                            if (!select) return null;
                            return Array.from(select.options).map(opt => ({
                                text: opt.text,
                                value: opt.value,
                                index: opt.index
                            }));
                        }
                        """,
                            element.xpath,
                        )
                        return ToolResult(output=f"Dropdown options: {options}")
                    except Exception as e:
                        return ToolResult(error=f"Erro ao obter opÃ§Ãµes do dropdown no Ã­ndice {index}: {str(e)}")

                elif action == "select_dropdown_option":
                    if index is None or not text:
                        return ToolResult(
                            error="Index and text are required for 'select_dropdown_option' action"
                        )
                    try:
                        element = await context.get_dom_element_by_index(index)
                        if not element:
                            return ToolResult(error=f"Element with index {index} not found")
                        page = await context.get_current_page()
                        await page.select_option(element.xpath, label=text)
                        return ToolResult(
                            output=f"Selected option '{text}' from dropdown at index {index}"
                        )
                    except Exception as e:
                        return ToolResult(error=f"Erro ao selecionar opÃ§Ã£o '{text}' do dropdown no Ã­ndice {index}: {str(e)}")

                # Content extraction actions
                elif action == "extract_content":
                    if not goal:
                        return ToolResult(
                            error="Goal is required for 'extract_content' action"
                        )
                    try: # Try principal da aÃ§Ã£o
                        page = await context.get_current_page()
                        # import markdownify # Movido para o topo do arquivo

                        # Bloco interno para obter conteÃºdo da pÃ¡gina, com seu prÃ³prio try-except
                        try:
                            page_content_html = await page.content()
                            content = markdownify.markdownify(page_content_html) # Assumindo que markdownify estÃ¡ importado no topo
                        except Exception as page_err:
                            logger.error(f"Erro ao obter/converter conteÃºdo da pÃ¡gina: {page_err}")
                            return ToolResult(error=f"Erro ao processar conteÃºdo da pÃ¡gina: {str(page_err)}")

                        prompt = f"""\
Your task is to extract the content of the page. You will be given a page and a goal, and you should extract all relevant information around this goal from the page. If the goal is vague, summarize the page. Respond in json format.
Extraction goal: {goal}

Page content:
{content[:max_content_length]}
"""
                        messages = [{"role": "system", "content": prompt}]

                        extraction_function = {
                            "type": "function",
                            "function": {
                                "name": "extract_content",
                                "description": "Extract specific information from a webpage based on a goal",
                                "parameters": {
                                    "type": "object",
                                    "properties": {
                                        "extracted_content": {
                                            "type": "object",
                                            "description": "The content extracted from the page according to the goal",
                                            "properties": {
                                                "text": {
                                                    "type": "string",
                                                    "description": "Text content extracted from the page",
                                                },
                                                "metadata": {
                                                    "type": "object",
                                                    "description": "Additional metadata about the extracted content",
                                                    "properties": {
                                                        "source": {
                                                            "type": "string",
                                                            "description": "Source of the extracted content",
                                                        }
                                                    },
                                                },
                                            },
                                        }
                                    },
                                    "required": ["extracted_content"],
                                },
                            },
                        }

                        response = await self.llm.ask_tool(
                            messages,
                            tools=[extraction_function],
                            tool_choice="required",
                        )

                        if response and response.tool_calls:
                            args = json.loads(response.tool_calls[0].function.arguments)
                            extracted_content = args.get("extracted_content", {})
                            return ToolResult(
                                output=f"Extracted from page:\n{extracted_content}\n"
                            )

                        return ToolResult(output="No content was extracted from the page.")

                    except asyncio.TimeoutError as e:
                        logger.error(f"Timeout durante a extraÃ§Ã£o de conteÃºdo para o objetivo '{goal}': {str(e)}")
                        return ToolResult(error=f"Timeout durante a extraÃ§Ã£o de conteÃºdo para o objetivo '{goal}': {str(e)}")
                    except Exception as e:
                        logger.error(f"Erro ao extrair conteÃºdo para o objetivo '{goal}': {str(e)}")
                        return ToolResult(error=f"Erro ao extrair conteÃºdo para o objetivo '{goal}': {str(e)}")

                # Tab management actions
                elif action == "switch_tab":
                    if tab_id is None:
                        return ToolResult(
                            error="Tab ID is required for 'switch_tab' action"
                        )
                    try:
                        await context.switch_to_tab(tab_id)
                        page = await context.get_current_page()
                        await page.wait_for_load_state()
                        return ToolResult(output=f"Switched to tab {tab_id}")
                    except Exception as e:
                        return ToolResult(error=f"Erro ao trocar para a aba {tab_id}: {str(e)}")

                elif action == "open_tab":
                    if not url:
                        return ToolResult(error="URL is required for 'open_tab' action")
                    try:
                        await context.create_new_tab(url)
                        return ToolResult(output=f"Opened new tab with {url}")
                    except Exception as e:
                        return ToolResult(error=f"Erro ao abrir nova aba com URL {url}: {str(e)}")

                elif action == "close_tab":
                    try:
                        await context.close_current_tab()
                        return ToolResult(output="Closed current tab")
                    except Exception as e:
                        return ToolResult(error=f"Erro ao fechar a aba atual: {str(e)}")

                # Utility actions
                elif action == "wait":
                    try:
                        seconds_to_wait = seconds if seconds is not None else 3
                        await asyncio.sleep(seconds_to_wait)
                        return ToolResult(output=f"Waited for {seconds_to_wait} seconds")
                    except Exception as e: # Embora improvÃ¡vel para asyncio.sleep, por consistÃªncia
                        return ToolResult(error=f"Erro durante a aÃ§Ã£o 'wait': {str(e)}")
                else:
                    return ToolResult(error=f"Unknown action: {action}")

            except asyncio.TimeoutError as e_timeout:
                logger.error(f"Playwright/Asyncio TimeoutError em BrowserUseTool action '{action}': {e_timeout}")
                return ToolResult(error=f"Timeout na aÃ§Ã£o do navegador '{action}': {str(e_timeout)}")
            except Exception as e_general:
                # Este Ã© um catch-all para erros inesperados nÃ£o capturados nos blocos internos
                # ou erros na inicializaÃ§Ã£o/validaÃ§Ã£o antes dos blocos de aÃ§Ã£o.
                logger.error(f"ExceÃ§Ã£o geral em BrowserUseTool action '{action}': {e_general}")
                return ToolResult(error=f"Falha geral na aÃ§Ã£o do navegador '{action}': {str(e_general)}")

    async def get_current_state(
        self, context: Optional[BrowserContext] = None
    ) -> ToolResult:
        """
        Get the current browser state as a ToolResult.
        If context is not provided, uses self.context.
        """
        try:
            # Use provided context or fall back to self.context
            ctx = context or self.context
            if not ctx:
                return ToolResult(error="Browser context not initialized")

            state = await ctx.get_state()

            # Create a viewport_info dictionary if it doesn't exist
            viewport_height = 0
            if hasattr(state, "viewport_info") and state.viewport_info:
                viewport_height = state.viewport_info.height
            elif hasattr(ctx, "config") and hasattr(ctx.config, "browser_window_size"):
                viewport_height = ctx.config.browser_window_size.get("height", 0)

            # Take a screenshot for the state
            page = await ctx.get_current_page()

            await page.bring_to_front()
            await page.wait_for_load_state()

            screenshot = await page.screenshot(
                full_page=True, animations="disabled", type="jpeg", quality=100
            )

            screenshot = base64.b64encode(screenshot).decode("utf-8")

            # Build the state info with all required fields
            state_info = {
                "url": state.url,
                "title": state.title,
                "tabs": [tab.model_dump() for tab in state.tabs],
                "help": "[0], [1], [2], etc., represent clickable indices corresponding to the elements listed. Clicking on these indices will navigate to or interact with the respective content behind them.",
                "interactive_elements": (
                    state.element_tree.clickable_elements_to_string()
                    if state.element_tree
                    else ""
                ),
                "scroll_info": {
                    "pixels_above": getattr(state, "pixels_above", 0),
                    "pixels_below": getattr(state, "pixels_below", 0),
                    "total_height": getattr(state, "pixels_above", 0)
                    + getattr(state, "pixels_below", 0)
                    + viewport_height,
                },
                "viewport_height": viewport_height,
            }

            return ToolResult(
                output=json.dumps(state_info, indent=4, ensure_ascii=False),
                base64_image=screenshot,
            )
        except Exception as e:
            return ToolResult(error=f"Failed to get browser state: {str(e)}")

    async def cleanup(self):
        """Clean up browser resources."""
        async with self.lock:
            if self.context is not None:
                try:
                    await self.context.close()
                    logger.info("BrowserUseTool: Context closed successfully.")
                except Exception as e:
                    logger.warning(f"BrowserUseTool: Error closing context: {e}. It might have been already closed.")
                finally:
                    self.context = None
                    self.dom_service = None # Ensure dom_service is also cleared
            else:
                logger.info("BrowserUseTool: Context was already None, no action taken.")

            if self.browser is not None:
                try:
                    await self.browser.close()
                    logger.info("BrowserUseTool: Browser closed successfully.")
                except Exception as e:
                    logger.warning(f"BrowserUseTool: Error closing browser: {e}. It might have been already closed.")
                finally:
                    self.browser = None
            else:
                logger.info("BrowserUseTool: Browser was already None, no action taken.")

    def __del__(self):
        """Ensure cleanup when object is destroyed.
        Note: Running asyncio code within __del__ can be problematic due to
        uncertainty about the state of the event loop, especially during
        interpreter shutdown or if called from different threads.
        The robustness of the `cleanup` method itself is key here.
        """
        # Check if cleanup is even necessary
        if self.browser is not None or self.context is not None:
            try:
                # Attempt to run cleanup using asyncio.run()
                # This will create a new event loop if one isn't running.
                asyncio.run(self.cleanup())
            except RuntimeError as e:
                # This typically means an event loop is already running in the current thread.
                # It's complex to reliably get and use the existing loop here,
                # or to know if it's the 'right' one for this cleanup.
                # Creating a new loop is a common fallback but has its own issues.
                # The warning below uses print as logger might also be in an uncertain state.
                print(f"WARNING: BrowserUseTool.__del__: RuntimeError during cleanup (possibly due to existing event loop): {e}")
                print("WARNING: BrowserUseTool.__del__: Attempting cleanup in a new event loop as a fallback.")
                new_loop = None
                try:
                    new_loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(new_loop)
                    new_loop.run_until_complete(self.cleanup())
                except Exception as e_new_loop:
                    print(f"ERROR: BrowserUseTool.__del__: Error during cleanup in new event loop: {e_new_loop}")
                finally:
                    if new_loop:
                        new_loop.close()
                    # It's important to restore the original event loop policy if changed.
                    # However, set_event_loop(None) after closing the current loop is standard.
                    # If another loop was previously set for this thread, this might disrupt it.
                    # This is part of why __del__ with asyncio is tricky.
                    asyncio.set_event_loop(None) # Resets the current event loop for the OS thread to None
            except Exception as e:
                # Catch any other unexpected errors during the cleanup attempt.
                print(f"ERROR: BrowserUseTool.__del__: Unexpected error during cleanup: {e}")
        # else:
            # print("DEBUG: BrowserUseTool.__del__: Cleanup not necessary, browser and context are None.")

    @classmethod
    def create_with_context(cls, context: Context) -> "BrowserUseTool[Context]":
        """Factory method to create a BrowserUseTool with a specific context."""
        tool = cls()
        tool.tool_context = context
        return tool

```

### ARQUIVO: app/tool/bash.py ###
```py
import asyncio
import os
from typing import Optional

from app.config import config
from app.exceptions import ToolError
from app.tool.base import BaseTool, CLIResult
from app.logger import logger # ADDED


_BASH_DESCRIPTION = '''Execute a bash command in the terminal.
* working_directory: Optional. The working directory from which to run the command. If not specified, uses the agent's current working directory. This directory is set when the session (re)starts.
* Long running commands: For commands that may run indefinitely, it should be run in the background and the output should be redirected to a file, e.g. command = `python3 app.py > server.log 2>&1 &`.
* Interactive: If a bash command returns exit code `-1`, this means the process is not yet finished. The assistant must then send a second call to terminal with an empty `command` (which will retrieve any additional logs), or it can send additional text (set `command` to the text) to STDIN of the running process, or it can send command=`ctrl+c` to interrupt the process.
* Timeout: If a command execution result says "Command timed out. Sending SIGINT to the process", the assistant should retry running the command in the background.'''


class _BashSession:
    """A session of a bash shell."""

    _started: bool
    _process: asyncio.subprocess.Process

    command: str = "/bin/bash"
    _output_delay: float = 0.2  # segundos
    _timeout: float = 86400.0  # segundos (24 horas)
    _sentinel: str = "<<exit>>"

    def __init__(self):
        self._started = False
        self._timed_out = False

    async def start(self, working_directory: Optional[str] = None): # Adicionar parÃ¢metro
        if self._started:
            return

        self._process = await asyncio.create_subprocess_shell(
            self.command,
            # preexec_fn=os.setsid, # Esta linha jÃ¡ deve estar removida/comentada
            shell=True,
            bufsize=0,
            cwd=working_directory, # Adicionar este parÃ¢metro
            stdin=asyncio.subprocess.PIPE,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
        )
        self._started = True

    def stop(self): # Renomear para indicar que Ã© sÃ­ncrono e apenas tenta terminar
        """Tenta encerrar o processo do shell bash."""
        if not self._started or not hasattr(self, '_process') or self._process.returncode is not None: # Adicionado hasattr
            return
        try:
            self._process.terminate()
            logger.info("Processo Bash encerrado.")
        except ProcessLookupError:
            logger.info("Processo Bash jÃ¡ encerrado.")
        except Exception as e:
            logger.error(f"Erro ao encerrar processo bash: {e}")

    async def close_async(self): # Novo mÃ©todo assÃ­ncrono para limpeza completa
        """Fecha stdin, encerra o processo e espera que ele saia."""
        logger.info("_BashSession.close_async: Iniciando...")
        if not self._started or not hasattr(self, '_process') or self._process.returncode is not None:
            logger.info("_BashSession.close_async: SessÃ£o jÃ¡ fechada ou nÃ£o iniciada.")
            return

        logger.info("_BashSession.close_async: Fechando sessÃ£o bash assincronamente...")
        try:
            if self._process.stdin and hasattr(self._process.stdin, 'is_closing') and not self._process.stdin.is_closing():
                try:
                    logger.info("_BashSession.close_async: Tentando escrever EOF para stdin.")
                    self._process.stdin.write_eof()
                    await self._process.stdin.drain()
                    logger.info("_BashSession.close_async: EOF do stdin do Bash enviado e drenado.")
                except (ConnectionResetError, BrokenPipeError, AttributeError) as e:
                    logger.warning(f"_BashSession.close_async: Erro ao enviar EOF para stdin do bash (pode jÃ¡ estar fechado): {e}")
                except Exception as e:
                    logger.error(f"_BashSession.close_async: Erro inesperado ao fechar stdin do bash: {e}")
                finally:
                    if self._process.stdin and hasattr(self._process.stdin, 'close') and hasattr(self._process.stdin, 'is_closing') and not self._process.stdin.is_closing(): # Checagens extras
                        self._process.stdin.close()

            if self._process.returncode is None:
                logger.info("_BashSession.close_async: Tentando encerrar processo.")
                self._process.terminate()
                logger.info("_BashSession.close_async: SIGTERM enviado para o processo bash.")
                try:
                    logger.info("_BashSession.close_async: Aguardando processo sair apÃ³s encerrar...")
                    await asyncio.wait_for(self._process.wait(), timeout=5.0)
                    logger.info(f"_BashSession.close_async: Processo Bash saiu com cÃ³digo {self._process.returncode}.")
                except asyncio.TimeoutError:
                    logger.warning("_BashSession.close_async: Processo Bash nÃ£o encerrou graciosamente apÃ³s 5s, enviando SIGKILL.")
                    if self._process.returncode is None:
                        logger.info("_BashSession.close_async: Processo nÃ£o encerrou, tentando matar.")
                        self._process.kill()
                        await self._process.wait()
                        logger.info(f"_BashSession.close_async: Processo Bash morto. CÃ³digo de saÃ­da {self._process.returncode}.")
                except ProcessLookupError:
                    logger.info("_BashSession.close_async: Processo Bash jÃ¡ havia saÃ­do antes de aguardar.")
                except Exception as e:
                    logger.error(f"_BashSession.close_async: Erro durante a espera do processo bash: {e}")
        except ProcessLookupError:
            logger.info("_BashSession.close_async: Processo Bash nÃ£o existe (jÃ¡ limpo).")
        except Exception as e:
            logger.error(f"_BashSession.close_async: Erro durante close_async da sessÃ£o bash: {e}")
        finally:
            logger.info("_BashSession.close_async: Definindo self._started para False.")
            self._started = False
            if hasattr(self, '_process'): # Garantir que _process existe
                logger.info(f"close_async da sessÃ£o Bash concluÃ­do. CÃ³digo de retorno final do processo: {self._process.returncode}")
            else:
                logger.info("close_async da sessÃ£o Bash concluÃ­do (atributo de processo ausente).")

    async def run(self, command: str):
        """Executa um comando no shell bash."""
        if not self._started:
            raise ToolError("A sessÃ£o nÃ£o foi iniciada.")
        if self._process.returncode is not None:
            return CLIResult(
                system="a ferramenta precisa ser reiniciada",
                error=f"bash saiu com cÃ³digo de retorno {self._process.returncode}",
            )
        if self._timed_out:
            raise ToolError(
                f"tempo esgotado: bash nÃ£o retornou em {self._timeout} segundos e precisa ser reiniciado",
            )

        # sabemos que estes nÃ£o sÃ£o None porque criamos o processo com PIPEs
        assert self._process.stdin
        assert self._process.stdout
        assert self._process.stderr

        # envia comando para o processo
        self._process.stdin.write(
            command.encode() + f"; echo '{self._sentinel}'\n".encode()
        )
        await self._process.stdin.drain()

        # lÃª a saÃ­da do processo, atÃ© que o sentinela seja encontrado
        async def _read_output_with_sentinel():
            while True:
                await asyncio.sleep(self._output_delay)
                # se lermos diretamente de stdout/stderr, ele esperarÃ¡ para sempre por
                # EOF. use o buffer StreamReader diretamente.
                output_val = ( # Renomeado para output_val para evitar conflito com 'output' do escopo externo
                    self._process.stdout._buffer.decode()
                )  # pyright: ignore[reportAttributeAccessIssue]
                if self._sentinel in output_val:
                    # remove o sentinela e quebra
                    output_val = output_val[: output_val.index(self._sentinel)]
                    return output_val # Retorna a saÃ­da quando o sentinela Ã© encontrado
                # Verifica se o processo saiu inesperadamente para evitar loop infinito.
                if self._process.returncode is not None:
                    logger.warning("_BashSession._read_output_with_sentinel: Processo saiu prematuramente.")
                    # Tenta obter qualquer saÃ­da restante, pode nÃ£o conter o sentinela
                    return self._process.stdout._buffer.decode() # pyright: ignore[reportAttributeAccessIssue]

        output = "" # Inicializa output para garantir que esteja definido
        try:
            output = await asyncio.wait_for(_read_output_with_sentinel(), timeout=self._timeout)
        except asyncio.TimeoutError:
            self._timed_out = True
            # logger.error(f"Comando atingiu o tempo limite apÃ³s {self._timeout}s em _BashSession.run") # Logger disponÃ­vel
            raise ToolError(
                f"tempo esgotado: bash nÃ£o retornou em {self._timeout} segundos e precisa ser reiniciado",
            ) from None

        if output and output.endswith("\n"): # Verifica se output nÃ£o Ã© None
            output = output[:-1]

        error = (
            self._process.stderr._buffer.decode()
        )  # pyright: ignore[reportAttributeAccessIssue]
        if error.endswith("\n"):
            error = error[:-1]

        # limpa os buffers para que a prÃ³xima saÃ­da possa ser lida corretamente
        self._process.stdout._buffer.clear()  # pyright: ignore[reportAttributeAccessIssue]
        self._process.stderr._buffer.clear()  # pyright: ignore[reportAttributeAccessIssue]

        return CLIResult(output=output, error=error)


class Bash(BaseTool):
    """Uma ferramenta para executar comandos bash"""

    name: str = "bash"
    description: str = _BASH_DESCRIPTION
    parameters: dict = {
        "type": "object",
        "properties": {
            "command": {
                "type": "string",
                "description": "O comando bash a ser executado. Pode estar vazio para visualizar logs adicionais quando o cÃ³digo de saÃ­da anterior for `-1`. Pode ser `ctrl+c` para interromper o processo em execuÃ§Ã£o no momento.",
            },
            "working_directory": { # Novo parÃ¢metro
                "type": "string",
                "description": "Opcional. O diretÃ³rio de trabalho a partir do qual executar o comando. Assume o diretÃ³rio de trabalho atual do agente se nÃ£o especificado. Este diretÃ³rio Ã© definido quando a sessÃ£o (re)inicia.",
                "nullable": True
            }
        },
        "required": ["command"],
    }

    _session: Optional[_BashSession] = None

    async def execute(
        self, command: str | None = None, restart: bool = False, working_directory: Optional[str] = None, **kwargs # Adicionar parÃ¢metro
    ) -> CLIResult:
        if restart:
            if self._session:
                await self._session.close_async() # MUDAR AQUI
            self._session = _BashSession()
            # Usar config.workspace_root como padrÃ£o para working_directory
            effective_working_directory = working_directory if working_directory is not None else str(config.workspace_root)
            await self._session.start(working_directory=effective_working_directory)
            return CLIResult(system="a ferramenta foi reiniciada.")

        if self._session is None:
            self._session = _BashSession()
            # Usar config.workspace_root como padrÃ£o para working_directory
            effective_working_directory = working_directory if working_directory is not None else str(config.workspace_root)
            await self._session.start(working_directory=effective_working_directory)

        if command is not None:
            # Nota: working_directory Ã© definido no inÃ­cio da sessÃ£o.
            # Se for necessÃ¡rio mudar por comando, o prÃ³prio comando 'cd' deve ser usado.
            return await self._session.run(command)

        raise ToolError("nenhum comando fornecido.")

    async def cleanup(self):
        """Limpa a sessÃ£o bash se ela existir."""
        logger.info("Bash.cleanup: Iniciando...")
        if self._session:
            logger.info("Bash.cleanup: Prester a chamar self._session.close_async()")
            await self._session.close_async()
            logger.info("Bash.cleanup: self._session.close_async() concluÃ­do.")
            self._session = None
            logger.info("Bash.cleanup: self._session definido como None.")
        else:
            logger.info("Bash.cleanup: Nenhuma sessÃ£o ativa da ferramenta Bash para limpar.")
        logger.info("Bash.cleanup: Finalizado.")


if __name__ == "__main__":
    bash = Bash()
    rst = asyncio.run(bash.execute("ls -l"))
    print(rst)

```

### ARQUIVO: app/tool/str_replace_editor.py ###
```py
"""File and directory manipulation tool with sandbox support."""
import os # Ensure os is imported
from collections import defaultdict
from pathlib import Path
from typing import Any, DefaultDict, List, Literal, Optional, get_args

from app.config import config
from app.exceptions import ToolError
from app.tool import BaseTool
from app.tool.base import CLIResult, ToolResult
from app.tool.file_operators import (
    FileOperator,
    LocalFileOperator,
    PathLike,
    SandboxFileOperator,
)
from app.logger import logger # Moved import here


Command = Literal[
    "view",
    "create",
    "str_replace",
    "insert",
    "undo_edit",
    "copy_to_sandbox", # Nova opÃ§Ã£o
]

# Constants
SNIPPET_LINES: int = 4
MAX_RESPONSE_LEN: int = 16000
TRUNCATED_MESSAGE: str = (
    "<response clipped><NOTE>To save on context only part of this file has been shown to you. "
    "You should retry this tool after you have searched inside the file with `grep -n` "
    "in order to find the line numbers of what you are looking for.</NOTE>"
)

# Tool description
_STR_REPLACE_EDITOR_DESCRIPTION = """Custom editing tool for viewing, creating and editing files
* State is persistent across command calls and discussions with the user
* If `path` is a file, `view` displays the result of applying `cat -n`. If `path` is a directory, `view` lists non-hidden files and directories up to 2 levels deep
* The `create` command cannot be used if the specified `path` already exists as a file
* If a `command` generates a long output, it will be truncated and marked with `<response clipped>`
* The `undo_edit` command will revert the last edit made to the file at `path`
* O comando `copy_to_sandbox` copia um arquivo do sistema de arquivos local (host) para dentro do diretÃ³rio `/workspace` do sandbox. Requer o parÃ¢metro `path` (caminho do arquivo no host) e opcionalmente `container_filename` (nome do arquivo no sandbox, se diferente do original).

Notes for using the `str_replace` command:
* The `old_str` parameter should match EXACTLY one or more consecutive lines from the original file. Be mindful of whitespaces!
* If the `old_str` parameter is not unique in the file, the replacement will not be performed. Make sure to include enough context in `old_str` to make it unique
* The `new_str` parameter should contain the edited lines that should replace the `old_str`
"""


def maybe_truncate(
    content: str, truncate_after: Optional[int] = MAX_RESPONSE_LEN
) -> str:
    """Truncate content and append a notice if content exceeds the specified length."""
    if not truncate_after or len(content) <= truncate_after:
        return content
    return content[:truncate_after] + TRUNCATED_MESSAGE


class StrReplaceEditor(BaseTool):
    """A tool for viewing, creating, and editing files with sandbox support."""

    name: str = "str_replace_editor"
    description: str = _STR_REPLACE_EDITOR_DESCRIPTION
    parameters: dict = {
        "type": "object",
        "properties": {
            "command": {
                "description": "The commands to run. Allowed options are: `view`, `create`, `str_replace`, `insert`, `undo_edit`, `copy_to_sandbox`.",
                "enum": ["view", "create", "str_replace", "insert", "undo_edit", "copy_to_sandbox"],
                "type": "string",
            },
            "path": {
                "description": "Absolute path to file or directory. For `copy_to_sandbox`, this is the source path on the host.",
                "type": "string",
            },
            "file_text": {
                "description": "Required parameter of `create` command, with the content of the file to be created.",
                "type": "string",
            },
            "old_str": {
                "description": "Required parameter of `str_replace` command containing the string in `path` to replace.",
                "type": "string",
            },
            "new_str": {
                "description": "Optional parameter of `str_replace` command containing the new string (if not given, no string will be added). Required parameter of `insert` command containing the string to insert.",
                "type": "string",
            },
            "insert_line": {
                "description": "Required parameter of `insert` command. The `new_str` will be inserted AFTER the line `insert_line` of `path`.",
                "type": "integer",
            },
            "view_range": {
                "description": "Optional parameter of `view` command when `path` points to a file. If none is given, the full file is shown. If provided, the file will be shown in the indicated line number range, e.g. [11, 12] will show lines 11 and 12. Indexing at 1 to start. Setting `[start_line, -1]` shows all lines from `start_line` to the end of the file.",
                "items": {"type": "integer"},
                "type": "array",
            },
            "container_filename": { # Novo parÃ¢metro
                "description": "Optional. For `copy_to_sandbox` command. The desired filename for the file inside the sandbox's /workspace directory. If not provided, the original filename from the host path is used.",
                "type": "string",
                "nullable": True
            },
            "overwrite": { # Added for create command
                "description": "Optional parameter of `create` command. If true, overwrite the file if it already exists. Defaults to false.",
                "type": "boolean",
            }
        },
        "required": ["command", "path"],
    }
    _file_history: DefaultDict[PathLike, List[str]] = defaultdict(list)
    _local_operator: LocalFileOperator = LocalFileOperator()
    _sandbox_operator: SandboxFileOperator = SandboxFileOperator()

    @staticmethod
    def _sanitize_text_for_file(text_content: Any) -> Any:
        if not isinstance(text_content, str):
            # Warning removed: print(f"Warning: StrReplaceEditor._sanitize_text_for_file expected string but got {type(text_content)}. Returning as is.", file=sys.stderr)
            return text_content
        sanitized_content = text_content.replace('\u0000', '')
        return sanitized_content

    def _get_operator(self) -> FileOperator:
        """Get the appropriate file operator based on execution mode."""
        return (
            self._sandbox_operator
            if config.sandbox.use_sandbox
            else self._local_operator
        )

    async def execute(
        self,
        *,
        command: Command,
        path: str,
        file_text: str | None = None,
        view_range: list[int] | None = None,
        old_str: str | None = None,
        new_str: str | None = None,
        insert_line: int | None = None,
        container_filename: Optional[str] = None,
        overwrite: bool = False, # Added overwrite parameter
        **kwargs: Any,
    ) -> ToolResult:
        """Execute a file operation command."""

        if command == "copy_to_sandbox":
            # Ensure path is absolute for host operations before any operator selection
            # or workspace path prepending, as copy_to_sandbox host path is always absolute from user.
            host_path_for_copy = Path(path)
            if not host_path_for_copy.is_absolute():
                 raise ToolError(f"For 'copy_to_sandbox', the source 'path' on the host ('{path}') must be absolute.")

            await self.validate_path(command, host_path_for_copy, self._local_operator)
            try:
                target_container_filename = container_filename or os.path.basename(path)
                if not target_container_filename:
                     raise ToolError("Could not determine a valid target filename for the container from the provided path.")
                container_path = f"/workspace/{target_container_filename}"
                # copy_to_sandbox always uses sandbox_operator's client for the destination.
                await self._sandbox_operator.sandbox_client.copy_to_sandbox(host_path=str(host_path_for_copy), container_path=container_path)
                result = ToolResult(output=f"Arquivo {str(host_path_for_copy)} copiado para {container_path} no sandbox com sucesso.")
                return result
            except Exception as e:
                raise ToolError(f"Erro ao copiar arquivo para o sandbox: {e}")

        # For commands other than copy_to_sandbox, determine operator and potentially make path relative to workspace
        operator = self._get_operator()

        path_obj = Path(path)
        if not path_obj.is_absolute():
            path = str(config.workspace_root / path_obj)
            path_obj = Path(path) # Update path_obj to the new absolute path

        # Validate path for non-copy_to_sandbox commands using the chosen operator
        # Pass the 'overwrite' flag to validate_path for the 'create' command
        await self.validate_path(command, path_obj, operator, overwrite_flag_for_create=overwrite if command == "create" else None)

        if command == "view":
            result = await self.view(path_obj, view_range, operator)
        elif command == "create":
            if file_text is None:
                raise ToolError("Parameter `file_text` is required for command: create")
            file_text = StrReplaceEditor._sanitize_text_for_file(file_text)

            # Existence check is now handled by validate_path for create (if overwrite is false)
            # If validate_path passed (either file doesn't exist, or it does and overwrite=True), we can write.
            log_message_action = "Overwriting file" if await operator.exists(path_obj) else "Creating file"
            await operator.write_file(path_obj, file_text)

            # Manage file history only for successful writes of new content (not overwrites of identical content, though current logic doesn't check that)
            # For simplicity, we'll record history on any write here.
            self._file_history[str(path_obj)].append(file_text) # Use string path for dict key
            action_past_tense = "overwritten" if log_message_action == "Overwriting file" else "created"
            result = ToolResult(output=f"File {action_past_tense} successfully at: {str(path_obj)}")
            return result # Ensure ToolResult is returned directly
        elif command == "str_replace":
            if old_str is None:
                raise ToolError(
                    "Parameter `old_str` is required for command: str_replace"
                )
            result = await self.str_replace(path, old_str, new_str, operator)
        elif command == "insert":
            if insert_line is None:
                raise ToolError(
                    "Parameter `insert_line` is required for command: insert"
                )
            if new_str is None:
                raise ToolError("Parameter `new_str` is required for command: insert")
            result = await self.insert(path, insert_line, new_str, operator)
        elif command == "undo_edit":
            result = await self.undo_edit(path, operator)
        else: # Should only be copy_to_sandbox if not caught above, but that is handled.
             # This case should ideally not be reached if command is valid and handled.
            raise ToolError(
                 f'Unrecognized command {command}. The allowed commands for the {self.name} tool are: {", ".join(get_args(Command))}'
            )
        return result # result is already a ToolResult from the branches above

    async def validate_path(
        self, command: str, path: Path, operator: FileOperator, overwrite_flag_for_create: Optional[bool] = None
    ) -> None:
        """Validate path and command combination based on execution environment."""

        if command == "copy_to_sandbox": # Validation for copy_to_sandbox (host path)
            host_path_obj = path # In this context, path is the host_path
            if not host_path_obj.is_absolute(): # This check might be redundant if called after host_path_for_copy is made absolute
                raise ToolError(f"Para 'copy_to_sandbox', o 'path' (origem no host) '{host_path_obj}' deve ser absoluto.")
            # Use os.path for host checks, not operator (which could be sandbox)
            if not os.path.exists(str(host_path_obj)):
                raise ToolError(f"Para 'copy_to_sandbox', o arquivo de origem no host '{host_path_obj}' nÃ£o existe.")
            if not os.path.isfile(str(host_path_obj)):
                raise ToolError(f"Para 'copy_to_sandbox', o 'path' de origem no host '{host_path_obj}' nÃ£o Ã© um arquivo.")
            return # Validation for copy_to_sandbox is complete

        # Validations for other commands (view, create, str_replace, insert, undo_edit)
        if not path.is_absolute(): # This should have been handled by the caller for non-copy_to_sandbox
            raise ToolError(f"The path {path} must be an absolute path for this operation.")

        path_exists_result = await operator.exists(path)

        if command == "create":
            if path_exists_result and overwrite_flag_for_create is False: # Explicitly check for False
                raise ToolError(
                    f"File '{str(path)}' already exists. Set 'overwrite=True' to replace it."
                )
            # If path_exists_result is True and overwrite_flag_for_create is True, it's okay.
            # If path_exists_result is False, it's also okay.
        else: # For commands other than 'create'
            if not path_exists_result:
                raise ToolError(
                    f"The path {path} does not exist. Please provide a valid path."
                )
            is_dir_result = await operator.is_directory(path)
            if is_dir_result and command != "view":
                raise ToolError(
                    f"The path {path} is a directory and only the `view` command can be used on directories."
                )

    async def view(
        self,
        path: PathLike, # path is now Path object
        view_range: Optional[List[int]] = None,
        operator: FileOperator = None,
    ) -> CLIResult:
        """Display file or directory content."""
        is_dir = await operator.is_directory(path)
        if is_dir:
            if view_range:
                raise ToolError(
                    "The `view_range` parameter is not allowed when `path` points to a directory."
                )
            return await self._view_directory(path, operator)
        else:
            return await self._view_file(path, operator, view_range)

    @staticmethod
    async def _view_directory(path: PathLike, operator: FileOperator) -> CLIResult:
        """Display directory contents."""
        effective_path = str(path)
        if isinstance(operator, SandboxFileOperator):
            effective_path = await operator.get_sandbox_path(path)
        find_cmd = f"find {effective_path} -maxdepth 2 -not -path '*/\\.*'"
        returncode, stdout, stderr = await operator.run_command(find_cmd)
        if not stderr:
            stdout = (
                f"Here's the files and directories up to 2 levels deep in {path}, "
                f"excluding hidden items:\n{stdout}\n"
            )
        return CLIResult(output=stdout, error=stderr)

    async def _view_file(
        self,
        path: PathLike,
        operator: FileOperator,
        view_range: Optional[List[int]] = None,
    ) -> CLIResult:
        """Display file content, optionally within a specified line range."""
        file_content = await operator.read_file(path)
        init_line = 1
        if view_range:
            if len(view_range) != 2 or not all(isinstance(i, int) for i in view_range):
                raise ToolError(
                    "Invalid `view_range`. It should be a list of two integers."
                )
            file_lines = file_content.split("\n")
            n_lines_file = len(file_lines)
            init_line, final_line = view_range
            if init_line < 1 or init_line > n_lines_file:
                raise ToolError(
                    f"Invalid `view_range`: {view_range}. Its first element `{init_line}` should be "
                    f"within the range of lines of the file: {[1, n_lines_file]}"
                )
            if final_line > n_lines_file: # Should be fine even if final_line == -1
                if final_line != -1 : # only raise if not -1
                    raise ToolError(
                        f"Invalid `view_range`: {view_range}. Its second element `{final_line}` should be "
                        f"smaller than or equal to the number of lines in the file: `{n_lines_file}`"
                    )
            if final_line != -1 and final_line < init_line:
                raise ToolError(
                    f"Invalid `view_range`: {view_range}. Its second element `{final_line}` should be "
                    f"larger or equal than its first `{init_line}`"
                )
            if final_line == -1:
                file_content = "\n".join(file_lines[init_line - 1 :])
            else:
                file_content = "\n".join(file_lines[init_line - 1 : final_line])

        output_str = self._make_output(
            file_content,
            str(path),
            init_line=init_line,
            full_content_for_size_info=None if view_range else await operator.read_file(path) # Pass full content if not ranged
        )
        return CLIResult(output=output_str)

    async def str_replace(
        self,
        path: PathLike,
        old_str: str,
        new_str: Optional[str] = None,
        operator: FileOperator = None,
    ) -> CLIResult:
        """Replace a unique string in a file with a new string."""
        file_content_raw = await operator.read_file(path)
        file_content = file_content_raw.expandtabs()
        old_str = old_str.expandtabs()
        new_str = new_str.expandtabs() if new_str is not None else ""
        occurrences = file_content.count(old_str)
        if occurrences == 0:
            raise ToolError(
                f"No replacement was performed, old_str `{old_str}` did not appear verbatim in {path}."
            )
        elif occurrences > 1:
            file_content_lines = file_content.split("\n")
            lines = [
                idx + 1
                for idx, line in enumerate(file_content_lines)
                if old_str in line
            ]
            raise ToolError(
                f"No replacement was performed. Multiple occurrences of old_str `{old_str}` "
                f"in lines {lines}. Please ensure it is unique"
            )
        new_file_content = file_content.replace(old_str, new_str)
        new_file_content = StrReplaceEditor._sanitize_text_for_file(new_file_content)
        await operator.write_file(path, new_file_content)
        self._file_history[path].append(file_content)
        replacement_line = file_content.split(old_str)[0].count("\n")
        start_line = max(0, replacement_line - SNIPPET_LINES)
        end_line = replacement_line + SNIPPET_LINES + new_str.count("\n")
        snippet = "\n".join(new_file_content.split("\n")[start_line : end_line + 1])
        success_msg = f"The file {path} has been edited. "
        success_msg += self._make_output(
            snippet, f"a snippet of {path}", start_line + 1
        )
        success_msg += "Review the changes and make sure they are as expected. Edit the file again if necessary."
        return CLIResult(output=success_msg)

    async def insert(
        self,
        path: PathLike,
        insert_line: int,
        new_str: str,
        operator: FileOperator = None,
    ) -> CLIResult:
        """Insert text at a specific line in a file."""
        file_text_raw = await operator.read_file(path)
        file_text = file_text_raw.expandtabs()
        new_str = new_str.expandtabs()
        file_text_lines = file_text.split("\n")
        n_lines_file = len(file_text_lines)
        if insert_line < 0 or insert_line > n_lines_file:
            raise ToolError(
                f"Invalid `insert_line` parameter: {insert_line}. It should be within "
                f"the range of lines of the file: {[0, n_lines_file]}"
            )
        new_str_lines = new_str.split("\n")
        new_file_text_lines = (
            file_text_lines[:insert_line]
            + new_str_lines
            + file_text_lines[insert_line:]
        )
        snippet_lines = (
            file_text_lines[max(0, insert_line - SNIPPET_LINES) : insert_line]
            + new_str_lines
            + file_text_lines[insert_line : insert_line + SNIPPET_LINES]
        )
        new_file_text = "\n".join(new_file_text_lines)
        snippet = "\n".join(snippet_lines)
        new_file_text = StrReplaceEditor._sanitize_text_for_file(new_file_text)
        await operator.write_file(path, new_file_text)
        self._file_history[path].append(file_text)
        success_msg = f"The file {path} has been edited. "
        success_msg += self._make_output(
            snippet,
            "a snippet of the edited file",
            max(1, insert_line - SNIPPET_LINES + 1),
        )
        success_msg += "Review the changes and make sure they are as expected (correct indentation, no duplicate lines, etc). Edit the file again if necessary."
        return CLIResult(output=success_msg)

    async def undo_edit(
        self, path: PathLike, operator: FileOperator = None
    ) -> CLIResult:
        """Revert the last edit made to a file."""
        if not self._file_history[path]:
            raise ToolError(f"No edit history found for {path}.")
        old_text = self._file_history[path].pop()
        await operator.write_file(path, old_text)
        return CLIResult(
            output=f"Last edit to {path} undone successfully. {self._make_output(old_text, str(path))}"
        )

    def _make_output(
        self,
        file_content: str,
        file_descriptor: str,
        init_line: int = 1,
        expand_tabs: bool = True,
        full_content_for_size_info: Optional[str] = None,
    ) -> str:
        """Format file content for display with line numbers."""
        truncated_content = maybe_truncate(file_content)
        if full_content_for_size_info and truncated_content.endswith(TRUNCATED_MESSAGE):
            actual_total_lines = len(full_content_for_size_info.split('\n'))
            actual_total_chars = len(full_content_for_size_info)
            detailed_truncation_msg = TRUNCATED_MESSAGE + f" Full file: {actual_total_lines} lines, {actual_total_chars} chars."
            truncated_content = truncated_content.replace(TRUNCATED_MESSAGE, detailed_truncation_msg)
        file_content = truncated_content
        if expand_tabs:
            file_content = file_content.expandtabs()
        file_content = "\n".join(
            [
                f"{i + init_line:6}\t{line}"
                for i, line in enumerate(file_content.split("\n"))
            ]
        )
        return (
            f"Here's the result of running `cat -n` on {file_descriptor}:\n"
            + file_content
            + "\n"
        )

```

### ARQUIVO: app/tool/file_operators.py ###
```py
"""Interfaces e implementaÃ§Ãµes de operaÃ§Ãµes de arquivo para ambientes locais e sandbox."""

import asyncio
from pathlib import Path
from typing import Optional, Protocol, Tuple, Union, runtime_checkable

# Garantir que estes sejam importados apenas uma vez e corretamente
from app.config import SandboxSettings, config # Garantir que 'config' seja importado
from app.exceptions import ToolError
from app.sandbox.client import SANDBOX_CLIENT
from app.logger import logger # Garantir que logger seja importado

PathLike = Union[str, Path]


@runtime_checkable
class FileOperator(Protocol):
    """Interface para operaÃ§Ãµes de arquivo em diferentes ambientes."""

    async def read_file(self, path: PathLike) -> str:
        """LÃª o conteÃºdo de um arquivo."""
        ...

    async def write_file(self, path: PathLike, content: str) -> None:
        """Escreve conteÃºdo em um arquivo."""
        ...

    async def is_directory(self, path: PathLike) -> bool:
        """Verifica se o caminho aponta para um diretÃ³rio."""
        ...

    async def exists(self, path: PathLike) -> bool:
        """Verifica se o caminho existe."""
        ...

    async def run_command(
        self, cmd: str, timeout: Optional[float] = 120.0
    ) -> Tuple[int, str, str]:
        """Executa um comando de shell e retorna (cÃ³digo_de_retorno, stdout, stderr)."""
        ...

    async def get_sandbox_path(self, host_path: PathLike) -> str:
        """Traduz um caminho do host para seu equivalente no sandbox, se aplicÃ¡vel."""
        raise NotImplementedError


class LocalFileOperator(FileOperator):
    """ImplementaÃ§Ã£o de operaÃ§Ãµes de arquivo para o sistema de arquivos local."""

    encoding: str = "utf-8"

    async def read_file(self, path: PathLike) -> str:
        """LÃª o conteÃºdo de um arquivo local."""
        try:
            content = Path(path).read_text(encoding=self.encoding)
            return content
        except Exception as e:
            raise ToolError(f"Falha ao ler {path}: {str(e)}") from None

    async def write_file(self, path: PathLike, content: str) -> None:
        """Escreve conteÃºdo em um arquivo local."""
        try:
            Path(path).write_text(content, encoding=self.encoding)
        except Exception as e:
            raise ToolError(f"Falha ao escrever em {path}: {str(e)}") from None

    async def is_directory(self, path: PathLike) -> bool:
        """Verifica se o caminho aponta para um diretÃ³rio."""
        result = Path(path).is_dir()
        return result

    async def exists(self, path: PathLike) -> bool:
        """Verifica se o caminho existe."""
        result = Path(path).exists()
        return result

    async def run_command(
        self, cmd: str, timeout: Optional[float] = 120.0
    ) -> Tuple[int, str, str]:
        """Executa um comando de shell localmente."""
        process = await asyncio.create_subprocess_shell(
            cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE
        )

        try:
            stdout, stderr = await asyncio.wait_for(
                process.communicate(), timeout=timeout
            )
            return (
                process.returncode or 0,
                stdout.decode(),
                stderr.decode(),
            )
        except asyncio.TimeoutError as exc:
            try:
                process.kill()
            except ProcessLookupError:
                pass # Processo jÃ¡ encerrado
            raise TimeoutError(
                f"Comando '{cmd}' excedeu o tempo limite apÃ³s {timeout} segundos"
            ) from exc

    async def get_sandbox_path(self, host_path: PathLike) -> str:
        """Operador local nÃ£o traduz para caminhos do sandbox, retorna o original."""
        return str(host_path)


class SandboxFileOperator(FileOperator):
    """ImplementaÃ§Ã£o de operaÃ§Ãµes de arquivo para o ambiente sandbox."""

    SANDBOX_WORKSPACE_PATH = "/workspace" # Workspace padrÃ£o do sandbox

    def __init__(self):
        self.sandbox_client = SANDBOX_CLIENT
        self.host_workspace_root = Path(config.workspace_root).resolve()

    def _translate_to_sandbox_path(self, host_path: PathLike) -> str:
        """Traduz um caminho absoluto do host para seu caminho correspondente no sandbox."""
        resolved_host_path = Path(host_path).resolve()
        try:
            relative_path = resolved_host_path.relative_to(self.host_workspace_root)
        except ValueError as e:
            raise ToolError(
                f"O caminho '{host_path}' nÃ£o estÃ¡ dentro do workspace do host configurado "
                f"'{self.host_workspace_root}'. NÃ£o Ã© possÃ­vel traduzir para o caminho do sandbox."
            ) from e
        sandbox_path = Path(self.SANDBOX_WORKSPACE_PATH) / relative_path
        return str(sandbox_path)

    async def get_sandbox_path(self, host_path: PathLike) -> str:
        """MÃ©todo pÃºblico para obter o caminho traduzido do sandbox."""
        translated_path = self._translate_to_sandbox_path(host_path)
        return translated_path

    async def _ensure_sandbox_initialized(self):
        """Garante que o sandbox esteja inicializado."""
        if not self.sandbox_client.sandbox:
            await self.sandbox_client.create(config=SandboxSettings())

    async def read_file(self, path: PathLike) -> str:
        """LÃª o conteÃºdo de um arquivo no sandbox."""
        await self._ensure_sandbox_initialized()
        sandbox_path = self._translate_to_sandbox_path(path)
        try:
            content = await self.sandbox_client.read_file(sandbox_path)
            return content
        except Exception as e:
            raise ToolError(f"Falha ao ler {sandbox_path} no sandbox: {str(e)}") from None

    async def write_file(self, path: PathLike, content: str) -> None:
        """Escreve conteÃºdo em um arquivo no sandbox."""
        await self._ensure_sandbox_initialized()
        sandbox_path = self._translate_to_sandbox_path(path)
        try:
            await self.sandbox_client.write_file(sandbox_path, content)
        except Exception as e:
            raise ToolError(f"Falha ao escrever em {sandbox_path} no sandbox: {str(e)}") from None

    async def is_directory(self, path: PathLike) -> bool:
        """Verifica se o caminho aponta para um diretÃ³rio no sandbox."""
        await self._ensure_sandbox_initialized()
        sandbox_path = self._translate_to_sandbox_path(path)
        cmd_str = f"test -d {sandbox_path} && echo 'true' || echo 'false'"
        result_str = await self.sandbox_client.run_command(cmd_str)
        result_bool = result_str.strip().lower() == "true" # Garante comparaÃ§Ã£o em minÃºsculas
        return result_bool

    async def exists(self, path: PathLike) -> bool:
        """Verifica se o caminho existe no sandbox."""
        await self._ensure_sandbox_initialized()
        sandbox_path = self._translate_to_sandbox_path(path)
        cmd_str = f"test -e {sandbox_path} && echo 'true' || echo 'false'"
        result_str = await self.sandbox_client.run_command(cmd_str)
        result_bool = result_str.strip().lower() == "true" # Garante comparaÃ§Ã£o em minÃºsculas
        return result_bool

    async def run_command(
        self, cmd: str, timeout: Optional[float] = 120.0
    ) -> Tuple[int, str, str]:
        """Executa um comando no ambiente sandbox."""
        await self._ensure_sandbox_initialized()
        try:
            stdout = await self.sandbox_client.run_command(
                cmd, timeout=int(timeout) if timeout else None
            )
            return (
                0,
                stdout,
                "",
            )
        except TimeoutError as exc:
            raise TimeoutError(
                f"Comando '{cmd}' excedeu o tempo limite apÃ³s {timeout} segundos no sandbox"
            ) from exc
        except Exception as exc:
            return 1, "", f"Erro ao executar comando no sandbox: {str(exc)}"

```

### ARQUIVO: app/tool/chart_visualization/README.md ###
```md


# Chart Visualization Tool

The chart visualization tool generates data processing code through Python and ultimately invokes [@visactor/vmind](https://github.com/VisActor/VMind) to obtain chart specifications. Chart rendering is implemented using [@visactor/vchart](https://github.com/VisActor/VChart).

## Installation

1. Install Node.js >= 18

```bash
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash
# After installation, restart the terminal and install the latest Node.js LTS version:
nvm install --lts
```

2. Install dependencies

```bash
cd app/tool/chart_visualization
npm install
```

## Tool
### python_execute

Execute the necessary parts of data analysis (excluding data visualization) using Python code, including data processing, data summary, report generation, and some general Python script code.

#### Input
```typescript
{
  // Code type: data processing/data report/other general tasks
  code_type: "process" | "report" | "others"
  // Final execution code
  code: string;
}
```

#### Output
Python execution results, including the saving of intermediate files and print output results.

### visualization_preparation

A pre-tool for data visualization with two purposes,

#### Data -> Chart
Used to extract the data needed for analysis (.csv) and the corresponding visualization description from the data, ultimately outputting a JSON configuration file.

#### Chart + Insight -> Chart
Select existing charts and corresponding data insights, choose data insights to add to the chart in the form of data annotations, and finally generate a JSON configuration file.

#### Input
```typescript
{
  // Code type: data visualization or data insight addition
  code_type: "visualization" | "insight"
  // Python code used to produce the final JSON file
  code: string;
}
```

#### Output
A configuration file for data visualization, used for the `data_visualization tool`.

## data_visualization

Generate specific data visualizations based on the content of `visualization_preparation`.

### Input
```typescript
{
  // Configuration file path
  json_path: string;
  // Current purpose, data visualization or insight annotation addition
  tool_type: "visualization" | "insight";
  // Final product png or html; html supports vchart rendering and interaction
  output_type: 'png' | 'html'
  // Language, currently supports Chinese and English
  language: "zh" | "en"
}
```

## VMind Configuration

### LLM

VMind requires LLM invocation for intelligent chart generation. By default, it uses the `config.llm["default"]` configuration.

### Generation Settings

Main configurations include chart dimensions, theme, and generation method:
### Generation Method
Default: png. Currently supports automatic selection of `output_type` by LLM based on context.

### Dimensions
Default dimensions are unspecified. For HTML output, charts fill the entire page by default. For PNG output, defaults to `1000*1000`.

### Theme
Default theme: `'light'`. VChart supports multiple themes. See [Themes](https://www.visactor.io/vchart/guide/tutorial_docs/Theme/Theme_Extension).

## Test

Currently, three tasks of different difficulty levels are set for testing.

### Simple Chart Generation Task

Provide data and specific chart generation requirements, test results, execute the command:
```bash
python -m app.tool.chart_visualization.test.chart_demo
```
The results should be located under `workspace\visualization`, involving 9 different chart results.

### Simple Data Report Task

Provide simple raw data analysis requirements, requiring simple processing of the data, execute the command:
```bash
python -m app.tool.chart_visualization.test.report_demo
```
The results are also located under `workspace\visualization`.

```

### ARQUIVO: app/tool/chart_visualization/README_ko.md ###
```md
# ì°¨íŠ¸ ì‹œê°í™” ë„êµ¬

ì°¨íŠ¸ ì‹œê°í™” ë„êµ¬ëŠ” Pythonì„ í†µí•´ ë°ì´í„° ì²˜ë¦¬ ì½”ë“œë¥¼ ìƒì„±í•˜ê³ , ìµœì¢…ì ìœ¼ë¡œ [@visactor/vmind](https://github.com/VisActor/VMind)ë¥¼ í˜¸ì¶œí•˜ì—¬ ì°¨íŠ¸ ì‚¬ì–‘ì„ ì–»ìŠµë‹ˆë‹¤. ì°¨íŠ¸ ë Œë”ë§ì€ [@visactor/vchart](https://github.com/VisActor/VChart)ë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬í˜„ë©ë‹ˆë‹¤.

## ì„¤ì¹˜ (Mac / Linux)

1. Node.js 18 ì´ìƒ ì„¤ì¹˜

```bash
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash
# nvm í™œì„±í™”, ì˜ˆë¥¼ ë“¤ì–´ Bash
source ~/.bashrc
# ê·¸ëŸ° ë‹¤ìŒ ìµœì‹  ì•ˆì • ë²„ì „ì˜ Node ì„¤ì¹˜
nvm install node
# ì‚¬ìš© í™œì„±í™”, ì˜ˆë¥¼ ë“¤ì–´ ìµœì‹  ì•ˆì • ë²„ì „ì´ 22ì¸ ê²½ìš° use 22
nvm use 22
```

2. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
# í˜„ì¬ ì €ì¥ì†Œì—ì„œ í•´ë‹¹ ìœ„ì¹˜ë¡œ ì´ë™
cd app/tool/chart_visualization
npm install
```

## ì„¤ì¹˜ (Windows)
1. nvm-windows ì„¤ì¹˜

    [ê³µì‹ GitHub í˜ì´ì§€](https://github.com/coreybutler/nvm-windows?tab=readme-ov-file#readme)ì—ì„œ ìµœì‹  ë²„ì „ì˜ `nvm-setup.exe`ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ì„¤ì¹˜í•©ë‹ˆë‹¤.

2. nvmì„ ì‚¬ìš©í•˜ì—¬ Node.js ì„¤ì¹˜

```powershell
# ê·¸ëŸ° ë‹¤ìŒ ìµœì‹  ì•ˆì • ë²„ì „ì˜ Node ì„¤ì¹˜
nvm install node
# ì‚¬ìš© í™œì„±í™”, ì˜ˆë¥¼ ë“¤ì–´ ìµœì‹  ì•ˆì • ë²„ì „ì´ 22ì¸ ê²½ìš° use 22
nvm use 22
```

3. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
# í˜„ì¬ ì €ì¥ì†Œì—ì„œ í•´ë‹¹ ìœ„ì¹˜ë¡œ ì´ë™
cd app/tool/chart_visualization
npm install
```

## ë„êµ¬
### python_execute

Python ì½”ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë¶„ì„ì˜ í•„ìš”í•œ ë¶€ë¶„(ë°ì´í„° ì‹œê°í™” ì œì™¸)ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ë°ì´í„° ì²˜ë¦¬, ë°ì´í„° ìš”ì•½, ë³´ê³ ì„œ ìƒì„± ë° ì¼ë¶€ ì¼ë°˜ì ì¸ Python ìŠ¤í¬ë¦½íŠ¸ ì½”ë“œê°€ í¬í•¨ë©ë‹ˆë‹¤.

#### ì…ë ¥
```typescript
{
  // ì½”ë“œ ìœ í˜•: ë°ì´í„° ì²˜ë¦¬/ë°ì´í„° ë³´ê³ ì„œ/ê¸°íƒ€ ì¼ë°˜ ì‘ì—…
  code_type: "process" | "report" | "others"
  // ìµœì¢… ì‹¤í–‰ ì½”ë“œ
  code: string;
}
```

#### ì¶œë ¥
Python ì‹¤í–‰ ê²°ê³¼, ì¤‘ê°„ íŒŒì¼ ì €ì¥ ë° ì¶œë ¥ ê²°ê³¼ í¬í•¨.

### visualization_preparation

ë°ì´í„° ì‹œê°í™”ë¥¼ ìœ„í•œ ì‚¬ì „ ë„êµ¬ë¡œ ë‘ ê°€ì§€ ëª©ì ì´ ìˆìŠµë‹ˆë‹¤.

#### ë°ì´í„° -> ì°¨íŠ¸
ë¶„ì„ì— í•„ìš”í•œ ë°ì´í„°(.csv)ì™€ í•´ë‹¹ ì‹œê°í™” ì„¤ëª…ì„ ë°ì´í„°ì—ì„œ ì¶”ì¶œí•˜ì—¬ ìµœì¢…ì ìœ¼ë¡œ JSON êµ¬ì„± íŒŒì¼ì„ ì¶œë ¥í•©ë‹ˆë‹¤.

#### ì°¨íŠ¸ + ì¸ì‚¬ì´íŠ¸ -> ì°¨íŠ¸
ê¸°ì¡´ ì°¨íŠ¸ì™€ í•´ë‹¹ ë°ì´í„° ì¸ì‚¬ì´íŠ¸ë¥¼ ì„ íƒí•˜ê³ , ë°ì´í„° ì£¼ì„ í˜•íƒœë¡œ ì°¨íŠ¸ì— ì¶”ê°€í•  ë°ì´í„° ì¸ì‚¬ì´íŠ¸ë¥¼ ì„ íƒí•˜ì—¬ ìµœì¢…ì ìœ¼ë¡œ JSON êµ¬ì„± íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.

#### ì…ë ¥
```typescript
{
  // ì½”ë“œ ìœ í˜•: ë°ì´í„° ì‹œê°í™” ë˜ëŠ” ë°ì´í„° ì¸ì‚¬ì´íŠ¸ ì¶”ê°€
  code_type: "visualization" | "insight"
  // ìµœì¢… JSON íŒŒì¼ì„ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” Python ì½”ë“œ
  code: string;
}
```

#### ì¶œë ¥
`data_visualization tool`ì— ì‚¬ìš©ë˜ëŠ” ë°ì´í„° ì‹œê°í™”ë¥¼ ìœ„í•œ êµ¬ì„± íŒŒì¼.

## data_visualization

`visualization_preparation`ì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ íŠ¹ì • ë°ì´í„° ì‹œê°í™”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

### ì…ë ¥
```typescript
{
  // êµ¬ì„± íŒŒì¼ ê²½ë¡œ
  json_path: string;
  // í˜„ì¬ ëª©ì , ë°ì´í„° ì‹œê°í™” ë˜ëŠ” ì¸ì‚¬ì´íŠ¸ ì£¼ì„ ì¶”ê°€
  tool_type: "visualization" | "insight";
  // ìµœì¢… ì œí’ˆ png ë˜ëŠ” html; htmlì€ vchart ë Œë”ë§ ë° ìƒí˜¸ì‘ìš© ì§€ì›
  output_type: 'png' | 'html'
  // ì–¸ì–´, í˜„ì¬ ì¤‘êµ­ì–´ ë° ì˜ì–´ ì§€ì›
  language: "zh" | "en"
}
```

## VMind êµ¬ì„±

### LLM

VMindëŠ” ì§€ëŠ¥í˜• ì°¨íŠ¸ ìƒì„±ì„ ìœ„í•´ LLM í˜¸ì¶œì´ í•„ìš”í•©ë‹ˆë‹¤. ê¸°ë³¸ì ìœ¼ë¡œ `config.llm["default"]` êµ¬ì„±ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

### ìƒì„± ì„¤ì •

ì£¼ìš” êµ¬ì„±ì—ëŠ” ì°¨íŠ¸ í¬ê¸°, í…Œë§ˆ ë° ìƒì„± ë°©ë²•ì´ í¬í•¨ë©ë‹ˆë‹¤.
### ìƒì„± ë°©ë²•
ê¸°ë³¸ê°’: png. í˜„ì¬ LLMì´ ì»¨í…ìŠ¤íŠ¸ì— ë”°ë¼ `output_type`ì„ ìë™ìœ¼ë¡œ ì„ íƒí•˜ëŠ” ê²ƒì„ ì§€ì›í•©ë‹ˆë‹¤.

### í¬ê¸°
ê¸°ë³¸ í¬ê¸°ëŠ” ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. HTML ì¶œë ¥ì˜ ê²½ìš° ì°¨íŠ¸ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ì „ì²´ í˜ì´ì§€ë¥¼ ì±„ì›ë‹ˆë‹¤. PNG ì¶œë ¥ì˜ ê²½ìš° ê¸°ë³¸ê°’ì€ `1000*1000`ì…ë‹ˆë‹¤.

### í…Œë§ˆ
ê¸°ë³¸ í…Œë§ˆ: `'light'`. VChartëŠ” ì—¬ëŸ¬ í…Œë§ˆë¥¼ ì§€ì›í•©ë‹ˆë‹¤. [í…Œë§ˆ](https://www.visactor.io/vchart/guide/tutorial_docs/Theme/Theme_Extension)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

## í…ŒìŠ¤íŠ¸

í˜„ì¬, ì„œë¡œ ë‹¤ë¥¸ ë‚œì´ë„ì˜

```

### ARQUIVO: app/tool/chart_visualization/README_ja.md ###
```md
# ã‚°ãƒ©ãƒ•å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«

ã‚°ãƒ©ãƒ•å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«ã¯ã€Pythonã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã€æœ€çµ‚çš„ã«[@visactor/vmind](https://github.com/VisActor/VMind)ã‚’å‘¼ã³å‡ºã—ã¦ã‚°ãƒ©ãƒ•ã®specçµæœã‚’å¾—ã¾ã™ã€‚ã‚°ãƒ©ãƒ•ã®ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã«ã¯[@visactor/vchart](https://github.com/VisActor/VChart)ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« (Mac / Linux)

1. Node >= 18ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash
# nvmã‚’æœ‰åŠ¹åŒ–ã€ä¾‹ã¨ã—ã¦Bashã‚’ä½¿ç”¨
source ~/.bashrc
# ãã®å¾Œã€æœ€æ–°ã®å®‰å®šç‰ˆNodeã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
nvm install node
# ä½¿ç”¨ã‚’æœ‰åŠ¹åŒ–ã€ä¾‹ãˆã°æœ€æ–°ã®å®‰å®šç‰ˆãŒ22ã®å ´åˆã€use 22
nvm use 22
```

2. ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
cd app/tool/chart_visualization
npm install
```

## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« (Windows)
1. nvm-windowsã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

    [GitHubå…¬å¼ã‚µã‚¤ãƒˆ](https://github.com/coreybutler/nvm-windows?tab=readme-ov-file#readme)ã‹ã‚‰æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®`nvm-setup.exe`ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

2. nvmã‚’ä½¿ç”¨ã—ã¦Nodeã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```powershell
# ãã®å¾Œã€æœ€æ–°ã®å®‰å®šç‰ˆNodeã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
nvm install node
# ä½¿ç”¨ã‚’æœ‰åŠ¹åŒ–ã€ä¾‹ãˆã°æœ€æ–°ã®å®‰å®šç‰ˆãŒ22ã®å ´åˆã€use 22
nvm use 22
```

3. ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# ç¾åœ¨ã®ãƒªãƒã‚¸ãƒˆãƒªã§é©åˆ‡ãªä½ç½®ã«ç§»å‹•
cd app/tool/chart_visualization
npm install
```

## ãƒ„ãƒ¼ãƒ«
### python_execute

Pythonã‚³ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿åˆ†æï¼ˆãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ã‚’é™¤ãï¼‰ã«å¿…è¦ãªéƒ¨åˆ†ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚ã“ã‚Œã«ã¯ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã€ãƒ‡ãƒ¼ã‚¿è¦ç´„ã€ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã€ãŠã‚ˆã³ä¸€èˆ¬çš„ãªPythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚³ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¾ã™ã€‚

#### å…¥åŠ›
```typescript
{
  // ã‚³ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ï¼šãƒ‡ãƒ¼ã‚¿å‡¦ç†/ãƒ‡ãƒ¼ã‚¿ãƒ¬ãƒãƒ¼ãƒˆ/ãã®ä»–ã®ä¸€èˆ¬çš„ãªã‚¿ã‚¹ã‚¯
  code_type: "process" | "report" | "others"
  // æœ€çµ‚å®Ÿè¡Œã‚³ãƒ¼ãƒ‰
  code: string;
}
```

#### å‡ºåŠ›
Pythonå®Ÿè¡Œçµæœã€ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ã¨printå‡ºåŠ›çµæœã‚’å«ã‚€

### visualization_preparation

ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ã®æº–å‚™ãƒ„ãƒ¼ãƒ«ã§ã€2ã¤ã®ç”¨é€”ãŒã‚ã‚Šã¾ã™ã€‚

#### Data -> Chart
ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åˆ†æã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿(.csv)ã¨å¯¾å¿œã™ã‚‹å¯è¦–åŒ–ã®èª¬æ˜ã‚’æŠ½å‡ºã—ã€æœ€çµ‚çš„ã«JSONè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚

#### Chart + Insight -> Chart
æ—¢å­˜ã®ã‚°ãƒ©ãƒ•ã¨å¯¾å¿œã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’é¸æŠã—ã€ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’ãƒ‡ãƒ¼ã‚¿æ³¨é‡ˆã®å½¢å¼ã§ã‚°ãƒ©ãƒ•ã«è¿½åŠ ã—ã€æœ€çµ‚çš„ã«JSONè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

#### å…¥åŠ›
```typescript
{
  // ã‚³ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ï¼šãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ã‚µã‚¤ãƒˆè¿½åŠ 
  code_type: "visualization" | "insight"
  // æœ€çµ‚çš„ãªJSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®Pythonã‚³ãƒ¼ãƒ‰
  code: string;
}
```

#### å‡ºåŠ›
ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã€`data_visualization tool`ã§ä½¿ç”¨

## data_visualization

`visualization_preparation`ã®å†…å®¹ã«åŸºã¥ã„ã¦å…·ä½“çš„ãªãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ã‚’ç”Ÿæˆ

### å…¥åŠ›
```typescript
{
  // è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
  json_path: string;
  // ç¾åœ¨ã®ç”¨é€”ã€ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ã¾ãŸã¯ã‚¤ãƒ³ã‚µã‚¤ãƒˆæ³¨é‡ˆè¿½åŠ 
  tool_type: "visualization" | "insight";
  // æœ€çµ‚æˆæœç‰©pngã¾ãŸã¯html;htmlã§ã¯vchartã®ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã¨ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã‚µãƒãƒ¼ãƒˆ
  output_type: 'png' | 'html'
  // è¨€èªã€ç¾åœ¨ã¯ä¸­å›½èªã¨è‹±èªã‚’ã‚µãƒãƒ¼ãƒˆ
  language: "zh" | "en"
}
```

## å‡ºåŠ›
æœ€çµ‚çš„ã«'png'ã¾ãŸã¯'html'ã®å½¢å¼ã§ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜ã•ã‚Œã€ä¿å­˜ã•ã‚ŒãŸã‚°ãƒ©ãƒ•ã®ãƒ‘ã‚¹ã¨ã‚°ãƒ©ãƒ•å†…ã§ç™ºè¦‹ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’å‡ºåŠ›

## VMindè¨­å®š

### LLM

VMindè‡ªä½“

```

### ARQUIVO: app/tool/chart_visualization/__init__.py ###
```py
from app.tool.chart_visualization.chart_prepare import VisualizationPrepare
from app.tool.chart_visualization.data_visualization import DataVisualization
from app.tool.chart_visualization.python_execute import NormalPythonExecute


__all__ = ["DataVisualization", "VisualizationPrepare", "NormalPythonExecute"]

```

### ARQUIVO: app/tool/chart_visualization/data_visualization.py ###
```py
import asyncio
import json
import os
from typing import Any, Hashable

import pandas as pd
from pydantic import Field, model_validator

from app.config import config
from app.llm import LLM
from app.logger import logger
from app.tool.base import BaseTool


class DataVisualization(BaseTool):
    name: str = "data_visualization"
    description: str = """Visualize statistical chart or Add insights in chart with JSON info from visualization_preparation tool. You can do steps as follows:
1. Visualize statistical chart
2. Choose insights into chart based on step 1 (Optional)
Outputs:
1. Charts (png/html)
2. Charts Insights (.md)(Optional)"""
    parameters: dict = {
        "type": "object",
        "properties": {
            "json_path": {
                "type": "string",
                "description": """file path of json info with ".json" in the end""",
            },
            "output_type": {
                "description": "Rendering format (html=interactive)",
                "type": "string",
                "default": "html",
                "enum": ["png", "html"],
            },
            "tool_type": {
                "description": "visualize chart or add insights",
                "type": "string",
                "default": "visualization",
                "enum": ["visualization", "insight"],
            },
            "language": {
                "description": "english(en) / chinese(zh)",
                "type": "string",
                "default": "en",
                "enum": ["zh", "en"],
            },
        },
        "required": ["code"],
    }
    llm: LLM = Field(default_factory=LLM, description="Language model instance")

    @model_validator(mode="after")
    def initialize_llm(self):
        """Initialize llm with default settings if not provided."""
        if self.llm is None or not isinstance(self.llm, LLM):
            self.llm = LLM(config_name=self.name.lower())
        return self

    def get_file_path(
        self,
        json_info: list[dict[str, str]],
        path_str: str,
        directory: str = None,
    ) -> list[str]:
        res = []
        for item in json_info:
            if os.path.exists(item[path_str]):
                res.append(item[path_str])
            elif os.path.exists(
                os.path.join(f"{directory or config.workspace_root}", item[path_str])
            ):
                res.append(
                    os.path.join(
                        f"{directory or config.workspace_root}", item[path_str]
                    )
                )
            else:
                raise Exception(f"No such file or directory: {item[path_str]}")
        return res

    def success_output_template(self, result: list[dict[str, str]]) -> str:
        content = ""
        if len(result) == 0:
            return "Is EMPTY!"
        for item in result:
            content += f"""## {item['title']}\nChart saved in: {item['chart_path']}"""
            if "insight_path" in item and item["insight_path"] and "insight_md" in item:
                content += "\n" + item["insight_md"]
            else:
                content += "\n"
        return f"Chart Generated Successful!\n{content}"

    async def data_visualization(
        self, json_info: list[dict[str, str]], output_type: str, language: str
    ) -> str:
        data_list = []
        csv_file_path = self.get_file_path(json_info, "csvFilePath")
        for index, item in enumerate(json_info):
            df = pd.read_csv(csv_file_path[index], encoding="utf-8")
            df = df.astype(object)
            df = df.where(pd.notnull(df), None)
            data_dict_list = df.to_json(orient="records", force_ascii=False)

            data_list.append(
                {
                    "file_name": os.path.basename(csv_file_path[index]).replace(
                        ".csv", ""
                    ),
                    "dict_data": data_dict_list,
                    "chartTitle": item["chartTitle"],
                }
            )
        tasks = [
            self.invoke_vmind(
                dict_data=item["dict_data"],
                chart_description=item["chartTitle"],
                file_name=item["file_name"],
                output_type=output_type,
                task_type="visualization",
                language=language,
            )
            for item in data_list
        ]

        results = await asyncio.gather(*tasks)
        error_list = []
        success_list = []
        for index, result in enumerate(results):
            csv_path = csv_file_path[index]
            if "error" in result and "chart_path" not in result:
                error_list.append(f"Error in {csv_path}: {result['error']}")
            else:
                success_list.append(
                    {
                        **result,
                        "title": json_info[index]["chartTitle"],
                    }
                )
        if len(error_list) > 0:
            return {
                "observation": f"# Error chart generated{'\n'.join(error_list)}\n{self.success_output_template(success_list)}",
                "success": False,
            }
        else:
            return {"observation": f"{self.success_output_template(success_list)}"}

    async def add_insighs(
        self, json_info: list[dict[str, str]], output_type: str
    ) -> str:
        data_list = []
        chart_file_path = self.get_file_path(
            json_info, "chartPath", os.path.join(config.workspace_root, "visualization")
        )
        for index, item in enumerate(json_info):
            if "insights_id" in item:
                data_list.append(
                    {
                        "file_name": os.path.basename(chart_file_path[index]).replace(
                            f".{output_type}", ""
                        ),
                        "insights_id": item["insights_id"],
                    }
                )
        tasks = [
            self.invoke_vmind(
                insights_id=item["insights_id"],
                file_name=item["file_name"],
                output_type=output_type,
                task_type="insight",
            )
            for item in data_list
        ]
        results = await asyncio.gather(*tasks)
        error_list = []
        success_list = []
        for index, result in enumerate(results):
            chart_path = chart_file_path[index]
            if "error" in result and "chart_path" not in result:
                error_list.append(f"Error in {chart_path}: {result['error']}")
            else:
                success_list.append(chart_path)
        success_template = (
            f"# Charts Update with Insights\n{','.join(success_list)}"
            if len(success_list) > 0
            else ""
        )
        if len(error_list) > 0:
            return {
                "observation": f"# Error in chart insights:{'\n'.join(error_list)}\n{success_template}",
                "success": False,
            }
        else:
            return {"observation": f"{success_template}"}

    async def execute(
        self,
        json_path: str,
        output_type: str | None = "html",
        tool_type: str | None = "visualization",
        language: str | None = "en",
    ) -> str:
        try:
            logger.info(f"ğŸ“ˆ data_visualization with {json_path} in: {tool_type} ")
            with open(json_path, "r", encoding="utf-8") as file:
                json_info = json.load(file)
            if tool_type == "visualization":
                return await self.data_visualization(json_info, output_type, language)
            else:
                return await self.add_insighs(json_info, output_type)
        except Exception as e:
            return {
                "observation": f"Error: {e}",
                "success": False,
            }

    async def invoke_vmind(
        self,
        file_name: str,
        output_type: str,
        task_type: str,
        insights_id: list[str] = None,
        dict_data: list[dict[Hashable, Any]] = None,
        chart_description: str = None,
        language: str = "en",
    ):
        llm_config = {
            "base_url": self.llm.base_url,
            "model": self.llm.model,
            "api_key": self.llm.api_key,
        }
        vmind_params = {
            "llm_config": llm_config,
            "user_prompt": chart_description,
            "dataset": dict_data,
            "file_name": file_name,
            "output_type": output_type,
            "insights_id": insights_id,
            "task_type": task_type,
            "directory": str(config.workspace_root),
            "language": language,
        }
        # build async sub process
        process = await asyncio.create_subprocess_exec(
            "npx",
            "ts-node",
            "src/chartVisualize.ts",
            stdin=asyncio.subprocess.PIPE,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
            cwd=os.path.dirname(__file__),
        )
        input_json = json.dumps(vmind_params, ensure_ascii=False).encode("utf-8")
        try:
            stdout, stderr = await process.communicate(input_json)
            stdout_str = stdout.decode("utf-8")
            stderr_str = stderr.decode("utf-8")
            if process.returncode == 0:
                return json.loads(stdout_str)
            else:
                return {"error": f"Node.js Error: {stderr_str}"}
        except Exception as e:
            return {"error": f"Subprocess Error: {str(e)}"}

```

### ARQUIVO: app/tool/chart_visualization/python_execute.py ###
```py
from app.config import config
from app.tool.python_execute import PythonExecute


class NormalPythonExecute(PythonExecute):
    """A tool for executing Python code with timeout and safety restrictions."""

    name: str = "python_execute"
    description: str = """Execute Python code for in-depth data analysis / data report(task conclusion) / other normal task without direct visualization."""
    parameters: dict = {
        "type": "object",
        "properties": {
            "code_type": {
                "description": "code type, data process / data report / others",
                "type": "string",
                "default": "process",
                "enum": ["process", "report", "others"],
            },
            "code": {
                "type": "string",
                "description": """Python code to execute.
# Note
1. The code should generate a comprehensive text-based report containing dataset overview, column details, basic statistics, derived metrics, timeseries comparisons, outliers, and key insights.
2. Use print() for all outputs so the analysis (including sections like 'Dataset Overview' or 'Preprocessing Results') is clearly visible and save it also
3. Save any report / processed files / each analysis result in worksapce directory: {directory}
4. Data reports need to be content-rich, including your overall analysis process and corresponding data visualization.
5. You can invode this tool step-by-step to do data analysis from summary to in-depth with data report saved also""".format(
                    directory=config.workspace_root
                ),
            },
        },
        "required": ["code"],
    }

    async def execute(self, code: str, code_type: str | None = None, timeout=5):
        return await super().execute(code, timeout)

```

### ARQUIVO: app/tool/chart_visualization/package.json ###
```json
{
  "name": "chart_visualization",
  "version": "1.0.0",
  "main": "src/index.ts",
  "devDependencies": {
    "@types/node": "^22.10.1",
    "ts-node": "^10.9.2",
    "typescript": "^5.7.2"
  },
  "dependencies": {
    "@visactor/vchart": "^1.13.7",
    "@visactor/vmind": "2.0.5",
    "canvas": "^2.11.2",
    "get-stdin": "^9.0.0"
  },
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "author": "",
  "license": "ISC",
  "description": ""
}

```

### ARQUIVO: app/tool/chart_visualization/README_pt-br.md ###
```md
# Ferramenta de VisualizaÃ§Ã£o de GrÃ¡ficos

A ferramenta de visualizaÃ§Ã£o de grÃ¡ficos gera cÃ³digo de processamento de dados atravÃ©s de Python e, por fim, invoca [@visactor/vmind](https://github.com/VisActor/VMind) para obter especificaÃ§Ãµes de grÃ¡ficos. A renderizaÃ§Ã£o dos grÃ¡ficos Ã© implementada usando [@visactor/vchart](https://github.com/VisActor/VChart).

## InstalaÃ§Ã£o

1. Instale o Node.js >= 18

```bash
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash
# ApÃ³s a instalaÃ§Ã£o, reinicie o terminal e instale a versÃ£o LTS mais recente do Node.js:
nvm install --lts
```

2. Instale as dependÃªncias

```bash
cd app/tool/chart_visualization
npm install
```

## Ferramentas
### python_execute

Execute as partes necessÃ¡rias da anÃ¡lise de dados (excluindo a visualizaÃ§Ã£o de dados) usando cÃ³digo Python, incluindo processamento de dados, resumo de dados, geraÃ§Ã£o de relatÃ³rios e algum cÃ³digo de script Python geral.

#### Entrada
```typescript
{
  // Tipo de cÃ³digo: processamento de dados/relatÃ³rio de dados/outras tarefas gerais
  code_type: "process" | "report" | "others"
  // CÃ³digo final de execuÃ§Ã£o
  code: string;
}
```

#### SaÃ­da
Resultados da execuÃ§Ã£o Python, incluindo o salvamento de arquivos intermediÃ¡rios e resultados de saÃ­da impressos.

### visualization_preparation

Uma prÃ©-ferramenta para visualizaÃ§Ã£o de dados com dois propÃ³sitos:

#### Dados -> GrÃ¡fico
Usado para extrair os dados necessÃ¡rios para anÃ¡lise (.csv) e a descriÃ§Ã£o da visualizaÃ§Ã£o correspondente dos dados, gerando finalmente um arquivo de configuraÃ§Ã£o JSON.

#### GrÃ¡fico + Insight -> GrÃ¡fico
Selecione grÃ¡ficos existentes e insights de dados correspondentes, escolha insights de dados para adicionar ao grÃ¡fico na forma de anotaÃ§Ãµes de dados e, finalmente, gere um arquivo de configuraÃ§Ã£o JSON.

#### Entrada
```typescript
{
  // Tipo de cÃ³digo: visualizaÃ§Ã£o de dados ou adiÃ§Ã£o de insight de dados
  code_type: "visualization" | "insight"
  // CÃ³digo Python usado para produzir o arquivo JSON final
  code: string;
}
```

#### SaÃ­da
Um arquivo de configuraÃ§Ã£o para visualizaÃ§Ã£o de dados, usado para a ferramenta `data_visualization`.

## data_visualization

Gere visualizaÃ§Ãµes de dados especÃ­ficas com base no conteÃºdo de `visualization_preparation`.

### Entrada
```typescript
{
  // Caminho do arquivo de configuraÃ§Ã£o
  json_path: string;
  // PropÃ³sito atual, visualizaÃ§Ã£o de dados ou adiÃ§Ã£o de anotaÃ§Ã£o de insight
  tool_type: "visualization" | "insight";
  // Produto final png ou html; html suporta renderizaÃ§Ã£o e interaÃ§Ã£o vchart
  output_type: 'png' | 'html'
  // Idioma, atualmente suporta chinÃªs e inglÃªs
  language: "zh" | "en"
}
```

## ConfiguraÃ§Ã£o do VMind

### LLM

O VMind requer invocaÃ§Ã£o de LLM para geraÃ§Ã£o inteligente de grÃ¡ficos. Por padrÃ£o, ele usa a configuraÃ§Ã£o `config.llm["default"]`.

### ConfiguraÃ§Ãµes de GeraÃ§Ã£o

As configuraÃ§Ãµes principais incluem dimensÃµes do grÃ¡fico, tema e mÃ©todo de geraÃ§Ã£o:

### MÃ©todo de GeraÃ§Ã£o
PadrÃ£o: png. Atualmente suporta a seleÃ§Ã£o automÃ¡tica de `output_type` pelo LLM com base no contexto.

### DimensÃµes
As dimensÃµes padrÃ£o nÃ£o sÃ£o especificadas. Para saÃ­da HTML, os grÃ¡ficos preenchem a pÃ¡gina inteira por padrÃ£o. Para saÃ­da PNG, o padrÃ£o Ã© `1000*1000`.

### Tema
Tema padrÃ£o: `'light'`. O VChart suporta mÃºltiplos temas. Consulte [Temas](https://www.visactor.io/vchart/guide/tutorial_docs/Theme/Theme_Extension).

## Teste

Atualmente, trÃªs tarefas de diferentes nÃ­veis de dificuldade sÃ£o definidas para teste.

### Tarefa Simples de GeraÃ§Ã£o de GrÃ¡fico

ForneÃ§a dados e requisitos especÃ­ficos de geraÃ§Ã£o de grÃ¡fico, teste os resultados, execute o comando:
```bash
python -m app.tool.chart_visualization.test.chart_demo
```
Os resultados devem estar localizados em `workspace\visualization`, envolvendo 9 resultados de grÃ¡ficos diferentes.

### Tarefa Simples de RelatÃ³rio de Dados

ForneÃ§a requisitos simples de anÃ¡lise de dados brutos, exigindo processamento simples dos dados, execute o comando:
```bash
python -m app.tool.chart_visualization.test.report_demo
```
Os resultados tambÃ©m estÃ£o localizados em `workspace\visualization`.
```

```

### ARQUIVO: app/tool/chart_visualization/package-lock.json ###
```json
{
  "name": "chart_visualization",
  "version": "1.0.0",
  "lockfileVersion": 3,
  "requires": true,
  "packages": {
    "": {
      "name": "chart_visualization",
      "version": "1.0.0",
      "license": "ISC",
      "dependencies": {
        "@visactor/vchart": "^1.13.7",
        "@visactor/vmind": "2.0.5",
        "canvas": "^2.11.2",
        "get-stdin": "^9.0.0"
      },
      "devDependencies": {
        "@types/node": "^22.10.1",
        "ts-node": "^10.9.2",
        "typescript": "^5.7.2"
      }
    },
    "node_modules/@cspotcode/source-map-support": {
      "version": "0.8.1",
      "resolved": "https://registry.npmjs.org/@cspotcode/source-map-support/-/source-map-support-0.8.1.tgz",
      "integrity": "sha512-IchNf6dN4tHoMFIn/7OE8LWZ19Y6q/67Bmf6vnGREv8RSbBVb9LPJxEcnwrcwX6ixSvaiGoomAUvu4YSxXrVgw==",
      "dev": true,
      "dependencies": {
        "@jridgewell/trace-mapping": "0.3.9"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@jridgewell/resolve-uri": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/@jridgewell/resolve-uri/-/resolve-uri-3.1.2.tgz",
      "integrity": "sha512-bRISgCIjP20/tbWSPWMEi54QVPRZExkuD9lJL+UIxUKtwVJA8wW1Trb1jMs1RFXo1CBTNZ/5hpC9QvmKWdopKw==",
      "dev": true,
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@jridgewell/sourcemap-codec": {
      "version": "1.5.0",
      "resolved": "https://registry.npmjs.org/@jridgewell/sourcemap-codec/-/sourcemap-codec-1.5.0.tgz",
      "integrity": "sha512-gv3ZRaISU3fjPAgNsriBRqGWQL6quFx04YMPW/zD8XMLsU32mhCCbfbO6KZFLjvYpCZ8zyDEgqsgf+PwPaM7GQ==",
      "dev": true
    },
    "node_modules/@jridgewell/trace-mapping": {
      "version": "0.3.9",
      "resolved": "https://registry.npmjs.org/@jridgewell/trace-mapping/-/trace-mapping-0.3.9.tgz",
      "integrity": "sha512-3Belt6tdc8bPgAtbcmdtNJlirVoTmEb5e2gC94PnkwEW9jI6CAHUeoG85tjWP5WquqfavoMtMwiG4P926ZKKuQ==",
      "dev": true,
      "dependencies": {
        "@jridgewell/resolve-uri": "^3.0.3",
        "@jridgewell/sourcemap-codec": "^1.4.10"
      }
    },
    "node_modules/@mapbox/node-pre-gyp": {
      "version": "1.0.11",
      "resolved": "https://registry.npmjs.org/@mapbox/node-pre-gyp/-/node-pre-gyp-1.0.11.tgz",
      "integrity": "sha512-Yhlar6v9WQgUp/He7BdgzOz8lqMQ8sU+jkCq7Wx8Myc5YFJLbEe7lgui/V7G1qB1DJykHSGwreceSaD60Y0PUQ==",
      "dependencies": {
        "detect-libc": "^2.0.0",
        "https-proxy-agent": "^5.0.0",
        "make-dir": "^3.1.0",
        "node-fetch": "^2.6.7",
        "nopt": "^5.0.0",
        "npmlog": "^5.0.1",
        "rimraf": "^3.0.2",
        "semver": "^7.3.5",
        "tar": "^6.1.11"
      },
      "bin": {
        "node-pre-gyp": "bin/node-pre-gyp"
      }
    },
    "node_modules/@resvg/resvg-js": {
      "version": "2.4.1",
      "resolved": "https://registry.npmjs.org/@resvg/resvg-js/-/resvg-js-2.4.1.tgz",
      "integrity": "sha512-wTOf1zerZX8qYcMmLZw3czR4paI4hXqPjShNwJRh5DeHxvgffUS5KM7XwxtbIheUW6LVYT5fhT2AJiP6mU7U4A==",
      "engines": {
        "node": ">= 10"
      },
      "optionalDependencies": {
        "@resvg/resvg-js-android-arm-eabi": "2.4.1",
        "@resvg/resvg-js-android-arm64": "2.4.1",
        "@resvg/resvg-js-darwin-arm64": "2.4.1",
        "@resvg/resvg-js-darwin-x64": "2.4.1",
        "@resvg/resvg-js-linux-arm-gnueabihf": "2.4.1",
        "@resvg/resvg-js-linux-arm64-gnu": "2.4.1",
        "@resvg/resvg-js-linux-arm64-musl": "2.4.1",
        "@resvg/resvg-js-linux-x64-gnu": "2.4.1",
        "@resvg/resvg-js-linux-x64-musl": "2.4.1",
        "@resvg/resvg-js-win32-arm64-msvc": "2.4.1",
        "@resvg/resvg-js-win32-ia32-msvc": "2.4.1",
        "@resvg/resvg-js-win32-x64-msvc": "2.4.1"
      }
    },
    "node_modules/@resvg/resvg-js-android-arm-eabi": {
      "version": "2.4.1",
      "resolved": "https://registry.npmjs.org/@resvg/resvg-js-android-arm-eabi/-/resvg-js-android-arm-eabi-2.4.1.tgz",
      "integrity": "sha512-AA6f7hS0FAPpvQMhBCf6f1oD1LdlqNXKCxAAPpKh6tR11kqV0YIB9zOlIYgITM14mq2YooLFl6XIbbvmY+jwUw==",
      "cpu": [
        "arm"
      ],
      "optional": true,
      "os": [
        "android"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@resvg/resvg-js-android-arm64": {
      "version": "2.4.1",
      "resolved": "https://registry.npmjs.org/@resvg/resvg-js-android-arm64/-/resvg-js-android-arm64-2.4.1.tgz",
      "integrity": "sha512-/QleoRdPfsEuH9jUjilYcDtKK/BkmWcK+1LXM8L2nsnf/CI8EnFyv7ZzCj4xAIvZGAy9dTYr/5NZBcTwxG2HQg==",
      "cpu": [
        "arm64"
      ],
      "optional": true,
      "os": [
        "android"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@resvg/resvg-js-darwin-arm64": {
      "version": "2.4.1",
      "resolved": "https://registry.npmjs.org/@resvg/resvg-js-darwin-arm64/-/resvg-js-darwin-arm64-2.4.1.tgz",
      "integrity": "sha512-U1oMNhea+kAXgiEXgzo7EbFGCD1Edq5aSlQoe6LMly6UjHzgx2W3N5kEXCwU/CgN5FiQhZr7PlSJSlcr7mdhfg==",
      "cpu": [
        "arm64"
      ],
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@resvg/resvg-js-darwin-x64": {
      "version": "2.4.1",
      "resolved": "https://registry.npmjs.org/@resvg/resvg-js-darwin-x64/-/resvg-js-darwin-x64-2.4.1.tgz",
      "integrity": "sha512-avyVh6DpebBfHHtTQTZYSr6NG1Ur6TEilk1+H0n7V+g4F7x7WPOo8zL00ZhQCeRQ5H4f8WXNWIEKL8fwqcOkYw==",
      "cpu": [
        "x64"
      ],
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@resvg/resvg-js-linux-arm-gnueabihf": {
      "version": "2.4.1",
      "resolved": "https://registry.npmjs.org/@resvg/resvg-js-linux-arm-gnueabihf/-/resvg-js-linux-arm-gnueabihf-2.4.1.tgz",
      "integrity": "sha512-isY/mdKoBWH4VB5v621co+8l101jxxYjuTkwOLsbW+5RK9EbLciPlCB02M99ThAHzI2MYxIUjXNmNgOW8btXvw==",
      "cpu": [
        "arm"
      ],
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@resvg/resvg-js-linux-arm64-gnu": {
      "version": "2.4.1",
      "resolved": "https://registry.npmjs.org/@resvg/resvg-js-linux-arm64-gnu/-/resvg-js-linux-arm64-gnu-2.4.1.tgz",
      "integrity": "sha512-uY5voSCrFI8TH95vIYBm5blpkOtltLxLRODyhKJhGfskOI7XkRw5/t1u0sWAGYD8rRSNX+CA+np86otKjubrNg==",
      "cpu": [
        "arm64"
      ],
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@resvg/resvg-js-linux-arm64-musl": {
      "version": "2.4.1",
      "resolved": "https://registry.npmjs.org/@resvg/resvg-js-linux-arm64-musl/-/resvg-js-linux-arm64-musl-2.4.1.tgz",
      "integrity": "sha512-6mT0+JBCsermKMdi/O2mMk3m7SqOjwi9TKAwSngRZ/nQoL3Z0Z5zV+572ztgbWr0GODB422uD8e9R9zzz38dRQ==",
      "cpu": [
        "arm64"
      ],
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@resvg/resvg-js-linux-x64-gnu": {
      "version": "2.4.1",
      "resolved": "https://registry.npmjs.org/@resvg/resvg-js-linux-x64-gnu/-/resvg-js-linux-x64-gnu-2.4.1.tgz",
      "integrity": "sha512-60KnrscLj6VGhkYOJEmmzPlqqfcw1keDh6U+vMcNDjPhV3B5vRSkpP/D/a8sfokyeh4VEacPSYkWGezvzS2/mg==",
      "cpu": [
        "x64"
      ],
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@resvg/resvg-js-linux-x64-musl": {
      "version": "2.4.1",
      "resolved": "https://registry.npmjs.org/@resvg/resvg-js-linux-x64-musl/-/resvg-js-linux-x64-musl-2.4.1.tgz",
      "integrity": "sha512-0AMyZSICC1D7ge115cOZQW8Pcad6PjWuZkBFF3FJuSxC6Dgok0MQnLTs2MfMdKBlAcwO9dXsf3bv9tJZj8pATA==",
      "cpu": [
        "x64"
      ],
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@resvg/resvg-js-win32-arm64-msvc": {
      "version": "2.4.1",
      "resolved": "https://registry.npmjs.org/@resvg/resvg-js-win32-arm64-msvc/-/resvg-js-win32-arm64-msvc-2.4.1.tgz",
      "integrity": "sha512-76XDFOFSa3d0QotmcNyChh2xHwk+JTFiEQBVxMlHpHMeq7hNrQJ1IpE1zcHSQvrckvkdfLboKRrlGB86B10Qjw==",
      "cpu": [
        "arm64"
      ],
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@resvg/resvg-js-win32-ia32-msvc": {
      "version": "2.4.1",
      "resolved": "https://registry.npmjs.org/@resvg/resvg-js-win32-ia32-msvc/-/resvg-js-win32-ia32-msvc-2.4.1.tgz",
      "integrity": "sha512-odyVFGrEWZIzzJ89KdaFtiYWaIJh9hJRW/frcEcG3agJ464VXkN/2oEVF5ulD+5mpGlug9qJg7htzHcKxDN8sg==",
      "cpu": [
        "ia32"
      ],
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@resvg/resvg-js-win32-x64-msvc": {
      "version": "2.4.1",
      "resolved": "https://registry.npmjs.org/@resvg/resvg-js-win32-x64-msvc/-/resvg-js-win32-x64-msvc-2.4.1.tgz",
      "integrity": "sha512-vY4kTLH2S3bP+puU5x7hlAxHv+ulFgcK6Zn3efKSr0M0KnZ9A3qeAjZteIpkowEFfUeMPNg2dvvoFRJA9zqxSw==",
      "cpu": [
        "x64"
      ],
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@stdlib/array-base-filled": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/array-base-filled/-/array-base-filled-0.2.2.tgz",
      "integrity": "sha512-T7nB7dni5Y4/nsq6Gc1bAhYfzJbcOdqsmVZJUI698xpDbhCdVCIIaEbf0PnDMGN24psN+5mgAVmnNBom+uF0Xg==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/array-base-zeros": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/array-base-zeros/-/array-base-zeros-0.2.2.tgz",
      "integrity": "sha512-iwxqaEtpi4c2qpqabmhFdaQGkzgo5COwjHPn2T0S0wfJuM1VuVl5UBl15syr+MmZPJQOB1eBbh6F1uTh9597qw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/array-base-filled": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/array-float32": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/array-float32/-/array-float32-0.2.2.tgz",
      "integrity": "sha512-pTcy1FNQrrJLL1LMxJjuVpcKJaibbGCFFTe41iCSXpSOC8SuTBuNohrO6K9+xR301Ruxxn4yrzjJJ6Fa3nQJ2g==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-has-float32array-support": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/array-float64": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/array-float64/-/array-float64-0.2.2.tgz",
      "integrity": "sha512-ZmV5wcacGrhT0maw9dfLXNv4N3ZwFUV3D7ItFfZFGFnKIJbubrWzwtaYnxzIXigrDc8g3F6FVHRpsQLMxq0/lA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-has-float64array-support": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/array-uint16": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/array-uint16/-/array-uint16-0.2.2.tgz",
      "integrity": "sha512-z5c/Izw43HkKfb1pTgEUMAS8GFvhtHkkHZSjX3XJN+17P0VjknxjlSvPiCBGqaDX9jXtlWH3mn1LSyDKtJQoeA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-has-uint16array-support": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/array-uint32": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/array-uint32/-/array-uint32-0.2.2.tgz",
      "integrity": "sha512-3T894I9C2MqZJJmRCYFTuJp4Qw9RAt+GzYnVPyIXoK1h3TepUXe9VIVx50cUFIibdXycgu0IFGASeAb3YMyupw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-has-uint32array-support": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/array-uint8": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/array-uint8/-/array-uint8-0.2.2.tgz",
      "integrity": "sha512-Ip9MUC8+10U9x0crMKWkpvfoUBBhWzc6k5SI4lxx38neFVmiJ3f+5MBADEagjpoKSBs71vlY2drnEZe+Gs2Ytg==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-has-uint8array-support": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-has-float32array-support": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-has-float32array-support/-/assert-has-float32array-support-0.2.2.tgz",
      "integrity": "sha512-pi2akQl8mVki43fF1GNQVLYW0bHIPp2HuRNThX9GjB3OFQTpvrV8/3zPSh4lOxQa5gRiabgf0+Rgeu3AOhEw9A==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-is-float32array": "^0.2.2",
        "@stdlib/constants-float64-pinf": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-has-float64array-support": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-has-float64array-support/-/assert-has-float64array-support-0.2.2.tgz",
      "integrity": "sha512-8L3GuKY1o0dJARCOsW9MXcugXapaMTpSG6dGxyNuUVEvFfY5UOzcj9/JIDal5FjqSgqVOGL5qZl2qtRwub34VA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-is-float64array": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-has-generator-support": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-has-generator-support/-/assert-has-generator-support-0.2.2.tgz",
      "integrity": "sha512-TcE9BGV8i7B2OmxPlJ/2DUrAwG0W4fFS/DE7HmVk68PXVZsgyNQ/WP/IHBoazHDjhN5c3dU21c20kM/Bw007Rw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/utils-eval": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-has-own-property": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-has-own-property/-/assert-has-own-property-0.2.2.tgz",
      "integrity": "sha512-m5rV4Z2/iNkwx2vRsNheM6sQZMzc8rQQOo90LieICXovXZy8wA5jNld4kRKjMNcRt/TjrNP7i2Rhh8hruRDlHg==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-has-symbol-support": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-has-symbol-support/-/assert-has-symbol-support-0.2.2.tgz",
      "integrity": "sha512-vCsGGmDZz5dikGgdF26rIL0y0nHvH7qaVf89HLLTybceuZijAqFSJEqcB3Gpl5uaeueLNAWExHi2EkoUVqKHGg==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-has-tostringtag-support": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-has-tostringtag-support/-/assert-has-tostringtag-support-0.2.2.tgz",
      "integrity": "sha512-bSHGqku11VH0swPEzO4Y2Dr+lTYEtjSWjamwqCTC8udOiOIOHKoxuU4uaMGKJjVfXG1L+XefLHqzuO5azxdRaA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-has-symbol-support": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-has-uint16array-support": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-has-uint16array-support/-/assert-has-uint16array-support-0.2.2.tgz",
      "integrity": "sha512-aL188V7rOkkEH4wYjfpB+1waDO4ULxo5ppGEK6X0kG4YiXYBL2Zyum53bjEQvo0Nkn6ixe18dNzqqWWytBmDeg==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-is-uint16array": "^0.2.1",
        "@stdlib/constants-uint16-max": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-has-uint32array-support": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-has-uint32array-support/-/assert-has-uint32array-support-0.2.2.tgz",
      "integrity": "sha512-+UHKP3mZOACkJ9CQjeKNfbXHm5HGQB862V5nV5q3UQlHPzhslnXKyG1SwAxTx+0g88C/2vlDLeqG8H4TH2UTFA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-is-uint32array": "^0.2.1",
        "@stdlib/constants-uint32-max": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-has-uint8array-support": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-has-uint8array-support/-/assert-has-uint8array-support-0.2.2.tgz",
      "integrity": "sha512-VfzrB0BMik9MvPyKcMDJL3waq4nM30RZUrr2EuuQ/RbUpromRWSDbzGTlRq5SfjtJrHDxILPV3rytDCc03dgWA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-is-uint8array": "^0.2.1",
        "@stdlib/constants-uint8-max": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-is-array": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-is-array/-/assert-is-array-0.2.2.tgz",
      "integrity": "sha512-aJyTX2U3JqAGCATgaAX9ygvDHc97GCIKkIhiZm/AZaLoFHPtMA1atQ4bKcefEC8Um9eefryxTHfFPfSr9CoNQQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/utils-native-class": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-is-big-endian": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-is-big-endian/-/assert-is-big-endian-0.2.2.tgz",
      "integrity": "sha512-mPEl30/bqZh++UyQbxlyOuB7k0wC73y5J9nD2J6Ud6Fcl76R5IAGHRW0WT3W18is/6jG1jzMd8hrISFyD7N0sA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/array-uint16": "^0.2.1",
        "@stdlib/array-uint8": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-is-boolean": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-is-boolean/-/assert-is-boolean-0.2.2.tgz",
      "integrity": "sha512-3KFLRTYZpX6u95baZ6PubBvjehJs2xBU6+zrenR0jx8KToUYCnJPxqqj7JXRhSD+cOURmcjj9rocVaG9Nz18Pg==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-has-tostringtag-support": "^0.2.2",
        "@stdlib/boolean-ctor": "^0.2.2",
        "@stdlib/utils-define-nonenumerable-read-only-property": "^0.2.2",
        "@stdlib/utils-native-class": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-is-buffer": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-is-buffer/-/assert-is-buffer-0.2.2.tgz",
      "integrity": "sha512-4/WMFTEcDYlVbRhxY8Wlqag4S70QCnn6WmQ4wmfiLW92kqQHsLvTNvdt/qqh/SDyDV31R/cpd3QPsVN534dNEA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-is-object-like": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-is-float32array": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-is-float32array/-/assert-is-float32array-0.2.2.tgz",
      "integrity": "sha512-hxEKz/Y4m1NYuOaiQKoqQA1HeAYwNXFqSk3FJ4hC71DuGNit2tuxucVyck3mcWLpLmqo0+Qlojgwo5P9/C/9MQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/utils-native-class": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-is-float64array": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-is-float64array/-/assert-is-float64array-0.2.2.tgz",
      "integrity": "sha512-3R1wLi6u/IHXsXMtaLnvN9BSpqAJ8tWhwjOOr6kadDqCWsU7Odc7xKLeAXAInAxwnV8VDpO4ifym4A3wehazPQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/utils-native-class": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-is-function": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-is-function/-/assert-is-function-0.2.2.tgz",
      "integrity": "sha512-whY69DUYWljCJ79Cvygp7VzWGOtGTsh3SQhzNuGt+ut6EsOW+8nwiRkyBXYKf/MOF+NRn15pxg8cJEoeRgsPcA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/utils-type-of": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-is-little-endian": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-is-little-endian/-/assert-is-little-endian-0.2.2.tgz",
      "integrity": "sha512-KMzPndj85jDiE1+hYCpw12k2OQOVkfpCo7ojCmCl8366wtKGEaEdGbz1iH98zkxRvnZLSMXcYXI2z3gtdmB0Ag==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/array-uint16": "^0.2.1",
        "@stdlib/array-uint8": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-is-number": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-is-number/-/assert-is-number-0.2.2.tgz",
      "integrity": "sha512-sWpJ59GqGbmlcdYSUV/OYkmQW8k47w10+E0K0zPu1x1VKzhjgA5ZB2sJcpgI8Vt3ckRLjdhuc62ZHJkrJujG7A==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-has-tostringtag-support": "^0.2.2",
        "@stdlib/number-ctor": "^0.2.2",
        "@stdlib/utils-define-nonenumerable-read-only-property": "^0.2.2",
        "@stdlib/utils-native-class": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-is-object": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-is-object/-/assert-is-object-0.2.2.tgz",
      "integrity": "sha512-sNnphJuHyMDHHHaonlx6vaCKMe4sHOn0ag5Ck4iW3kJtM2OZB2J4h8qFcwKzlMk7fgFu7vYNGCZtpm1dYbbUfQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-is-array": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-is-object-like": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-is-object-like/-/assert-is-object-like-0.2.2.tgz",
      "integrity": "sha512-MjQBpHdEebbJwLlxh/BKNH8IEHqY0YlcCMRKOQU0UOlILSJg0vG+GL4fDDqtx9FSXxcTqC+w3keHx8kAKvQhzg==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-tools-array-function": "^0.2.1",
        "@stdlib/utils-define-nonenumerable-read-only-property": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-is-plain-object": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-is-plain-object/-/assert-is-plain-object-0.2.2.tgz",
      "integrity": "sha512-o4AFWgBsSNzZAOOfIrxoDFYTqnLuGiaHDFwIeZGUHdpQeav2Fll+sGeaqOcekF7yKawoswnwWdJqTsjapb4Yzw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-has-own-property": "^0.2.1",
        "@stdlib/assert-is-function": "^0.2.1",
        "@stdlib/assert-is-object": "^0.2.1",
        "@stdlib/utils-get-prototype-of": "^0.2.1",
        "@stdlib/utils-native-class": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-is-regexp": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-is-regexp/-/assert-is-regexp-0.2.2.tgz",
      "integrity": "sha512-2JtiUtRJxPaVXL7dkWoV3n5jouI65DwYDXsDXg3xo23TXlTNGgU/HhKO4FWC1Yqju7YMZi0hcZSW6E9v8ISqeQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-has-tostringtag-support": "^0.2.2",
        "@stdlib/utils-native-class": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-is-string": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-is-string/-/assert-is-string-0.2.2.tgz",
      "integrity": "sha512-SOkFg4Hq443hkadM4tzcwTHWvTyKP9ULOZ8MSnnqmU0nBX1zLVFLFGY8jnF6Cary0dL0V7QQBCfuxqKFM6u2PQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-has-tostringtag-support": "^0.2.2",
        "@stdlib/utils-define-nonenumerable-read-only-property": "^0.2.2",
        "@stdlib/utils-native-class": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-is-uint16array": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-is-uint16array/-/assert-is-uint16array-0.2.2.tgz",
      "integrity": "sha512-w3+HeTiXGLJGw5nCqr0WbvgArNMEj7ulED1Yd19xXbmmk2W1ZUB+g9hJDOQTiKsTU4AVyH4/As+aA8eDVmWtmg==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/utils-native-class": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-is-uint32array": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-is-uint32array/-/assert-is-uint32array-0.2.2.tgz",
      "integrity": "sha512-3F4nIHg1Qp0mMIsImWUC8DwQ3qBK5vdIJTjS2LufLbFBhHNmv5kK1yJiIXQDTLkENU0STZe05TByo01ZNLOmDQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/utils-native-class": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-is-uint8array": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-is-uint8array/-/assert-is-uint8array-0.2.2.tgz",
      "integrity": "sha512-51WnDip6H2RrN0CbqWmfqySAjam8IZ0VjlfUDc3PtcgrZGrKKjVgyHAsT/L3ZDydwF+aB94uvYJu5QyrCPNaZw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/utils-native-class": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/assert-tools-array-function": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/assert-tools-array-function/-/assert-tools-array-function-0.2.2.tgz",
      "integrity": "sha512-FYeT7X9x0C8Nh+MN6IJUDz+7i7yB6mio2/SDlrvyepjyPSU/cfHfwW0GEOnQhxZ+keLZC/YqDD930WjRODwMdA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-is-array": "^0.2.1",
        "@stdlib/error-tools-fmtprodmsg": "^0.2.2",
        "@stdlib/string-format": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/boolean-ctor": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/boolean-ctor/-/boolean-ctor-0.2.2.tgz",
      "integrity": "sha512-qIkHzmfxDvGzQ3XI9R7sZG97QSaWG5TvWVlrvcysOGT1cs6HtQgnf4D//SRzZ52VLm8oICP+6OKtd8Hpm6G7Ww==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/complex-float32": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/complex-float32/-/complex-float32-0.2.1.tgz",
      "integrity": "sha512-tp83HfJzcZLK7/6P6gZPcAa/8F/aHS7gBHgB6ft45d/n6oE+/VbnyOvsJKanRv8S96kBRj8xkvlWHz4IiBrT0Q==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-is-number": "^0.2.1",
        "@stdlib/number-float64-base-to-float32": "^0.2.1",
        "@stdlib/string-format": "^0.2.1",
        "@stdlib/utils-define-nonenumerable-read-only-property": "^0.2.1",
        "@stdlib/utils-define-property": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/complex-float32-ctor": {
      "version": "0.0.2",
      "resolved": "https://registry.npmjs.org/@stdlib/complex-float32-ctor/-/complex-float32-ctor-0.0.2.tgz",
      "integrity": "sha512-QsTLynhTRmDT0mSkfdHj0FSqQSxh2nKx+vvrH3Y0/Cd/r0WoHFZwyibndDxshfkf9B7nist8QKyvV82I3IZciA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-is-number": "^0.2.2",
        "@stdlib/error-tools-fmtprodmsg": "^0.2.2",
        "@stdlib/number-float64-base-to-float32": "^0.2.1",
        "@stdlib/string-format": "^0.2.2",
        "@stdlib/utils-define-nonenumerable-read-only-property": "^0.2.2",
        "@stdlib/utils-define-property": "^0.2.4"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/complex-float32-reim": {
      "version": "0.1.2",
      "resolved": "https://registry.npmjs.org/@stdlib/complex-float32-reim/-/complex-float32-reim-0.1.2.tgz",
      "integrity": "sha512-24H+t1xwQF6vhOoMZdDA3TFB4M+jb5Swm/FwNaepovlzVIG2NlthUZs6mZg1T3oegqesIRQRwhpn4jIPjuGiTw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/array-float32": "^0.2.2",
        "@stdlib/complex-float32-ctor": "^0.0.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/complex-float64": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/complex-float64/-/complex-float64-0.2.1.tgz",
      "integrity": "sha512-vN9GqlSaonoREf8/RIN9tfNLnkfN4s7AI0DPsGnvc1491oOqq9UqMw8rYTrnxuum9/OaNAAUqDkb5GLu5uTveQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-is-number": "^0.2.1",
        "@stdlib/complex-float32": "^0.2.1",
        "@stdlib/string-format": "^0.2.1",
        "@stdlib/utils-define-nonenumerable-read-only-property": "^0.2.1",
        "@stdlib/utils-define-property": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/complex-float64-ctor": {
      "version": "0.0.3",
      "resolved": "https://registry.npmjs.org/@stdlib/complex-float64-ctor/-/complex-float64-ctor-0.0.3.tgz",
      "integrity": "sha512-oixCtBif+Uab2rKtgedwQTbQTEC+wVSu4JQH935eJ8Jo0eL6vXUHHlVrkLgYKlCDLvq5px1QQn42Czg/ixh6Gw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-is-number": "^0.2.2",
        "@stdlib/complex-float32-ctor": "^0.0.2",
        "@stdlib/error-tools-fmtprodmsg": "^0.2.2",
        "@stdlib/string-format": "^0.2.2",
        "@stdlib/utils-define-nonenumerable-read-only-property": "^0.2.2",
        "@stdlib/utils-define-property": "^0.2.4"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/complex-float64-reim": {
      "version": "0.1.2",
      "resolved": "https://registry.npmjs.org/@stdlib/complex-float64-reim/-/complex-float64-reim-0.1.2.tgz",
      "integrity": "sha512-q6RnfgbUunApAYuGmkft1oOM3x3xVMVJwNRlRgfIXwKDb8pYt+S/CeIwi3Su5SF6ay3AqA1s+ze7m21osXAJyw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/array-float64": "^0.2.2",
        "@stdlib/complex-float64-ctor": "^0.0.3"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/complex-reim": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/complex-reim/-/complex-reim-0.2.1.tgz",
      "integrity": "sha512-67nakj+HwBRx/ha3j/sLbrMr2hwFVgEZtaczOgn1Jy/cU03lKvNbMkR7QI9s+sA+b+A3yJB3ob8ZQSqh3D1+dA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/array-float64": "^0.2.1",
        "@stdlib/complex-float64": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/complex-reimf": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/complex-reimf/-/complex-reimf-0.2.1.tgz",
      "integrity": "sha512-6HyPPmo0CEHoBjOg2w70mMFLcFEunM78ljnW6kf1OxjM/mqMaBM1NRpDrQoFwCIdh1RF1ojl3JR0YLllEf0qyQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/array-float32": "^0.2.1",
        "@stdlib/complex-float32": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float32-max": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float32-max/-/constants-float32-max-0.2.2.tgz",
      "integrity": "sha512-uxvIm/KmIeZP4vyfoqPd72l5/uidnCN9YJT3p7Z2LD8hYN3PPLu6pd/5b51HMFLwfkZ27byRJ9+YK6XnneJP0Q==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float32-smallest-normal": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float32-smallest-normal/-/constants-float32-smallest-normal-0.2.2.tgz",
      "integrity": "sha512-2qkGjGML2/8P9YguHnac2AKXLbfycpYdCxKmuXQdAVzMMNCJWjHoIqZMFG29WBEDBOP057X+48S6WhIqoxRpWA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-e": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-e/-/constants-float64-e-0.2.2.tgz",
      "integrity": "sha512-7fxHaABwosbUzpBsw6Z9Dd9MqUYne8x+44EjohVcWDr0p0mHB/DXVYEYTlwEP/U/XbRrKdO3jUG6IO/GsEjzWg==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-eps": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-eps/-/constants-float64-eps-0.2.2.tgz",
      "integrity": "sha512-61Pb2ip9aPhHXxiCn+VZ0UVw2rMYUp0xrX93FXyB3UTLacrofRKLMKtbV0SFac4VXx5igv2+0G+h6G/fwCgjyw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-eulergamma": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-eulergamma/-/constants-float64-eulergamma-0.2.2.tgz",
      "integrity": "sha512-XsuVud0d1hLTQspFzgUSH2e3IawTXLlJi2k4Vg0Nn6juulxfNO9PnAGtHz+p1BynYF/YwN+qhKnISQxrN31rsQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-exponent-bias": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-exponent-bias/-/constants-float64-exponent-bias-0.2.2.tgz",
      "integrity": "sha512-zLWkjzDYHSsBsXB/4mwHysOGl64JS3XBt/McjvjCLc/IZpfsUNFxLCl7oVCplXzYYHcQj/RfEBFy6cxQ6FvdpQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-fourth-pi": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-fourth-pi/-/constants-float64-fourth-pi-0.2.2.tgz",
      "integrity": "sha512-j0NOg45ouibms4ML8pfS/eDrurdtnhJTNPCGQM4mg3X+1ljsuO0pvkpVCvuz29t5J23KTcfGBXXr90ikoBmjlw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-gamma-lanczos-g": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-gamma-lanczos-g/-/constants-float64-gamma-lanczos-g-0.2.2.tgz",
      "integrity": "sha512-hCaZbZ042htCy9mlGrfUEbz4d0xW/DLdr3vHs5KiBWU+G+WHVH33vubSnEoyT0ugWpAk2ZqWXe/V8sLGgOu0xg==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-half-ln-two": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-half-ln-two/-/constants-float64-half-ln-two-0.2.2.tgz",
      "integrity": "sha512-yv1XhzZR2AfJmnAGL0kdWlIUhc/vqdWol+1Gq2brXPVfgqbUmJu5XZuuK+jZA2k+fHyvRHNEwQRv9OPnOjchFg==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-half-pi": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-half-pi/-/constants-float64-half-pi-0.2.2.tgz",
      "integrity": "sha512-lM3SiDsZCKiuF5lPThZFFqioIwh1bUiBUnnDMLB04/QkVRCAaXUo+dsq2hOB6iBhHoYhiKds6T+PsHSBlpqAaA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-high-word-abs-mask": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-high-word-abs-mask/-/constants-float64-high-word-abs-mask-0.2.2.tgz",
      "integrity": "sha512-YtYngcHlw9qvOpmsSlkNHi6cy/7Y7QkyYh5kJbDvuOUXPDKa3rEwBln4mKjbWsXhmmN0bk7TLypH7Ryd/UAjUQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-high-word-exponent-mask": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-high-word-exponent-mask/-/constants-float64-high-word-exponent-mask-0.2.2.tgz",
      "integrity": "sha512-LhYUXvpnLOFnWr8ucHA9N/H75VxcS2T9EoBDTmWBZoKj2Pg0icGVDmcNciRLIWbuPA9osgcKpxoU+ADIfaipVA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-high-word-sign-mask": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-high-word-sign-mask/-/constants-float64-high-word-sign-mask-0.2.1.tgz",
      "integrity": "sha512-Fep/Ccgvz5i9d5k96zJsDjgXGno8HJfmH7wihLmziFmA2z9t7NSacH4/BH4rPJ5yXFHLkacNLDxaF1gO1XpcLA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-high-word-significand-mask": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-high-word-significand-mask/-/constants-float64-high-word-significand-mask-0.2.2.tgz",
      "integrity": "sha512-eDDyiQ5PR1/qyklrW0Pus0ZopM7BYjkWTjqhSHhj0DibH6UMwSMlIl4ddCh3VX37p5eByuAavnaPgizk5c9mUw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-ln-sqrt-two-pi": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-ln-sqrt-two-pi/-/constants-float64-ln-sqrt-two-pi-0.2.2.tgz",
      "integrity": "sha512-C9YS9W/lvv54wUC7DojQSRH9faKw0sMAM09oMRVm8OOYNr01Rs1wXeSPStl9ns4qiV/G13vZzd1I3nGqgqihbw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-ln-two": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-ln-two/-/constants-float64-ln-two-0.2.2.tgz",
      "integrity": "sha512-EQ8EJ6B1wPfuhva0aApKIsF7lTna++txV4AUzL2wTfwDHw6RzWpA44u+k54KnLF8ZXUNIYDNQHHvtzdfKrFzCA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-max": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-max/-/constants-float64-max-0.2.2.tgz",
      "integrity": "sha512-S3kcIKTK65hPqirziof3KTYqfFKopgaTnaiDlDKdzaCzBZ5qkrAcRd4vl+W1KHoZruUyWC2/RYZUa/8+h075TQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-max-base2-exponent": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-max-base2-exponent/-/constants-float64-max-base2-exponent-0.2.2.tgz",
      "integrity": "sha512-KmDe98pJ2HXz2SbqyFfSDhlSSVD7JssjbZ5K11HEK2avqMcoCbdHH20T+6/TpA01VqaK8dLbeyphOfALcDdMKA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-max-base2-exponent-subnormal": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-max-base2-exponent-subnormal/-/constants-float64-max-base2-exponent-subnormal-0.2.1.tgz",
      "integrity": "sha512-D1wBNn54Hu2pK6P/yBz0FtPBI3/7HdgK8igYjWDKWUKzC92R/6PHZ9q5NzedcGxoBs8MUk1zNpP0tZyYj9Y4YQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-max-ln": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-max-ln/-/constants-float64-max-ln-0.2.2.tgz",
      "integrity": "sha512-FPAEGjnoQMDPWJbCyyto7HWQ/SY2jjD8IkjyD8aOwENqbswjCbOINXRiK2ar27OOXG7Dv7CCpFpoorTxv0gmfA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-max-safe-integer": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-max-safe-integer/-/constants-float64-max-safe-integer-0.2.2.tgz",
      "integrity": "sha512-d+sxmxhkt980SDFhnnRDSpujPQTv4nEt5Ox3L86HgYZU4mQU/wbzYVkMuHIANW9x3ehww5blnGXTKYG9rQCXAw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-max-safe-nth-factorial": {
      "version": "0.1.0",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-max-safe-nth-factorial/-/constants-float64-max-safe-nth-factorial-0.1.0.tgz",
      "integrity": "sha512-sppIfkBbeyKNwfRbmNFi5obI7Q+IJCQzfWKYqvzmEJVOkmEg6hhtEeFc8zZJGCU7+Pndc3M2wdbTT5a3rhamHw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-min-base2-exponent": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-min-base2-exponent/-/constants-float64-min-base2-exponent-0.2.2.tgz",
      "integrity": "sha512-YZmBiKik6LbWB4EOZ/ZUs/u6OIF742xNK8mhEqL0OEN4NuJe3OdErpOic6KjMmHjQuqCXdFoSqsWZaFHcIN7HA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-min-base2-exponent-subnormal": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-min-base2-exponent-subnormal/-/constants-float64-min-base2-exponent-subnormal-0.2.1.tgz",
      "integrity": "sha512-fTXfvctXWj/48gK+gbRBrHuEHEKY4QOJoXSGp414Sz6vUxHusHJJ686p8ze3XqM7CY6fmL09ZgdGz/uhJl/7lw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-min-ln": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-min-ln/-/constants-float64-min-ln-0.2.2.tgz",
      "integrity": "sha512-N1Sxjo3uTdEIpHeG2TzaX06UuvpcKHvjYKpIMhJSajbxvfVDURHlc9kIpfbP9C9/YYoCy0FvewA/kvbqNaYypA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-ninf": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-ninf/-/constants-float64-ninf-0.2.2.tgz",
      "integrity": "sha512-Iu+wZs/vgudAKVg9FEcRY3FadkmvsWuq/wJ3jIHjhaP5xcnoF3XJUO4IneEndybHwehfJL65NShnDsJcg1gicw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/number-ctor": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-pi": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-pi/-/constants-float64-pi-0.2.2.tgz",
      "integrity": "sha512-ix34KmpUQ0LUM++L6avLhM9LFCcGTlsUDyWD/tYVGZBiIzDS3TMKShHRkZvC+v87fuyYNPoxolYtk5AlbacI6g==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-pinf": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-pinf/-/constants-float64-pinf-0.2.2.tgz",
      "integrity": "sha512-UcwnWaSkUMD8QyKADwkXPlY7yOosCPZpE2EDXf/+WOzuWi5vpsec+JaasD5ggAN8Rv8OTVmexTFs1uZfrHgqVQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-smallest-normal": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-smallest-normal/-/constants-float64-smallest-normal-0.2.2.tgz",
      "integrity": "sha512-GXNBkdqLT9X+dU59O1kmb7W5da/RhSXSvxx0xG5r7ipJPOtRLfTXGGvvTzWD4xA3Z5TKlrEL6ww5sph9BsPJnA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-smallest-subnormal": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-smallest-subnormal/-/constants-float64-smallest-subnormal-0.2.2.tgz",
      "integrity": "sha512-KuF+scDOsP0okx8RLF+q3l1RheaYChf+u/HbhzFbz82GeCIdIVp86UMwoBgfn8AT8cnR5SrtvLtQw15MGfa/vg==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-sqrt-eps": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-sqrt-eps/-/constants-float64-sqrt-eps-0.2.2.tgz",
      "integrity": "sha512-X7LnGfnwNnhiwlY+zd3FX6zclsx61MaboGTNAAdaV78YjBDTdGdWMHk5MQo1U17ryPlhdGphOAejhDHeaSnTXQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-sqrt-two": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-sqrt-two/-/constants-float64-sqrt-two-0.2.2.tgz",
      "integrity": "sha512-iqqouCuS9pUhjD91i5siScxLDtQTF1HsSZor6jaZRviMiOjCj/mjzxxTFHWUlU/rxHMBBhj/u7i12fv6a7dCAQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-sqrt-two-pi": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-sqrt-two-pi/-/constants-float64-sqrt-two-pi-0.2.2.tgz",
      "integrity": "sha512-I8Ylr64x8AFSQ2hFBT8szuIBAy2wqPx69taJMzfcmuM5SnSbS8SE/H19YnCimZErVFo4bz0Rh8Fp3edN4i6teQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-float64-two-pi": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-float64-two-pi/-/constants-float64-two-pi-0.2.2.tgz",
      "integrity": "sha512-cyXuwYOersVsA8tDSJ0ocMbtOc5KGxjlGvYC4vrpLQVkgNpxcGbA57n6JvaGmNk7+InXXbQ7qhTWGbTNgafcLQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-int32-max": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-int32-max/-/constants-int32-max-0.3.0.tgz",
      "integrity": "sha512-jYN84QfG/yP2RYw98OR6UYehFFs0PsGAihV6pYU0ey+WF9IOXgSjRP56KMoZ7ctHwl4wsnj9I+qB2tGuEXr+pQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-uint16-max": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-uint16-max/-/constants-uint16-max-0.2.2.tgz",
      "integrity": "sha512-qaFXbxgFnAkt73P5Ch7ODb0TsOTg0LEBM52hw6qt7+gTMZUdS0zBAiy5J2eEkTxA9rD9X3nIyUtLf2C7jafNdw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-uint32-max": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-uint32-max/-/constants-uint32-max-0.2.2.tgz",
      "integrity": "sha512-2G44HQgIKDrh3tJUkmvtz+eM+uwDvOMF+2I3sONcTHacANb+zP7la4LDYiTp+HFkPJyfh/kPapXBiHpissAb1A==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/constants-uint8-max": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-uint8-max/-/constants-uint8-max-0.2.2.tgz",
      "integrity": "sha512-ZTBQq3fqS/Y4ll6cPY5SKaS266EfmKP9PW3YLJaTELmYIzVo9w2RFtfCqN05G3olTQ6Le9MUEE/C6VFgZNElDQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/error-tools-fmtprodmsg": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/error-tools-fmtprodmsg/-/error-tools-fmtprodmsg-0.2.2.tgz",
      "integrity": "sha512-2IliQfTes4WV5odPidZFGD5eYDswZrPXob7oOu95Q69ERqImo8WzSwnG2EDbHPyOyYCewuMfM5Ha6Ggf+u944Q==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/fs-exists": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/fs-exists/-/fs-exists-0.2.2.tgz",
      "integrity": "sha512-uGLqc7izCIam2aTyv0miyktl4l8awgRkCS39eIEvvvnKIaTBF6pxfac7FtFHeEQKE3XhtKsOmdQ/yJjUMChLuA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/utils-define-nonenumerable-read-only-property": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/fs-resolve-parent-path": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/fs-resolve-parent-path/-/fs-resolve-parent-path-0.2.2.tgz",
      "integrity": "sha512-ZG78ouZc+pdPLtU+sSpYTvbKTiLUgn6NTtlVFYmcmkYRFn+fGOOakwVuhYMcYG6ti10cLD6WzB/YujxIt8f+nA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-has-own-property": "^0.2.2",
        "@stdlib/assert-is-function": "^0.2.2",
        "@stdlib/assert-is-plain-object": "^0.2.2",
        "@stdlib/assert-is-string": "^0.2.2",
        "@stdlib/error-tools-fmtprodmsg": "^0.2.2",
        "@stdlib/fs-exists": "^0.2.2",
        "@stdlib/process-cwd": "^0.2.2",
        "@stdlib/string-format": "^0.2.2",
        "@stdlib/utils-define-nonenumerable-read-only-property": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/function-ctor": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/function-ctor/-/function-ctor-0.2.2.tgz",
      "integrity": "sha512-qSn1XQnnhgCSYBfFy4II0dY5eW4wdOprgDTHcOJ3PkPWuZHDC1fXZsok1OYAosHqIiIw44zBFcMS/JRex4ebdQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-assert-is-even": {
      "version": "0.2.3",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-assert-is-even/-/math-base-assert-is-even-0.2.3.tgz",
      "integrity": "sha512-cziGv8F/aNyfME7Wx2XJjnYBnf9vIeh8yTIzlLELd0OqGHqfsHU5OQxxcl9x5DbjZ1G/w0lphWxHFHYCuwFCHw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/math-base-assert-is-integer": "^0.2.4",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-assert-is-infinite": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-assert-is-infinite/-/math-base-assert-is-infinite-0.2.2.tgz",
      "integrity": "sha512-4zDZuinC3vkXRdQepr0ZTwWX3KgM0VIWqYthOmCSgLLA87L9M9z9MgUZL1QeYeYa0+60epjDcQ8MS3ecT70Jxw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-ninf": "^0.2.2",
        "@stdlib/constants-float64-pinf": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-assert-is-integer": {
      "version": "0.2.5",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-assert-is-integer/-/math-base-assert-is-integer-0.2.5.tgz",
      "integrity": "sha512-Zi8N66GbWtSCR3OUsRdBknjNlX+aBN8w6CaVEP5+Jy/a7MgMYzevS52TNS5sm8jqzKBlFhZlPLex+Zl2GlPvSA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/math-base-special-floor": "^0.2.3",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-assert-is-nan": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-assert-is-nan/-/math-base-assert-is-nan-0.2.2.tgz",
      "integrity": "sha512-QVS8rpWdkR9YmHqiYLDVLsCiM+dASt/2feuTl4T/GSdou3Y/PS/4j/tuDvCDoHDNfDkULUW+FCVjKYpbyoeqBQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/utils-library-manifest": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-assert-is-negative-zero": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-assert-is-negative-zero/-/math-base-assert-is-negative-zero-0.2.2.tgz",
      "integrity": "sha512-WvKNuBZ6CDarOTzOuFLmO1jwZnFD+butIvfD2Ws6SsuqSCiWOaF4OhIckqPzo1XEdkqqhRNPqBxqc0D+hsEYVA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-ninf": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-assert-is-odd": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-assert-is-odd/-/math-base-assert-is-odd-0.3.0.tgz",
      "integrity": "sha512-V44F3xdR5/bHXqqYvE/AldLnVmijLr/rgf7EjnJXXDQLfPCgemy0iHTFl19N68KG1YO9SMPdyOaNjh4K0O9Qqw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/math-base-assert-is-even": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-assert-is-positive-zero": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-assert-is-positive-zero/-/math-base-assert-is-positive-zero-0.2.2.tgz",
      "integrity": "sha512-mMX5xsemKpHRAgjpVJCb3eVZ3WIkZh6KnHQH8i8n4vI44pcdpN5rcTdEAMlhLjxT/rT7H2wq85f7/FRsq9r9rw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-pinf": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-napi-binary": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-napi-binary/-/math-base-napi-binary-0.3.0.tgz",
      "integrity": "sha512-bhwsmGMOMN1srcpNAFRjDMSXe9ue1s/XmaoBBlqcG6S2nqRQlIVnKKH4WZx4hmC1jDqoFXuNPJGE47VXpVV+mA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/complex-float32-ctor": "^0.0.2",
        "@stdlib/complex-float32-reim": "^0.1.2",
        "@stdlib/complex-float64-ctor": "^0.0.3",
        "@stdlib/complex-float64-reim": "^0.1.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-napi-unary": {
      "version": "0.2.3",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-napi-unary/-/math-base-napi-unary-0.2.3.tgz",
      "integrity": "sha512-BCyJmpq2S8EFo2yMt1z+v1EL7nn8RHcM6jn7fa8n3BTP679K0MSlawIh3A0CFogfrTdjPM4G44VO1ddsdLExcg==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/complex-float32-ctor": "^0.0.2",
        "@stdlib/complex-float32-reim": "^0.1.1",
        "@stdlib/complex-float64-ctor": "^0.0.3",
        "@stdlib/complex-float64-reim": "^0.1.1",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-abs": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-abs/-/math-base-special-abs-0.2.2.tgz",
      "integrity": "sha512-cw5CXj05c/L0COaD9J+paHXwmoN5IBYh+Spk0331f1pEMvGxSO1KmCREZaooUEEFKPhKDukEHKeitja2yAQh4Q==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-high-word-abs-mask": "^0.2.2",
        "@stdlib/math-base-napi-unary": "^0.2.3",
        "@stdlib/number-float64-base-to-words": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-acos": {
      "version": "0.2.3",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-acos/-/math-base-special-acos-0.2.3.tgz",
      "integrity": "sha512-f66Ikq0E3U5XQm6sTu4UHwP3TmcPrVgSK/mZTvg2JenswZ6qPtGO1A8KHZ5+/5bk1TSc9EW4zDGUqWG7mGzT4Q==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-fourth-pi": "^0.2.2",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-napi-unary": "^0.2.3",
        "@stdlib/math-base-special-asin": "^0.2.2",
        "@stdlib/math-base-special-sqrt": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-asin": {
      "version": "0.2.3",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-asin/-/math-base-special-asin-0.2.3.tgz",
      "integrity": "sha512-Ju1UFJspOOL630SqBtVmUh3lHv5JMu1szcAgx7kQupJwZiwWljoVQ5MmxlNY4l3nGM5oMokenlqTDNXOau43lw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-fourth-pi": "^0.2.2",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-napi-unary": "^0.2.3",
        "@stdlib/math-base-special-sqrt": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-beta": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-beta/-/math-base-special-beta-0.2.1.tgz",
      "integrity": "sha512-/crN/ptCu7ld7KodGkYUJIweUTHdxO5mw+rgkrMqNVqJ83QQPd1czB6hvNYFLfmhy3ckj7t/UYoYhhg/x/Wd7g==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-e": "^0.2.1",
        "@stdlib/constants-float64-eps": "^0.2.1",
        "@stdlib/math-base-assert-is-nan": "^0.2.1",
        "@stdlib/math-base-special-abs": "^0.2.1",
        "@stdlib/math-base-special-exp": "^0.2.1",
        "@stdlib/math-base-special-log1p": "^0.2.1",
        "@stdlib/math-base-special-pow": "^0.2.1",
        "@stdlib/math-base-special-sqrt": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-betainc": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-betainc/-/math-base-special-betainc-0.2.2.tgz",
      "integrity": "sha512-95tzDgn5d9RV9al4gxHwKfszd9M6AizlpnhAiwIi0JwqcO+OY3xgbABWal4/H09Tb8DaC9jDqiyGuyPuB0iDew==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/math-base-special-kernel-betainc": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-binomcoef": {
      "version": "0.2.3",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-binomcoef/-/math-base-special-binomcoef-0.2.3.tgz",
      "integrity": "sha512-RxnQ/QGgKUeqTvBL+7IH8rNKQYCfGs0I3PsFYfb0e9V1O2yIVvthURUpzjukurZM89JRapK1dN6aeZ5UM71Zgw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-max-safe-integer": "^0.2.2",
        "@stdlib/constants-float64-pinf": "^0.2.2",
        "@stdlib/math-base-assert-is-integer": "^0.2.5",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-assert-is-odd": "^0.3.0",
        "@stdlib/math-base-special-floor": "^0.2.3",
        "@stdlib/math-base-special-gcd": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-ceil": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-ceil/-/math-base-special-ceil-0.2.2.tgz",
      "integrity": "sha512-zGkDaMcPrxQ9Zo+fegf2MyI8UPIrVTK5sc/FgCN9qdwEFJTKGLsBd249T3xH7L2MDxx5JbIMGrr6L4U4uEm2Hw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/math-base-napi-unary": "^0.2.3",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-copysign": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-copysign/-/math-base-special-copysign-0.2.2.tgz",
      "integrity": "sha512-m9nWIQhKsaNrZtS2vIPeToWDbzs/T0d0NWy7gSci38auQVufSbF6FYnCKl0f+uwiWlh5GYXs0uVbyCp7FFXN+A==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-high-word-abs-mask": "^0.2.2",
        "@stdlib/constants-float64-high-word-sign-mask": "^0.2.1",
        "@stdlib/math-base-napi-binary": "^0.3.0",
        "@stdlib/number-float64-base-from-words": "^0.2.2",
        "@stdlib/number-float64-base-get-high-word": "^0.2.2",
        "@stdlib/number-float64-base-to-words": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-cos": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-cos/-/math-base-special-cos-0.2.1.tgz",
      "integrity": "sha512-Yre+ASwsv4pQJk5dqY6488ZfmYDA6vtUTdapAVjCx28NluSFhXw1+S8EmsqnzYnqp/4x7Y1H7V2UPZfw+AdnbQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/math-base-special-kernel-cos": "^0.2.1",
        "@stdlib/math-base-special-kernel-sin": "^0.2.1",
        "@stdlib/math-base-special-rempio2": "^0.2.1",
        "@stdlib/number-float64-base-get-high-word": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-erfc": {
      "version": "0.2.4",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-erfc/-/math-base-special-erfc-0.2.4.tgz",
      "integrity": "sha512-tVI+mMnW+oDfQXwoH86sZ8q4ximpUXX6wZFCYZB6KcO5GXeKuvK74DnU0YyIm+sTV+r9WJiTSBEW9iVQLZOkzg==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-ninf": "^0.2.2",
        "@stdlib/constants-float64-pinf": "^0.2.2",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-napi-unary": "^0.2.3",
        "@stdlib/math-base-special-exp": "^0.2.4",
        "@stdlib/number-float64-base-set-low-word": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-erfcinv": {
      "version": "0.2.3",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-erfcinv/-/math-base-special-erfcinv-0.2.3.tgz",
      "integrity": "sha512-B8u7WZiIh0+rX8VWNOwvjPWpmeKBHIQoJtIigUseBgbch/rmgV43k63MCkjh2u+V2SmcFo38yD94qJg5bYyWeA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-ninf": "^0.2.2",
        "@stdlib/constants-float64-pinf": "^0.2.2",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-napi-unary": "^0.2.3",
        "@stdlib/math-base-special-ln": "^0.2.4",
        "@stdlib/math-base-special-sqrt": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-exp": {
      "version": "0.2.4",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-exp/-/math-base-special-exp-0.2.4.tgz",
      "integrity": "sha512-G6pZqu1wA4WwBj7DcnztA+/ro61wXJUTpKFLOwrIb2f/28pHGpA//Lub+3vAk6/ksAkhJ+qM/dfdM2ue7zLuEw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-ninf": "^0.2.2",
        "@stdlib/constants-float64-pinf": "^0.2.2",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-napi-unary": "^0.2.3",
        "@stdlib/math-base-special-ldexp": "^0.2.3",
        "@stdlib/math-base-special-trunc": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-expm1": {
      "version": "0.2.3",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-expm1/-/math-base-special-expm1-0.2.3.tgz",
      "integrity": "sha512-uJlYZjPjG9X8owuwp1h1/iz9xf21v3dlyEAuutQ0NoacUDzZKVSCbQ3Of0i2Mujn+4N+kjCvEeph6cqhfYAl+A==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-exponent-bias": "^0.2.2",
        "@stdlib/constants-float64-half-ln-two": "^0.2.2",
        "@stdlib/constants-float64-ninf": "^0.2.2",
        "@stdlib/constants-float64-pinf": "^0.2.2",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-napi-unary": "^0.2.3",
        "@stdlib/number-float64-base-from-words": "^0.2.2",
        "@stdlib/number-float64-base-get-high-word": "^0.2.2",
        "@stdlib/number-float64-base-set-high-word": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-factorial": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-factorial/-/math-base-special-factorial-0.2.1.tgz",
      "integrity": "sha512-uqsANeW4gHFzhgDrV9X0INEwO74MPzQvDVXbxY9+b0E13Vq2HHCi0GqdtPOWXdhOCUk8RkLRs9GizU3X6Coy8A==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-pinf": "^0.2.1",
        "@stdlib/math-base-assert-is-integer": "^0.2.1",
        "@stdlib/math-base-assert-is-nan": "^0.2.1",
        "@stdlib/math-base-special-gamma": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-floor": {
      "version": "0.2.3",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-floor/-/math-base-special-floor-0.2.3.tgz",
      "integrity": "sha512-zTkxVRawtWwJ4NmAT/1e+ZsIoBj1JqUquGOpiNVGNIKtyLOeCONZlZSbN7zuxPkshvmcSjpQ/VLKR8Tw/37E9A==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/math-base-napi-unary": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-fmod": {
      "version": "0.1.0",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-fmod/-/math-base-special-fmod-0.1.0.tgz",
      "integrity": "sha512-osHwmEOT5MPWOXRx8y3wKCp362eGHIcJRt8LARJJICr/qTZlu1HMnZnbwuhfy1NIQzpJ8aLOhEdl2PrProTt3A==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-exponent-bias": "^0.2.2",
        "@stdlib/constants-float64-high-word-abs-mask": "^0.2.2",
        "@stdlib/constants-float64-high-word-exponent-mask": "^0.2.2",
        "@stdlib/constants-float64-high-word-sign-mask": "^0.2.1",
        "@stdlib/constants-float64-high-word-significand-mask": "^0.2.2",
        "@stdlib/constants-float64-min-base2-exponent": "^0.2.2",
        "@stdlib/math-base-napi-binary": "^0.3.0",
        "@stdlib/number-float64-base-from-words": "^0.2.2",
        "@stdlib/number-float64-base-to-words": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-gamma": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-gamma/-/math-base-special-gamma-0.2.1.tgz",
      "integrity": "sha512-Sfq1HnVoL4kN9EDHH3YparEAF0r7QD5jNFppUTOXmrqkofgImSl5tLttttnr2I7O9zsNhYkBAiTx9q0y25bAiA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-eulergamma": "^0.2.1",
        "@stdlib/constants-float64-ninf": "^0.2.1",
        "@stdlib/constants-float64-pi": "^0.2.1",
        "@stdlib/constants-float64-pinf": "^0.2.1",
        "@stdlib/constants-float64-sqrt-two-pi": "^0.2.1",
        "@stdlib/math-base-assert-is-integer": "^0.2.1",
        "@stdlib/math-base-assert-is-nan": "^0.2.1",
        "@stdlib/math-base-assert-is-negative-zero": "^0.2.1",
        "@stdlib/math-base-special-abs": "^0.2.1",
        "@stdlib/math-base-special-exp": "^0.2.1",
        "@stdlib/math-base-special-floor": "^0.2.1",
        "@stdlib/math-base-special-pow": "^0.2.1",
        "@stdlib/math-base-special-sin": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-gamma-delta-ratio": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-gamma-delta-ratio/-/math-base-special-gamma-delta-ratio-0.2.2.tgz",
      "integrity": "sha512-lan+cfafH7aoyUxa88vLO+pYwLA+0uiyVFmCumxDemQUboCrTiNCYhBjONFGI/ljE3RukHoE3ZV4AccIcx526A==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-e": "^0.2.2",
        "@stdlib/constants-float64-eps": "^0.2.2",
        "@stdlib/constants-float64-gamma-lanczos-g": "^0.2.2",
        "@stdlib/math-base-special-abs": "^0.2.2",
        "@stdlib/math-base-special-exp": "^0.2.4",
        "@stdlib/math-base-special-factorial": "^0.2.1",
        "@stdlib/math-base-special-floor": "^0.2.3",
        "@stdlib/math-base-special-gamma": "^0.2.1",
        "@stdlib/math-base-special-gamma-lanczos-sum": "^0.3.0",
        "@stdlib/math-base-special-log1p": "^0.2.3",
        "@stdlib/math-base-special-pow": "^0.3.0"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-gamma-delta-ratio/node_modules/@stdlib/math-base-special-pow": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-pow/-/math-base-special-pow-0.3.0.tgz",
      "integrity": "sha512-sMDYRUYGFyMXDHcCYy7hE07lV7jgI6rDspLMROKyESWcH4n8j54XE4/0w0i8OpdzR40H895MaPWU/tVnU1tP6w==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-exponent-bias": "^0.2.2",
        "@stdlib/constants-float64-high-word-abs-mask": "^0.2.2",
        "@stdlib/constants-float64-high-word-significand-mask": "^0.2.2",
        "@stdlib/constants-float64-ln-two": "^0.2.2",
        "@stdlib/constants-float64-ninf": "^0.2.2",
        "@stdlib/constants-float64-pinf": "^0.2.2",
        "@stdlib/math-base-assert-is-infinite": "^0.2.2",
        "@stdlib/math-base-assert-is-integer": "^0.2.5",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-assert-is-odd": "^0.3.0",
        "@stdlib/math-base-napi-binary": "^0.3.0",
        "@stdlib/math-base-special-abs": "^0.2.2",
        "@stdlib/math-base-special-copysign": "^0.2.1",
        "@stdlib/math-base-special-ldexp": "^0.2.2",
        "@stdlib/math-base-special-sqrt": "^0.2.2",
        "@stdlib/number-float64-base-get-high-word": "^0.2.2",
        "@stdlib/number-float64-base-set-high-word": "^0.2.2",
        "@stdlib/number-float64-base-set-low-word": "^0.2.2",
        "@stdlib/number-float64-base-to-words": "^0.2.2",
        "@stdlib/number-uint32-base-to-int32": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-gamma-lanczos-sum": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-gamma-lanczos-sum/-/math-base-special-gamma-lanczos-sum-0.3.0.tgz",
      "integrity": "sha512-q13p6r7G0TmbD54cU8QgG8wGgdGGznV9dNKiNszw+hOqCQ+1DqziG8I6vN64R3EQLP7QN4yVprZcmuXSK+fgsg==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-pinf": "^0.2.2",
        "@stdlib/math-base-napi-unary": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-gamma-lanczos-sum-expg-scaled": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-gamma-lanczos-sum-expg-scaled/-/math-base-special-gamma-lanczos-sum-expg-scaled-0.3.0.tgz",
      "integrity": "sha512-hScjKZvueOK5piX84ZLIV3ZiYvtvYtcixN8psxkPIxJlN7Bd5nAmSkEOBL+T+LeW2RjmdEMXFFJMF7FsK1js/Q==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/math-base-napi-unary": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-gamma1pm1": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-gamma1pm1/-/math-base-special-gamma1pm1-0.2.2.tgz",
      "integrity": "sha512-lNT1lk0ifK2a/ta3GfR5V8KvfgkgheE44n5AQ/07BBfcVBMiAdqNuyjSMeWqsH/zVGzjU6G8+kLBzmaJXivPXQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-eps": "^0.2.2",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-special-expm1": "^0.2.3",
        "@stdlib/math-base-special-gamma": "^0.2.1",
        "@stdlib/math-base-special-ln": "^0.2.4",
        "@stdlib/math-base-special-log1p": "^0.2.3"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-gammainc": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-gammainc/-/math-base-special-gammainc-0.2.2.tgz",
      "integrity": "sha512-ffKZFiv/41SXs2Xms7IW3lPnICR898yfWAidq5uKjOLgRb3wrzNjq0sZ6EAVXvdBwyGULvSjyud28PpVhDLv3A==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-e": "^0.2.2",
        "@stdlib/constants-float64-gamma-lanczos-g": "^0.2.2",
        "@stdlib/constants-float64-max": "^0.2.2",
        "@stdlib/constants-float64-max-ln": "^0.2.2",
        "@stdlib/constants-float64-min-ln": "^0.2.2",
        "@stdlib/constants-float64-pi": "^0.2.2",
        "@stdlib/constants-float64-pinf": "^0.2.2",
        "@stdlib/constants-float64-sqrt-eps": "^0.2.2",
        "@stdlib/constants-float64-sqrt-two-pi": "^0.2.2",
        "@stdlib/constants-float64-two-pi": "^0.2.2",
        "@stdlib/math-base-special-abs": "^0.2.2",
        "@stdlib/math-base-special-erfc": "^0.2.4",
        "@stdlib/math-base-special-exp": "^0.2.4",
        "@stdlib/math-base-special-floor": "^0.2.3",
        "@stdlib/math-base-special-gamma": "^0.3.0",
        "@stdlib/math-base-special-gamma-lanczos-sum-expg-scaled": "^0.3.0",
        "@stdlib/math-base-special-gamma1pm1": "^0.2.2",
        "@stdlib/math-base-special-gammaln": "^0.2.2",
        "@stdlib/math-base-special-ln": "^0.2.4",
        "@stdlib/math-base-special-log1p": "^0.2.3",
        "@stdlib/math-base-special-log1pmx": "^0.2.3",
        "@stdlib/math-base-special-max": "^0.3.0",
        "@stdlib/math-base-special-min": "^0.2.3",
        "@stdlib/math-base-special-pow": "^0.3.0",
        "@stdlib/math-base-special-powm1": "^0.3.0",
        "@stdlib/math-base-special-sqrt": "^0.2.2",
        "@stdlib/math-base-tools-continued-fraction": "^0.2.2",
        "@stdlib/math-base-tools-evalpoly": "^0.2.2",
        "@stdlib/math-base-tools-sum-series": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-gammainc/node_modules/@stdlib/math-base-special-gamma": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-gamma/-/math-base-special-gamma-0.3.0.tgz",
      "integrity": "sha512-YfW+e5xuSDoUxgpquXPrFtAbdwOzE7Kqt7M0dcAkDNot8/yUn+QmrDGzURyBVzUyhRm9SaC9bACHxTShdJkcuA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-eulergamma": "^0.2.2",
        "@stdlib/constants-float64-ninf": "^0.2.2",
        "@stdlib/constants-float64-pi": "^0.2.2",
        "@stdlib/constants-float64-pinf": "^0.2.2",
        "@stdlib/constants-float64-sqrt-two-pi": "^0.2.2",
        "@stdlib/math-base-assert-is-integer": "^0.2.5",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-assert-is-negative-zero": "^0.2.2",
        "@stdlib/math-base-napi-unary": "^0.2.3",
        "@stdlib/math-base-special-abs": "^0.2.2",
        "@stdlib/math-base-special-exp": "^0.2.4",
        "@stdlib/math-base-special-floor": "^0.2.3",
        "@stdlib/math-base-special-pow": "^0.3.0",
        "@stdlib/math-base-special-sin": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-gammainc/node_modules/@stdlib/math-base-special-max": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-max/-/math-base-special-max-0.3.0.tgz",
      "integrity": "sha512-yXsmdFCLHRB24l34Kn1kHZXHKoGqBxPY/5Mi+n5qLg+FwrX85ZG6KGVbO3DfcpG1NxDTcEKb1hxbUargI0P5fw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-pinf": "^0.2.2",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-assert-is-positive-zero": "^0.2.2",
        "@stdlib/math-base-napi-binary": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-gammainc/node_modules/@stdlib/math-base-special-max/node_modules/@stdlib/math-base-napi-binary": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-napi-binary/-/math-base-napi-binary-0.2.1.tgz",
      "integrity": "sha512-ewGarSRaz5gaLsE17yJ4me03e56ICgPAA0ru0SYFCeMK2E5Z4Z2Lbu7HAQTTg+8XhpoaZSw0h2GJopTV7PCKmw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/complex-float32": "^0.2.1",
        "@stdlib/complex-float64": "^0.2.1",
        "@stdlib/complex-reim": "^0.2.1",
        "@stdlib/complex-reimf": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-gammainc/node_modules/@stdlib/math-base-special-pow": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-pow/-/math-base-special-pow-0.3.0.tgz",
      "integrity": "sha512-sMDYRUYGFyMXDHcCYy7hE07lV7jgI6rDspLMROKyESWcH4n8j54XE4/0w0i8OpdzR40H895MaPWU/tVnU1tP6w==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-exponent-bias": "^0.2.2",
        "@stdlib/constants-float64-high-word-abs-mask": "^0.2.2",
        "@stdlib/constants-float64-high-word-significand-mask": "^0.2.2",
        "@stdlib/constants-float64-ln-two": "^0.2.2",
        "@stdlib/constants-float64-ninf": "^0.2.2",
        "@stdlib/constants-float64-pinf": "^0.2.2",
        "@stdlib/math-base-assert-is-infinite": "^0.2.2",
        "@stdlib/math-base-assert-is-integer": "^0.2.5",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-assert-is-odd": "^0.3.0",
        "@stdlib/math-base-napi-binary": "^0.3.0",
        "@stdlib/math-base-special-abs": "^0.2.2",
        "@stdlib/math-base-special-copysign": "^0.2.1",
        "@stdlib/math-base-special-ldexp": "^0.2.2",
        "@stdlib/math-base-special-sqrt": "^0.2.2",
        "@stdlib/number-float64-base-get-high-word": "^0.2.2",
        "@stdlib/number-float64-base-set-high-word": "^0.2.2",
        "@stdlib/number-float64-base-set-low-word": "^0.2.2",
        "@stdlib/number-float64-base-to-words": "^0.2.2",
        "@stdlib/number-uint32-base-to-int32": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-gammaincinv": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-gammaincinv/-/math-base-special-gammaincinv-0.2.2.tgz",
      "integrity": "sha512-bIZ94ob1rY87seDWsvBTBRxp8Ja2Y46DLtQYuaylHUQuK+I2xKy8XKL2ZHPsOfuwhXRqm+q+91PDjPEAdH1dQw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float32-max": "^0.2.2",
        "@stdlib/constants-float32-smallest-normal": "^0.2.2",
        "@stdlib/constants-float64-ln-sqrt-two-pi": "^0.2.2",
        "@stdlib/constants-float64-pinf": "^0.2.2",
        "@stdlib/constants-float64-sqrt-two-pi": "^0.2.2",
        "@stdlib/constants-float64-two-pi": "^0.2.2",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-special-abs": "^0.2.2",
        "@stdlib/math-base-special-erfcinv": "^0.2.3",
        "@stdlib/math-base-special-exp": "^0.2.4",
        "@stdlib/math-base-special-gamma": "^0.3.0",
        "@stdlib/math-base-special-gammainc": "^0.2.2",
        "@stdlib/math-base-special-gammaln": "^0.2.2",
        "@stdlib/math-base-special-ln": "^0.2.4",
        "@stdlib/math-base-special-min": "^0.2.3",
        "@stdlib/math-base-special-pow": "^0.3.0",
        "@stdlib/math-base-special-sqrt": "^0.2.2",
        "@stdlib/math-base-tools-evalpoly": "^0.2.2",
        "debug": "^2.6.9"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-gammaincinv/node_modules/@stdlib/math-base-special-gamma": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-gamma/-/math-base-special-gamma-0.3.0.tgz",
      "integrity": "sha512-YfW+e5xuSDoUxgpquXPrFtAbdwOzE7Kqt7M0dcAkDNot8/yUn+QmrDGzURyBVzUyhRm9SaC9bACHxTShdJkcuA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-eulergamma": "^0.2.2",
        "@stdlib/constants-float64-ninf": "^0.2.2",
        "@stdlib/constants-float64-pi": "^0.2.2",
        "@stdlib/constants-float64-pinf": "^0.2.2",
        "@stdlib/constants-float64-sqrt-two-pi": "^0.2.2",
        "@stdlib/math-base-assert-is-integer": "^0.2.5",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-assert-is-negative-zero": "^0.2.2",
        "@stdlib/math-base-napi-unary": "^0.2.3",
        "@stdlib/math-base-special-abs": "^0.2.2",
        "@stdlib/math-base-special-exp": "^0.2.4",
        "@stdlib/math-base-special-floor": "^0.2.3",
        "@stdlib/math-base-special-pow": "^0.3.0",
        "@stdlib/math-base-special-sin": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-gammaincinv/node_modules/@stdlib/math-base-special-pow": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-pow/-/math-base-special-pow-0.3.0.tgz",
      "integrity": "sha512-sMDYRUYGFyMXDHcCYy7hE07lV7jgI6rDspLMROKyESWcH4n8j54XE4/0w0i8OpdzR40H895MaPWU/tVnU1tP6w==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-exponent-bias": "^0.2.2",
        "@stdlib/constants-float64-high-word-abs-mask": "^0.2.2",
        "@stdlib/constants-float64-high-word-significand-mask": "^0.2.2",
        "@stdlib/constants-float64-ln-two": "^0.2.2",
        "@stdlib/constants-float64-ninf": "^0.2.2",
        "@stdlib/constants-float64-pinf": "^0.2.2",
        "@stdlib/math-base-assert-is-infinite": "^0.2.2",
        "@stdlib/math-base-assert-is-integer": "^0.2.5",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-assert-is-odd": "^0.3.0",
        "@stdlib/math-base-napi-binary": "^0.3.0",
        "@stdlib/math-base-special-abs": "^0.2.2",
        "@stdlib/math-base-special-copysign": "^0.2.1",
        "@stdlib/math-base-special-ldexp": "^0.2.2",
        "@stdlib/math-base-special-sqrt": "^0.2.2",
        "@stdlib/number-float64-base-get-high-word": "^0.2.2",
        "@stdlib/number-float64-base-set-high-word": "^0.2.2",
        "@stdlib/number-float64-base-set-low-word": "^0.2.2",
        "@stdlib/number-float64-base-to-words": "^0.2.2",
        "@stdlib/number-uint32-base-to-int32": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-gammaln": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-gammaln/-/math-base-special-gammaln-0.2.2.tgz",
      "integrity": "sha512-opG6HUlspi/GLvQAr4pcwyAevm7BYuymlopgNZ1VulWUvksDpytalaX3zva0idlD2HvniKrDmzHngT1N9p0J1A==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-pi": "^0.2.2",
        "@stdlib/constants-float64-pinf": "^0.2.2",
        "@stdlib/math-base-assert-is-infinite": "^0.2.2",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-special-abs": "^0.2.2",
        "@stdlib/math-base-special-ln": "^0.2.4",
        "@stdlib/math-base-special-sinpi": "^0.2.1",
        "@stdlib/math-base-special-trunc": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-gcd": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-gcd/-/math-base-special-gcd-0.2.1.tgz",
      "integrity": "sha512-w10k9W176lDkbiDIwnmVr1nkTyypTQLwA3/CN9qEUmXh/u8NlxkSnDYBpArcWnxE0oFaIggw8sLJ58TuMvxMaw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-ninf": "^0.2.1",
        "@stdlib/constants-float64-pinf": "^0.2.1",
        "@stdlib/constants-int32-max": "^0.2.1",
        "@stdlib/math-base-assert-is-integer": "^0.2.1",
        "@stdlib/math-base-assert-is-nan": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-gcd/node_modules/@stdlib/constants-int32-max": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/constants-int32-max/-/constants-int32-max-0.2.1.tgz",
      "integrity": "sha512-vKtp3q/HdAeGG8BJBZdNzFrYpVQeleODgvOxh9Pn/TX1Ktjc50I9TVl7nTVWsT2QnacruOorILk2zNsdgBHPUQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-kernel-betainc": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-kernel-betainc/-/math-base-special-kernel-betainc-0.2.2.tgz",
      "integrity": "sha512-DQwQUWQkmZtjRgdvZ1yZOEdAYLQoEUEndbr47Z69Oe6AgwKwxxpZUh09h9imKheFCFHLVnwVUz20azIM5KifQw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-e": "^0.2.2",
        "@stdlib/constants-float64-eps": "^0.2.2",
        "@stdlib/constants-float64-gamma-lanczos-g": "^0.2.2",
        "@stdlib/constants-float64-half-pi": "^0.2.2",
        "@stdlib/constants-float64-max": "^0.2.2",
        "@stdlib/constants-float64-max-ln": "^0.2.2",
        "@stdlib/constants-float64-min-ln": "^0.2.2",
        "@stdlib/constants-float64-pi": "^0.2.2",
        "@stdlib/constants-float64-smallest-normal": "^0.2.2",
        "@stdlib/constants-int32-max": "^0.3.0",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-special-abs": "^0.2.2",
        "@stdlib/math-base-special-asin": "^0.2.3",
        "@stdlib/math-base-special-beta": "^0.3.0",
        "@stdlib/math-base-special-binomcoef": "^0.2.3",
        "@stdlib/math-base-special-exp": "^0.2.4",
        "@stdlib/math-base-special-expm1": "^0.2.3",
        "@stdlib/math-base-special-factorial": "^0.3.0",
        "@stdlib/math-base-special-floor": "^0.2.3",
        "@stdlib/math-base-special-gamma": "^0.3.0",
        "@stdlib/math-base-special-gamma-delta-ratio": "^0.2.2",
        "@stdlib/math-base-special-gamma-lanczos-sum-expg-scaled": "^0.3.0",
        "@stdlib/math-base-special-gammainc": "^0.2.1",
        "@stdlib/math-base-special-gammaln": "^0.2.2",
        "@stdlib/math-base-special-ln": "^0.2.4",
        "@stdlib/math-base-special-log1p": "^0.2.3",
        "@stdlib/math-base-special-max": "^0.3.0",
        "@stdlib/math-base-special-maxabs": "^0.3.0",
        "@stdlib/math-base-special-min": "^0.2.3",
        "@stdlib/math-base-special-minabs": "^0.2.3",
        "@stdlib/math-base-special-pow": "^0.3.0",
        "@stdlib/math-base-special-sqrt": "^0.2.2",
        "@stdlib/math-base-tools-continued-fraction": "^0.2.2",
        "@stdlib/math-base-tools-sum-series": "^0.2.2",
        "@stdlib/utils-define-nonenumerable-read-only-property": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-kernel-betainc/node_modules/@stdlib/math-base-special-beta": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-beta/-/math-base-special-beta-0.3.0.tgz",
      "integrity": "sha512-SWUF1AZLqaEJ8g1Lj0/UOfj955AsIS3QPYH/ZMijELVxCwmp7VRgalI0AxMM09IraJt1cH5WrSwSnouH1WC3ZQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-e": "^0.2.2",
        "@stdlib/constants-float64-eps": "^0.2.2",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-napi-binary": "^0.3.0",
        "@stdlib/math-base-special-abs": "^0.2.2",
        "@stdlib/math-base-special-exp": "^0.2.4",
        "@stdlib/math-base-special-log1p": "^0.2.3",
        "@stdlib/math-base-special-pow": "^0.3.0",
        "@stdlib/math-base-special-sqrt": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-kernel-betainc/node_modules/@stdlib/math-base-special-factorial": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-factorial/-/math-base-special-factorial-0.3.0.tgz",
      "integrity": "sha512-tXdXqstF4gmy4HpzALo3Bhkj2UQSlyk+PU3alWXZH5XtKUozHuXhQDnak+2c4w0JqnKxHq4mnaR2qgjfkDNZcA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-max-safe-nth-factorial": "^0.1.0",
        "@stdlib/constants-float64-pinf": "^0.2.2",
        "@stdlib/math-base-assert-is-integer": "^0.2.5",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-napi-unary": "^0.2.3",
        "@stdlib/math-base-special-gamma": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-kernel-betainc/node_modules/@stdlib/math-base-special-factorial/node_modules/@stdlib/math-base-assert-is-odd": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-assert-is-odd/-/math-base-assert-is-odd-0.2.1.tgz",
      "integrity": "sha512-V4qQuCO6/AA5udqlNatMRZ8R/MgpqD8mPIkFrpSZJdpLcGYSz815uAAf3NBOuWXkE2Izw0/Tg/hTQ+YcOW2g5g==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/math-base-assert-is-even": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-kernel-betainc/node_modules/@stdlib/math-base-special-factorial/node_modules/@stdlib/math-base-special-gamma": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-gamma/-/math-base-special-gamma-0.2.1.tgz",
      "integrity": "sha512-Sfq1HnVoL4kN9EDHH3YparEAF0r7QD5jNFppUTOXmrqkofgImSl5tLttttnr2I7O9zsNhYkBAiTx9q0y25bAiA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-eulergamma": "^0.2.1",
        "@stdlib/constants-float64-ninf": "^0.2.1",
        "@stdlib/constants-float64-pi": "^0.2.1",
        "@stdlib/constants-float64-pinf": "^0.2.1",
        "@stdlib/constants-float64-sqrt-two-pi": "^0.2.1",
        "@stdlib/math-base-assert-is-integer": "^0.2.1",
        "@stdlib/math-base-assert-is-nan": "^0.2.1",
        "@stdlib/math-base-assert-is-negative-zero": "^0.2.1",
        "@stdlib/math-base-special-abs": "^0.2.1",
        "@stdlib/math-base-special-exp": "^0.2.1",
        "@stdlib/math-base-special-floor": "^0.2.1",
        "@stdlib/math-base-special-pow": "^0.2.1",
        "@stdlib/math-base-special-sin": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-kernel-betainc/node_modules/@stdlib/math-base-special-factorial/node_modules/@stdlib/math-base-special-pow": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-pow/-/math-base-special-pow-0.2.1.tgz",
      "integrity": "sha512-7SvgVzDkuilZKrHh4tPiXx9fypF/V7PSvAcUVjvcRj5kVEwv/15RpzlmCJlT9B20VPSx4gJ1S0UIA6xgmYFuAg==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-exponent-bias": "^0.2.1",
        "@stdlib/constants-float64-high-word-abs-mask": "^0.2.1",
        "@stdlib/constants-float64-high-word-significand-mask": "^0.2.1",
        "@stdlib/constants-float64-ln-two": "^0.2.1",
        "@stdlib/constants-float64-ninf": "^0.2.1",
        "@stdlib/constants-float64-pinf": "^0.2.1",
        "@stdlib/math-base-assert-is-infinite": "^0.2.1",
        "@stdlib/math-base-assert-is-integer": "^0.2.1",
        "@stdlib/math-base-assert-is-nan": "^0.2.1",
        "@stdlib/math-base-assert-is-odd": "^0.2.1",
        "@stdlib/math-base-special-abs": "^0.2.1",
        "@stdlib/math-base-special-copysign": "^0.2.1",
        "@stdlib/math-base-special-ldexp": "^0.2.1",
        "@stdlib/math-base-special-sqrt": "^0.2.1",
        "@stdlib/number-float64-base-get-high-word": "^0.2.1",
        "@stdlib/number-float64-base-set-high-word": "^0.2.1",
        "@stdlib/number-float64-base-set-low-word": "^0.2.1",
        "@stdlib/number-float64-base-to-words": "^0.2.1",
        "@stdlib/number-uint32-base-to-int32": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-kernel-betainc/node_modules/@stdlib/math-base-special-gamma": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-gamma/-/math-base-special-gamma-0.3.0.tgz",
      "integrity": "sha512-YfW+e5xuSDoUxgpquXPrFtAbdwOzE7Kqt7M0dcAkDNot8/yUn+QmrDGzURyBVzUyhRm9SaC9bACHxTShdJkcuA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-eulergamma": "^0.2.2",
        "@stdlib/constants-float64-ninf": "^0.2.2",
        "@stdlib/constants-float64-pi": "^0.2.2",
        "@stdlib/constants-float64-pinf": "^0.2.2",
        "@stdlib/constants-float64-sqrt-two-pi": "^0.2.2",
        "@stdlib/math-base-assert-is-integer": "^0.2.5",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-assert-is-negative-zero": "^0.2.2",
        "@stdlib/math-base-napi-unary": "^0.2.3",
        "@stdlib/math-base-special-abs": "^0.2.2",
        "@stdlib/math-base-special-exp": "^0.2.4",
        "@stdlib/math-base-special-floor": "^0.2.3",
        "@stdlib/math-base-special-pow": "^0.3.0",
        "@stdlib/math-base-special-sin": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-kernel-betainc/node_modules/@stdlib/math-base-special-max": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-max/-/math-base-special-max-0.3.0.tgz",
      "integrity": "sha512-yXsmdFCLHRB24l34Kn1kHZXHKoGqBxPY/5Mi+n5qLg+FwrX85ZG6KGVbO3DfcpG1NxDTcEKb1hxbUargI0P5fw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-pinf": "^0.2.2",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-assert-is-positive-zero": "^0.2.2",
        "@stdlib/math-base-napi-binary": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-kernel-betainc/node_modules/@stdlib/math-base-special-max/node_modules/@stdlib/math-base-napi-binary": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-napi-binary/-/math-base-napi-binary-0.2.1.tgz",
      "integrity": "sha512-ewGarSRaz5gaLsE17yJ4me03e56ICgPAA0ru0SYFCeMK2E5Z4Z2Lbu7HAQTTg+8XhpoaZSw0h2GJopTV7PCKmw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/complex-float32": "^0.2.1",
        "@stdlib/complex-float64": "^0.2.1",
        "@stdlib/complex-reim": "^0.2.1",
        "@stdlib/complex-reimf": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-kernel-betainc/node_modules/@stdlib/math-base-special-pow": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-pow/-/math-base-special-pow-0.3.0.tgz",
      "integrity": "sha512-sMDYRUYGFyMXDHcCYy7hE07lV7jgI6rDspLMROKyESWcH4n8j54XE4/0w0i8OpdzR40H895MaPWU/tVnU1tP6w==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-exponent-bias": "^0.2.2",
        "@stdlib/constants-float64-high-word-abs-mask": "^0.2.2",
        "@stdlib/constants-float64-high-word-significand-mask": "^0.2.2",
        "@stdlib/constants-float64-ln-two": "^0.2.2",
        "@stdlib/constants-float64-ninf": "^0.2.2",
        "@stdlib/constants-float64-pinf": "^0.2.2",
        "@stdlib/math-base-assert-is-infinite": "^0.2.2",
        "@stdlib/math-base-assert-is-integer": "^0.2.5",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-assert-is-odd": "^0.3.0",
        "@stdlib/math-base-napi-binary": "^0.3.0",
        "@stdlib/math-base-special-abs": "^0.2.2",
        "@stdlib/math-base-special-copysign": "^0.2.1",
        "@stdlib/math-base-special-ldexp": "^0.2.2",
        "@stdlib/math-base-special-sqrt": "^0.2.2",
        "@stdlib/number-float64-base-get-high-word": "^0.2.2",
        "@stdlib/number-float64-base-set-high-word": "^0.2.2",
        "@stdlib/number-float64-base-set-low-word": "^0.2.2",
        "@stdlib/number-float64-base-to-words": "^0.2.2",
        "@stdlib/number-uint32-base-to-int32": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-kernel-betaincinv": {
      "version": "0.1.1",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-kernel-betaincinv/-/math-base-special-kernel-betaincinv-0.1.1.tgz",
      "integrity": "sha512-DZLALmQj0m3Wx8L8/na8Jj9vluNj4Z5DxmAPvnA1AWGYy7KsotmP4HXwgSTlsfbXeF3iGcrmworPOo4HJUSxIQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-eps": "^0.2.1",
        "@stdlib/constants-float64-half-pi": "^0.2.1",
        "@stdlib/constants-float64-max": "^0.2.1",
        "@stdlib/constants-float64-pi": "^0.2.1",
        "@stdlib/constants-float64-smallest-normal": "^0.2.1",
        "@stdlib/constants-float64-smallest-subnormal": "^0.2.1",
        "@stdlib/constants-float64-sqrt-two": "^0.2.1",
        "@stdlib/math-base-special-abs": "^0.2.1",
        "@stdlib/math-base-special-acos": "^0.2.1",
        "@stdlib/math-base-special-asin": "^0.2.1",
        "@stdlib/math-base-special-beta": "^0.2.1",
        "@stdlib/math-base-special-betainc": "^0.2.1",
        "@stdlib/math-base-special-cos": "^0.2.1",
        "@stdlib/math-base-special-erfcinv": "^0.2.1",
        "@stdlib/math-base-special-exp": "^0.2.1",
        "@stdlib/math-base-special-expm1": "^0.2.1",
        "@stdlib/math-base-special-floor": "^0.2.1",
        "@stdlib/math-base-special-gamma-delta-ratio": "^0.2.1",
        "@stdlib/math-base-special-gammaincinv": "^0.2.1",
        "@stdlib/math-base-special-kernel-betainc": "^0.2.1",
        "@stdlib/math-base-special-ldexp": "^0.2.1",
        "@stdlib/math-base-special-ln": "^0.2.1",
        "@stdlib/math-base-special-log1p": "^0.2.1",
        "@stdlib/math-base-special-max": "^0.2.1",
        "@stdlib/math-base-special-min": "^0.2.1",
        "@stdlib/math-base-special-pow": "^0.2.1",
        "@stdlib/math-base-special-round": "^0.2.1",
        "@stdlib/math-base-special-signum": "^0.2.1",
        "@stdlib/math-base-special-sin": "^0.2.1",
        "@stdlib/math-base-special-sqrt": "^0.2.1",
        "@stdlib/math-base-tools-evalpoly": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-kernel-cos": {
      "version": "0.2.3",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-kernel-cos/-/math-base-special-kernel-cos-0.2.3.tgz",
      "integrity": "sha512-K5FbN25SmEc5Z89GejUkrZpqCv05ZX6D7g9SUFcKWFJ1fwiZNgxrF8q4aJtGDQhuV3q66C1gaKJyQeLq/OI8lQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/math-base-napi-binary": "^0.3.0",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-kernel-sin": {
      "version": "0.2.3",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-kernel-sin/-/math-base-special-kernel-sin-0.2.3.tgz",
      "integrity": "sha512-PFnlGdapUaCaMXqZr+tG5Ioq+l4TCyGE5e8XEYlsyhNDILf0XE2ghHzlROA/wW365Arl4sPLWUoo4oH98DUPqw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/math-base-napi-binary": "^0.3.0",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-ldexp": {
      "version": "0.2.3",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-ldexp/-/math-base-special-ldexp-0.2.3.tgz",
      "integrity": "sha512-yD4YisQGVTJmTJUshuzpaoq34sxJtrU+Aw4Ih39mzgXiQi6sh3E3nijB8WXDNKr2v05acUWJ1PRMkkJSfu16Kg==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-exponent-bias": "^0.2.2",
        "@stdlib/constants-float64-max-base2-exponent": "^0.2.2",
        "@stdlib/constants-float64-max-base2-exponent-subnormal": "^0.2.1",
        "@stdlib/constants-float64-min-base2-exponent-subnormal": "^0.2.1",
        "@stdlib/constants-float64-ninf": "^0.2.2",
        "@stdlib/constants-float64-pinf": "^0.2.2",
        "@stdlib/math-base-assert-is-infinite": "^0.2.2",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-special-abs": "^0.2.2",
        "@stdlib/math-base-special-copysign": "^0.2.1",
        "@stdlib/number-float32-base-to-word": "^0.2.2",
        "@stdlib/number-float64-base-exponent": "^0.2.2",
        "@stdlib/number-float64-base-from-words": "^0.2.2",
        "@stdlib/number-float64-base-normalize": "^0.2.3",
        "@stdlib/number-float64-base-to-words": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-ln": {
      "version": "0.2.4",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-ln/-/math-base-special-ln-0.2.4.tgz",
      "integrity": "sha512-lSB47USaixrEmxwadT0/yByvTtxNhaRwN0FIXt5oj38bsgMXGW4V8xrANOy1N+hrn3KGfHJNDyFPYbXWVdMTIw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-exponent-bias": "^0.2.2",
        "@stdlib/constants-float64-ninf": "^0.2.2",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-napi-unary": "^0.2.1",
        "@stdlib/number-float64-base-get-high-word": "^0.2.2",
        "@stdlib/number-float64-base-set-high-word": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-log1p": {
      "version": "0.2.3",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-log1p/-/math-base-special-log1p-0.2.3.tgz",
      "integrity": "sha512-1Pu3attNR+DcskIvhvyls+2KRZ0UCHQ/jP2tvgFI9bWDCgb4oEimXPzjFteGNg9Mj6WlAW2b9wU9tHt3bp8R3g==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-exponent-bias": "^0.2.2",
        "@stdlib/constants-float64-ninf": "^0.2.2",
        "@stdlib/constants-float64-pinf": "^0.2.2",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-napi-unary": "^0.2.1",
        "@stdlib/number-float64-base-get-high-word": "^0.2.2",
        "@stdlib/number-float64-base-set-high-word": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-log1pmx": {
      "version": "0.2.3",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-log1pmx/-/math-base-special-log1pmx-0.2.3.tgz",
      "integrity": "sha512-HfjDXcbFztm/GQRrn7a9FMYS0rm/4VPXWa50sYQzBHSYaEwYv5Y1awaZz+cA/ncuqAq1Mw0dfcwEMNRmZtnxEQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-eps": "^0.2.2",
        "@stdlib/math-base-napi-unary": "^0.2.3",
        "@stdlib/math-base-special-abs": "^0.2.2",
        "@stdlib/math-base-special-ln": "^0.2.4",
        "@stdlib/math-base-special-log1p": "^0.2.3",
        "@stdlib/math-base-tools-sum-series": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-max": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-max/-/math-base-special-max-0.2.1.tgz",
      "integrity": "sha512-jsA3x5azfclbULDFwvHjNlB2nciUDHwrw7qHP/QlSdJi47E1iBDNYdzhlOa3JKzblbrITpzgZEsGBcpCinEInQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-pinf": "^0.2.1",
        "@stdlib/math-base-assert-is-nan": "^0.2.1",
        "@stdlib/math-base-assert-is-positive-zero": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-maxabs": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-maxabs/-/math-base-special-maxabs-0.3.0.tgz",
      "integrity": "sha512-SDj+rGD9itZ/YG2hKzhLX4Tf13SNJdOyNsMy1ezjec6Az3xJXKzv2wJAJIteo0KF6jQnEDkI/F6OIF65MY+o0g==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/math-base-napi-binary": "^0.2.1",
        "@stdlib/math-base-special-abs": "^0.2.2",
        "@stdlib/math-base-special-max": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-maxabs/node_modules/@stdlib/math-base-napi-binary": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-napi-binary/-/math-base-napi-binary-0.2.1.tgz",
      "integrity": "sha512-ewGarSRaz5gaLsE17yJ4me03e56ICgPAA0ru0SYFCeMK2E5Z4Z2Lbu7HAQTTg+8XhpoaZSw0h2GJopTV7PCKmw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/complex-float32": "^0.2.1",
        "@stdlib/complex-float64": "^0.2.1",
        "@stdlib/complex-reim": "^0.2.1",
        "@stdlib/complex-reimf": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-min": {
      "version": "0.2.3",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-min/-/math-base-special-min-0.2.3.tgz",
      "integrity": "sha512-tNrKnkcHCRVWzteZJpZ/xql9B6N6EzecnUVizDYqG9y66bOVtI+TADcQ5I/bijEwAIi2BjrIVeq/TBEgQEQBkw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-ninf": "^0.2.2",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-assert-is-negative-zero": "^0.2.2",
        "@stdlib/math-base-napi-binary": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-min/node_modules/@stdlib/math-base-napi-binary": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-napi-binary/-/math-base-napi-binary-0.2.1.tgz",
      "integrity": "sha512-ewGarSRaz5gaLsE17yJ4me03e56ICgPAA0ru0SYFCeMK2E5Z4Z2Lbu7HAQTTg+8XhpoaZSw0h2GJopTV7PCKmw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/complex-float32": "^0.2.1",
        "@stdlib/complex-float64": "^0.2.1",
        "@stdlib/complex-reim": "^0.2.1",
        "@stdlib/complex-reimf": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-minabs": {
      "version": "0.2.3",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-minabs/-/math-base-special-minabs-0.2.3.tgz",
      "integrity": "sha512-IV7PSL09S2GHmsxxtFgebPEwLm/wHnC1e1ulP8Uiuo2zinOiv4NXy2tpf9T+nq95d0ICFMnr9IGxFs6Nd74hRw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/math-base-napi-binary": "^0.2.1",
        "@stdlib/math-base-special-abs": "^0.2.2",
        "@stdlib/math-base-special-min": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-minabs/node_modules/@stdlib/math-base-napi-binary": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-napi-binary/-/math-base-napi-binary-0.2.1.tgz",
      "integrity": "sha512-ewGarSRaz5gaLsE17yJ4me03e56ICgPAA0ru0SYFCeMK2E5Z4Z2Lbu7HAQTTg+8XhpoaZSw0h2GJopTV7PCKmw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/complex-float32": "^0.2.1",
        "@stdlib/complex-float64": "^0.2.1",
        "@stdlib/complex-reim": "^0.2.1",
        "@stdlib/complex-reimf": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-pow": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-pow/-/math-base-special-pow-0.2.1.tgz",
      "integrity": "sha512-7SvgVzDkuilZKrHh4tPiXx9fypF/V7PSvAcUVjvcRj5kVEwv/15RpzlmCJlT9B20VPSx4gJ1S0UIA6xgmYFuAg==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-exponent-bias": "^0.2.1",
        "@stdlib/constants-float64-high-word-abs-mask": "^0.2.1",
        "@stdlib/constants-float64-high-word-significand-mask": "^0.2.1",
        "@stdlib/constants-float64-ln-two": "^0.2.1",
        "@stdlib/constants-float64-ninf": "^0.2.1",
        "@stdlib/constants-float64-pinf": "^0.2.1",
        "@stdlib/math-base-assert-is-infinite": "^0.2.1",
        "@stdlib/math-base-assert-is-integer": "^0.2.1",
        "@stdlib/math-base-assert-is-nan": "^0.2.1",
        "@stdlib/math-base-assert-is-odd": "^0.2.1",
        "@stdlib/math-base-special-abs": "^0.2.1",
        "@stdlib/math-base-special-copysign": "^0.2.1",
        "@stdlib/math-base-special-ldexp": "^0.2.1",
        "@stdlib/math-base-special-sqrt": "^0.2.1",
        "@stdlib/number-float64-base-get-high-word": "^0.2.1",
        "@stdlib/number-float64-base-set-high-word": "^0.2.1",
        "@stdlib/number-float64-base-set-low-word": "^0.2.1",
        "@stdlib/number-float64-base-to-words": "^0.2.1",
        "@stdlib/number-uint32-base-to-int32": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-pow/node_modules/@stdlib/math-base-assert-is-odd": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-assert-is-odd/-/math-base-assert-is-odd-0.2.1.tgz",
      "integrity": "sha512-V4qQuCO6/AA5udqlNatMRZ8R/MgpqD8mPIkFrpSZJdpLcGYSz815uAAf3NBOuWXkE2Izw0/Tg/hTQ+YcOW2g5g==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/math-base-assert-is-even": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-powm1": {
      "version": "0.3.1",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-powm1/-/math-base-special-powm1-0.3.1.tgz",
      "integrity": "sha512-Pz7e2JlZH9EktJCDuyFPoT9IxMUSiZiJquyh2xB92NQQi9CAIdyaPUryNo36LxG65bne5GZF47MeiWCE8oWgiA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/math-base-assert-is-infinite": "^0.2.2",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-napi-binary": "^0.3.0",
        "@stdlib/math-base-special-abs": "^0.2.2",
        "@stdlib/math-base-special-expm1": "^0.2.3",
        "@stdlib/math-base-special-fmod": "^0.1.0",
        "@stdlib/math-base-special-ln": "^0.2.4",
        "@stdlib/math-base-special-pow": "^0.3.0",
        "@stdlib/math-base-special-trunc": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-powm1/node_modules/@stdlib/math-base-special-pow": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-pow/-/math-base-special-pow-0.3.0.tgz",
      "integrity": "sha512-sMDYRUYGFyMXDHcCYy7hE07lV7jgI6rDspLMROKyESWcH4n8j54XE4/0w0i8OpdzR40H895MaPWU/tVnU1tP6w==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-exponent-bias": "^0.2.2",
        "@stdlib/constants-float64-high-word-abs-mask": "^0.2.2",
        "@stdlib/constants-float64-high-word-significand-mask": "^0.2.2",
        "@stdlib/constants-float64-ln-two": "^0.2.2",
        "@stdlib/constants-float64-ninf": "^0.2.2",
        "@stdlib/constants-float64-pinf": "^0.2.2",
        "@stdlib/math-base-assert-is-infinite": "^0.2.2",
        "@stdlib/math-base-assert-is-integer": "^0.2.5",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-assert-is-odd": "^0.3.0",
        "@stdlib/math-base-napi-binary": "^0.3.0",
        "@stdlib/math-base-special-abs": "^0.2.2",
        "@stdlib/math-base-special-copysign": "^0.2.1",
        "@stdlib/math-base-special-ldexp": "^0.2.2",
        "@stdlib/math-base-special-sqrt": "^0.2.2",
        "@stdlib/number-float64-base-get-high-word": "^0.2.2",
        "@stdlib/number-float64-base-set-high-word": "^0.2.2",
        "@stdlib/number-float64-base-set-low-word": "^0.2.2",
        "@stdlib/number-float64-base-to-words": "^0.2.2",
        "@stdlib/number-uint32-base-to-int32": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-rempio2": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-rempio2/-/math-base-special-rempio2-0.2.1.tgz",
      "integrity": "sha512-ErV5EAe3SQCSijg4Pi4Z0sRPOGrODF3jkyCeiLM+iYj2TMOwDaOWQ0xCTME0p9G45TDrbZCLM5arxN83TfzgXQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/array-base-zeros": "^0.2.1",
        "@stdlib/constants-float64-high-word-abs-mask": "^0.2.1",
        "@stdlib/constants-float64-high-word-exponent-mask": "^0.2.1",
        "@stdlib/constants-float64-high-word-significand-mask": "^0.2.1",
        "@stdlib/math-base-special-floor": "^0.2.1",
        "@stdlib/math-base-special-ldexp": "^0.2.1",
        "@stdlib/math-base-special-round": "^0.2.1",
        "@stdlib/number-float64-base-from-words": "^0.2.1",
        "@stdlib/number-float64-base-get-high-word": "^0.2.1",
        "@stdlib/number-float64-base-get-low-word": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-round": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-round/-/math-base-special-round-0.2.1.tgz",
      "integrity": "sha512-ibeKiN9z//6wS4H4uaa+vGnh/t1vJtZYXz+NqRVtwoP+nnE/mtL+fIrBlAnkIWVIH+smQPNNo8qsohjyGLBvUQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-signum": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-signum/-/math-base-special-signum-0.2.2.tgz",
      "integrity": "sha512-cszwgkfeMTnUiORRWdWv6Q/tpoXkXkMYNMoAFO5qzHTuahnDP37Lkn8fTmCEtgHEasg3Cm69xLbqP0UDuNPHyA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-napi-unary": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-sin": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-sin/-/math-base-special-sin-0.2.1.tgz",
      "integrity": "sha512-IQ6+bzfiZ6/VUn5DIe6iwCsYERE1pwtAOsAWkgNZ1Ih3FzXUxdEOyHtv1zraPrVUb8mR+V5q7OfAGy8TCTnkUg==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-high-word-abs-mask": "^0.2.1",
        "@stdlib/constants-float64-high-word-exponent-mask": "^0.2.1",
        "@stdlib/math-base-special-kernel-cos": "^0.2.1",
        "@stdlib/math-base-special-kernel-sin": "^0.2.1",
        "@stdlib/math-base-special-rempio2": "^0.2.1",
        "@stdlib/number-float64-base-get-high-word": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-sinpi": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-sinpi/-/math-base-special-sinpi-0.2.1.tgz",
      "integrity": "sha512-Q3yCp1CoD7gemIILO28bU7iBn8OFiCgXm9vP/9q0tRBxmjtiUnjqbFd+3jRXdAmiCc/B/bPjwGBtVnCnrEMY9g==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-pi": "^0.2.1",
        "@stdlib/math-base-assert-is-infinite": "^0.2.1",
        "@stdlib/math-base-assert-is-nan": "^0.2.1",
        "@stdlib/math-base-special-abs": "^0.2.1",
        "@stdlib/math-base-special-copysign": "^0.2.1",
        "@stdlib/math-base-special-cos": "^0.2.1",
        "@stdlib/math-base-special-sin": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-sqrt": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-sqrt/-/math-base-special-sqrt-0.2.2.tgz",
      "integrity": "sha512-YWxe9vVE5blDbRPDAdZfU03vfGTBHy/8pLDa/qLz7SiJj5n5sVWKObdbMR2oPHF4c6DaZh4IYkrcHFleiY8YkQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/math-base-napi-unary": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-special-trunc": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-special-trunc/-/math-base-special-trunc-0.2.2.tgz",
      "integrity": "sha512-cvizbo6oFEbdiv7BrtEMODGW+cJcBgyAIleJnIpCf75C722Y/IZgWikWhACSjv4stxGywFubx85B7uvm3vLgwA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/math-base-napi-unary": "^0.2.3",
        "@stdlib/math-base-special-ceil": "^0.2.1",
        "@stdlib/math-base-special-floor": "^0.2.3",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-tools-continued-fraction": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-tools-continued-fraction/-/math-base-tools-continued-fraction-0.2.2.tgz",
      "integrity": "sha512-5dm72lTXwSVOsBsOLF57RZqqHehRd9X3HKdQ3WhOoHx7fNc0lxJJEDjtK8gMdV3NvfoER1MBiGbs2h23oaK5qw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-has-generator-support": "^0.2.2",
        "@stdlib/constants-float32-smallest-normal": "^0.2.2",
        "@stdlib/constants-float64-eps": "^0.2.2",
        "@stdlib/math-base-special-abs": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-tools-evalpoly": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-tools-evalpoly/-/math-base-tools-evalpoly-0.2.2.tgz",
      "integrity": "sha512-vLvfkMkccXZGFiyI3GPf8Ayi6vPEZeHgENnoBDGC+eMIDIoVWmOpVWsjpUz8xtc5xGNsa1hKalSI40IrouHsYA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/function-ctor": "^0.2.1",
        "@stdlib/utils-define-nonenumerable-read-only-property": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/math-base-tools-sum-series": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/math-base-tools-sum-series/-/math-base-tools-sum-series-0.2.2.tgz",
      "integrity": "sha512-P3X+jMONClp93ucJi1Up/x26uwL0kH20CMV9bLzcQyRY8Mceh7jPZuEwzGQR0jq/tJ/4J7AnHg4kdrx4Pd+BNA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-has-generator-support": "^0.2.2",
        "@stdlib/constants-float64-eps": "^0.2.2",
        "@stdlib/math-base-special-abs": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/number-ctor": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/number-ctor/-/number-ctor-0.2.2.tgz",
      "integrity": "sha512-98pL4f1uiXVIw9uRV6t4xecMFUYRRTUoctsqDDV8MSRtKEYDzqkWCNz/auupJFJ135L1ejzkejh73fASsgcwKQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/number-float32-base-to-word": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/number-float32-base-to-word/-/number-float32-base-to-word-0.2.2.tgz",
      "integrity": "sha512-/I866ocLExPpAjgZnHAjeaBw3ZHg5tVPcRdJoTPEiBG2hwD/OonHdCsfB9lu6FxO6sbp7I9BR1JolCoEyrhmYg==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/array-float32": "^0.2.2",
        "@stdlib/array-uint32": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/number-float64-base-exponent": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/number-float64-base-exponent/-/number-float64-base-exponent-0.2.2.tgz",
      "integrity": "sha512-mYivBQKCuu54ulorf5A5rIhFaGPjGvmtkxhvK14q7gzRA80si83dk8buUsLpeeYsakg7yLn10RCVjBEP9/gm7Q==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-exponent-bias": "^0.2.2",
        "@stdlib/constants-float64-high-word-exponent-mask": "^0.2.2",
        "@stdlib/number-float64-base-get-high-word": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/number-float64-base-from-words": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/number-float64-base-from-words/-/number-float64-base-from-words-0.2.2.tgz",
      "integrity": "sha512-SzMDXSnIDZ8l3PDmtN9TPKTf0mUmh83kKCtj4FisKTcTbcmUmT/ovmrpMTiqdposymjHBieNvGiCz/K03NmlAA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/array-float64": "^0.2.1",
        "@stdlib/array-uint32": "^0.2.2",
        "@stdlib/assert-is-little-endian": "^0.2.1",
        "@stdlib/number-float64-base-to-words": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/number-float64-base-get-high-word": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/number-float64-base-get-high-word/-/number-float64-base-get-high-word-0.2.2.tgz",
      "integrity": "sha512-LMNQAHdLZepKOFMRXAXLuq30GInmEdTtR0rO7Ka4F3m7KpYvw84JMyvZByMQHBu+daR6JNr2a/o9aFjmVIe51g==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/array-float64": "^0.2.1",
        "@stdlib/array-uint32": "^0.2.2",
        "@stdlib/assert-is-little-endian": "^0.2.1",
        "@stdlib/number-float64-base-to-words": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/number-float64-base-get-low-word": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/number-float64-base-get-low-word/-/number-float64-base-get-low-word-0.2.2.tgz",
      "integrity": "sha512-VZjflvoQ9//rZwwuhl7uSLUnnscdIIYmBrHofnBHRjHwdLGUzSd9PM0iagtvI82OHw5QnydBYI4hohBeAAg+aQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/array-float64": "^0.2.1",
        "@stdlib/array-uint32": "^0.2.2",
        "@stdlib/assert-is-little-endian": "^0.2.1",
        "@stdlib/number-float64-base-to-words": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/number-float64-base-normalize": {
      "version": "0.2.3",
      "resolved": "https://registry.npmjs.org/@stdlib/number-float64-base-normalize/-/number-float64-base-normalize-0.2.3.tgz",
      "integrity": "sha512-HT+3fhYZOEg2JgHBWS/ysc9ZveQZV10weKbtxhLHOsvceQVp1GbThsLik62mU2/3f96S9MgiVfPfSDI3jnBoYw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/constants-float64-smallest-normal": "^0.2.2",
        "@stdlib/math-base-assert-is-infinite": "^0.2.2",
        "@stdlib/math-base-assert-is-nan": "^0.2.2",
        "@stdlib/math-base-special-abs": "^0.2.1",
        "@stdlib/utils-define-nonenumerable-read-only-property": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/number-float64-base-set-high-word": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/number-float64-base-set-high-word/-/number-float64-base-set-high-word-0.2.2.tgz",
      "integrity": "sha512-bLvH15GJgX5URMaOOJAQgO8/dCJPYUQoXPZH7ecSC3XnnVMfWEf43knkjEGYCnWp4nro5hPRElbtdV4mKEjpUg==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/array-float64": "^0.2.1",
        "@stdlib/array-uint32": "^0.2.2",
        "@stdlib/assert-is-little-endian": "^0.2.1",
        "@stdlib/number-float64-base-to-words": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/number-float64-base-set-low-word": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/number-float64-base-set-low-word/-/number-float64-base-set-low-word-0.2.2.tgz",
      "integrity": "sha512-E1pGjTwacJ+Tkt5rKQNdwitKnM1iDgMlulYosNdn6CtvU0Pkq359bNhscMscxehdY3MifwuJpuGzDWD2EGUXzQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/array-float64": "^0.2.1",
        "@stdlib/array-uint32": "^0.2.2",
        "@stdlib/assert-is-little-endian": "^0.2.1",
        "@stdlib/number-float64-base-to-words": "^0.2.1",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/number-float64-base-to-float32": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/number-float64-base-to-float32/-/number-float64-base-to-float32-0.2.2.tgz",
      "integrity": "sha512-T5snDkVNZY6pomrSW/qLWQfZ9JHgqCFLi8jaaarfNj2o+5NMUuvvRifLUIacTm8/uC96xB0j3+wKTh1zbIV5ig==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/array-float32": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/number-float64-base-to-words": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/number-float64-base-to-words/-/number-float64-base-to-words-0.2.2.tgz",
      "integrity": "sha512-nkFHHXoMhb3vcfl7ZvzgiNdqBdBfbKxHtgvDXRxrNQoVmyYbnjljjYD489d2/TAhe+Zvn7qph6QLgTod3zaeww==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/array-float64": "^0.2.1",
        "@stdlib/array-uint32": "^0.2.2",
        "@stdlib/assert-is-little-endian": "^0.2.1",
        "@stdlib/os-byte-order": "^0.2.1",
        "@stdlib/os-float-word-order": "^0.2.2",
        "@stdlib/utils-define-nonenumerable-read-only-property": "^0.2.2",
        "@stdlib/utils-library-manifest": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/number-uint32-base-to-int32": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/number-uint32-base-to-int32/-/number-uint32-base-to-int32-0.2.2.tgz",
      "integrity": "sha512-NPADfdHE/3VEifKDttXM24dRj5YQqxwh2wTRD8fQrpHeaWiMIUo8yDqWrrFNIdLVAcqjL2SwWpo4VJ7oKTYaIA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/object-ctor": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/object-ctor/-/object-ctor-0.2.1.tgz",
      "integrity": "sha512-HEIBBpfdQS9Nh5mmIqMk9fzedx6E0tayJrVa2FD7No86rVuq/Ikxq1QP7qNXm+i6z9iNUUS/lZq7BmJESWO/Zg==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/os-byte-order": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/os-byte-order/-/os-byte-order-0.2.2.tgz",
      "integrity": "sha512-2y6rHAvZo43YmZu9u/E/7cnqZa0hNTLoIiMpV1IxQ/7iv03xZ45Z3xyvWMk0b7bAWwWL7iUknOAAmEchK/kHBA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-is-big-endian": "^0.2.1",
        "@stdlib/assert-is-little-endian": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/os-float-word-order": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/os-float-word-order/-/os-float-word-order-0.2.2.tgz",
      "integrity": "sha512-5xpcEuxv/CudKctHS5czKdM7Bj/gC+sm/5R5bRPYyqxANM67t365j3v2v8rmmOxkEp9t0fa8Dggx8VmOkpJXaA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/os-byte-order": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/process-cwd": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/process-cwd/-/process-cwd-0.2.2.tgz",
      "integrity": "sha512-8Q/nA/ud5d5PEzzG6ZtKzcOw+RMLm5CWR8Wd+zVO5vcPj+JD7IV7M2lBhbzfUzr63Torrf/vEhT3cob8vUHV/A==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/regexp-extended-length-path": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/regexp-extended-length-path/-/regexp-extended-length-path-0.2.2.tgz",
      "integrity": "sha512-z3jqauEsaxpsQU3rj1A1QnOgu17pyW5kt+Az8QkoTk7wqNE8HhPikI6k4o7XBHV689rSFWZCl4c4W+7JAiNObQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/utils-define-nonenumerable-read-only-property": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/regexp-function-name": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/regexp-function-name/-/regexp-function-name-0.2.2.tgz",
      "integrity": "sha512-0z/KRsgHJJ3UQkmBeLH+Nin0hXIeA+Fw1T+mnG2V5CHnTA6FKlpxJxWrvwLEsRX7mR/DNtDp06zGyzMFE/4kig==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/utils-define-nonenumerable-read-only-property": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/stats-base-dists-t-quantile": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/@stdlib/stats-base-dists-t-quantile/-/stats-base-dists-t-quantile-0.2.1.tgz",
      "integrity": "sha512-59sdJjHsOMd9JlZ/Kdz4Jc/QHESejDRATw/G/zHafMrO6vIhaus9Y5O2PYUzPQx7nR6i5hsXnT8OQwqZ+RoVNQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/math-base-assert-is-nan": "^0.2.1",
        "@stdlib/math-base-special-kernel-betaincinv": "^0.1.1",
        "@stdlib/math-base-special-signum": "^0.2.1",
        "@stdlib/math-base-special-sqrt": "^0.2.1",
        "@stdlib/utils-constant-function": "^0.2.1",
        "@stdlib/utils-define-nonenumerable-read-only-property": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/string-base-format-interpolate": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/string-base-format-interpolate/-/string-base-format-interpolate-0.2.2.tgz",
      "integrity": "sha512-i9nU9rAB2+o/RR66TS9iQ8x+YzeUDL1SGiAo6GY3hP6Umz5Dx9Qp/v8T69gWVsb4a1YSclz5+YeCWaFgwvPjKA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/string-base-format-tokenize": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/string-base-format-tokenize/-/string-base-format-tokenize-0.2.2.tgz",
      "integrity": "sha512-kXq2015i+LJjqth5dN+hYnvJXBSzRm8w0ABWB5tYAsIuQTpQK+mSo2muM8JBEFEnqUHAwpUsu2qNTK/9o8lsJg==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/string-base-lowercase": {
      "version": "0.4.0",
      "resolved": "https://registry.npmjs.org/@stdlib/string-base-lowercase/-/string-base-lowercase-0.4.0.tgz",
      "integrity": "sha512-IH35Z5e4T+S3b3SfYY39mUhrD2qvJVp4VS7Rn3+jgj4+C3syocuAPsJ8C4OQXWGfblX/N9ymizbpFBCiVvMW8w==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/string-base-replace": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/string-base-replace/-/string-base-replace-0.2.2.tgz",
      "integrity": "sha512-Y4jZwRV4Uertw7AlA/lwaYl1HjTefSriN5+ztRcQQyDYmoVN3gzoVKLJ123HPiggZ89vROfC+sk/6AKvly+0CA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/string-format": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/string-format/-/string-format-0.2.2.tgz",
      "integrity": "sha512-GUa50uxgMAtoItsxTbMmwkyhIwrCxCrsjzk3nAbLnt/1Kt1EWOWMwsALqZdD6K4V/xSJ4ns6PZur3W6w+vKk9g==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/string-base-format-interpolate": "^0.2.1",
        "@stdlib/string-base-format-tokenize": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/string-replace": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/string-replace/-/string-replace-0.2.2.tgz",
      "integrity": "sha512-czNS5IU7sBuHjac45Y3VWUTsUoi82yc8JsMZrOMcjgSrEuDrVmA6sNJg7HC1DuSpdPjm/v9uUk102s1gIfk3Nw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-is-function": "^0.2.2",
        "@stdlib/assert-is-regexp": "^0.2.2",
        "@stdlib/assert-is-string": "^0.2.2",
        "@stdlib/error-tools-fmtprodmsg": "^0.2.2",
        "@stdlib/string-base-replace": "^0.2.2",
        "@stdlib/string-format": "^0.2.2",
        "@stdlib/utils-escape-regexp-string": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/symbol-ctor": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/symbol-ctor/-/symbol-ctor-0.2.2.tgz",
      "integrity": "sha512-XsmiTfHnTb9jSPf2SoK3O0wrNOXMxqzukvDvtzVur1XBKfim9+seaAS4akmV1H3+AroAXQWVtde885e1B6jz1w==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/utils-constant-function": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/utils-constant-function/-/utils-constant-function-0.2.2.tgz",
      "integrity": "sha512-ezRenGy5zU4R0JTfha/bpF8U+Hx0b52AZV++ca/pcaQVvPBRkgCsJacXX0eDbexoBB4+ZZ1vcyIi4RKJ0RRlbQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/utils-constructor-name": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/utils-constructor-name/-/utils-constructor-name-0.2.2.tgz",
      "integrity": "sha512-TBtO3MKDAf05ij5ajmyBCbpKKt0Lfahn5tu18gqds4PkFltgcw5tVZfSHY5DZ2HySJQ2GMMYjPW2Kbg6yPCSVg==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-is-buffer": "^0.2.1",
        "@stdlib/regexp-function-name": "^0.2.2",
        "@stdlib/utils-native-class": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/utils-convert-path": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/utils-convert-path/-/utils-convert-path-0.2.2.tgz",
      "integrity": "sha512-8nNuAgt23Np9NssjShUrPK42c6gRTweGuoQw+yTpTfBR9VQv8WFyt048n8gRGUlAHizrdMNpEY9VAb7IBzpVYw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-is-string": "^0.2.2",
        "@stdlib/error-tools-fmtprodmsg": "^0.2.2",
        "@stdlib/regexp-extended-length-path": "^0.2.2",
        "@stdlib/string-base-lowercase": "^0.4.0",
        "@stdlib/string-format": "^0.2.2",
        "@stdlib/string-replace": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/utils-define-nonenumerable-read-only-property": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/utils-define-nonenumerable-read-only-property/-/utils-define-nonenumerable-read-only-property-0.2.2.tgz",
      "integrity": "sha512-V3mpAesJemLYDKG376CsmoczWPE/4LKsp8xBvUxCt5CLNAx3J/1W39iZQyA5q6nY1RStGinGn1/dYZwa8ig0Uw==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/utils-define-property": "^0.2.3"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/utils-define-property": {
      "version": "0.2.4",
      "resolved": "https://registry.npmjs.org/@stdlib/utils-define-property/-/utils-define-property-0.2.4.tgz",
      "integrity": "sha512-XlMdz7xwuw/sqXc9LbsV8XunCzZXjbZPC+OAdf4t4PBw4ZRwGzlTI6WED+f4PYR5Tp9F1cHgLPyMYCIBfA2zRg==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/error-tools-fmtprodmsg": "^0.2.1",
        "@stdlib/string-format": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/utils-escape-regexp-string": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/utils-escape-regexp-string/-/utils-escape-regexp-string-0.2.2.tgz",
      "integrity": "sha512-areCibzgpmvm6pGKBg+mXkSDJW4NxtS5jcAT7RtunGMdAYhA/I5whISMPaeJkIT2XhjjFkjKBaIs5pF6aPr4fQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-is-string": "^0.2.1",
        "@stdlib/error-tools-fmtprodmsg": "^0.2.2",
        "@stdlib/string-format": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/utils-eval": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/utils-eval/-/utils-eval-0.2.2.tgz",
      "integrity": "sha512-MaFpWZh3fGcTjUeozju5faXqH8w4MRVfpO/M5pon3osTM0by8zrKiI5D9oWqNVygb9JBd+etE+4tj2L1nr5j2A==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/utils-get-prototype-of": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/utils-get-prototype-of/-/utils-get-prototype-of-0.2.2.tgz",
      "integrity": "sha512-eDb1BAvt7GW/jduBkfuQrUsA9p09mV8RW20g0DWPaxci6ORYg/UB0tdbAA23aZz2QUoxdYY5s/UJxlq/GHwoKQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-is-function": "^0.2.1",
        "@stdlib/object-ctor": "^0.2.1",
        "@stdlib/utils-native-class": "^0.2.1"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/utils-global": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/utils-global/-/utils-global-0.2.2.tgz",
      "integrity": "sha512-A4E8VFHn+1bpfJ4PA8H2b62CMQpjv2A+H3QDEBrouLFWne0wrx0TNq8vH6VYHxx9ZRxhgWQjfHiSAxtUJobrbQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-is-boolean": "^0.2.1",
        "@stdlib/error-tools-fmtprodmsg": "^0.2.2",
        "@stdlib/string-format": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/utils-library-manifest": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/utils-library-manifest/-/utils-library-manifest-0.2.2.tgz",
      "integrity": "sha512-YqzVLuBsB4wTqzdUtRArAjBJoT3x61iop2jFChXexhl6ejV3vDpHcukEEkqIOcJKut+1cG5TLJdexgHNt1C0NA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/fs-resolve-parent-path": "^0.2.1",
        "@stdlib/utils-convert-path": "^0.2.1",
        "debug": "^2.6.9",
        "resolve": "^1.1.7"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/utils-native-class": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/utils-native-class/-/utils-native-class-0.2.2.tgz",
      "integrity": "sha512-cSn/FozbEpfR/FlJAoceQtZ8yUJFhZ8RFkbEsxW/7+H4o09yln3lBS0HSfUJISYNtpTNN/2/Fup88vmvwspvwA==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/assert-has-own-property": "^0.2.1",
        "@stdlib/assert-has-tostringtag-support": "^0.2.2",
        "@stdlib/symbol-ctor": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@stdlib/utils-type-of": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/@stdlib/utils-type-of/-/utils-type-of-0.2.2.tgz",
      "integrity": "sha512-RLGFxPNgY9AtVVrFGdKO6Y3pOd/Ov2WA4O2/czZN/AbgYzbPdoF0KkfvHRIney6k+TtvoyYB8YqZXJ4G88f9BQ==",
      "os": [
        "aix",
        "darwin",
        "freebsd",
        "linux",
        "macos",
        "openbsd",
        "sunos",
        "win32",
        "windows"
      ],
      "dependencies": {
        "@stdlib/utils-constructor-name": "^0.2.1",
        "@stdlib/utils-global": "^0.2.2"
      },
      "engines": {
        "node": ">=0.10.0",
        "npm": ">2.7.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/stdlib"
      }
    },
    "node_modules/@tsconfig/node10": {
      "version": "1.0.11",
      "resolved": "https://registry.npmjs.org/@tsconfig/node10/-/node10-1.0.11.tgz",
      "integrity": "sha512-DcRjDCujK/kCk/cUe8Xz8ZSpm8mS3mNNpta+jGCA6USEDfktlNvm1+IuZ9eTcDbNk41BHwpHHeW+N1lKCz4zOw==",
      "dev": true
    },
    "node_modules/@tsconfig/node12": {
      "version": "1.0.11",
      "resolved": "https://registry.npmjs.org/@tsconfig/node12/-/node12-1.0.11.tgz",
      "integrity": "sha512-cqefuRsh12pWyGsIoBKJA9luFu3mRxCA+ORZvA4ktLSzIuCUtWVxGIuXigEwO5/ywWFMZ2QEGKWvkZG1zDMTag==",
      "dev": true
    },
    "node_modules/@tsconfig/node14": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/@tsconfig/node14/-/node14-1.0.3.tgz",
      "integrity": "sha512-ysT8mhdixWK6Hw3i1V2AeRqZ5WfXg1G43mqoYlM2nc6388Fq5jcXyr5mRsqViLx/GJYdoL0bfXD8nmF+Zn/Iow==",
      "dev": true
    },
    "node_modules/@tsconfig/node16": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/@tsconfig/node16/-/node16-1.0.4.tgz",
      "integrity": "sha512-vxhUy4J8lyeyinH7Azl1pdd43GJhZH/tP2weN8TntQblOY+A0XbT8DJk1/oCPuOOyg/Ja757rG0CgHcWC8OfMA==",
      "dev": true
    },
    "node_modules/@turf/boolean-clockwise": {
      "version": "6.5.0",
      "resolved": "https://registry.npmjs.org/@turf/boolean-clockwise/-/boolean-clockwise-6.5.0.tgz",
      "integrity": "sha512-45+C7LC5RMbRWrxh3Z0Eihsc8db1VGBO5d9BLTOAwU4jR6SgsunTfRWR16X7JUwIDYlCVEmnjcXJNi/kIU3VIw==",
      "dependencies": {
        "@turf/helpers": "^6.5.0",
        "@turf/invariant": "^6.5.0"
      },
      "funding": {
        "url": "https://opencollective.com/turf"
      }
    },
    "node_modules/@turf/clone": {
      "version": "6.5.0",
      "resolved": "https://registry.npmjs.org/@turf/clone/-/clone-6.5.0.tgz",
      "integrity": "sha512-mzVtTFj/QycXOn6ig+annKrM6ZlimreKYz6f/GSERytOpgzodbQyOgkfwru100O1KQhhjSudKK4DsQ0oyi9cTw==",
      "dependencies": {
        "@turf/helpers": "^6.5.0"
      },
      "funding": {
        "url": "https://opencollective.com/turf"
      }
    },
    "node_modules/@turf/flatten": {
      "version": "6.5.0",
      "resolved": "https://registry.npmjs.org/@turf/flatten/-/flatten-6.5.0.tgz",
      "integrity": "sha512-IBZVwoNLVNT6U/bcUUllubgElzpMsNoCw8tLqBw6dfYg9ObGmpEjf9BIYLr7a2Yn5ZR4l7YIj2T7kD5uJjZADQ==",
      "dependencies": {
        "@turf/helpers": "^6.5.0",
        "@turf/meta": "^6.5.0"
      },
      "funding": {
        "url": "https://opencollective.com/turf"
      }
    },
    "node_modules/@turf/helpers": {
      "version": "6.5.0",
      "resolved": "https://registry.npmjs.org/@turf/helpers/-/helpers-6.5.0.tgz",
      "integrity": "sha512-VbI1dV5bLFzohYYdgqwikdMVpe7pJ9X3E+dlr425wa2/sMJqYDhTO++ec38/pcPvPE6oD9WEEeU3Xu3gza+VPw==",
      "funding": {
        "url": "https://opencollective.com/turf"
      }
    },
    "node_modules/@turf/invariant": {
      "version": "6.5.0",
      "resolved": "https://registry.npmjs.org/@turf/invariant/-/invariant-6.5.0.tgz",
      "integrity": "sha512-Wv8PRNCtPD31UVbdJE/KVAWKe7l6US+lJItRR/HOEW3eh+U/JwRCSUl/KZ7bmjM/C+zLNoreM2TU6OoLACs4eg==",
      "dependencies": {
        "@turf/helpers": "^6.5.0"
      },
      "funding": {
        "url": "https://opencollective.com/turf"
      }
    },
    "node_modules/@turf/meta": {
      "version": "6.5.0",
      "resolved": "https://registry.npmjs.org/@turf/meta/-/meta-6.5.0.tgz",
      "integrity": "sha512-RrArvtsV0vdsCBegoBtOalgdSOfkBrTJ07VkpiCnq/491W67hnMWmDu7e6Ztw0C3WldRYTXkg3SumfdzZxLBHA==",
      "dependencies": {
        "@turf/helpers": "^6.5.0"
      },
      "funding": {
        "url": "https://opencollective.com/turf"
      }
    },
    "node_modules/@turf/rewind": {
      "version": "6.5.0",
      "resolved": "https://registry.npmjs.org/@turf/rewind/-/rewind-6.5.0.tgz",
      "integrity": "sha512-IoUAMcHWotBWYwSYuYypw/LlqZmO+wcBpn8ysrBNbazkFNkLf3btSDZMkKJO/bvOzl55imr/Xj4fi3DdsLsbzQ==",
      "dependencies": {
        "@turf/boolean-clockwise": "^6.5.0",
        "@turf/clone": "^6.5.0",
        "@turf/helpers": "^6.5.0",
        "@turf/invariant": "^6.5.0",
        "@turf/meta": "^6.5.0"
      },
      "funding": {
        "url": "https://opencollective.com/turf"
      }
    },
    "node_modules/@types/node": {
      "version": "22.13.17",
      "resolved": "https://registry.npmjs.org/@types/node/-/node-22.13.17.tgz",
      "integrity": "sha512-nAJuQXoyPj04uLgu+obZcSmsfOenUg6DxPKogeUy6yNCFwWaj5sBF8/G/pNo8EtBJjAfSVgfIlugR/BCOleO+g==",
      "dev": true,
      "dependencies": {
        "undici-types": "~6.20.0"
      }
    },
    "node_modules/@visactor/calculator": {
      "version": "2.0.5",
      "resolved": "https://bnpm.byted.org/@visactor/calculator/-/calculator-2.0.5.tgz",
      "integrity": "sha512-/NBDB/wBQLeQuSspDBuiEAbbyfJS/xPX6mubVsLGhfy65UwUBojAQgmX25FcRJnUsRXooK5heshni19DBBf8xA==",
      "dependencies": {
        "@visactor/vutils": "~0.19.3",
        "node-sql-parser": "~4.17.0",
        "ts-pattern": "~4.1.4"
      }
    },
    "node_modules/@visactor/chart-advisor": {
      "version": "2.0.5",
      "resolved": "https://bnpm.byted.org/@visactor/chart-advisor/-/chart-advisor-2.0.5.tgz",
      "integrity": "sha512-pvHceRlworB7kDSmbWXUtherLLXh5nMj0aEGuxtzKQyHmeO0sjuu9gGXBFIgscGliSZM4tmeNrFU9eBLGJ8dxw==",
      "dependencies": {
        "@visactor/vutils": "~0.19.3"
      }
    },
    "node_modules/@visactor/vchart": {
      "version": "1.13.8",
      "resolved": "https://registry.npmjs.org/@visactor/vchart/-/vchart-1.13.8.tgz",
      "integrity": "sha512-g8GacKxDvxUiuT4kW83u5vrAoAvpJ0+yca4IUYvdSTxdYXzipJEgiNmSnwd46GP8eBKJj36ZmqzEhLVzPJ+/Pw==",
      "dependencies": {
        "@visactor/vdataset": "~0.19.4",
        "@visactor/vgrammar-core": "0.16.3",
        "@visactor/vgrammar-hierarchy": "0.16.3",
        "@visactor/vgrammar-projection": "0.16.3",
        "@visactor/vgrammar-sankey": "0.16.3",
        "@visactor/vgrammar-util": "0.16.3",
        "@visactor/vgrammar-venn": "0.16.3",
        "@visactor/vgrammar-wordcloud": "0.16.3",
        "@visactor/vgrammar-wordcloud-shape": "0.16.3",
        "@visactor/vrender-components": "0.22.6",
        "@visactor/vrender-core": "0.22.6",
        "@visactor/vrender-kits": "0.22.6",
        "@visactor/vscale": "~0.19.4",
        "@visactor/vutils": "~0.19.4",
        "@visactor/vutils-extension": "1.13.8"
      }
    },
    "node_modules/@visactor/vchart-theme": {
      "version": "1.12.2",
      "resolved": "https://registry.npmjs.org/@visactor/vchart-theme/-/vchart-theme-1.12.2.tgz",
      "integrity": "sha512-r298TUdK+CKbHGVYWgQnNSEB5uqpFvF2/aMNZ/2POQnd2CovAPJOx2nTE6hAcOn8rra2FwJ2xF8AyP1O5OhrTw==",
      "peerDependencies": {
        "@visactor/vchart": ">=1.10.4"
      }
    },
    "node_modules/@visactor/vdataset": {
      "version": "0.19.4",
      "resolved": "https://registry.npmjs.org/@visactor/vdataset/-/vdataset-0.19.4.tgz",
      "integrity": "sha512-xxglcFtvho5jWiQPKwTolKXbNOG8f77CrK7TJhfiqNlzoe27qO8B+A6lUKlLMt1kZaCH7ZNrFFkHyPjnnZ/gng==",
      "dependencies": {
        "@turf/flatten": "^6.5.0",
        "@turf/helpers": "^6.5.0",
        "@turf/rewind": "^6.5.0",
        "@visactor/vutils": "0.19.4",
        "d3-dsv": "^2.0.0",
        "d3-geo": "^1.12.1",
        "d3-hexbin": "^0.2.2",
        "d3-hierarchy": "^3.1.1",
        "eventemitter3": "^4.0.7",
        "geobuf": "^3.0.1",
        "geojson-dissolve": "^3.1.0",
        "path-browserify": "^1.0.1",
        "pbf": "^3.2.1",
        "point-at-length": "^1.1.0",
        "simple-statistics": "^7.7.3",
        "simplify-geojson": "^1.0.4",
        "topojson-client": "^3.1.0"
      }
    },
    "node_modules/@visactor/vgrammar-coordinate": {
      "version": "0.16.3",
      "resolved": "https://registry.npmjs.org/@visactor/vgrammar-coordinate/-/vgrammar-coordinate-0.16.3.tgz",
      "integrity": "sha512-tfDSi3WgY/GWDvbf67eus4a7jR74y7OMod3JrTqyDVzSNZUOgUtS3ieEM71f9yipxjY8gxo53GPDpH/advxUZw==",
      "dependencies": {
        "@visactor/vgrammar-util": "0.16.3",
        "@visactor/vutils": "~0.19.4"
      }
    },
    "node_modules/@visactor/vgrammar-core": {
      "version": "0.16.3",
      "resolved": "https://registry.npmjs.org/@visactor/vgrammar-core/-/vgrammar-core-0.16.3.tgz",
      "integrity": "sha512-cd7hmh9JobbCDUJPOshmQB5V0KVM0GLTPBe/ZySJDi1cUSWpukAgRrLozEk/M5XgDbVIT+4pjqe6siacCad8dg==",
      "dependencies": {
        "@visactor/vdataset": "~0.19.4",
        "@visactor/vgrammar-coordinate": "0.16.3",
        "@visactor/vgrammar-util": "0.16.3",
        "@visactor/vrender-components": "0.22.6",
        "@visactor/vrender-core": "0.22.6",
        "@visactor/vrender-kits": "0.22.6",
        "@visactor/vscale": "~0.19.4",
        "@visactor/vutils": "~0.19.4"
      }
    },
    "node_modules/@visactor/vgrammar-hierarchy": {
      "version": "0.16.3",
      "resolved": "https://registry.npmjs.org/@visactor/vgrammar-hierarchy/-/vgrammar-hierarchy-0.16.3.tgz",
      "integrity": "sha512-qnfSWRt1PErkVPTtet8DVc4MY+WwmgJoNNW2FALFht1qUfPdglTqT96drPbkurwiZMzSk+Xfr7+IPUA8ZQwWag==",
      "dependencies": {
        "@visactor/vgrammar-core": "0.16.3",
        "@visactor/vgrammar-util": "0.16.3",
        "@visactor/vrender-core": "0.22.6",
        "@visactor/vrender-kits": "0.22.6",
        "@visactor/vutils": "~0.19.4"
      }
    },
    "node_modules/@visactor/vgrammar-projection": {
      "version": "0.16.3",
      "resolved": "https://registry.npmjs.org/@visactor/vgrammar-projection/-/vgrammar-projection-0.16.3.tgz",
      "integrity": "sha512-c+MJ3qgtsNQHwZCDBVT7fNahNxe0g827IiytQWvrtMxavLIrtJqeul5H+6BYrGvYk8d81ByxNZdoVNn/mfNtDw==",
      "dependencies": {
        "@visactor/vgrammar-core": "0.16.3",
        "@visactor/vgrammar-util": "0.16.3",
        "@visactor/vutils": "~0.19.4",
        "d3-geo": "^1.12.1"
      }
    },
    "node_modules/@visactor/vgrammar-sankey": {
      "version": "0.16.3",
      "resolved": "https://registry.npmjs.org/@visactor/vgrammar-sankey/-/vgrammar-sankey-0.16.3.tgz",
      "integrity": "sha512-7j0xx77Yn2KzY4EcZ27qFF6R1KTcmy3BtQQewOHA1uoUX8ZRsfe57eziYRiBhyVrzdFWoa0IJqzH7Yk/zITvuQ==",
      "dependencies": {
        "@visactor/vgrammar-core": "0.16.3",
        "@visactor/vgrammar-util": "0.16.3",
        "@visactor/vrender-core": "0.22.6",
        "@visactor/vrender-kits": "0.22.6",
        "@visactor/vutils": "~0.19.4"
      }
    },
    "node_modules/@visactor/vgrammar-util": {
      "version": "0.16.3",
      "resolved": "https://registry.npmjs.org/@visactor/vgrammar-util/-/vgrammar-util-0.16.3.tgz",
      "integrity": "sha512-aF9MqjTR7YvBAVDtp1A/CDVcXFGlO+TxkHVPEQVrn7cVu2DGRXCZnu/iQ+AUhttVYaWlSRflZj4cnQrKS4zy4g==",
      "dependencies": {
        "@visactor/vrender-core": "0.22.6",
        "@visactor/vutils": "~0.19.4"
      }
    },
    "node_modules/@visactor/vgrammar-venn": {
      "version": "0.16.3",
      "resolved": "https://registry.npmjs.org/@visactor/vgrammar-venn/-/vgrammar-venn-0.16.3.tgz",
      "integrity": "sha512-M6mtCrpOcPrD6nkQFZ3Fl0Z2zPaKFTyRIPeO235vDwB/ZzefN5BObh85UGsv0swK46L5yu3daBxW0VtrGMBZRA==",
      "dependencies": {
        "@visactor/vgrammar-core": "0.16.3",
        "@visactor/vgrammar-util": "0.16.3",
        "@visactor/vrender-core": "0.22.6",
        "@visactor/vrender-kits": "0.22.6",
        "@visactor/vutils": "~0.19.4"
      }
    },
    "node_modules/@visactor/vgrammar-wordcloud": {
      "version": "0.16.3",
      "resolved": "https://registry.npmjs.org/@visactor/vgrammar-wordcloud/-/vgrammar-wordcloud-0.16.3.tgz",
      "integrity": "sha512-uIHUJ3CGir+IjDjv4SpJR5SZvWSIYU2VoBdoCvFdhP9j8t15wadGYfe0/br9d6xOM3laiSCFYvPdhy0Ke5sP4w==",
      "dependencies": {
        "@visactor/vgrammar-core": "0.16.3",
        "@visactor/vgrammar-util": "0.16.3",
        "@visactor/vrender-core": "0.22.6",
        "@visactor/vrender-kits": "0.22.6",
        "@visactor/vutils": "~0.19.4"
      }
    },
    "node_modules/@visactor/vgrammar-wordcloud-shape": {
      "version": "0.16.3",
      "resolved": "https://registry.npmjs.org/@visactor/vgrammar-wordcloud-shape/-/vgrammar-wordcloud-shape-0.16.3.tgz",
      "integrity": "sha512-ZWRHbec4WM2W3v2t57gRaX1IUGy+nDRjumcctgzSvmCpmR3nORgLKmMhxXYEA0VwcpY+umM0lVcd42iqPH8c7g==",
      "dependencies": {
        "@visactor/vgrammar-core": "0.16.3",
        "@visactor/vgrammar-util": "0.16.3",
        "@visactor/vrender-core": "0.22.6",
        "@visactor/vrender-kits": "0.22.6",
        "@visactor/vscale": "~0.19.4",
        "@visactor/vutils": "~0.19.4"
      }
    },
    "node_modules/@visactor/vmind": {
      "version": "2.0.5",
      "resolved": "https://bnpm.byted.org/@visactor/vmind/-/vmind-2.0.5.tgz",
      "integrity": "sha512-QztQaeSkdeRZYOUlB4qaBpx3/swyO3JzFH8eYvSgvptS/rf8aQDZiufAUasafDLkcME5N6RpBGkcGYIDkmt74Q==",
      "dependencies": {
        "@stdlib/stats-base-dists-t-quantile": "0.2.1",
        "@visactor/calculator": "2.0.5",
        "@visactor/chart-advisor": "2.0.5",
        "@visactor/vchart-theme": "^1.11.2",
        "@visactor/vdataset": "~0.19.3",
        "@visactor/vutils": "~0.19.3",
        "alasql": "~4.3.2",
        "array-normalize": "~2.0.0",
        "axios": "^1.4.0",
        "bayesian-changepoint": "~1.0.1",
        "dayjs": "~1.11.10",
        "density-clustering": "~1.3.0",
        "euclidean-distance": "~1.0.0",
        "js-yaml": "~4.1.0",
        "json5": "~2.2.3",
        "jsonrepair": "~3.8.1",
        "jstat": "~1.9.6",
        "string-similarity-js": "~2.1.4"
      }
    },
    "node_modules/@visactor/vrender-components": {
      "version": "0.22.6",
      "resolved": "https://registry.npmjs.org/@visactor/vrender-components/-/vrender-components-0.22.6.tgz",
      "integrity": "sha512-YHLjA2GzP5LQxAAgzo2iniBxDldy9GtEzjm/sCXrrOGzzwMFlyhAeXCbUVEIMhTTfpRdK5LocAP1PSJsv4BObA==",
      "dependencies": {
        "@visactor/vrender-core": "0.22.6",
        "@visactor/vrender-kits": "0.22.6",
        "@visactor/vscale": "~0.19.4",
        "@visactor/vutils": "~0.19.4"
      }
    },
    "node_modules/@visactor/vrender-core": {
      "version": "0.22.6",
      "resolved": "https://registry.npmjs.org/@visactor/vrender-core/-/vrender-core-0.22.6.tgz",
      "integrity": "sha512-R/MPjAuF9vT5atn7tAqhA5K1FMqYzv2SOhREsJpgP6QbJSnGR2uMTrNENRFvrM81ikR6yeh7WeTx6Fh2av+M4A==",
      "dependencies": {
        "@visactor/vutils": "~0.19.4",
        "color-convert": "2.0.1"
      }
    },
    "node_modules/@visactor/vrender-kits": {
      "version": "0.22.6",
      "resolved": "https://registry.npmjs.org/@visactor/vrender-kits/-/vrender-kits-0.22.6.tgz",
      "integrity": "sha512-0yRvhMhnT3JeFKCOi8riubkuKjNMIlzcW1FQV+kIyOGGV6nCSjvFL4+XDuEGalHlHt76BSlM1/cmxnmRNTHCRQ==",
      "dependencies": {
        "@resvg/resvg-js": "2.4.1",
        "@visactor/vrender-core": "0.22.6",
        "@visactor/vutils": "~0.19.4",
        "gifuct-js": "2.1.2",
        "lottie-web": "^5.12.2",
        "roughjs": "4.5.2"
      }
    },
    "node_modules/@visactor/vscale": {
      "version": "0.19.4",
      "resolved": "https://registry.npmjs.org/@visactor/vscale/-/vscale-0.19.4.tgz",
      "integrity": "sha512-kp69hPMof3GBKRuUiXSR9+9K+Z8ZXsTlOAwcnknXmiiZDhdcDkPlv27/d+Xx1Wi/iqw+BS2S7YIjHmfzdiVQ/Q==",
      "dependencies": {
        "@visactor/vutils": "0.19.4"
      }
    },
    "node_modules/@visactor/vutils": {
      "version": "0.19.4",
      "resolved": "https://registry.npmjs.org/@visactor/vutils/-/vutils-0.19.4.tgz",
      "integrity": "sha512-kLbcsTe1/3HSSvEJvJikzGD0plY0gdHbpxt98oo7W6OrianfYd97nm/w7rFXcq/S49e6C5d1SdU4MZk/PYxhEQ==",
      "dependencies": {
        "@turf/helpers": "^6.5.0",
        "@turf/invariant": "^6.5.0",
        "eventemitter3": "^4.0.7"
      }
    },
    "node_modules/@visactor/vutils-extension": {
      "version": "1.13.8",
      "resolved": "https://registry.npmjs.org/@visactor/vutils-extension/-/vutils-extension-1.13.8.tgz",
      "integrity": "sha512-mOtUJjUEthQTHyYnynWJs8wbbW+UoW0z18lH++TqGoDbsJLcr4Mlpxhe8IDP/bda7kRVTI/FHbzVHhKWKLBvxw==",
      "dependencies": {
        "@visactor/vdataset": "~0.19.4",
        "@visactor/vutils": "~0.19.4"
      }
    },
    "node_modules/abbrev": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/abbrev/-/abbrev-1.1.1.tgz",
      "integrity": "sha512-nne9/IiQ/hzIhY6pdDnbBtz7DjPTKrY00P/zvPSm5pOFkl6xuGrGnXn/VtTNNfNtAfZ9/1RtehkszU9qcTii0Q=="
    },
    "node_modules/abs-svg-path": {
      "version": "0.1.1",
      "resolved": "https://registry.npmjs.org/abs-svg-path/-/abs-svg-path-0.1.1.tgz",
      "integrity": "sha512-d8XPSGjfyzlXC3Xx891DJRyZfqk5JU0BJrDQcsWomFIV1/BIzPW5HDH5iDdWpqWaav0YVIEzT1RHTwWr0FFshA=="
    },
    "node_modules/acorn": {
      "version": "8.14.1",
      "resolved": "https://registry.npmjs.org/acorn/-/acorn-8.14.1.tgz",
      "integrity": "sha512-OvQ/2pUDKmgfCg++xsTX1wGxfTaszcHVcTctW4UJB4hibJx2HXxxO5UmVgyjMa+ZDsiaf5wWLXYpRWMmBI0QHg==",
      "dev": true,
      "bin": {
        "acorn": "bin/acorn"
      },
      "engines": {
        "node": ">=0.4.0"
      }
    },
    "node_modules/acorn-walk": {
      "version": "8.3.4",
      "resolved": "https://registry.npmjs.org/acorn-walk/-/acorn-walk-8.3.4.tgz",
      "integrity": "sha512-ueEepnujpqee2o5aIYnvHU6C0A42MNdsIDeqy5BydrkuC5R1ZuUFnm27EeFJGoEHJQgn3uleRvmTXaJgfXbt4g==",
      "dev": true,
      "dependencies": {
        "acorn": "^8.11.0"
      },
      "engines": {
        "node": ">=0.4.0"
      }
    },
    "node_modules/agent-base": {
      "version": "6.0.2",
      "resolved": "https://registry.npmjs.org/agent-base/-/agent-base-6.0.2.tgz",
      "integrity": "sha512-RZNwNclF7+MS/8bDg70amg32dyeZGZxiDuQmZxKLAlQjr3jGyLx+4Kkk58UO7D2QdgFIQCovuSuZESne6RG6XQ==",
      "dependencies": {
        "debug": "4"
      },
      "engines": {
        "node": ">= 6.0.0"
      }
    },
    "node_modules/agent-base/node_modules/debug": {
      "version": "4.4.0",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.4.0.tgz",
      "integrity": "sha512-6WTZ/IxCY/T6BALoZHaE4ctp9xm+Z5kY/pzYaCHRFeyVhojxlrm+46y68HA6hr0TcwEssoxNiDEUJQjfPZ/RYA==",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/agent-base/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA=="
    },
    "node_modules/alasql": {
      "version": "4.3.3",
      "resolved": "https://registry.npmjs.org/alasql/-/alasql-4.3.3.tgz",
      "integrity": "sha512-IP64TOG+zBTPA41OB2NJVkM3urEIhvZtYwtPFC/1QSH7nCzwShIwWfxwyOhTK7yzF/ZaNGEpc3Eexyzb2nUbFg==",
      "dependencies": {
        "cross-fetch": "4",
        "yargs": "16"
      },
      "bin": {
        "alasql": "bin/alasql-cli.js"
      },
      "engines": {
        "node": ">=15"
      }
    },
    "node_modules/ansi-regex": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-5.0.1.tgz",
      "integrity": "sha512-quJQXlTSUGL2LH9SUXo8VwsY4soanhgo6LNSm84E1LBcE8s3O0wpdiRzyR9z/ZZJMlMWv37qOOb9pdJlMUEKFQ==",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/ansi-styles": {
      "version": "4.3.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-4.3.0.tgz",
      "integrity": "sha512-zbB9rCJAT1rbjiVDb2hqKFHNYLxgtk8NURxZ3IZwD3F6NtxbXZQCnnSi1Lkx+IDohdPlFp222wVALIheZJQSEg==",
      "dependencies": {
        "color-convert": "^2.0.1"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/aproba": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/aproba/-/aproba-2.0.0.tgz",
      "integrity": "sha512-lYe4Gx7QT+MKGbDsA+Z+he/Wtef0BiwDOlK/XkBrdfsh9J/jPPXbX0tE9x9cl27Tmu5gg3QUbUrQYa/y+KOHPQ=="
    },
    "node_modules/are-we-there-yet": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/are-we-there-yet/-/are-we-there-yet-2.0.0.tgz",
      "integrity": "sha512-Ci/qENmwHnsYo9xKIcUJN5LeDKdJ6R1Z1j9V/J5wyq8nh/mYPEpIKJbBZXtZjG04HiK7zV/p6Vs9952MrMeUIw==",
      "deprecated": "This package is no longer supported.",
      "dependencies": {
        "delegates": "^1.0.0",
        "readable-stream": "^3.6.0"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/arg": {
      "version": "4.1.3",
      "resolved": "https://registry.npmjs.org/arg/-/arg-4.1.3.tgz",
      "integrity": "sha512-58S9QDqG0Xx27YwPSt9fJxivjYl432YCwfDMfZ+71RAqUrZef7LrKQZ3LHLOwCS4FLNBplP533Zx895SeOCHvA==",
      "dev": true
    },
    "node_modules/argparse": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/argparse/-/argparse-2.0.1.tgz",
      "integrity": "sha512-8+9WqebbFzpX9OR+Wa6O29asIogeRMzcGtAINdpMHHyAg10f05aSFVBbcEqGf/PXw1EjAZ+q2/bEBg3DvurK3Q=="
    },
    "node_modules/array-bounds": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/array-bounds/-/array-bounds-1.0.1.tgz",
      "integrity": "sha512-8wdW3ZGk6UjMPJx/glyEt0sLzzwAE1bhToPsO1W2pbpR2gULyxe3BjSiuJFheP50T/GgODVPz2fuMUmIywt8cQ=="
    },
    "node_modules/array-normalize": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/array-normalize/-/array-normalize-2.0.0.tgz",
      "integrity": "sha512-WofPolGg9OqpmfYh2qqOJ0yeJ9Idjn+EcQ+Nyy3eQbqtuz0MRyqTEHB0PH/Ypp2PpsOAfjsqTMzu1fHOaPzO1Q==",
      "dependencies": {
        "array-bounds": "^1.0.0"
      }
    },
    "node_modules/array-source": {
      "version": "0.0.4",
      "resolved": "https://registry.npmjs.org/array-source/-/array-source-0.0.4.tgz",
      "integrity": "sha512-frNdc+zBn80vipY+GdcJkLEbMWj3xmzArYApmUGxoiV8uAu/ygcs9icPdsGdA26h0MkHUMW6EN2piIvVx+M5Mw=="
    },
    "node_modules/asynckit": {
      "version": "0.4.0",
      "resolved": "https://registry.npmjs.org/asynckit/-/asynckit-0.4.0.tgz",
      "integrity": "sha512-Oei9OH4tRh0YqU3GxhX79dM/mwVgvbZJaSNaRk+bshkj0S5cfHcgYakreBjrHwatXKbz+IoIdYLxrKim2MjW0Q=="
    },
    "node_modules/axios": {
      "version": "1.8.4",
      "resolved": "https://registry.npmjs.org/axios/-/axios-1.8.4.tgz",
      "integrity": "sha512-eBSYY4Y68NNlHbHBMdeDmKNtDgXWhQsJcGqzO3iLUM0GraQFSS9cVgPX5I9b3lbdFKyYoAEGAZF1DwhTaljNAw==",
      "dependencies": {
        "follow-redirects": "^1.15.6",
        "form-data": "^4.0.0",
        "proxy-from-env": "^1.1.0"
      }
    },
    "node_modules/balanced-match": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/balanced-match/-/balanced-match-1.0.2.tgz",
      "integrity": "sha512-3oSeUO0TMV67hN1AmbXsK4yaqU7tjiHlbxRDZOpH0KW9+CeX4bRAaX0Anxt0tx2MrpRpWwQaPwIlISEJhYU5Pw=="
    },
    "node_modules/bayesian-changepoint": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/bayesian-changepoint/-/bayesian-changepoint-1.0.1.tgz",
      "integrity": "sha512-OhSHWfGiEcBtI46b5guJGmj6pJEjvyaXsRPCAQy5MPoVaDZ38poXmzVZLSIuw6VLQmZs58+uf5F9iFA4NVmTTA=="
    },
    "node_modules/big-integer": {
      "version": "1.6.52",
      "resolved": "https://bnpm.byted.org/big-integer/-/big-integer-1.6.52.tgz",
      "integrity": "sha512-QxD8cf2eVqJOOz63z6JIN9BzvVs/dlySa5HGSBH5xtR8dPteIRQnBxxKqkNTiT6jbDTF6jAfrd4oMcND9RGbQg==",
      "engines": {
        "node": ">=0.6"
      }
    },
    "node_modules/brace-expansion": {
      "version": "1.1.11",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.11.tgz",
      "integrity": "sha512-iCuPHDFgrHX7H2vEI/5xpz07zSHB00TpugqhmYtVmMO6518mCuRMoOYFldEBl0g187ufozdaHgWKcYFb61qGiA==",
      "dependencies": {
        "balanced-match": "^1.0.0",
        "concat-map": "0.0.1"
      }
    },
    "node_modules/buffer-from": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/buffer-from/-/buffer-from-1.1.2.tgz",
      "integrity": "sha512-E+XQCRwSbaaiChtv6k6Dwgc+bx+Bs6vuKJHHl5kox/BaKbhiXzqQOwK4cO22yElGp2OCmjwVhT3HmxgyPGnJfQ=="
    },
    "node_modules/call-bind-apply-helpers": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/call-bind-apply-helpers/-/call-bind-apply-helpers-1.0.2.tgz",
      "integrity": "sha512-Sp1ablJ0ivDkSzjcaJdxEunN5/XvksFJ2sMBFfq6x0ryhQV/2b/KwFe21cMpmHtPOSij8K99/wSfoEuTObmuMQ==",
      "dependencies": {
        "es-errors": "^1.3.0",
        "function-bind": "^1.1.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/canvas": {
      "version": "2.11.2",
      "resolved": "https://registry.npmjs.org/canvas/-/canvas-2.11.2.tgz",
      "integrity": "sha512-ItanGBMrmRV7Py2Z+Xhs7cT+FNt5K0vPL4p9EZ/UX/Mu7hFbkxSjKF2KVtPwX7UYWp7dRKnrTvReflgrItJbdw==",
      "hasInstallScript": true,
      "dependencies": {
        "@mapbox/node-pre-gyp": "^1.0.0",
        "nan": "^2.17.0",
        "simple-get": "^3.0.3"
      },
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/chownr": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/chownr/-/chownr-2.0.0.tgz",
      "integrity": "sha512-bIomtDF5KGpdogkLd9VspvFzk9KfpyyGlS8YFVZl7TGPBHL5snIOnxeshwVgPteQ9b4Eydl+pVbIyE1DcvCWgQ==",
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/cliui": {
      "version": "7.0.4",
      "resolved": "https://registry.npmjs.org/cliui/-/cliui-7.0.4.tgz",
      "integrity": "sha512-OcRE68cOsVMXp1Yvonl/fzkQOyjLSu/8bhPDfQt0e0/Eb283TKP20Fs2MqoPsr9SwA595rRCA+QMzYc9nBP+JQ==",
      "dependencies": {
        "string-width": "^4.2.0",
        "strip-ansi": "^6.0.0",
        "wrap-ansi": "^7.0.0"
      }
    },
    "node_modules/color-convert": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/color-convert/-/color-convert-2.0.1.tgz",
      "integrity": "sha512-RRECPsj7iu/xb5oKYcsFHSppFNnsj/52OVTRKb4zP5onXwVF3zVmmToNcOfGC+CRDpfK/U584fMg38ZHCaElKQ==",
      "dependencies": {
        "color-name": "~1.1.4"
      },
      "engines": {
        "node": ">=7.0.0"
      }
    },
    "node_modules/color-name": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/color-name/-/color-name-1.1.4.tgz",
      "integrity": "sha512-dOy+3AuW3a2wNbZHIuMZpTcgjGuLU/uBL/ubcZF9OXbDo8ff4O8yVp5Bf0efS8uEoYo5q4Fx7dY9OgQGXgAsQA=="
    },
    "node_modules/color-support": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/color-support/-/color-support-1.1.3.tgz",
      "integrity": "sha512-qiBjkpbMLO/HL68y+lh4q0/O1MZFj2RX6X/KmMa3+gJD3z+WwI1ZzDHysvqHGS3mP6mznPckpXmw1nI9cJjyRg==",
      "bin": {
        "color-support": "bin.js"
      }
    },
    "node_modules/combined-stream": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/combined-stream/-/combined-stream-1.0.8.tgz",
      "integrity": "sha512-FQN4MRfuJeHf7cBbBMJFXhKSDq+2kAArBlmRBvcvFE5BB1HZKXtSFASDhdlz9zOYwxh8lDdnvmMOe/+5cdoEdg==",
      "dependencies": {
        "delayed-stream": "~1.0.0"
      },
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/commander": {
      "version": "2.20.3",
      "resolved": "https://registry.npmjs.org/commander/-/commander-2.20.3.tgz",
      "integrity": "sha512-GpVkmM8vF2vQUkj2LvZmD35JxeJOLCwJ9cUkugyk2nuhbv3+mJvpLYYt+0+USMxE+oj+ey/lJEnhZw75x/OMcQ=="
    },
    "node_modules/concat-map": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/concat-map/-/concat-map-0.0.1.tgz",
      "integrity": "sha512-/Srv4dswyQNBfohGpz9o6Yb3Gz3SrUDqBH5rTuhGR7ahtlbYKnVxw2bCFMRljaA7EXHaXZ8wsHdodFvbkhKmqg=="
    },
    "node_modules/concat-stream": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/concat-stream/-/concat-stream-2.0.0.tgz",
      "integrity": "sha512-MWufYdFw53ccGjCA+Ol7XJYpAlW6/prSMzuPOTRnJGcGzuhLn4Scrz7qf6o8bROZ514ltazcIFJZevcfbo0x7A==",
      "engines": [
        "node >= 6.0"
      ],
      "dependencies": {
        "buffer-from": "^1.0.0",
        "inherits": "^2.0.3",
        "readable-stream": "^3.0.2",
        "typedarray": "^0.0.6"
      }
    },
    "node_modules/console-control-strings": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/console-control-strings/-/console-control-strings-1.1.0.tgz",
      "integrity": "sha512-ty/fTekppD2fIwRvnZAVdeOiGd1c7YXEixbgJTNzqcxJWKQnjJ/V1bNEEE6hygpM3WjwHFUVK6HTjWSzV4a8sQ=="
    },
    "node_modules/core-util-is": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/core-util-is/-/core-util-is-1.0.3.tgz",
      "integrity": "sha512-ZQBvi1DcpJ4GDqanjucZ2Hj3wEO5pZDS89BWbkcrvdxksJorwUDDZamX9ldFkp9aw2lmBDLgkObEA4DWNJ9FYQ=="
    },
    "node_modules/create-require": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/create-require/-/create-require-1.1.1.tgz",
      "integrity": "sha512-dcKFX3jn0MpIaXjisoRvexIJVEKzaq7z2rZKxf+MSr9TkdmHmsU4m2lcLojrj/FHl8mk5VxMmYA+ftRkP/3oKQ==",
      "dev": true
    },
    "node_modules/cross-fetch": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/cross-fetch/-/cross-fetch-4.1.0.tgz",
      "integrity": "sha512-uKm5PU+MHTootlWEY+mZ4vvXoCn4fLQxT9dSc1sXVMSFkINTJVN8cAQROpwcKm8bJ/c7rgZVIBWzH5T78sNZZw==",
      "dependencies": {
        "node-fetch": "^2.7.0"
      }
    },
    "node_modules/d3-array": {
      "version": "1.2.4",
      "resolved": "https://registry.npmjs.org/d3-array/-/d3-array-1.2.4.tgz",
      "integrity": "sha512-KHW6M86R+FUPYGb3R5XiYjXPq7VzwxZ22buHhAEVG5ztoEcZZMLov530mmccaqA1GghZArjQV46fuc8kUqhhHw=="
    },
    "node_modules/d3-dsv": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/d3-dsv/-/d3-dsv-2.0.0.tgz",
      "integrity": "sha512-E+Pn8UJYx9mViuIUkoc93gJGGYut6mSDKy2+XaPwccwkRGlR+LO97L2VCCRjQivTwLHkSnAJG7yo00BWY6QM+w==",
      "dependencies": {
        "commander": "2",
        "iconv-lite": "0.4",
        "rw": "1"
      },
      "bin": {
        "csv2json": "bin/dsv2json",
        "csv2tsv": "bin/dsv2dsv",
        "dsv2dsv": "bin/dsv2dsv",
        "dsv2json": "bin/dsv2json",
        "json2csv": "bin/json2dsv",
        "json2dsv": "bin/json2dsv",
        "json2tsv": "bin/json2dsv",
        "tsv2csv": "bin/dsv2dsv",
        "tsv2json": "bin/dsv2json"
      }
    },
    "node_modules/d3-geo": {
      "version": "1.12.1",
      "resolved": "https://registry.npmjs.org/d3-geo/-/d3-geo-1.12.1.tgz",
      "integrity": "sha512-XG4d1c/UJSEX9NfU02KwBL6BYPj8YKHxgBEw5om2ZnTRSbIcego6dhHwcxuSR3clxh0EpE38os1DVPOmnYtTPg==",
      "dependencies": {
        "d3-array": "1"
      }
    },
    "node_modules/d3-hexbin": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/d3-hexbin/-/d3-hexbin-0.2.2.tgz",
      "integrity": "sha512-KS3fUT2ReD4RlGCjvCEm1RgMtp2NFZumdMu4DBzQK8AZv3fXRM6Xm8I4fSU07UXvH4xxg03NwWKWdvxfS/yc4w=="
    },
    "node_modules/d3-hierarchy": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/d3-hierarchy/-/d3-hierarchy-3.1.2.tgz",
      "integrity": "sha512-FX/9frcub54beBdugHjDCdikxThEqjnR93Qt7PvQTOHxyiNCAlvMrHhclk3cD5VeAaq9fxmfRp+CnWw9rEMBuA==",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/dayjs": {
      "version": "1.11.13",
      "resolved": "https://registry.npmjs.org/dayjs/-/dayjs-1.11.13.tgz",
      "integrity": "sha512-oaMBel6gjolK862uaPQOVTA7q3TZhuSvuMQAAglQDOWYO9A91IrAOUJEyKVlqJlHE0vq5p5UXxzdPfMH/x6xNg=="
    },
    "node_modules/debug": {
      "version": "2.6.9",
      "resolved": "https://registry.npmjs.org/debug/-/debug-2.6.9.tgz",
      "integrity": "sha512-bC7ElrdJaJnPbAP+1EotYvqZsb3ecl5wi6Bfi6BJTUcNowp6cvspg0jXznRTKDjm/E7AdgFBVeAPVMNcKGsHMA==",
      "dependencies": {
        "ms": "2.0.0"
      }
    },
    "node_modules/decompress-response": {
      "version": "4.2.1",
      "resolved": "https://registry.npmjs.org/decompress-response/-/decompress-response-4.2.1.tgz",
      "integrity": "sha512-jOSne2qbyE+/r8G1VU+G/82LBs2Fs4LAsTiLSHOCOMZQl2OKZ6i8i4IyHemTe+/yIXOtTcRQMzPcgyhoFlqPkw==",
      "dependencies": {
        "mimic-response": "^2.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/delayed-stream": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/delayed-stream/-/delayed-stream-1.0.0.tgz",
      "integrity": "sha512-ZySD7Nf91aLB0RxL4KGrKHBXl7Eds1DAmEdcoVawXnLD7SDhpNgtuII2aAkg7a7QS41jxPSZ17p4VdGnMHk3MQ==",
      "engines": {
        "node": ">=0.4.0"
      }
    },
    "node_modules/delegates": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/delegates/-/delegates-1.0.0.tgz",
      "integrity": "sha512-bd2L678uiWATM6m5Z1VzNCErI3jiGzt6HGY8OVICs40JQq/HALfbyNJmp0UDakEY4pMMaN0Ly5om/B1VI/+xfQ=="
    },
    "node_modules/density-clustering": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/density-clustering/-/density-clustering-1.3.0.tgz",
      "integrity": "sha512-icpmBubVTwLnsaor9qH/4tG5+7+f61VcqMN3V3pm9sxxSCt2Jcs0zWOgwZW9ARJYaKD3FumIgHiMOcIMRRAzFQ=="
    },
    "node_modules/detect-libc": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/detect-libc/-/detect-libc-2.0.3.tgz",
      "integrity": "sha512-bwy0MGW55bG41VqxxypOsdSdGqLwXPI/focwgTYCFMbdUiBAxLg9CFzG08sz2aqzknwiX7Hkl0bQENjg8iLByw==",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/diff": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/diff/-/diff-4.0.2.tgz",
      "integrity": "sha512-58lmxKSA4BNyLz+HHMUzlOEpg09FV+ev6ZMe3vJihgdxzgcwZ8VoEEPmALCZG9LmqfVoNMMKpttIYTVG6uDY7A==",
      "dev": true,
      "engines": {
        "node": ">=0.3.1"
      }
    },
    "node_modules/dunder-proto": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/dunder-proto/-/dunder-proto-1.0.1.tgz",
      "integrity": "sha512-KIN/nDJBQRcXw0MLVhZE9iQHmG68qAVIBg9CqmUYjmQIhgij9U5MFvrqkUL5FbtyyzZuOeOt0zdeRe4UY7ct+A==",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.1",
        "es-errors": "^1.3.0",
        "gopd": "^1.2.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/emoji-regex": {
      "version": "8.0.0",
      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-8.0.0.tgz",
      "integrity": "sha512-MSjYzcWNOA0ewAHpz0MxpYFvwg6yjy1NG3xteoqz644VCo/RPgnr1/GGt+ic3iJTzQ8Eu3TdM14SawnVUmGE6A=="
    },
    "node_modules/es-define-property": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/es-define-property/-/es-define-property-1.0.1.tgz",
      "integrity": "sha512-e3nRfgfUZ4rNGL232gUgX06QNyyez04KdjFrF+LTRoOXmrOgFKDg4BCdsjW8EnT69eqdYGmRpJwiPVYNrCaW3g==",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-errors": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/es-errors/-/es-errors-1.3.0.tgz",
      "integrity": "sha512-Zf5H2Kxt2xjTvbJvP2ZWLEICxA6j+hAmMzIlypy4xcBg1vKVnx89Wy0GbS+kf5cwCVFFzdCFh2XSCFNULS6csw==",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-object-atoms": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/es-object-atoms/-/es-object-atoms-1.1.1.tgz",
      "integrity": "sha512-FGgH2h8zKNim9ljj7dankFPcICIK9Cp5bm+c2gQSYePhpaG5+esrLODihIorn+Pe6FGJzWhXQotPv73jTaldXA==",
      "dependencies": {
        "es-errors": "^1.3.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-set-tostringtag": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/es-set-tostringtag/-/es-set-tostringtag-2.1.0.tgz",
      "integrity": "sha512-j6vWzfrGVfyXxge+O0x5sh6cvxAog0a/4Rdd2K36zCMV5eJ+/+tOAngRO8cODMNWbVRdVlmGZQL2YS3yR8bIUA==",
      "dependencies": {
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.6",
        "has-tostringtag": "^1.0.2",
        "hasown": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/escalade": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/escalade/-/escalade-3.2.0.tgz",
      "integrity": "sha512-WUj2qlxaQtO4g6Pq5c29GTcWGDyd8itL8zTlipgECz3JesAiiOKotd8JU6otB3PACgG6xkJUyVhboMS+bje/jA==",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/euclidean-distance": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/euclidean-distance/-/euclidean-distance-1.0.0.tgz",
      "integrity": "sha512-3+1fOi9GKT2PhSX+uKZ/cX4F98wLY2gTibZPPZeToEPvHZNLnnoymcJgQzWeeIMvqciQRIhn9KEKY7QVplC7hQ=="
    },
    "node_modules/eventemitter3": {
      "version": "4.0.7",
      "resolved": "https://registry.npmjs.org/eventemitter3/-/eventemitter3-4.0.7.tgz",
      "integrity": "sha512-8guHBZCwKnFhYdHr2ysuRWErTwhoN2X8XELRlrRwpmfeY2jjuUN4taQMsULKUVo1K4DvZl+0pgfyoysHxvmvEw=="
    },
    "node_modules/file-source": {
      "version": "0.6.1",
      "resolved": "https://registry.npmjs.org/file-source/-/file-source-0.6.1.tgz",
      "integrity": "sha512-1R1KneL7eTXmXfKxC10V/9NeGOdbsAXJ+lQ//fvvcHUgtaZcZDWNJNblxAoVOyV1cj45pOtUrR3vZTBwqcW8XA==",
      "dependencies": {
        "stream-source": "0.3"
      }
    },
    "node_modules/follow-redirects": {
      "version": "1.15.9",
      "resolved": "https://registry.npmjs.org/follow-redirects/-/follow-redirects-1.15.9.tgz",
      "integrity": "sha512-gew4GsXizNgdoRyqmyfMHyAmXsZDk6mHkSxZFCzW9gwlbtOW44CDtYavM+y+72qD/Vq2l550kMF52DT8fOLJqQ==",
      "funding": [
        {
          "type": "individual",
          "url": "https://github.com/sponsors/RubenVerborgh"
        }
      ],
      "engines": {
        "node": ">=4.0"
      },
      "peerDependenciesMeta": {
        "debug": {
          "optional": true
        }
      }
    },
    "node_modules/form-data": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/form-data/-/form-data-4.0.2.tgz",
      "integrity": "sha512-hGfm/slu0ZabnNt4oaRZ6uREyfCj6P4fT/n6A1rGV+Z0VdGXjfOhVUpkn6qVQONHGIFwmveGXyDs75+nr6FM8w==",
      "dependencies": {
        "asynckit": "^0.4.0",
        "combined-stream": "^1.0.8",
        "es-set-tostringtag": "^2.1.0",
        "mime-types": "^2.1.12"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/fs-minipass": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/fs-minipass/-/fs-minipass-2.1.0.tgz",
      "integrity": "sha512-V/JgOLFCS+R6Vcq0slCuaeWEdNC3ouDlJMNIsacH2VtALiu9mV4LPrHc5cDl8k5aw6J8jwgWWpiTo5RYhmIzvg==",
      "dependencies": {
        "minipass": "^3.0.0"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/fs-minipass/node_modules/minipass": {
      "version": "3.3.6",
      "resolved": "https://registry.npmjs.org/minipass/-/minipass-3.3.6.tgz",
      "integrity": "sha512-DxiNidxSEK+tHG6zOIklvNOwm3hvCrbUrdtzY74U6HKTJxvIDfOUL5W5P2Ghd3DTkhhKPYGqeNUIh5qcM4YBfw==",
      "dependencies": {
        "yallist": "^4.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/fs.realpath": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/fs.realpath/-/fs.realpath-1.0.0.tgz",
      "integrity": "sha512-OO0pH2lK6a0hZnAdau5ItzHPI6pUlvI7jMVnxUQRtw4owF2wk8lOSabtGDCTP4Ggrg2MbGnWO9X8K1t4+fGMDw=="
    },
    "node_modules/function-bind": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/function-bind/-/function-bind-1.1.2.tgz",
      "integrity": "sha512-7XHNxH7qX9xG5mIwxkhumTox/MIRNcOgDrxWsMt2pAr23WHp6MrRlN7FBSFpCpr+oVO0F744iUgR82nJMfG2SA==",
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/gauge": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/gauge/-/gauge-3.0.2.tgz",
      "integrity": "sha512-+5J6MS/5XksCuXq++uFRsnUd7Ovu1XenbeuIuNRJxYWjgQbPuFhT14lAvsWfqfAmnwluf1OwMjz39HjfLPci0Q==",
      "deprecated": "This package is no longer supported.",
      "dependencies": {
        "aproba": "^1.0.3 || ^2.0.0",
        "color-support": "^1.1.2",
        "console-control-strings": "^1.0.0",
        "has-unicode": "^2.0.1",
        "object-assign": "^4.1.1",
        "signal-exit": "^3.0.0",
        "string-width": "^4.2.3",
        "strip-ansi": "^6.0.1",
        "wide-align": "^1.1.2"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/geobuf": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/geobuf/-/geobuf-3.0.2.tgz",
      "integrity": "sha512-ASgKwEAQQRnyNFHNvpd5uAwstbVYmiTW0Caw3fBb509tNTqXyAAPMyFs5NNihsLZhLxU1j/kjFhkhLWA9djuVg==",
      "dependencies": {
        "concat-stream": "^2.0.0",
        "pbf": "^3.2.1",
        "shapefile": "~0.6.6"
      },
      "bin": {
        "geobuf2json": "bin/geobuf2json",
        "json2geobuf": "bin/json2geobuf",
        "shp2geobuf": "bin/shp2geobuf"
      }
    },
    "node_modules/geojson-dissolve": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/geojson-dissolve/-/geojson-dissolve-3.1.0.tgz",
      "integrity": "sha512-JXHfn+A3tU392HA703gJbjmuHaQOAE/C1KzbELCczFRFux+GdY6zt1nKb1VMBHp4LWeE7gUY2ql+g06vJqhiwQ==",
      "dependencies": {
        "@turf/meta": "^3.7.5",
        "geojson-flatten": "^0.2.1",
        "geojson-linestring-dissolve": "0.0.1",
        "topojson-client": "^3.0.0",
        "topojson-server": "^3.0.0"
      }
    },
    "node_modules/geojson-dissolve/node_modules/@turf/meta": {
      "version": "3.14.0",
      "resolved": "https://registry.npmjs.org/@turf/meta/-/meta-3.14.0.tgz",
      "integrity": "sha512-OtXqLQuR9hlQ/HkAF/OdzRea7E0eZK1ay8y8CBXkoO2R6v34CsDrWYLMSo0ZzMsaQDpKo76NPP2GGo+PyG1cSg=="
    },
    "node_modules/geojson-flatten": {
      "version": "0.2.4",
      "resolved": "https://registry.npmjs.org/geojson-flatten/-/geojson-flatten-0.2.4.tgz",
      "integrity": "sha512-LiX6Jmot8adiIdZ/fthbcKKPOfWjTQchX/ggHnwMZ2e4b0I243N1ANUos0LvnzepTEsj0+D4fIJ5bKhBrWnAHA==",
      "dependencies": {
        "get-stdin": "^6.0.0",
        "minimist": "1.2.0"
      },
      "bin": {
        "geojson-flatten": "geojson-flatten"
      }
    },
    "node_modules/geojson-flatten/node_modules/get-stdin": {
      "version": "6.0.0",
      "resolved": "https://registry.npmjs.org/get-stdin/-/get-stdin-6.0.0.tgz",
      "integrity": "sha512-jp4tHawyV7+fkkSKyvjuLZswblUtz+SQKzSWnBbii16BuZksJlU1wuBYXY75r+duh/llF1ur6oNwi+2ZzjKZ7g==",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/geojson-linestring-dissolve": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/geojson-linestring-dissolve/-/geojson-linestring-dissolve-0.0.1.tgz",
      "integrity": "sha512-Y8I2/Ea28R/Xeki7msBcpMvJL2TaPfaPKP8xqueJfQ9/jEhps+iOJxOR2XCBGgVb12Z6XnDb1CMbaPfLepsLaw=="
    },
    "node_modules/get-caller-file": {
      "version": "2.0.5",
      "resolved": "https://registry.npmjs.org/get-caller-file/-/get-caller-file-2.0.5.tgz",
      "integrity": "sha512-DyFP3BM/3YHTQOCUL/w0OZHR0lpKeGrxotcHWcqNEdnltqFwXVfhEBQ94eIo34AfQpo0rGki4cyIiftY06h2Fg==",
      "engines": {
        "node": "6.* || 8.* || >= 10.*"
      }
    },
    "node_modules/get-intrinsic": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/get-intrinsic/-/get-intrinsic-1.3.0.tgz",
      "integrity": "sha512-9fSjSaos/fRIVIp+xSJlE6lfwhES7LNtKaCBIamHsjr2na1BiABJPo0mOjjz8GJDURarmCPGqaiVg5mfjb98CQ==",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.2",
        "es-define-property": "^1.0.1",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.1.1",
        "function-bind": "^1.1.2",
        "get-proto": "^1.0.1",
        "gopd": "^1.2.0",
        "has-symbols": "^1.1.0",
        "hasown": "^2.0.2",
        "math-intrinsics": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/get-proto": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/get-proto/-/get-proto-1.0.1.tgz",
      "integrity": "sha512-sTSfBjoXBp89JvIKIefqw7U2CCebsc74kiY6awiGogKtoSGbgjYE/G/+l9sF3MWFPNc9IcoOC4ODfKHfxFmp0g==",
      "dependencies": {
        "dunder-proto": "^1.0.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/get-stdin": {
      "version": "9.0.0",
      "resolved": "https://registry.npmjs.org/get-stdin/-/get-stdin-9.0.0.tgz",
      "integrity": "sha512-dVKBjfWisLAicarI2Sf+JuBE/DghV4UzNAVe9yhEJuzeREd3JhOTE9cUaJTeSa77fsbQUK3pcOpJfM59+VKZaA==",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/gifuct-js": {
      "version": "2.1.2",
      "resolved": "https://registry.npmjs.org/gifuct-js/-/gifuct-js-2.1.2.tgz",
      "integrity": "sha512-rI2asw77u0mGgwhV3qA+OEgYqaDn5UNqgs+Bx0FGwSpuqfYn+Ir6RQY5ENNQ8SbIiG/m5gVa7CD5RriO4f4Lsg==",
      "dependencies": {
        "js-binary-schema-parser": "^2.0.3"
      }
    },
    "node_modules/glob": {
      "version": "7.2.3",
      "resolved": "https://registry.npmjs.org/glob/-/glob-7.2.3.tgz",
      "integrity": "sha512-nFR0zLpU2YCaRxwoCJvL6UvCH2JFyFVIvwTLsIf21AuHlMskA1hhTdk+LlYJtOlYt9v6dvszD2BGRqBL+iQK9Q==",
      "deprecated": "Glob versions prior to v9 are no longer supported",
      "dependencies": {
        "fs.realpath": "^1.0.0",
        "inflight": "^1.0.4",
        "inherits": "2",
        "minimatch": "^3.1.1",
        "once": "^1.3.0",
        "path-is-absolute": "^1.0.0"
      },
      "engines": {
        "node": "*"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/gopd": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/gopd/-/gopd-1.2.0.tgz",
      "integrity": "sha512-ZUKRh6/kUFoAiTAtTYPZJ3hw9wNxx+BIBOijnlG9PnrJsCcSjs1wyyD6vJpaYtgnzDrKYRSqf3OO6Rfa93xsRg==",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-symbols": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/has-symbols/-/has-symbols-1.1.0.tgz",
      "integrity": "sha512-1cDNdwJ2Jaohmb3sg4OmKaMBwuC48sYni5HUw2DvsC8LjGTLK9h+eb1X6RyuOHe4hT0ULCW68iomhjUoKUqlPQ==",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-tostringtag": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/has-tostringtag/-/has-tostringtag-1.0.2.tgz",
      "integrity": "sha512-NqADB8VjPFLM2V0VvHUewwwsw0ZWBaIdgo+ieHtK3hasLz4qeCRjYcqfB6AQrBggRKppKF8L52/VqdVsO47Dlw==",
      "dependencies": {
        "has-symbols": "^1.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-unicode": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/has-unicode/-/has-unicode-2.0.1.tgz",
      "integrity": "sha512-8Rf9Y83NBReMnx0gFzA8JImQACstCYWUplepDa9xprwwtmgEZUF0h/i5xSA625zB/I37EtrswSST6OXxwaaIJQ=="
    },
    "node_modules/hasown": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/hasown/-/hasown-2.0.2.tgz",
      "integrity": "sha512-0hJU9SCPvmMzIBdZFqNPXWa6dqh7WdH0cII9y+CyS8rG3nL48Bclra9HmKhVVUHyPWNH5Y7xDwAB7bfgSjkUMQ==",
      "dependencies": {
        "function-bind": "^1.1.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/https-proxy-agent": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/https-proxy-agent/-/https-proxy-agent-5.0.1.tgz",
      "integrity": "sha512-dFcAjpTQFgoLMzC2VwU+C/CbS7uRL0lWmxDITmqm7C+7F0Odmj6s9l6alZc6AELXhrnggM2CeWSXHGOdX2YtwA==",
      "dependencies": {
        "agent-base": "6",
        "debug": "4"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/https-proxy-agent/node_modules/debug": {
      "version": "4.4.0",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.4.0.tgz",
      "integrity": "sha512-6WTZ/IxCY/T6BALoZHaE4ctp9xm+Z5kY/pzYaCHRFeyVhojxlrm+46y68HA6hr0TcwEssoxNiDEUJQjfPZ/RYA==",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/https-proxy-agent/node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA=="
    },
    "node_modules/iconv-lite": {
      "version": "0.4.24",
      "resolved": "https://registry.npmjs.org/iconv-lite/-/iconv-lite-0.4.24.tgz",
      "integrity": "sha512-v3MXnZAcvnywkTUEZomIActle7RXXeedOR31wwl7VlyoXO4Qi9arvSenNQWne1TcRwhCL1HwLI21bEqdpj8/rA==",
      "dependencies": {
        "safer-buffer": ">= 2.1.2 < 3"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/ieee754": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/ieee754/-/ieee754-1.2.1.tgz",
      "integrity": "sha512-dcyqhDvX1C46lXZcVqCpK+FtMRQVdIMN6/Df5js2zouUsqG7I6sFxitIC+7KYK29KdXOLHdu9zL4sFnoVQnqaA==",
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/feross"
        },
        {
          "type": "patreon",
          "url": "https://www.patreon.com/feross"
        },
        {
          "type": "consulting",
          "url": "https://feross.org/support"
        }
      ]
    },
    "node_modules/inflight": {
      "version": "1.0.6",
      "resolved": "https://registry.npmjs.org/inflight/-/inflight-1.0.6.tgz",
      "integrity": "sha512-k92I/b08q4wvFscXCLvqfsHCrjrF7yiXsQuIVvVE7N82W3+aqpzuUdBbfhWcy/FZR3/4IgflMgKLOsvPDrGCJA==",
      "deprecated": "This module is not supported, and leaks memory. Do not use it. Check out lru-cache if you want a good and tested way to coalesce async requests by a key value, which is much more comprehensive and powerful.",
      "dependencies": {
        "once": "^1.3.0",
        "wrappy": "1"
      }
    },
    "node_modules/inherits": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/inherits/-/inherits-2.0.4.tgz",
      "integrity": "sha512-k/vGaX4/Yla3WzyMCvTQOXYeIHvqOKtnqBduzTHpzpQZzAskKMhZ2K+EnBiSM9zGSoIFeMpXKxa4dYeZIQqewQ=="
    },
    "node_modules/is-core-module": {
      "version": "2.16.1",
      "resolved": "https://registry.npmjs.org/is-core-module/-/is-core-module-2.16.1.tgz",
      "integrity": "sha512-UfoeMA6fIJ8wTYFEUjelnaGI67v6+N7qXJEvQuIGa99l4xsCruSYOVSQ0uPANn4dAzm8lkYPaKLrrijLq7x23w==",
      "dependencies": {
        "hasown": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-fullwidth-code-point": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/is-fullwidth-code-point/-/is-fullwidth-code-point-3.0.0.tgz",
      "integrity": "sha512-zymm5+u+sCsSWyD9qNaejV3DFvhCKclKdizYaJUuHA83RLjb7nSuGnddCHGv0hk+KY7BMAlsWeK4Ueg6EV6XQg==",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/isarray": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/isarray/-/isarray-0.0.1.tgz",
      "integrity": "sha512-D2S+3GLxWH+uhrNEcoh/fnmYeP8E8/zHl644d/jdA0g2uyXvy3sb0qxotE+ne0LtccHknQzWwZEzhak7oJ0COQ=="
    },
    "node_modules/js-binary-schema-parser": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/js-binary-schema-parser/-/js-binary-schema-parser-2.0.3.tgz",
      "integrity": "sha512-xezGJmOb4lk/M1ZZLTR/jaBHQ4gG/lqQnJqdIv4721DMggsa1bDVlHXNeHYogaIEHD9vCRv0fcL4hMA+Coarkg=="
    },
    "node_modules/js-yaml": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/js-yaml/-/js-yaml-4.1.0.tgz",
      "integrity": "sha512-wpxZs9NoxZaJESJGIZTyDEaYpl0FKSA+FB9aJiyemKhMwkxQg63h4T1KJgUGHpTqPDNRcmmYLugrRjJlBtWvRA==",
      "dependencies": {
        "argparse": "^2.0.1"
      },
      "bin": {
        "js-yaml": "bin/js-yaml.js"
      }
    },
    "node_modules/json5": {
      "version": "2.2.3",
      "resolved": "https://registry.npmjs.org/json5/-/json5-2.2.3.tgz",
      "integrity": "sha512-XmOWe7eyHYH14cLdVPoyg+GOH3rYX++KpzrylJwSW98t3Nk+U8XOl8FWKOgwtzdb8lXGf6zYwDUzeHMWfxasyg==",
      "bin": {
        "json5": "lib/cli.js"
      },
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/jsonrepair": {
      "version": "3.8.1",
      "resolved": "https://registry.npmjs.org/jsonrepair/-/jsonrepair-3.8.1.tgz",
      "integrity": "sha512-5wnjaO53EJOhfLFY92nvBz2B9gqF9ql/D4HKUb1WOSBaqtVcAifFfmurblnhCJn/ySqKFA8U3n7nhGMAu/hEjQ==",
      "bin": {
        "jsonrepair": "bin/cli.js"
      }
    },
    "node_modules/jstat": {
      "version": "1.9.6",
      "resolved": "https://registry.npmjs.org/jstat/-/jstat-1.9.6.tgz",
      "integrity": "sha512-rPBkJbK2TnA8pzs93QcDDPlKcrtZWuuCo2dVR0TFLOJSxhqfWOVCSp8aV3/oSbn+4uY4yw1URtLpHQedtmXfug=="
    },
    "node_modules/lottie-web": {
      "version": "5.12.2",
      "resolved": "https://registry.npmjs.org/lottie-web/-/lottie-web-5.12.2.tgz",
      "integrity": "sha512-uvhvYPC8kGPjXT3MyKMrL3JitEAmDMp30lVkuq/590Mw9ok6pWcFCwXJveo0t5uqYw1UREQHofD+jVpdjBv8wg=="
    },
    "node_modules/make-dir": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/make-dir/-/make-dir-3.1.0.tgz",
      "integrity": "sha512-g3FeP20LNwhALb/6Cz6Dd4F2ngze0jz7tbzrD2wAV+o9FeNHe4rL+yK2md0J/fiSf1sa1ADhXqi5+oVwOM/eGw==",
      "dependencies": {
        "semver": "^6.0.0"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/make-dir/node_modules/semver": {
      "version": "6.3.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-6.3.1.tgz",
      "integrity": "sha512-BR7VvDCVHO+q2xBEWskxS6DJE1qRnb7DxzUrogb71CWoSficBxYsiAGd+Kl0mmq/MprG9yArRkyrQxTO6XjMzA==",
      "bin": {
        "semver": "bin/semver.js"
      }
    },
    "node_modules/make-error": {
      "version": "1.3.6",
      "resolved": "https://registry.npmjs.org/make-error/-/make-error-1.3.6.tgz",
      "integrity": "sha512-s8UhlNe7vPKomQhC1qFelMokr/Sc3AgNbso3n74mVPA5LTZwkB9NlXf4XPamLxJE8h0gh73rM94xvwRT2CVInw==",
      "dev": true
    },
    "node_modules/math-intrinsics": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/math-intrinsics/-/math-intrinsics-1.1.0.tgz",
      "integrity": "sha512-/IXtbwEk5HTPyEwyKX6hGkYXxM9nbj64B+ilVJnC/R6B0pH5G4V3b0pVbL7DBj4tkhBAppbQUlf6F6Xl9LHu1g==",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/mime-db": {
      "version": "1.52.0",
      "resolved": "https://registry.npmjs.org/mime-db/-/mime-db-1.52.0.tgz",
      "integrity": "sha512-sPU4uV7dYlvtWJxwwxHD0PuihVNiE7TyAbQ5SWxDCB9mUYvOgroQOwYQQOKPJ8CIbE+1ETVlOoK1UC2nU3gYvg==",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/mime-types": {
      "version": "2.1.35",
      "resolved": "https://registry.npmjs.org/mime-types/-/mime-types-2.1.35.tgz",
      "integrity": "sha512-ZDY+bPm5zTTF+YpCrAU9nK0UgICYPT0QtT1NZWFv4s++TNkcgVaT0g6+4R2uI4MjQjzysHB1zxuWL50hzaeXiw==",
      "dependencies": {
        "mime-db": "1.52.0"
      },
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/mimic-response": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/mimic-response/-/mimic-response-2.1.0.tgz",
      "integrity": "sha512-wXqjST+SLt7R009ySCglWBCFpjUygmCIfD790/kVbiGmUgfYGuB14PiTd5DwVxSV4NcYHjzMkoj5LjQZwTQLEA==",
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/minimatch": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-3.1.2.tgz",
      "integrity": "sha512-J7p63hRiAjw1NDEww1W7i37+ByIrOWO5XQQAzZ3VOcL0PNybwpfmV/N05zFAzwQ9USyEcX6t3UO+K5aqBQOIHw==",
      "dependencies": {
        "brace-expansion": "^1.1.7"
      },
      "engines": {
        "node": "*"
      }
    },
    "node_modules/minimist": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/minimist/-/minimist-1.2.0.tgz",
      "integrity": "sha512-7Wl+Jz+IGWuSdgsQEJ4JunV0si/iMhg42MnQQG6h1R6TNeVenp4U9x5CC5v/gYqz/fENLQITAWXidNtVL0NNbw=="
    },
    "node_modules/minipass": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/minipass/-/minipass-5.0.0.tgz",
      "integrity": "sha512-3FnjYuehv9k6ovOEbyOswadCDPX1piCfhV8ncmYtHOjuPwylVWsghTLo7rabjC3Rx5xD4HDx8Wm1xnMF7S5qFQ==",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/minizlib": {
      "version": "2.1.2",
      "resolved": "https://registry.npmjs.org/minizlib/-/minizlib-2.1.2.tgz",
      "integrity": "sha512-bAxsR8BVfj60DWXHE3u30oHzfl4G7khkSuPW+qvpd7jFRHm7dLxOjUk1EHACJ/hxLY8phGJ0YhYHZo7jil7Qdg==",
      "dependencies": {
        "minipass": "^3.0.0",
        "yallist": "^4.0.0"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/minizlib/node_modules/minipass": {
      "version": "3.3.6",
      "resolved": "https://registry.npmjs.org/minipass/-/minipass-3.3.6.tgz",
      "integrity": "sha512-DxiNidxSEK+tHG6zOIklvNOwm3hvCrbUrdtzY74U6HKTJxvIDfOUL5W5P2Ghd3DTkhhKPYGqeNUIh5qcM4YBfw==",
      "dependencies": {
        "yallist": "^4.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/mkdirp": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/mkdirp/-/mkdirp-1.0.4.tgz",
      "integrity": "sha512-vVqVZQyf3WLx2Shd0qJ9xuvqgAyKPLAiqITEtqW0oIUjzo3PePDd6fW9iFz30ef7Ysp/oiWqbhszeGWW2T6Gzw==",
      "bin": {
        "mkdirp": "bin/cmd.js"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/ms": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.0.0.tgz",
      "integrity": "sha512-Tpp60P6IUJDTuOq/5Z8cdskzJujfwqfOTkrwIwj7IRISpnkJnT6SyJ4PCPnGMoFjC9ddhal5KVIYtAt97ix05A=="
    },
    "node_modules/nan": {
      "version": "2.22.2",
      "resolved": "https://registry.npmjs.org/nan/-/nan-2.22.2.tgz",
      "integrity": "sha512-DANghxFkS1plDdRsX0X9pm0Z6SJNN6gBdtXfanwoZ8hooC5gosGFSBGRYHUVPz1asKA/kMRqDRdHrluZ61SpBQ=="
    },
    "node_modules/node-fetch": {
      "version": "2.7.0",
      "resolved": "https://registry.npmjs.org/node-fetch/-/node-fetch-2.7.0.tgz",
      "integrity": "sha512-c4FRfUm/dbcWZ7U+1Wq0AwCyFL+3nt2bEw05wfxSz+DWpWsitgmSgYmy2dQdWyKC1694ELPqMs/YzUSNozLt8A==",
      "dependencies": {
        "whatwg-url": "^5.0.0"
      },
      "engines": {
        "node": "4.x || >=6.0.0"
      },
      "peerDependencies": {
        "encoding": "^0.1.0"
      },
      "peerDependenciesMeta": {
        "encoding": {
          "optional": true
        }
      }
    },
    "node_modules/node-sql-parser": {
      "version": "4.17.0",
      "resolved": "https://bnpm.byted.org/node-sql-parser/-/node-sql-parser-4.17.0.tgz",
      "integrity": "sha512-3IhovpmUBpcETnoKK/KBdkz2mz53kVG5E1dnqz1QuYvtzdxYZW5xaGGEvW9u6Yyy2ivwR3eUZrn9inmEVef02w==",
      "dependencies": {
        "big-integer": "^1.6.48"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/nopt": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/nopt/-/nopt-5.0.0.tgz",
      "integrity": "sha512-Tbj67rffqceeLpcRXrT7vKAN8CwfPeIBgM7E6iBkmKLV7bEMwpGgYLGv0jACUsECaa/vuxP0IjEont6umdMgtQ==",
      "dependencies": {
        "abbrev": "1"
      },
      "bin": {
        "nopt": "bin/nopt.js"
      },
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/npmlog": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/npmlog/-/npmlog-5.0.1.tgz",
      "integrity": "sha512-AqZtDUWOMKs1G/8lwylVjrdYgqA4d9nu8hc+0gzRxlDb1I10+FHBGMXs6aiQHFdCUUlqH99MUMuLfzWDNDtfxw==",
      "deprecated": "This package is no longer supported.",
      "dependencies": {
        "are-we-there-yet": "^2.0.0",
        "console-control-strings": "^1.1.0",
        "gauge": "^3.0.0",
        "set-blocking": "^2.0.0"
      }
    },
    "node_modules/object-assign": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/object-assign/-/object-assign-4.1.1.tgz",
      "integrity": "sha512-rJgTQnkUnH1sFw8yT6VSU3zD3sWmu6sZhIseY8VX+GRu3P6F7Fu+JNDoXfklElbLJSnc3FUQHVe4cU5hj+BcUg==",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/once": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/once/-/once-1.4.0.tgz",
      "integrity": "sha512-lNaJgI+2Q5URQBkccEKHTQOPaXdUxnZZElQTZY0MFUAuaEqe1E+Nyvgdz/aIyNi6Z9MzO5dv1H8n58/GELp3+w==",
      "dependencies": {
        "wrappy": "1"
      }
    },
    "node_modules/parse-svg-path": {
      "version": "0.1.2",
      "resolved": "https://registry.npmjs.org/parse-svg-path/-/parse-svg-path-0.1.2.tgz",
      "integrity": "sha512-JyPSBnkTJ0AI8GGJLfMXvKq42cj5c006fnLz6fXy6zfoVjJizi8BNTpu8on8ziI1cKy9d9DGNuY17Ce7wuejpQ=="
    },
    "node_modules/path-browserify": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/path-browserify/-/path-browserify-1.0.1.tgz",
      "integrity": "sha512-b7uo2UCUOYZcnF/3ID0lulOJi/bafxa1xPe7ZPsammBSpjSWQkjNxlt635YGS2MiR9GjvuXCtz2emr3jbsz98g=="
    },
    "node_modules/path-data-parser": {
      "version": "0.1.0",
      "resolved": "https://registry.npmjs.org/path-data-parser/-/path-data-parser-0.1.0.tgz",
      "integrity": "sha512-NOnmBpt5Y2RWbuv0LMzsayp3lVylAHLPUTut412ZA3l+C4uw4ZVkQbjShYCQ8TCpUMdPapr4YjUqLYD6v68j+w=="
    },
    "node_modules/path-is-absolute": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/path-is-absolute/-/path-is-absolute-1.0.1.tgz",
      "integrity": "sha512-AVbw3UJ2e9bq64vSaS9Am0fje1Pa8pbGqTTsmXfaIiMpnr5DlDhfJOuLj9Sf95ZPVDAUerDfEk88MPmPe7UCQg==",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/path-parse": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/path-parse/-/path-parse-1.0.7.tgz",
      "integrity": "sha512-LDJzPVEEEPR+y48z93A0Ed0yXb8pAByGWo/k5YYdYgpY2/2EsOsksJrq7lOHxryrVOn1ejG6oAp8ahvOIQD8sw=="
    },
    "node_modules/path-source": {
      "version": "0.1.3",
      "resolved": "https://registry.npmjs.org/path-source/-/path-source-0.1.3.tgz",
      "integrity": "sha512-dWRHm5mIw5kw0cs3QZLNmpUWty48f5+5v9nWD2dw3Y0Hf+s01Ag8iJEWV0Sm0kocE8kK27DrIowha03e1YR+Qw==",
      "dependencies": {
        "array-source": "0.0",
        "file-source": "0.6"
      }
    },
    "node_modules/pbf": {
      "version": "3.3.0",
      "resolved": "https://registry.npmjs.org/pbf/-/pbf-3.3.0.tgz",
      "integrity": "sha512-XDF38WCH3z5OV/OVa8GKUNtLAyneuzbCisx7QUCF8Q6Nutx0WnJrQe5O+kOtBlLfRNUws98Y58Lblp+NJG5T4Q==",
      "dependencies": {
        "ieee754": "^1.1.12",
        "resolve-protobuf-schema": "^2.1.0"
      },
      "bin": {
        "pbf": "bin/pbf"
      }
    },
    "node_modules/point-at-length": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/point-at-length/-/point-at-length-1.1.0.tgz",
      "integrity": "sha512-nNHDk9rNEh/91o2Y8kHLzBLNpLf80RYd2gCun9ss+V0ytRSf6XhryBTx071fesktjbachRmGuUbId+JQmzhRXw==",
      "dependencies": {
        "abs-svg-path": "~0.1.1",
        "isarray": "~0.0.1",
        "parse-svg-path": "~0.1.1"
      }
    },
    "node_modules/points-on-curve": {
      "version": "0.2.0",
      "resolved": "https://registry.npmjs.org/points-on-curve/-/points-on-curve-0.2.0.tgz",
      "integrity": "sha512-0mYKnYYe9ZcqMCWhUjItv/oHjvgEsfKvnUTg8sAtnHr3GVy7rGkXCb6d5cSyqrWqL4k81b9CPg3urd+T7aop3A=="
    },
    "node_modules/points-on-path": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/points-on-path/-/points-on-path-0.2.1.tgz",
      "integrity": "sha512-25ClnWWuw7JbWZcgqY/gJ4FQWadKxGWk+3kR/7kD0tCaDtPPMj7oHu2ToLaVhfpnHrZzYby2w6tUA0eOIuUg8g==",
      "dependencies": {
        "path-data-parser": "0.1.0",
        "points-on-curve": "0.2.0"
      }
    },
    "node_modules/protocol-buffers-schema": {
      "version": "3.6.0",
      "resolved": "https://registry.npmjs.org/protocol-buffers-schema/-/protocol-buffers-schema-3.6.0.tgz",
      "integrity": "sha512-TdDRD+/QNdrCGCE7v8340QyuXd4kIWIgapsE2+n/SaGiSSbomYl4TjHlvIoCWRpE7wFt02EpB35VVA2ImcBVqw=="
    },
    "node_modules/proxy-from-env": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/proxy-from-env/-/proxy-from-env-1.1.0.tgz",
      "integrity": "sha512-D+zkORCbA9f1tdWRK0RaCR3GPv50cMxcrz4X8k5LTSUD1Dkw47mKJEZQNunItRTkWwgtaUSo1RVFRIG9ZXiFYg=="
    },
    "node_modules/readable-stream": {
      "version": "3.6.2",
      "resolved": "https://registry.npmjs.org/readable-stream/-/readable-stream-3.6.2.tgz",
      "integrity": "sha512-9u/sniCrY3D5WdsERHzHE4G2YCXqoG5FTHUiCC4SIbr6XcLZBY05ya9EKjYek9O5xOAwjGq+1JdGBAS7Q9ScoA==",
      "dependencies": {
        "inherits": "^2.0.3",
        "string_decoder": "^1.1.1",
        "util-deprecate": "^1.0.1"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/require-directory": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/require-directory/-/require-directory-2.1.1.tgz",
      "integrity": "sha512-fGxEI7+wsG9xrvdjsrlmL22OMTTiHRwAMroiEeMgq8gzoLC/PQr7RsRDSTLUg/bZAZtF+TVIkHc6/4RIKrui+Q==",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/resolve": {
      "version": "1.22.10",
      "resolved": "https://registry.npmjs.org/resolve/-/resolve-1.22.10.tgz",
      "integrity": "sha512-NPRy+/ncIMeDlTAsuqwKIiferiawhefFJtkNSW0qZJEqMEb+qBt/77B/jGeeek+F0uOeN05CDa6HXbbIgtVX4w==",
      "dependencies": {
        "is-core-module": "^2.16.0",
        "path-parse": "^1.0.7",
        "supports-preserve-symlinks-flag": "^1.0.0"
      },
      "bin": {
        "resolve": "bin/resolve"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/resolve-protobuf-schema": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/resolve-protobuf-schema/-/resolve-protobuf-schema-2.1.0.tgz",
      "integrity": "sha512-kI5ffTiZWmJaS/huM8wZfEMer1eRd7oJQhDuxeCLe3t7N7mX3z94CN0xPxBQxFYQTSNz9T0i+v6inKqSdK8xrQ==",
      "dependencies": {
        "protocol-buffers-schema": "^3.3.1"
      }
    },
    "node_modules/rimraf": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/rimraf/-/rimraf-3.0.2.tgz",
      "integrity": "sha512-JZkJMZkAGFFPP2YqXZXPbMlMBgsxzE8ILs4lMIX/2o0L9UBw9O/Y3o6wFw/i9YLapcUJWwqbi3kdxIPdC62TIA==",
      "deprecated": "Rimraf versions prior to v4 are no longer supported",
      "dependencies": {
        "glob": "^7.1.3"
      },
      "bin": {
        "rimraf": "bin.js"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/roughjs": {
      "version": "4.5.2",
      "resolved": "https://registry.npmjs.org/roughjs/-/roughjs-4.5.2.tgz",
      "integrity": "sha512-2xSlLDKdsWyFxrveYWk9YQ/Y9UfK38EAMRNkYkMqYBJvPX8abCa9PN0x3w02H8Oa6/0bcZICJU+U95VumPqseg==",
      "dependencies": {
        "path-data-parser": "^0.1.0",
        "points-on-curve": "^0.2.0",
        "points-on-path": "^0.2.1"
      }
    },
    "node_modules/rw": {
      "version": "1.3.3",
      "resolved": "https://registry.npmjs.org/rw/-/rw-1.3.3.tgz",
      "integrity": "sha512-PdhdWy89SiZogBLaw42zdeqtRJ//zFd2PgQavcICDUgJT5oW10QCRKbJ6bg4r0/UY2M6BWd5tkxuGFRvCkgfHQ=="
    },
    "node_modules/safe-buffer": {
      "version": "5.2.1",
      "resolved": "https://registry.npmjs.org/safe-buffer/-/safe-buffer-5.2.1.tgz",
      "integrity": "sha512-rp3So07KcdmmKbGvgaNxQSJr7bGVSVk5S9Eq1F+ppbRo70+YeaDxkw5Dd8NPN+GD6bjnYm2VuPuCXmpuYvmCXQ==",
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/feross"
        },
        {
          "type": "patreon",
          "url": "https://www.patreon.com/feross"
        },
        {
          "type": "consulting",
          "url": "https://feross.org/support"
        }
      ]
    },
    "node_modules/safer-buffer": {
      "version": "2.1.2",
      "resolved": "https://registry.npmjs.org/safer-buffer/-/safer-buffer-2.1.2.tgz",
      "integrity": "sha512-YZo3K82SD7Riyi0E1EQPojLz7kpepnSQI9IyPbHHg1XXXevb5dJI7tpyN2ADxGcQbHG7vcyRHk0cbwqcQriUtg=="
    },
    "node_modules/semver": {
      "version": "7.7.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-7.7.1.tgz",
      "integrity": "sha512-hlq8tAfn0m/61p4BVRcPzIGr6LKiMwo4VM6dGi6pt4qcRkmNzTcWq6eCEjEh+qXjkMDvPlOFFSGwQjoEa6gyMA==",
      "bin": {
        "semver": "bin/semver.js"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/set-blocking": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/set-blocking/-/set-blocking-2.0.0.tgz",
      "integrity": "sha512-KiKBS8AnWGEyLzofFfmvKwpdPzqiy16LvQfK3yv/fVH7Bj13/wl3JSR1J+rfgRE9q7xUJK4qvgS8raSOeLUehw=="
    },
    "node_modules/shapefile": {
      "version": "0.6.6",
      "resolved": "https://registry.npmjs.org/shapefile/-/shapefile-0.6.6.tgz",
      "integrity": "sha512-rLGSWeK2ufzCVx05wYd+xrWnOOdSV7xNUW5/XFgx3Bc02hBkpMlrd2F1dDII7/jhWzv0MSyBFh5uJIy9hLdfuw==",
      "dependencies": {
        "array-source": "0.0",
        "commander": "2",
        "path-source": "0.1",
        "slice-source": "0.4",
        "stream-source": "0.3",
        "text-encoding": "^0.6.4"
      },
      "bin": {
        "dbf2json": "bin/dbf2json",
        "shp2json": "bin/shp2json"
      }
    },
    "node_modules/signal-exit": {
      "version": "3.0.7",
      "resolved": "https://registry.npmjs.org/signal-exit/-/signal-exit-3.0.7.tgz",
      "integrity": "sha512-wnD2ZE+l+SPC/uoS0vXeE9L1+0wuaMqKlfz9AMUo38JsyLSBWSFcHR1Rri62LZc12vLr1gb3jl7iwQhgwpAbGQ=="
    },
    "node_modules/simple-concat": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/simple-concat/-/simple-concat-1.0.1.tgz",
      "integrity": "sha512-cSFtAPtRhljv69IK0hTVZQ+OfE9nePi/rtJmw5UjHeVyVroEqJXP1sFztKUy1qU+xvz3u/sfYJLa947b7nAN2Q==",
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/feross"
        },
        {
          "type": "patreon",
          "url": "https://www.patreon.com/feross"
        },
        {
          "type": "consulting",
          "url": "https://feross.org/support"
        }
      ]
    },
    "node_modules/simple-get": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/simple-get/-/simple-get-3.1.1.tgz",
      "integrity": "sha512-CQ5LTKGfCpvE1K0n2us+kuMPbk/q0EKl82s4aheV9oXjFEz6W/Y7oQFVJuU6QG77hRT4Ghb5RURteF5vnWjupA==",
      "dependencies": {
        "decompress-response": "^4.2.0",
        "once": "^1.3.1",
        "simple-concat": "^1.0.0"
      }
    },
    "node_modules/simple-statistics": {
      "version": "7.8.8",
      "resolved": "https://registry.npmjs.org/simple-statistics/-/simple-statistics-7.8.8.tgz",
      "integrity": "sha512-CUtP0+uZbcbsFpqEyvNDYjJCl+612fNgjT8GaVuvMG7tBuJg8gXGpsP5M7X658zy0IcepWOZ6nPBu1Qb9ezA1w==",
      "engines": {
        "node": "*"
      }
    },
    "node_modules/simplify-geojson": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/simplify-geojson/-/simplify-geojson-1.0.5.tgz",
      "integrity": "sha512-02l1W4UipP5ivNVq6kX15mAzCRIV1oI3tz0FUEyOsNiv1ltuFDjbNhO+nbv/xhbDEtKqWLYuzpWhUsJrjR/ypA==",
      "dependencies": {
        "concat-stream": "~1.4.1",
        "minimist": "1.2.6",
        "simplify-geometry": "0.0.2"
      },
      "bin": {
        "simplify-geojson": "cli.js"
      }
    },
    "node_modules/simplify-geojson/node_modules/concat-stream": {
      "version": "1.4.11",
      "resolved": "https://registry.npmjs.org/concat-stream/-/concat-stream-1.4.11.tgz",
      "integrity": "sha512-X3JMh8+4je3U1cQpG87+f9lXHDrqcb2MVLg9L7o8b1UZ0DzhRrUpdn65ttzu10PpJPPI3MQNkis+oha6TSA9Mw==",
      "engines": [
        "node >= 0.8"
      ],
      "dependencies": {
        "inherits": "~2.0.1",
        "readable-stream": "~1.1.9",
        "typedarray": "~0.0.5"
      }
    },
    "node_modules/simplify-geojson/node_modules/minimist": {
      "version": "1.2.6",
      "resolved": "https://registry.npmjs.org/minimist/-/minimist-1.2.6.tgz",
      "integrity": "sha512-Jsjnk4bw3YJqYzbdyBiNsPWHPfO++UGG749Cxs6peCu5Xg4nrena6OVxOYxrQTqww0Jmwt+Ref8rggumkTLz9Q=="
    },
    "node_modules/simplify-geojson/node_modules/readable-stream": {
      "version": "1.1.14",
      "resolved": "https://registry.npmjs.org/readable-stream/-/readable-stream-1.1.14.tgz",
      "integrity": "sha512-+MeVjFf4L44XUkhM1eYbD8fyEsxcV81pqMSR5gblfcLCHfZvbrqy4/qYHE+/R5HoBUT11WV5O08Cr1n3YXkWVQ==",
      "dependencies": {
        "core-util-is": "~1.0.0",
        "inherits": "~2.0.1",
        "isarray": "0.0.1",
        "string_decoder": "~0.10.x"
      }
    },
    "node_modules/simplify-geojson/node_modules/string_decoder": {
      "version": "0.10.31",
      "resolved": "https://registry.npmjs.org/string_decoder/-/string_decoder-0.10.31.tgz",
      "integrity": "sha512-ev2QzSzWPYmy9GuqfIVildA4OdcGLeFZQrq5ys6RtiuF+RQQiZWr8TZNyAcuVXyQRYfEO+MsoB/1BuQVhOJuoQ=="
    },
    "node_modules/simplify-geometry": {
      "version": "0.0.2",
      "resolved": "https://registry.npmjs.org/simplify-geometry/-/simplify-geometry-0.0.2.tgz",
      "integrity": "sha512-ZEyrplkqgCqDlL7V8GbbYgTLlcnNF+MWWUdy8s8ZeJru50bnI71rDew/I+HG36QS2mPOYAq1ZjwNXxHJ8XOVBw=="
    },
    "node_modules/slice-source": {
      "version": "0.4.1",
      "resolved": "https://registry.npmjs.org/slice-source/-/slice-source-0.4.1.tgz",
      "integrity": "sha512-YiuPbxpCj4hD9Qs06hGAz/OZhQ0eDuALN0lRWJez0eD/RevzKqGdUx1IOMUnXgpr+sXZLq3g8ERwbAH0bCb8vg=="
    },
    "node_modules/stream-source": {
      "version": "0.3.5",
      "resolved": "https://registry.npmjs.org/stream-source/-/stream-source-0.3.5.tgz",
      "integrity": "sha512-ZuEDP9sgjiAwUVoDModftG0JtYiLUV8K4ljYD1VyUMRWtbVf92474o4kuuul43iZ8t/hRuiDAx1dIJSvirrK/g=="
    },
    "node_modules/string_decoder": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/string_decoder/-/string_decoder-1.3.0.tgz",
      "integrity": "sha512-hkRX8U1WjJFd8LsDJ2yQ/wWWxaopEsABU1XfkM8A+j0+85JAGppt16cr1Whg6KIbb4okU6Mql6BOj+uup/wKeA==",
      "dependencies": {
        "safe-buffer": "~5.2.0"
      }
    },
    "node_modules/string-similarity-js": {
      "version": "2.1.4",
      "resolved": "https://registry.npmjs.org/string-similarity-js/-/string-similarity-js-2.1.4.tgz",
      "integrity": "sha512-uApODZNjCHGYROzDSAdCmAHf60L/pMDHnP/yk6TAbvGg7JSPZlSto/ceCI7hZEqzc53/juU2aOJFkM2yUVTMTA=="
    },
    "node_modules/string-width": {
      "version": "4.2.3",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-4.2.3.tgz",
      "integrity": "sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g==",
      "dependencies": {
        "emoji-regex": "^8.0.0",
        "is-fullwidth-code-point": "^3.0.0",
        "strip-ansi": "^6.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/strip-ansi": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-6.0.1.tgz",
      "integrity": "sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==",
      "dependencies": {
        "ansi-regex": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/supports-preserve-symlinks-flag": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/supports-preserve-symlinks-flag/-/supports-preserve-symlinks-flag-1.0.0.tgz",
      "integrity": "sha512-ot0WnXS9fgdkgIcePe6RHNk1WA8+muPa6cSjeR3V8K27q9BB1rTE3R1p7Hv0z1ZyAc8s6Vvv8DIyWf681MAt0w==",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/tar": {
      "version": "6.2.1",
      "resolved": "https://registry.npmjs.org/tar/-/tar-6.2.1.tgz",
      "integrity": "sha512-DZ4yORTwrbTj/7MZYq2w+/ZFdI6OZ/f9SFHR+71gIVUZhOQPHzVCLpvRnPgyaMpfWxxk/4ONva3GQSyNIKRv6A==",
      "dependencies": {
        "chownr": "^2.0.0",
        "fs-minipass": "^2.0.0",
        "minipass": "^5.0.0",
        "minizlib": "^2.1.1",
        "mkdirp": "^1.0.3",
        "yallist": "^4.0.0"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/text-encoding": {
      "version": "0.6.4",
      "resolved": "https://registry.npmjs.org/text-encoding/-/text-encoding-0.6.4.tgz",
      "integrity": "sha512-hJnc6Qg3dWoOMkqP53F0dzRIgtmsAge09kxUIqGrEUS4qr5rWLckGYaQAVr+opBrIMRErGgy6f5aPnyPpyGRfg==",
      "deprecated": "no longer maintained"
    },
    "node_modules/topojson-client": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/topojson-client/-/topojson-client-3.1.0.tgz",
      "integrity": "sha512-605uxS6bcYxGXw9qi62XyrV6Q3xwbndjachmNxu8HWTtVPxZfEJN9fd/SZS1Q54Sn2y0TMyMxFj/cJINqGHrKw==",
      "dependencies": {
        "commander": "2"
      },
      "bin": {
        "topo2geo": "bin/topo2geo",
        "topomerge": "bin/topomerge",
        "topoquantize": "bin/topoquantize"
      }
    },
    "node_modules/topojson-server": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/topojson-server/-/topojson-server-3.0.1.tgz",
      "integrity": "sha512-/VS9j/ffKr2XAOjlZ9CgyyeLmgJ9dMwq6Y0YEON8O7p/tGGk+dCWnrE03zEdu7i4L7YsFZLEPZPzCvcB7lEEXw==",
      "dependencies": {
        "commander": "2"
      },
      "bin": {
        "geo2topo": "bin/geo2topo"
      }
    },
    "node_modules/tr46": {
      "version": "0.0.3",
      "resolved": "https://registry.npmjs.org/tr46/-/tr46-0.0.3.tgz",
      "integrity": "sha512-N3WMsuqV66lT30CrXNbEjx4GEwlow3v6rr4mCcv6prnfwhS01rkgyFdjPNBYd9br7LpXV1+Emh01fHnq2Gdgrw=="
    },
    "node_modules/ts-node": {
      "version": "10.9.2",
      "resolved": "https://registry.npmjs.org/ts-node/-/ts-node-10.9.2.tgz",
      "integrity": "sha512-f0FFpIdcHgn8zcPSbf1dRevwt047YMnaiJM3u2w2RewrB+fob/zePZcrOyQoLMMO7aBIddLcQIEK5dYjkLnGrQ==",
      "dev": true,
      "dependencies": {
        "@cspotcode/source-map-support": "^0.8.0",
        "@tsconfig/node10": "^1.0.7",
        "@tsconfig/node12": "^1.0.7",
        "@tsconfig/node14": "^1.0.0",
        "@tsconfig/node16": "^1.0.2",
        "acorn": "^8.4.1",
        "acorn-walk": "^8.1.1",
        "arg": "^4.1.0",
        "create-require": "^1.1.0",
        "diff": "^4.0.1",
        "make-error": "^1.1.1",
        "v8-compile-cache-lib": "^3.0.1",
        "yn": "3.1.1"
      },
      "bin": {
        "ts-node": "dist/bin.js",
        "ts-node-cwd": "dist/bin-cwd.js",
        "ts-node-esm": "dist/bin-esm.js",
        "ts-node-script": "dist/bin-script.js",
        "ts-node-transpile-only": "dist/bin-transpile.js",
        "ts-script": "dist/bin-script-deprecated.js"
      },
      "peerDependencies": {
        "@swc/core": ">=1.2.50",
        "@swc/wasm": ">=1.2.50",
        "@types/node": "*",
        "typescript": ">=2.7"
      },
      "peerDependenciesMeta": {
        "@swc/core": {
          "optional": true
        },
        "@swc/wasm": {
          "optional": true
        }
      }
    },
    "node_modules/ts-pattern": {
      "version": "4.1.4",
      "resolved": "https://bnpm.byted.org/ts-pattern/-/ts-pattern-4.1.4.tgz",
      "integrity": "sha512-Mcw65oUd1w5ktKi5BRwrnz16Otwk9iv7P0dKgvbi+A1albCDgnixohSqNLuFwIp5dzxPmTPm0iDQ6p1ZJr9uGw=="
    },
    "node_modules/typedarray": {
      "version": "0.0.6",
      "resolved": "https://registry.npmjs.org/typedarray/-/typedarray-0.0.6.tgz",
      "integrity": "sha512-/aCDEGatGvZ2BIk+HmLf4ifCJFwvKFNb9/JeZPMulfgFracn9QFcAf5GO8B/mweUjSoblS5In0cWhqpfs/5PQA=="
    },
    "node_modules/typescript": {
      "version": "5.8.2",
      "resolved": "https://registry.npmjs.org/typescript/-/typescript-5.8.2.tgz",
      "integrity": "sha512-aJn6wq13/afZp/jT9QZmwEjDqqvSGp1VT5GVg+f/t6/oVyrgXM6BY1h9BRh/O5p3PlUPAe+WuiEZOmb/49RqoQ==",
      "dev": true,
      "bin": {
        "tsc": "bin/tsc",
        "tsserver": "bin/tsserver"
      },
      "engines": {
        "node": ">=14.17"
      }
    },
    "node_modules/undici-types": {
      "version": "6.20.0",
      "resolved": "https://registry.npmjs.org/undici-types/-/undici-types-6.20.0.tgz",
      "integrity": "sha512-Ny6QZ2Nju20vw1SRHe3d9jVu6gJ+4e3+MMpqu7pqE5HT6WsTSlce++GQmK5UXS8mzV8DSYHrQH+Xrf2jVcuKNg==",
      "dev": true
    },
    "node_modules/util-deprecate": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/util-deprecate/-/util-deprecate-1.0.2.tgz",
      "integrity": "sha512-EPD5q1uXyFxJpCrLnCc1nHnq3gOa6DZBocAIiI2TaSCA7VCJ1UJDMagCzIkXNsUYfD1daK//LTEQ8xiIbrHtcw=="
    },
    "node_modules/v8-compile-cache-lib": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/v8-compile-cache-lib/-/v8-compile-cache-lib-3.0.1.tgz",
      "integrity": "sha512-wa7YjyUGfNZngI/vtK0UHAN+lgDCxBPCylVXGp0zu59Fz5aiGtNXaq3DhIov063MorB+VfufLh3JlF2KdTK3xg==",
      "dev": true
    },
    "node_modules/webidl-conversions": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/webidl-conversions/-/webidl-conversions-3.0.1.tgz",
      "integrity": "sha512-2JAn3z8AR6rjK8Sm8orRC0h/bcl/DqL7tRPdGZ4I1CjdF+EaMLmYxBHyXuKL849eucPFhvBoxMsflfOb8kxaeQ=="
    },
    "node_modules/whatwg-url": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/whatwg-url/-/whatwg-url-5.0.0.tgz",
      "integrity": "sha512-saE57nupxk6v3HY35+jzBwYa0rKSy0XR8JSxZPwgLr7ys0IBzhGviA1/TUGJLmSVqs8pb9AnvICXEuOHLprYTw==",
      "dependencies": {
        "tr46": "~0.0.3",
        "webidl-conversions": "^3.0.0"
      }
    },
    "node_modules/wide-align": {
      "version": "1.1.5",
      "resolved": "https://registry.npmjs.org/wide-align/-/wide-align-1.1.5.tgz",
      "integrity": "sha512-eDMORYaPNZ4sQIuuYPDHdQvf4gyCF9rEEV/yPxGfwPkRodwEgiMUUXTx/dex+Me0wxx53S+NgUHaP7y3MGlDmg==",
      "dependencies": {
        "string-width": "^1.0.2 || 2 || 3 || 4"
      }
    },
    "node_modules/wrap-ansi": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/wrap-ansi/-/wrap-ansi-7.0.0.tgz",
      "integrity": "sha512-YVGIj2kamLSTxw6NsZjoBxfSwsn0ycdesmc4p+Q21c5zPuZ1pl+NfxVdxPtdHvmNVOQ6XSYG4AUtyt/Fi7D16Q==",
      "dependencies": {
        "ansi-styles": "^4.0.0",
        "string-width": "^4.1.0",
        "strip-ansi": "^6.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/wrap-ansi?sponsor=1"
      }
    },
    "node_modules/wrappy": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/wrappy/-/wrappy-1.0.2.tgz",
      "integrity": "sha512-l4Sp/DRseor9wL6EvV2+TuQn63dMkPjZ/sp9XkghTEbV9KlPS1xUsZ3u7/IQO4wxtcFB4bgpQPRcR3QCvezPcQ=="
    },
    "node_modules/y18n": {
      "version": "5.0.8",
      "resolved": "https://registry.npmjs.org/y18n/-/y18n-5.0.8.tgz",
      "integrity": "sha512-0pfFzegeDWJHJIAmTLRP2DwHjdF5s7jo9tuztdQxAhINCdvS+3nGINqPd00AphqJR/0LhANUS6/+7SCb98YOfA==",
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/yallist": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/yallist/-/yallist-4.0.0.tgz",
      "integrity": "sha512-3wdGidZyq5PB084XLES5TpOSRA3wjXAlIWMhum2kRcv/41Sn2emQ0dycQW4uZXLejwKvg6EsvbdlVL+FYEct7A=="
    },
    "node_modules/yargs": {
      "version": "16.2.0",
      "resolved": "https://registry.npmjs.org/yargs/-/yargs-16.2.0.tgz",
      "integrity": "sha512-D1mvvtDG0L5ft/jGWkLpG1+m0eQxOfaBvTNELraWj22wSVUMWxZUvYgJYcKh6jGGIkJFhH4IZPQhR4TKpc8mBw==",
      "dependencies": {
        "cliui": "^7.0.2",
        "escalade": "^3.1.1",
        "get-caller-file": "^2.0.5",
        "require-directory": "^2.1.1",
        "string-width": "^4.2.0",
        "y18n": "^5.0.5",
        "yargs-parser": "^20.2.2"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/yargs-parser": {
      "version": "20.2.9",
      "resolved": "https://registry.npmjs.org/yargs-parser/-/yargs-parser-20.2.9.tgz",
      "integrity": "sha512-y11nGElTIV+CT3Zv9t7VKl+Q3hTQoT9a1Qzezhhl6Rp21gJ/IVTW7Z3y9EWXhuUBC2Shnf+DX0antecpAwSP8w==",
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/yn": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/yn/-/yn-3.1.1.tgz",
      "integrity": "sha512-Ux4ygGWsu2c7isFWe8Yu1YluJmqVhxqK2cLXNQA5AcC3QfbGNpM7fu0Y8b/z16pXLnFxZYvWhd3fhBY9DLmC6Q==",
      "dev": true,
      "engines": {
        "node": ">=6"
      }
    }
  }
}

```

### ARQUIVO: app/tool/chart_visualization/chart_prepare.py ###
```py
from app.tool.chart_visualization.python_execute import NormalPythonExecute


class VisualizationPrepare(NormalPythonExecute):
    """A tool for Chart Generation Preparation"""

    name: str = "visualization_preparation"
    description: str = "Using Python code to generates metadata of data_visualization tool. Outputs: 1) JSON Information. 2) Cleaned CSV data files (Optional)."
    parameters: dict = {
        "type": "object",
        "properties": {
            "code_type": {
                "description": "code type, visualization: csv -> chart; insight: choose insight into chart",
                "type": "string",
                "default": "visualization",
                "enum": ["visualization", "insight"],
            },
            "code": {
                "type": "string",
                "description": """Python code for data_visualization prepare.
## Visualization Type
1. Data loading logic
2. Csv Data and chart description generate
2.1 Csv data (The data you want to visulazation, cleaning / transform from origin data, saved in .csv)
2.2 Chart description of csv data (The chart title or description should be concise and clear. Examples: 'Product sales distribution', 'Monthly revenue trend'.)
3. Save information in json file.( format: {"csvFilePath": string, "chartTitle": string}[])
## Insight Type
1. Select the insights from the data_visualization results that you want to add to the chart.
2. Save information in json file.( format: {"chartPath": string, "insights_id": number[]}[])
# Note
1. You can generate one or multiple csv data with different visualization needs.
2. Make each chart data esay, clean and different.
3. Json file saving in utf-8 with path print: print(json_path)
""",
            },
        },
        "required": ["code", "code_type"],
    }

```

### ARQUIVO: app/tool/chart_visualization/README_zh.md ###
```md
# å›¾è¡¨å¯è§†åŒ–å·¥å…·

å›¾è¡¨å¯è§†åŒ–å·¥å…·ï¼Œé€šè¿‡pythonç”Ÿæˆæ•°æ®å¤„ç†ä»£ç ï¼Œæœ€ç»ˆè°ƒç”¨[@visactor/vmind](https://github.com/VisActor/VMind)å¾—åˆ°å›¾è¡¨çš„specç»“æœï¼Œå›¾è¡¨æ¸²æŸ“ä½¿ç”¨[@visactor/vchart](https://github.com/VisActor/VChart)

## å®‰è£…

1. å®‰è£…node >= 18

```bash
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash
# å®‰è£…å®Œæˆåé‡å¯ç»ˆç«¯ï¼Œç„¶åå®‰è£… Node æœ€æ–° LTS ç‰ˆæœ¬ï¼š
nvm install --lts
```

2. å®‰è£…ä¾èµ–

```bash
cd app/tool/chart_visualization
npm install
```
## Tool
### python_execute

ç”¨pythonä»£ç æ‰§è¡Œæ•°æ®åˆ†æï¼ˆé™¤æ•°æ®å¯è§†åŒ–ä»¥å¤–ï¼‰ä¸­éœ€è¦çš„éƒ¨åˆ†ï¼ŒåŒ…æ‹¬æ•°æ®å¤„ç†ï¼Œæ•°æ®æ€»ç»“æ‘˜è¦ï¼ŒæŠ¥å‘Šç”Ÿæˆä»¥åŠä¸€äº›é€šç”¨pythonè„šæœ¬ä»£ç 

#### è¾“å…¥
```typescript
{
  // ä»£ç ç±»å‹ï¼šæ•°æ®å¤„ç†/æ•°æ®æŠ¥å‘Š/å…¶ä»–é€šç”¨ä»»åŠ¡
  code_type: "process" | "report" | "others"
  // æœ€ç»ˆæ‰§è¡Œä»£ç 
  code: string;
}
```

#### è¾“å‡º
pythonæ‰§è¡Œç»“æœï¼Œå¸¦æœ‰ä¸­é—´æ–‡ä»¶çš„ä¿å­˜å’Œprintè¾“å‡ºç»“æœ

### visualization_preparation

æ•°æ®å¯è§†åŒ–å‰ç½®å·¥å…·ï¼Œæœ‰ä¸¤ç§ç”¨é€”ï¼Œ

#### Data -ã€‰ Chart
ç”¨äºä»æ•°æ®ä¸­æå–éœ€è¦åˆ†æçš„æ•°æ®(.csv)å’Œå¯¹åº”å¯è§†åŒ–çš„æè¿°ï¼Œæœ€ç»ˆè¾“å‡ºä¸€ä»½jsoné…ç½®æ–‡ä»¶ã€‚

#### Chart + Insight -> Chart
é€‰å–å·²æœ‰çš„å›¾è¡¨å’Œå¯¹åº”çš„æ•°æ®æ´å¯Ÿï¼ŒæŒ‘é€‰æ•°æ®æ´å¯Ÿä»¥æ•°æ®æ ‡æ³¨çš„å½¢å¼å¢åŠ åˆ°å›¾è¡¨ä¸­ï¼Œæœ€ç»ˆç”Ÿæˆä¸€ä»½jsoné…ç½®æ–‡ä»¶ã€‚

#### è¾“å…¥
```typescript
{
  // ä»£ç ç±»å‹ï¼šæ•°æ®å¯è§†åŒ– æˆ–è€… æ•°æ®æ´å¯Ÿæ·»åŠ 
  code_type: "visualization" | "insight"
  // ç”¨äºç”Ÿäº§æœ€ç»ˆjsonæ–‡ä»¶çš„pythonä»£ç 
  code: string;
}
```

#### è¾“å‡º
æ•°æ®å¯è§†åŒ–çš„é…ç½®æ–‡ä»¶ï¼Œç”¨äº`data_visualization tool`


## data_visualization

æ ¹æ®`visualization_preparation`çš„å†…å®¹ï¼Œç”Ÿæˆå…·ä½“çš„æ•°æ®å¯è§†åŒ–

### è¾“å…¥
```typescript
{
  // é…ç½®æ–‡ä»¶è·¯å¾„
  json_path: string;
  // å½“å‰ç”¨é€”ï¼Œæ•°æ®å¯è§†åŒ–æˆ–è€…æ´å¯Ÿæ ‡æ³¨æ·»åŠ 
  tool_type: "visualization" | "insight";
  // æœ€ç»ˆäº§ç‰©pngæˆ–è€…html;htmlä¸‹æ”¯æŒvchartæ¸²æŸ“å’Œäº¤äº’
  output_type: 'png' | 'html'
  // è¯­è¨€,ç›®å‰æ”¯æŒä¸­æ–‡å’Œè‹±æ–‡
  language: "zh" | "en"
}
```

## è¾“å‡º
æœ€ç»ˆä»¥'png'æˆ–è€…'html'çš„å½¢å¼ä¿å­˜åœ¨æœ¬åœ°ï¼Œè¾“å‡ºä¿å­˜çš„å›¾è¡¨è·¯å¾„ä»¥åŠå›¾è¡¨ä¸­å‘ç°çš„æ•°æ®æ´å¯Ÿ

## VMindé…ç½®

### LLM

VMindæœ¬èº«ä¹Ÿéœ€è¦é€šè¿‡è°ƒç”¨å¤§æ¨¡å‹å¾—åˆ°æ™ºèƒ½å›¾è¡¨ç”Ÿæˆç»“æœï¼Œç›®å‰é»˜è®¤ä¼šä½¿ç”¨`config.llm["default"]`é…ç½®

### ç”Ÿæˆé…ç½®

ä¸»è¦ç”Ÿæˆé…ç½®åŒ…æ‹¬å›¾è¡¨çš„å®½é«˜ã€ä¸»é¢˜ä»¥åŠç”Ÿæˆæ–¹å¼ï¼›
### ç”Ÿæˆæ–¹å¼
é»˜è®¤ä¸ºpngï¼Œç›®å‰æ”¯æŒå¤§æ¨¡å‹æ ¹æ®ä¸Šä¸‹æ–‡è‡ªå·±é€‰æ‹©`output_type`

### å®½é«˜
ç›®å‰é»˜è®¤ä¸æŒ‡å®šå®½é«˜ï¼Œ`html`ä¸‹é»˜è®¤å æ»¡æ•´ä¸ªé¡µé¢ï¼Œ'png'ä¸‹é»˜è®¤ä¸º`1000 * 1000`

### ä¸»é¢˜
ç›®å‰é»˜è®¤ä¸»é¢˜ä¸º`'light'`ï¼ŒVChartå›¾è¡¨æ”¯æŒå¤šç§ä¸»é¢˜ï¼Œè¯¦è§[ä¸»é¢˜](https://www.visactor.io/vchart/guide/tutorial_docs/Theme/Theme_Extension)


## æµ‹è¯•

å½“å‰è®¾ç½®äº†ä¸‰ç§ä¸åŒéš¾åº¦çš„ä»»åŠ¡ç”¨äºæµ‹è¯•

### ç®€å•å›¾è¡¨ç”Ÿæˆä»»åŠ¡

ç»™äºˆæ•°æ®å’Œå…·ä½“çš„å›¾è¡¨ç”Ÿæˆéœ€æ±‚ï¼Œæµ‹è¯•ç»“æœï¼Œæ‰§è¡Œå‘½ä»¤ï¼š
```bash
python -m app.tool.chart_visualization.test.simple_chart
```
ç»“æœåº”ä½äº`worksapce\visualization`ä¸‹ï¼Œæ¶‰åŠåˆ°9ç§ä¸åŒçš„å›¾è¡¨ç»“æœ

### ç®€å•æ•°æ®æŠ¥è¡¨ä»»åŠ¡

ç»™äºˆç®€å•åŸå§‹æ•°æ®å¯åˆ†æéœ€æ±‚ï¼Œéœ€è¦å¯¹æ•°æ®è¿›è¡Œç®€å•åŠ å·¥å¤„ç†ï¼Œæ‰§è¡Œå‘½ä»¤ï¼š
```bash
python -m app.tool.chart_visualization.test.simple_report
```
ç»“æœåŒæ ·ä½äº`worksapce\visualization`ä¸‹

```

### ARQUIVO: app/tool/chart_visualization/tsconfig.json ###
```json
{
  "include": [
    "src/**/*.ts",
  ],
  "compilerOptions": {
    /* Visit https://aka.ms/tsconfig to read more about this file */
    /* Projects */
    // "incremental": true,                              /* Save .tsbuildinfo files to allow for incremental compilation of projects. */
    // "composite": true,                                /* Enable constraints that allow a TypeScript project to be used with project references. */
    // "tsBuildInfoFile": "./.tsbuildinfo",              /* Specify the path to .tsbuildinfo incremental compilation file. */
    // "disableSourceOfProjectReferenceRedirect": true,  /* Disable preferring source files instead of declaration files when referencing composite projects. */
    // "disableSolutionSearching": true,                 /* Opt a project out of multi-project reference checking when editing. */
    // "disableReferencedProjectLoad": true,             /* Reduce the number of projects loaded automatically by TypeScript. */
    /* Language and Environment */
    "target": "ES2021", /* Set the JavaScript language version for emitted JavaScript and include compatible library declarations. */
    // "lib": [],                                        /* Specify a set of bundled library declaration files that describe the target runtime environment. */
    // "jsx": "preserve",                                /* Specify what JSX code is generated. */
    // "experimentalDecorators": true,                   /* Enable experimental support for legacy experimental decorators. */
    // "emitDecoratorMetadata": true,                    /* Emit design-type metadata for decorated declarations in source files. */
    // "jsxFactory": "",                                 /* Specify the JSX factory function used when targeting React JSX emit, e.g. 'React.createElement' or 'h'. */
    // "jsxFragmentFactory": "",                         /* Specify the JSX Fragment reference used for fragments when targeting React JSX emit e.g. 'React.Fragment' or 'Fragment'. */
    // "jsxImportSource": "",                            /* Specify module specifier used to import the JSX factory functions when using 'jsx: react-jsx*'. */
    // "reactNamespace": "",                             /* Specify the object invoked for 'createElement'. This only applies when targeting 'react' JSX emit. */
    // "noLib": true,                                    /* Disable including any library files, including the default lib.d.ts. */
    // "useDefineForClassFields": true,                  /* Emit ECMAScript-standard-compliant class fields. */
    // "moduleDetection": "auto",                        /* Control what method is used to detect module-format JS files. */
    /* Modules */
    "module": "commonjs", /* Specify what module code is generated. */
    // "rootDir": "./",                                  /* Specify the root folder within your source files. */
    "moduleResolution": "node", /* Specify how TypeScript looks up a file from a given module specifier. */
    // "baseUrl": "./",                                  /* Specify the base directory to resolve non-relative module names. */
    // "paths": {},                                      /* Specify a set of entries that re-map imports to additional lookup locations. */
    // "rootDirs": [],                                   /* Allow multiple folders to be treated as one when resolving modules. */
    "typeRoots": [
      "./node_modules/@types",
      "src/types"
    ], /* Specify multiple folders that act like './node_modules/@types'. */
    // "types": [],                                      /* Specify type package names to be included without being referenced in a source file. */
    // "allowUmdGlobalAccess": true,                     /* Allow accessing UMD globals from modules. */
    // "moduleSuffixes": [],                             /* List of file name suffixes to search when resolving a module. */
    // "allowImportingTsExtensions": true,               /* Allow imports to include TypeScript file extensions. Requires '--moduleResolution bundler' and either '--noEmit' or '--emitDeclarationOnly' to be set. */
    // "rewriteRelativeImportExtensions": true,          /* Rewrite '.ts', '.tsx', '.mts', and '.cts' file extensions in relative import paths to their JavaScript equivalent in output files. */
    // "resolvePackageJsonExports": true,                /* Use the package.json 'exports' field when resolving package imports. */
    // "resolvePackageJsonImports": true,                /* Use the package.json 'imports' field when resolving imports. */
    // "customConditions": [],                           /* Conditions to set in addition to the resolver-specific defaults when resolving imports. */
    // "noUncheckedSideEffectImports": true,             /* Check side effect imports. */
    // "resolveJsonModule": true,                        /* Enable importing .json files. */
    // "allowArbitraryExtensions": true,                 /* Enable importing files with any extension, provided a declaration file is present. */
    // "noResolve": true,                                /* Disallow 'import's, 'require's or '<reference>'s from expanding the number of files TypeScript should add to a project. */
    /* JavaScript Support */
    "allowJs": true, /* Allow JavaScript files to be a part of your program. Use the 'checkJS' option to get errors from these files. */
    "checkJs": false, /* Enable error reporting in type-checked JavaScript files. */
    // "maxNodeModuleJsDepth": 1,                        /* Specify the maximum folder depth used for checking JavaScript files from 'node_modules'. Only applicable with 'allowJs'. */
    /* Emit */
    // "declaration": true,                              /* Generate .d.ts files from TypeScript and JavaScript files in your project. */
    // "declarationMap": true,                           /* Create sourcemaps for d.ts files. */
    // "emitDeclarationOnly": true,                      /* Only output d.ts files and not JavaScript files. */
    // "sourceMap": true,                                /* Create source map files for emitted JavaScript files. */
    // "inlineSourceMap": true,                          /* Include sourcemap files inside the emitted JavaScript. */
    // "noEmit": true,                                   /* Disable emitting files from a compilation. */
    // "outFile": "./",                                  /* Specify a file that bundles all outputs into one JavaScript file. If 'declaration' is true, also designates a file that bundles all .d.ts output. */
    // "outDir": "./",                                   /* Specify an output folder for all emitted files. */
    // "removeComments": true,                           /* Disable emitting comments. */
    // "importHelpers": true,                            /* Allow importing helper functions from tslib once per project, instead of including them per-file. */
    // "downlevelIteration": true,                       /* Emit more compliant, but verbose and less performant JavaScript for iteration. */
    // "sourceRoot": "",                                 /* Specify the root path for debuggers to find the reference source code. */
    // "mapRoot": "",                                    /* Specify the location where debugger should locate map files instead of generated locations. */
    // "inlineSources": true,                            /* Include source code in the sourcemaps inside the emitted JavaScript. */
    // "emitBOM": true,                                  /* Emit a UTF-8 Byte Order Mark (BOM) in the beginning of output files. */
    // "newLine": "crlf",                                /* Set the newline character for emitting files. */
    // "stripInternal": true,                            /* Disable emitting declarations that have '@internal' in their JSDoc comments. */
    // "noEmitHelpers": true,                            /* Disable generating custom helper functions like '__extends' in compiled output. */
    // "noEmitOnError": true,                            /* Disable emitting files if any type checking errors are reported. */
    // "preserveConstEnums": true,                       /* Disable erasing 'const enum' declarations in generated code. */
    // "declarationDir": "./",                           /* Specify the output directory for generated declaration files. */
    /* Interop Constraints */
    // "isolatedModules": true,                          /* Ensure that each file can be safely transpiled without relying on other imports. */
    // "verbatimModuleSyntax": true,                     /* Do not transform or elide any imports or exports not marked as type-only, ensuring they are written in the output file's format based on the 'module' setting. */
    // "isolatedDeclarations": true,                     /* Require sufficient annotation on exports so other tools can trivially generate declaration files. */
    // "allowSyntheticDefaultImports": true,             /* Allow 'import x from y' when a module doesn't have a default export. */
    "esModuleInterop": true, /* Emit additional JavaScript to ease support for importing CommonJS modules. This enables 'allowSyntheticDefaultImports' for type compatibility. */
    // "preserveSymlinks": true,                         /* Disable resolving symlinks to their realpath. This correlates to the same flag in node. */
    "forceConsistentCasingInFileNames": true, /* Ensure that casing is correct in imports. */
    /* Type Checking */
    "strict": true, /* Enable all strict type-checking options. */
    // "noImplicitAny": true,                            /* Enable error reporting for expressions and declarations with an implied 'any' type. */
    // "strictNullChecks": true,                         /* When type checking, take into account 'null' and 'undefined'. */
    // "strictFunctionTypes": true,                      /* When assigning functions, check to ensure parameters and the return values are subtype-compatible. */
    // "strictBindCallApply": true,                      /* Check that the arguments for 'bind', 'call', and 'apply' methods match the original function. */
    // "strictPropertyInitialization": true,             /* Check for class properties that are declared but not set in the constructor. */
    // "strictBuiltinIteratorReturn": true,              /* Built-in iterators are instantiated with a 'TReturn' type of 'undefined' instead of 'any'. */
    // "noImplicitThis": true,                           /* Enable error reporting when 'this' is given the type 'any'. */
    // "useUnknownInCatchVariables": true,               /* Default catch clause variables as 'unknown' instead of 'any'. */
    // "alwaysStrict": true,                             /* Ensure 'use strict' is always emitted. */
    // "noUnusedLocals": true,                           /* Enable error reporting when local variables aren't read. */
    // "noUnusedParameters": true,                       /* Raise an error when a function parameter isn't read. */
    // "exactOptionalPropertyTypes": true,               /* Interpret optional property types as written, rather than adding 'undefined'. */
    // "noImplicitReturns": true,                        /* Enable error reporting for codepaths that do not explicitly return in a function. */
    // "noFallthroughCasesInSwitch": true,               /* Enable error reporting for fallthrough cases in switch statements. */
    // "noUncheckedIndexedAccess": true,                 /* Add 'undefined' to a type when accessed using an index. */
    // "noImplicitOverride": true,                       /* Ensure overriding members in derived classes are marked with an override modifier. */
    // "noPropertyAccessFromIndexSignature": true,       /* Enforces using indexed accessors for keys declared using an indexed type. */
    // "allowUnusedLabels": true,                        /* Disable error reporting for unused labels. */
    // "allowUnreachableCode": true,                     /* Disable error reporting for unreachable code. */
    /* Completeness */
    // "skipDefaultLibCheck": true,                      /* Skip type checking .d.ts files that are included with TypeScript. */
    "skipLibCheck": true /* Skip type checking all .d.ts files. */
  }
}

```

### ARQUIVO: app/tool/chart_visualization/src/chartVisualize.ts ###
```ts
import Canvas from "canvas";
import path from "path";
import fs from "fs";
import VMind, { ChartType, DataTable } from "@visactor/vmind";
import VChart from "@visactor/vchart";
import { isString } from "@visactor/vutils";

enum AlgorithmType {
  OverallTrending = "overallTrend",
  AbnormalTrend = "abnormalTrend",
  PearsonCorrelation = "pearsonCorrelation",
  SpearmanCorrelation = "spearmanCorrelation",
  ExtremeValue = "extremeValue",
  MajorityValue = "majorityValue",
  StatisticsAbnormal = "statisticsAbnormal",
  StatisticsBase = "statisticsBase",
  DbscanOutlier = "dbscanOutlier",
  LOFOutlier = "lofOutlier",
  TurningPoint = "turningPoint",
  PageHinkley = "pageHinkley",
  DifferenceOutlier = "differenceOutlier",
  Volatility = "volatility",
}

const getBase64 = async (spec: any, width?: number, height?: number) => {
  spec.animation = false;
  width && (spec.width = width);
  height && (spec.height = height);
  const cs = new VChart(spec, {
    mode: "node",
    modeParams: Canvas,
    animation: false,
    dpr: 2,
  });

  await cs.renderAsync();

  const buffer = await cs.getImageBuffer();
  return buffer;
};

const serializeSpec = (spec: any) => {
  return JSON.stringify(spec, (key, value) => {
    if (typeof value === "function") {
      const funcStr = value
        .toString()
        .replace(/(\r\n|\n|\r)/gm, "")
        .replace(/\s+/g, " ");

      return `__FUNCTION__${funcStr}`;
    }
    return value;
  });
};

async function getHtmlVChart(spec: any, width?: number, height?: number) {
  return `<!DOCTYPE html>
<html>
<head>
    <title>VChart ç¤ºä¾‹</title>
    <script src="https://unpkg.com/@visactor/vchart/build/index.min.js"></script>
</head>
<body>
    <div id="chart-container" style="width: ${
      width ? `${width}px` : "100%"
    }; height: ${height ? `${height}px` : "100%"};"></div>
    <script>
      // parse spec with function
      function parseSpec(stringSpec) {
        return JSON.parse(stringSpec, (k, v) => {
          if (typeof v === 'string' && v.startsWith('__FUNCTION__')) {
            const funcBody = v.slice(12); // ç§»é™¤æ ‡è®°
            try {
              return new Function('return (' + funcBody + ')')();
            } catch(e) {
              console.error('å‡½æ•°è§£æå¤±è´¥:', e);
              return () => {};
            }
          }
          return v;
        });
      }
      const spec = parseSpec(\`${serializeSpec(spec)}\`);
      const chart = new VChart.VChart(spec, {
          dom: 'chart-container'
      });
      chart.renderSync();
    </script>
</body>
</html>
`;
}

/**
 * get file path saved string
 * @param isUpdate {boolean} default: false, update existed file when is true
 */
function getSavedPathName(
  directory: string,
  fileName: string,
  outputType: "html" | "png" | "json" | "md",
  isUpdate: boolean = false
) {
  let newFileName = fileName;
  while (
    !isUpdate &&
    fs.existsSync(
      path.join(directory, "visualization", `${newFileName}.${outputType}`)
    )
  ) {
    newFileName += "_new";
  }
  return path.join(directory, "visualization", `${newFileName}.${outputType}`);
}

const readStdin = (): Promise<string> => {
  return new Promise((resolve) => {
    let input = "";
    process.stdin.setEncoding("utf-8"); // ç¡®ä¿ç¼–ç ä¸ Python ç«¯ä¸€è‡´
    process.stdin.on("data", (chunk) => (input += chunk));
    process.stdin.on("end", () => resolve(input));
  });
};

/** Save insights markdown in local, and return content && path */
const setInsightTemplate = (
  path: string,
  title: string,
  insights: string[]
) => {
  let res = "";
  if (insights.length) {
    res += `## ${title} Insights`;
    insights.forEach((insight, index) => {
      res += `\n${index + 1}. ${insight}`;
    });
  }
  if (res) {
    fs.writeFileSync(path, res, "utf-8");
    return { insight_path: path, insight_md: res };
  }
  return {};
};

/** Save vmind result into local file, Return chart file path */
async function saveChartRes(options: {
  spec: any;
  directory: string;
  outputType: "png" | "html";
  fileName: string;
  width?: number;
  height?: number;
  isUpdate?: boolean;
}) {
  const { directory, fileName, spec, outputType, width, height, isUpdate } =
    options;
  const specPath = getSavedPathName(directory, fileName, "json", isUpdate);
  fs.writeFileSync(specPath, JSON.stringify(spec, null, 2));
  const savedPath = getSavedPathName(directory, fileName, outputType, isUpdate);
  if (outputType === "png") {
    const base64 = await getBase64(spec, width, height);
    fs.writeFileSync(savedPath, base64);
  } else {
    const html = await getHtmlVChart(spec, width, height);
    fs.writeFileSync(savedPath, html, "utf-8");
  }
  return savedPath;
}

async function generateChart(
  vmind: VMind,
  options: {
    dataset: string | DataTable;
    userPrompt: string;
    directory: string;
    outputType: "png" | "html";
    fileName: string;
    width?: number;
    height?: number;
    language?: "en" | "zh";
  }
) {
  let res: {
    chart_path?: string;
    error?: string;
    insight_path?: string;
    insight_md?: string;
  } = {};
  const {
    dataset,
    userPrompt,
    directory,
    width,
    height,
    outputType,
    fileName,
    language,
  } = options;
  try {
    // Get chart spec and save in local file
    const jsonDataset = isString(dataset) ? JSON.parse(dataset) : dataset;
    const { spec, error, chartType } = await vmind.generateChart(
      userPrompt,
      undefined,
      jsonDataset,
      {
        enableDataQuery: false,
        theme: "light",
      }
    );
    if (error || !spec) {
      return {
        error: error || "Spec of Chart was Empty!",
      };
    }

    spec.title = {
      text: userPrompt,
    };
    if (!fs.existsSync(path.join(directory, "visualization"))) {
      fs.mkdirSync(path.join(directory, "visualization"));
    }
    const specPath = getSavedPathName(directory, fileName, "json");
    res.chart_path = await saveChartRes({
      directory,
      spec,
      width,
      height,
      fileName,
      outputType,
    });

    // get chart insights and save in local
    const insights = [];
    if (
      chartType &&
      [
        ChartType.BarChart,
        ChartType.LineChart,
        ChartType.AreaChart,
        ChartType.ScatterPlot,
        ChartType.DualAxisChart,
      ].includes(chartType)
    ) {
      const { insights: vmindInsights } = await vmind.getInsights(spec, {
        maxNum: 6,
        algorithms: [
          AlgorithmType.OverallTrending,
          AlgorithmType.AbnormalTrend,
          AlgorithmType.PearsonCorrelation,
          AlgorithmType.SpearmanCorrelation,
          AlgorithmType.StatisticsAbnormal,
          AlgorithmType.LOFOutlier,
          AlgorithmType.DbscanOutlier,
          AlgorithmType.MajorityValue,
          AlgorithmType.PageHinkley,
          AlgorithmType.TurningPoint,
          AlgorithmType.StatisticsBase,
          AlgorithmType.Volatility,
        ],
        usePolish: false,
        language: language === "en" ? "english" : "chinese",
      });
      insights.push(...vmindInsights);
    }
    const insightsText = insights
      .map((insight) => insight.textContent?.plainText)
      .filter((insight) => !!insight) as string[];
    spec.insights = insights;
    fs.writeFileSync(specPath, JSON.stringify(spec, null, 2));
    res = {
      ...res,
      ...setInsightTemplate(
        getSavedPathName(directory, fileName, "md"),
        userPrompt,
        insightsText
      ),
    };
  } catch (error: any) {
    res.error = error.toString();
  } finally {
    return res;
  }
}

async function updateChartWithInsight(
  vmind: VMind,
  options: {
    directory: string;
    outputType: "png" | "html";
    fileName: string;
    insightsId: number[];
  }
) {
  const { directory, outputType, fileName, insightsId } = options;
  let res: { error?: string; chart_path?: string } = {};
  try {
    const specPath = getSavedPathName(directory, fileName, "json", true);
    const spec = JSON.parse(fs.readFileSync(specPath, "utf8"));
    // llm select index from 1
    const insights = (spec.insights || []).filter(
      (_insight: any, index: number) => insightsId.includes(index + 1)
    );
    const { newSpec, error } = await vmind.updateSpecByInsights(spec, insights);
    if (error) {
      throw error;
    }
    res.chart_path = await saveChartRes({
      spec: newSpec,
      directory,
      outputType,
      fileName,
      isUpdate: true,
    });
  } catch (error: any) {
    res.error = error.toString();
  } finally {
    return res;
  }
}

async function executeVMind() {
  const input = await readStdin();
  const inputData = JSON.parse(input);
  let res;
  const {
    llm_config,
    width,
    dataset = [],
    height,
    directory,
    user_prompt: userPrompt,
    output_type: outputType = "png",
    file_name: fileName,
    task_type: taskType = "visualization",
    insights_id: insightsId = [],
    language = "en",
  } = inputData;
  const { base_url: baseUrl, model, api_key: apiKey } = llm_config;
  const vmind = new VMind({
    url: `${baseUrl}/chat/completions`,
    model,
    headers: {
      "api-key": apiKey,
      Authorization: `Bearer ${apiKey}`,
    },
  });
  if (taskType === "visualization") {
    res = await generateChart(vmind, {
      dataset,
      userPrompt,
      directory,
      outputType,
      fileName,
      width,
      height,
      language,
    });
  } else if (taskType === "insight" && insightsId.length) {
    res = await updateChartWithInsight(vmind, {
      directory,
      fileName,
      outputType,
      insightsId,
    });
  }
  console.log(JSON.stringify(res));
}

executeVMind();

```

### ARQUIVO: app/tool/chart_visualization/test/report_demo.py ###
```py
import asyncio

from app.agent.data_analysis import DataAnalysis


# from app.agent.manus import Manus


async def main():
    agent = DataAnalysis()
    # agent = Manus()
    await agent.run(
        """Requirement:
1. Analyze the following data and generate a graphical data report in HTML format. The final product should be a data report.
Data:
Month | Team A | Team B | Team C
January | 1200 hours | 1350 hours | 1100 hours
February | 1250 hours | 1400 hours | 1150 hours
March | 1180 hours | 1300 hours | 1300 hours
April | 1220 hours | 1280 hours | 1400 hours
May | 1230 hours | 1320 hours | 1450 hours
June | 1200 hours | 1250 hours | 1500 hours  """
    )


if __name__ == "__main__":
    asyncio.run(main())

```

### ARQUIVO: app/tool/chart_visualization/test/chart_demo.py ###
```py
import asyncio

from app.agent.data_analysis import DataAnalysis
from app.logger import logger


prefix = "Help me generate charts and save them locally, specifically:"
tasks = [
    {
        "prompt": "Help me show the sales of different products in different regions",
        "data": """Product Name,Region,Sales
Coke,South,2350
Coke,East,1027
Coke,West,1027
Coke,North,1027
Sprite,South,215
Sprite,East,654
Sprite,West,159
Sprite,North,28
Fanta,South,345
Fanta,East,654
Fanta,West,2100
Fanta,North,1679
Xingmu,South,1476
Xingmu,East,830
Xingmu,West,532
Xingmu,North,498
""",
    },
    {
        "prompt": "Show market share of each brand",
        "data": """Brand Name,Market Share,Average Price,Net Profit
Apple,0.5,7068,314531
Samsung,0.2,6059,362345
Vivo,0.05,3406,234512
Nokia,0.01,1064,-1345
Xiaomi,0.1,4087,131345""",
    },
    {
        "prompt": "Please help me show the sales trend of each product",
        "data": """Date,Type,Value
2023-01-01,Product A,52.9
2023-01-01,Product B,63.6
2023-01-01,Product C,11.2
2023-01-02,Product A,45.7
2023-01-02,Product B,89.1
2023-01-02,Product C,21.4
2023-01-03,Product A,67.2
2023-01-03,Product B,82.4
2023-01-03,Product C,31.7
2023-01-04,Product A,80.7
2023-01-04,Product B,55.1
2023-01-04,Product C,21.1
2023-01-05,Product A,65.6
2023-01-05,Product B,78
2023-01-05,Product C,31.3
2023-01-06,Product A,75.6
2023-01-06,Product B,89.1
2023-01-06,Product C,63.5
2023-01-07,Product A,67.3
2023-01-07,Product B,77.2
2023-01-07,Product C,43.7
2023-01-08,Product A,96.1
2023-01-08,Product B,97.6
2023-01-08,Product C,59.9
2023-01-09,Product A,96.1
2023-01-09,Product B,100.6
2023-01-09,Product C,66.8
2023-01-10,Product A,101.6
2023-01-10,Product B,108.3
2023-01-10,Product C,56.9""",
    },
    {
        "prompt": "Show the popularity of search keywords",
        "data": """Keyword,Popularity
Hot Word,1000
Zao Le Wo Men,800
Rao Jian Huo,400
My Wish is World Peace,400
Xiu Xiu Xiu,400
Shenzhou 11,400
Hundred Birds Facing the Wind,400
China Women's Volleyball Team,400
My Guan Na,400
Leg Dong,400
Hot Pot Hero,400
Baby's Heart is Bitter,400
Olympics,400
Awesome My Brother,400
Poetry and Distance,400
Song Joong-ki,400
PPAP,400
Blue Thin Mushroom,400
Rain Dew Evenly,400
Friendship's Little Boat Says It Flips,400
Beijing Slump,400
Dedication,200
Apple,200
Dog Belt,200
Old Driver,200
Melon-Eating Crowd,200
Zootopia,200
City Will Play,200
Routine,200
Water Reverse,200
Why Don't You Go to Heaven,200
Snake Spirit Man,200
Why Don't You Go to Heaven,200
Samsung Explosion Gate,200
Little Li Oscar,200
Ugly People Need to Read More,200
Boyfriend Power,200
A Face of Confusion,200
Descendants of the Sun,200""",
    },
    {
        "prompt": "Help me compare the performance of different electric vehicle brands using a scatter plot",
        "data": """Range,Charging Time,Brand Name,Average Price
2904,46,Brand1,2350
1231,146,Brand2,1027
5675,324,Brand3,1242
543,57,Brand4,6754
326,234,Brand5,215
1124,67,Brand6,654
3426,81,Brand7,159
2134,24,Brand8,28
1234,52,Brand9,345
2345,27,Brand10,654
526,145,Brand11,2100
234,93,Brand12,1679
567,94,Brand13,1476
789,45,Brand14,830
469,75,Brand15,532
5689,54,Brand16,498
""",
    },
    {
        "prompt": "Show conversion rates for each process",
        "data": """Process,Conversion Rate,Month
Step1,100,1
Step2,80,1
Step3,60,1
Step4,40,1""",
    },
    {
        "prompt": "Show the difference in breakfast consumption between men and women",
        "data": """Day,Men-Breakfast,Women-Breakfast
Monday,15,22
Tuesday,12,10
Wednesday,15,20
Thursday,10,12
Friday,13,15
Saturday,10,15
Sunday,12,14""",
    },
    {
        "prompt": "Help me show this person's performance in different aspects, is he a hexagonal warrior",
        "data": """dimension,performance
Strength,5
Speed,5
Shooting,3
Endurance,5
Precision,5
Growth,5""",
    },
    {
        "prompt": "Show data flow",
        "data": """Origin,Destination,value
Node A,Node 1,10
Node A,Node 2,5
Node B,Node 2,8
Node B,Node 3,2
Node C,Node 2,4
Node A,Node C,2
Node C,Node 1,2""",
    },
]


async def main():
    for index, item in enumerate(tasks):
        logger.info(f"Begin task {index} / {len(tasks)}!")
        agent = DataAnalysis()
        await agent.run(
            f"{prefix},chart_description:{item['prompt']},Data:{item['data']}"
        )
        logger.info(f"Finish with {item['prompt']}")


if __name__ == "__main__":
    asyncio.run(main())

```

### ARQUIVO: app/tool/search/duckduckgo_search.py ###
```py
from typing import List

from duckduckgo_search import DDGS

from app.tool.search.base import SearchItem, WebSearchEngine


class DuckDuckGoSearchEngine(WebSearchEngine):
    def perform_search(
        self, query: str, num_results: int = 10, *args, **kwargs
    ) -> List[SearchItem]:
        """
        DuckDuckGo search engine.

        Returns results formatted according to SearchItem model.
        """
        raw_results = DDGS().text(query, max_results=num_results)

        results = []
        for i, item in enumerate(raw_results):
            if isinstance(item, str):
                # If it's just a URL
                results.append(
                    SearchItem(
                        title=f"DuckDuckGo Result {i + 1}", url=item, description=None
                    )
                )
            elif isinstance(item, dict):
                # Extract data from the dictionary
                results.append(
                    SearchItem(
                        title=item.get("title", f"DuckDuckGo Result {i + 1}"),
                        url=item.get("href", ""),
                        description=item.get("body", None),
                    )
                )
            else:
                # Try to extract attributes directly
                try:
                    results.append(
                        SearchItem(
                            title=getattr(item, "title", f"DuckDuckGo Result {i + 1}"),
                            url=getattr(item, "href", ""),
                            description=getattr(item, "body", None),
                        )
                    )
                except Exception:
                    # Fallback
                    results.append(
                        SearchItem(
                            title=f"DuckDuckGo Result {i + 1}",
                            url=str(item),
                            description=None,
                        )
                    )

        return results

```

### ARQUIVO: app/tool/search/base.py ###
```py
from typing import List, Optional

from pydantic import BaseModel, Field


class SearchItem(BaseModel):
    """Represents a single search result item"""

    title: str = Field(description="The title of the search result")
    url: str = Field(description="The URL of the search result")
    description: Optional[str] = Field(
        default=None, description="A description or snippet of the search result"
    )

    def __str__(self) -> str:
        """String representation of a search result item."""
        return f"{self.title} - {self.url}"


class WebSearchEngine(BaseModel):
    """Base class for web search engines."""

    model_config = {"arbitrary_types_allowed": True}

    def perform_search(
        self, query: str, num_results: int = 10, *args, **kwargs
    ) -> List[SearchItem]:
        """
        Perform a web search and return a list of search items.

        Args:
            query (str): The search query to submit to the search engine.
            num_results (int, optional): The number of search results to return. Default is 10.
            args: Additional arguments.
            kwargs: Additional keyword arguments.

        Returns:
            List[SearchItem]: A list of SearchItem objects matching the search query.
        """
        raise NotImplementedError

```

### ARQUIVO: app/tool/search/bing_search.py ###
```py
from typing import List, Optional, Tuple

import requests
from bs4 import BeautifulSoup

from app.logger import logger
from app.tool.search.base import SearchItem, WebSearchEngine


ABSTRACT_MAX_LENGTH = 300

USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36",
    "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/49.0.2623.108 Chrome/49.0.2623.108 Safari/537.36",
    "Mozilla/5.0 (Windows; U; Windows NT 5.1; pt-BR) AppleWebKit/533.3 (KHTML, like Gecko) QtWeb Internet Browser/3.7 http://www.QtWeb.net",
    "Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36",
    "Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/532.2 (KHTML, like Gecko) ChromePlus/4.0.222.3 Chrome/4.0.222.3 Safari/532.2",
    "Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.4pre) Gecko/20070404 K-Ninja/2.1.3",
    "Mozilla/5.0 (Future Star Technologies Corp.; Star-Blade OS; x86_64; U; en-US) iNet Browser 4.7",
    "Mozilla/5.0 (Windows; U; Windows NT 6.1; rv:2.2) Gecko/20110201",
    "Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.13) Gecko/20080414 Firefox/2.0.0.13 Pogo/2.0.0.13.6866",
]

HEADERS = {
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8",
    "Content-Type": "application/x-www-form-urlencoded",
    "User-Agent": USER_AGENTS[0],
    "Referer": "https://www.bing.com/",
    "Accept-Encoding": "gzip, deflate",
    "Accept-Language": "zh-CN,zh;q=0.9",
}

BING_HOST_URL = "https://www.bing.com"
BING_SEARCH_URL = "https://www.bing.com/search?q="


class BingSearchEngine(WebSearchEngine):
    session: Optional[requests.Session] = None

    def __init__(self, **data):
        """Initialize the BingSearch tool with a requests session."""
        super().__init__(**data)
        self.session = requests.Session()
        self.session.headers.update(HEADERS)

    def _search_sync(self, query: str, num_results: int = 10) -> List[SearchItem]:
        """
        Synchronous Bing search implementation to retrieve search results.

        Args:
            query (str): The search query to submit to Bing.
            num_results (int, optional): Maximum number of results to return. Defaults to 10.

        Returns:
            List[SearchItem]: A list of search items with title, URL, and description.
        """
        if not query:
            return []

        list_result = []
        first = 1
        next_url = BING_SEARCH_URL + query

        while len(list_result) < num_results:
            data, next_url = self._parse_html(
                next_url, rank_start=len(list_result), first=first
            )
            if data:
                list_result.extend(data)
            if not next_url:
                break
            first += 10

        return list_result[:num_results]

    def _parse_html(
        self, url: str, rank_start: int = 0, first: int = 1
    ) -> Tuple[List[SearchItem], str]:
        """
        Parse Bing search result HTML to extract search results and the next page URL.

        Returns:
            tuple: (List of SearchItem objects, next page URL or None)
        """
        try:
            res = self.session.get(url=url)
            res.encoding = "utf-8"
            root = BeautifulSoup(res.text, "lxml")

            list_data = []
            ol_results = root.find("ol", id="b_results")
            if not ol_results:
                return [], None

            for li in ol_results.find_all("li", class_="b_algo"):
                title = ""
                url = ""
                abstract = ""
                try:
                    h2 = li.find("h2")
                    if h2:
                        title = h2.text.strip()
                        url = h2.a["href"].strip()

                    p = li.find("p")
                    if p:
                        abstract = p.text.strip()

                    if ABSTRACT_MAX_LENGTH and len(abstract) > ABSTRACT_MAX_LENGTH:
                        abstract = abstract[:ABSTRACT_MAX_LENGTH]

                    rank_start += 1

                    # Create a SearchItem object
                    list_data.append(
                        SearchItem(
                            title=title or f"Bing Result {rank_start}",
                            url=url,
                            description=abstract,
                        )
                    )
                except Exception:
                    continue

            next_btn = root.find("a", title="Next page")
            if not next_btn:
                return list_data, None

            next_url = BING_HOST_URL + next_btn["href"]
            return list_data, next_url
        except Exception as e:
            logger.warning(f"Error parsing HTML: {e}")
            return [], None

    def perform_search(
        self, query: str, num_results: int = 10, *args, **kwargs
    ) -> List[SearchItem]:
        """
        Bing search engine.

        Returns results formatted according to SearchItem model.
        """
        return self._search_sync(query, num_results=num_results)

```

### ARQUIVO: app/tool/search/__init__.py ###
```py
from app.tool.search.baidu_search import BaiduSearchEngine
from app.tool.search.base import WebSearchEngine
from app.tool.search.bing_search import BingSearchEngine
from app.tool.search.duckduckgo_search import DuckDuckGoSearchEngine
from app.tool.search.google_search import GoogleSearchEngine


__all__ = [
    "WebSearchEngine",
    "BaiduSearchEngine",
    "DuckDuckGoSearchEngine",
    "GoogleSearchEngine",
    "BingSearchEngine",
]

```

### ARQUIVO: app/tool/search/baidu_search.py ###
```py
from typing import List

from baidusearch.baidusearch import search

from app.tool.search.base import SearchItem, WebSearchEngine


class BaiduSearchEngine(WebSearchEngine):
    def perform_search(
        self, query: str, num_results: int = 10, *args, **kwargs
    ) -> List[SearchItem]:
        """
        Baidu search engine.

        Returns results formatted according to SearchItem model.
        """
        raw_results = search(query, num_results=num_results)

        # Convert raw results to SearchItem format
        results = []
        for i, item in enumerate(raw_results):
            if isinstance(item, str):
                # If it's just a URL
                results.append(
                    SearchItem(title=f"Baidu Result {i+1}", url=item, description=None)
                )
            elif isinstance(item, dict):
                # If it's a dictionary with details
                results.append(
                    SearchItem(
                        title=item.get("title", f"Baidu Result {i+1}"),
                        url=item.get("url", ""),
                        description=item.get("abstract", None),
                    )
                )
            else:
                # Try to get attributes directly
                try:
                    results.append(
                        SearchItem(
                            title=getattr(item, "title", f"Baidu Result {i+1}"),
                            url=getattr(item, "url", ""),
                            description=getattr(item, "abstract", None),
                        )
                    )
                except Exception:
                    # Fallback to a basic result
                    results.append(
                        SearchItem(
                            title=f"Baidu Result {i+1}", url=str(item), description=None
                        )
                    )

        return results

```

### ARQUIVO: app/tool/search/google_search.py ###
```py
from typing import List

from googlesearch import search

from app.tool.search.base import SearchItem, WebSearchEngine


class GoogleSearchEngine(WebSearchEngine):
    def perform_search(
        self, query: str, num_results: int = 10, *args, **kwargs
    ) -> List[SearchItem]:
        """
        Mecanismo de busca do Google.

        Retorna resultados formatados de acordo com o modelo SearchItem.
        """
        raw_results = search(query, num_results=num_results, advanced=True)

        results = []
        for i, item in enumerate(raw_results):
            if isinstance(item, str):
                # Se for apenas uma URL
                results.append(
                    {"title": f"Resultado do Google {i+1}", "url": item, "description": ""}
                )
            else:
                results.append(
                    SearchItem(
                        title=item.title, url=item.url, description=item.description
                    )
                )

        return results

```

### ARQUIVO: app/flow/base.py ###
```py
from abc import ABC, abstractmethod
from typing import Dict, List, Optional, Union

from pydantic import BaseModel

from app.agent.base import BaseAgent


class BaseFlow(BaseModel, ABC):
    """Base class for execution flows supporting multiple agents"""

    agents: Dict[str, BaseAgent]
    tools: Optional[List] = None
    primary_agent_key: Optional[str] = None

    class Config:
        arbitrary_types_allowed = True

    def __init__(
        self, agents: Union[BaseAgent, List[BaseAgent], Dict[str, BaseAgent]], **data
    ):
        # Handle different ways of providing agents
        if isinstance(agents, BaseAgent):
            agents_dict = {"default": agents}
        elif isinstance(agents, list):
            agents_dict = {f"agent_{i}": agent for i, agent in enumerate(agents)}
        else:
            agents_dict = agents

        # If primary agent not specified, use first agent
        primary_key = data.get("primary_agent_key")
        if not primary_key and agents_dict:
            primary_key = next(iter(agents_dict))
            data["primary_agent_key"] = primary_key

        # Set the agents dictionary
        data["agents"] = agents_dict

        # Initialize using BaseModel's init
        super().__init__(**data)

    @property
    def primary_agent(self) -> Optional[BaseAgent]:
        """Get the primary agent for the flow"""
        return self.agents.get(self.primary_agent_key)

    def get_agent(self, key: str) -> Optional[BaseAgent]:
        """Get a specific agent by key"""
        return self.agents.get(key)

    def add_agent(self, key: str, agent: BaseAgent) -> None:
        """Add a new agent to the flow"""
        self.agents[key] = agent

    @abstractmethod
    async def execute(self, input_text: str) -> str:
        """Execute the flow with given input"""

```

### ARQUIVO: app/flow/__init__.py ###
```py

```

### ARQUIVO: app/flow/flow_factory.py ###
```py
from enum import Enum
from typing import Dict, List, Union

from app.agent.base import BaseAgent
from app.flow.base import BaseFlow
from app.flow.planning import PlanningFlow


class FlowType(str, Enum):
    PLANNING = "planning"


class FlowFactory:
    """Factory for creating different types of flows with support for multiple agents"""

    @staticmethod
    def create_flow(
        flow_type: FlowType,
        agents: Union[BaseAgent, List[BaseAgent], Dict[str, BaseAgent]],
        **kwargs,
    ) -> BaseFlow:
        flows = {
            FlowType.PLANNING: PlanningFlow,
        }

        flow_class = flows.get(flow_type)
        if not flow_class:
            raise ValueError(f"Unknown flow type: {flow_type}")

        return flow_class(agents, **kwargs)

```

### ARQUIVO: app/flow/planning.py ###
```py
import json
import time
from enum import Enum
from typing import Dict, List, Optional, Union

from pydantic import Field

from app.agent.base import BaseAgent
from app.flow.base import BaseFlow
from app.llm import LLM
from app.logger import logger
from app.schema import AgentState, Message, ToolChoice
from app.tool import PlanningTool


class PlanStepStatus(str, Enum):
    """Classe Enum que define os status possÃ­veis de um passo do plano"""

    NOT_STARTED = "not_started"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    BLOCKED = "blocked"

    @classmethod
    def get_all_statuses(cls) -> list[str]:
        """Retorna uma lista de todos os valores de status de passo possÃ­veis"""
        return [status.value for status in cls]

    @classmethod
    def get_active_statuses(cls) -> list[str]:
        """Retorna uma lista de valores que representam status ativos (nÃ£o iniciado ou em progresso)"""
        return [cls.NOT_STARTED.value, cls.IN_PROGRESS.value]

    @classmethod
    def get_status_marks(cls) -> Dict[str, str]:
        """Retorna um mapeamento de status para seus sÃ­mbolos marcadores"""
        return {
            cls.COMPLETED.value: "[âœ“]",
            cls.IN_PROGRESS.value: "[â†’]",
            cls.BLOCKED.value: "[!]",
            cls.NOT_STARTED.value: "[ ]",
        }


class PlanningFlow(BaseFlow):
    """Um fluxo que gerencia o planejamento e a execuÃ§Ã£o de tarefas usando agentes."""

    llm: LLM = Field(default_factory=lambda: LLM())
    planning_tool: PlanningTool = Field(default_factory=PlanningTool)
    executor_keys: List[str] = Field(default_factory=list)
    active_plan_id: str = Field(default_factory=lambda: f"plan_{int(time.time())}")
    current_step_index: Optional[int] = None

    def __init__(
        self, agents: Union[BaseAgent, List[BaseAgent], Dict[str, BaseAgent]], **data
    ):
        # Define as chaves do executor antes de super().__init__
        if "executors" in data:
            data["executor_keys"] = data.pop("executors")

        # Define o ID do plano se fornecido
        if "plan_id" in data:
            data["active_plan_id"] = data.pop("plan_id")

        # Inicializa a ferramenta de planejamento se nÃ£o fornecida
        if "planning_tool" not in data:
            planning_tool = PlanningTool()
            data["planning_tool"] = planning_tool

        # Chama o init do pai com os dados processados
        super().__init__(agents, **data)

        # Define executor_keys para todas as chaves de agente se nÃ£o especificado
        if not self.executor_keys:
            self.executor_keys = list(self.agents.keys())

    def get_executor(self, step_type: Optional[str] = None) -> BaseAgent:
        """
        ObtÃ©m um agente executor apropriado para o passo atual.
        Pode ser estendido para selecionar agentes com base no tipo/requisitos do passo.
        """
        # Se o tipo de passo for fornecido e corresponder a uma chave de agente, use esse agente
        if step_type and step_type in self.agents:
            return self.agents[step_type]

        # Caso contrÃ¡rio, use o primeiro executor disponÃ­vel ou recorra ao agente primÃ¡rio
        for key in self.executor_keys:
            if key in self.agents:
                return self.agents[key]

        # Recorrer ao agente primÃ¡rio
        return self.primary_agent

    async def execute(self, input_text: str) -> str:
        """Executa o fluxo de planejamento com agentes."""
        try:
            if not self.primary_agent:
                raise ValueError("Nenhum agente primÃ¡rio disponÃ­vel")

            # Cria plano inicial se a entrada for fornecida
            if input_text:
                await self._create_initial_plan(input_text)

                # Verifica se o plano foi criado com sucesso
                if self.active_plan_id not in self.planning_tool.plans:
                    logger.error(
                        f"CriaÃ§Ã£o do plano falhou. ID do plano {self.active_plan_id} nÃ£o encontrado na ferramenta de planejamento."
                    )
                    return f"Falha ao criar plano para: {input_text}"

            result = ""
            while True:
                # ObtÃ©m o passo atual para executar
                self.current_step_index, step_info = await self._get_current_step_info()

                # Sai se nÃ£o houver mais passos ou se o plano estiver concluÃ­do
                if self.current_step_index is None:
                    result += await self._finalize_plan()
                    break

                # Executa o passo atual com o agente apropriado
                step_type = step_info.get("type") if step_info else None
                executor = self.get_executor(step_type)
                step_result = await self._execute_step(executor, step_info)
                result += step_result + "\n"

                # Verifica se o agente quer encerrar
                if hasattr(executor, "state") and executor.state == AgentState.FINISHED:
                    break

            return result
        except Exception as e:
            logger.error(f"Erro em PlanningFlow: {str(e)}")
            return f"ExecuÃ§Ã£o falhou: {str(e)}"

    async def _create_initial_plan(self, request: str) -> None:
        """Cria um plano inicial com base na solicitaÃ§Ã£o usando o LLM e PlanningTool do fluxo."""
        logger.info(f"Criando plano inicial com ID: {self.active_plan_id}")

        # Cria uma mensagem de sistema para criaÃ§Ã£o do plano
        system_message = Message.system_message(
            "VocÃª Ã© um assistente de planejamento. Crie um plano conciso e acionÃ¡vel com passos claros. "
            "Concentre-se em marcos chave em vez de sub-passos detalhados. "
            "Otimize para clareza e eficiÃªncia."
        )

        # Cria uma mensagem de usuÃ¡rio com a solicitaÃ§Ã£o
        user_message = Message.user_message(
            f"Crie um plano razoÃ¡vel com passos claros para realizar a tarefa: {request}"
        )

        # Chama LLM com PlanningTool
        response = await self.llm.ask_tool(
            messages=[user_message],
            system_msgs=[system_message],
            tools=[self.planning_tool.to_param()],
            tool_choice=ToolChoice.AUTO,
        )

        # Processa chamadas de ferramenta se presentes
        if response.tool_calls:
            for tool_call in response.tool_calls:
                if tool_call.function.name == "planning":
                    # Analisa os argumentos
                    args = tool_call.function.arguments
                    if isinstance(args, str):
                        try:
                            args = json.loads(args)
                        except json.JSONDecodeError:
                            logger.error(f"Falha ao analisar argumentos da ferramenta: {args}")
                            continue

                    # Garante que plan_id esteja definido corretamente e executa a ferramenta
                    args["plan_id"] = self.active_plan_id

                    # Executa a ferramenta via ToolCollection em vez de diretamente
                    result = await self.planning_tool.execute(**args)

                    logger.info(f"Resultado da criaÃ§Ã£o do plano: {str(result)}")
                    return

        # Se a execuÃ§Ã£o chegou aqui, cria um plano padrÃ£o
        logger.warning("Criando plano padrÃ£o")

        # Cria plano padrÃ£o usando ToolCollection
        await self.planning_tool.execute(
            **{
                "command": "create",
                "plan_id": self.active_plan_id,
                "title": f"Plano para: {request[:50]}{'...' if len(request) > 50 else ''}",
                "steps": ["Analisar solicitaÃ§Ã£o", "Executar tarefa", "Verificar resultados"],
            }
        )

    async def _get_current_step_info(self) -> tuple[Optional[int], Optional[dict]]:
        """
        Analisa o plano atual para identificar o Ã­ndice e as informaÃ§Ãµes do primeiro passo nÃ£o concluÃ­do.
        Retorna (None, None) se nenhum passo ativo for encontrado.
        """
        if (
            not self.active_plan_id
            or self.active_plan_id not in self.planning_tool.plans
        ):
            logger.error(f"Plano com ID {self.active_plan_id} nÃ£o encontrado")
            return None, None

        try:
            # Acesso direto aos dados do plano do armazenamento da ferramenta de planejamento
            plan_data = self.planning_tool.plans[self.active_plan_id]
            steps = plan_data.get("steps", [])
            step_statuses = plan_data.get("step_statuses", [])

            # Encontra o primeiro passo nÃ£o concluÃ­do
            for i, step in enumerate(steps):
                if i >= len(step_statuses):
                    status = PlanStepStatus.NOT_STARTED.value
                else:
                    status = step_statuses[i]

                if status in PlanStepStatus.get_active_statuses():
                    # Extrai o tipo/categoria do passo se disponÃ­vel
                    step_info = {"text": step}

                    # Tenta extrair o tipo de passo do texto (ex: [SEARCH] ou [CODE])
                    import re

                    type_match = re.search(r"\[([A-Z_]+)\]", step)
                    if type_match:
                        step_info["type"] = type_match.group(1).lower()

                    # Marca o passo atual como em_progresso
                    try:
                        await self.planning_tool.execute(
                            command="mark_step",
                            plan_id=self.active_plan_id,
                            step_index=i,
                            step_status=PlanStepStatus.IN_PROGRESS.value,
                        )
                    except Exception as e:
                        logger.warning(f"Erro ao marcar passo como em_progresso: {e}")
                        # Atualiza o status do passo diretamente se necessÃ¡rio
                        if i < len(step_statuses):
                            step_statuses[i] = PlanStepStatus.IN_PROGRESS.value
                        else:
                            while len(step_statuses) < i:
                                step_statuses.append(PlanStepStatus.NOT_STARTED.value)
                            step_statuses.append(PlanStepStatus.IN_PROGRESS.value)

                        plan_data["step_statuses"] = step_statuses

                    return i, step_info

            return None, None  # Nenhum passo ativo encontrado

        except Exception as e:
            logger.warning(f"Erro ao encontrar Ã­ndice do passo atual: {e}")
            return None, None

    async def _execute_step(self, executor: BaseAgent, step_info: dict) -> str:
        """Executa o passo atual com o agente especificado usando agent.run()."""
        # Prepara o contexto para o agente com o status atual do plano
        plan_status = await self._get_plan_text()
        step_text = step_info.get("text", f"Passo {self.current_step_index}")

        # Cria um prompt para o agente executar o passo atual
        step_prompt = f"""
        STATUS ATUAL DO PLANO:
        {plan_status}

        SUA TAREFA ATUAL:
        VocÃª estÃ¡ trabalhando no passo {self.current_step_index}: "{step_text}"

        Por favor, execute este passo usando as ferramentas apropriadas. Quando terminar, forneÃ§a um resumo do que vocÃª realizou.
        """

        # Usa agent.run() para executar o passo
        try:
            step_result = await executor.run(step_prompt)

            # Marca o passo como concluÃ­do apÃ³s execuÃ§Ã£o bem-sucedida
            await self._mark_step_completed()

            return step_result
        except Exception as e:
            logger.error(f"Erro ao executar passo {self.current_step_index}: {e}")
            return f"Erro ao executar passo {self.current_step_index}: {str(e)}"

    async def _mark_step_completed(self) -> None:
        """Marca o passo atual como concluÃ­do."""
        if self.current_step_index is None:
            return

        try:
            # Marca o passo como concluÃ­do
            await self.planning_tool.execute(
                command="mark_step",
                plan_id=self.active_plan_id,
                step_index=self.current_step_index,
                step_status=PlanStepStatus.COMPLETED.value,
            )
            logger.info(
                f"Marcado passo {self.current_step_index} como concluÃ­do no plano {self.active_plan_id}"
            )
        except Exception as e:
            logger.warning(f"Falha ao atualizar status do plano: {e}")
            # Atualiza o status do passo diretamente no armazenamento da ferramenta de planejamento
            if self.active_plan_id in self.planning_tool.plans:
                plan_data = self.planning_tool.plans[self.active_plan_id]
                step_statuses = plan_data.get("step_statuses", [])

                # Garante que a lista step_statuses seja longa o suficiente
                while len(step_statuses) <= self.current_step_index:
                    step_statuses.append(PlanStepStatus.NOT_STARTED.value)

                # Atualiza o status
                step_statuses[self.current_step_index] = PlanStepStatus.COMPLETED.value
                plan_data["step_statuses"] = step_statuses

    async def _get_plan_text(self) -> str:
        """ObtÃ©m o plano atual como texto formatado."""
        try:
            result = await self.planning_tool.execute(
                command="get", plan_id=self.active_plan_id
            )
            return result.output if hasattr(result, "output") else str(result)
        except Exception as e:
            logger.error(f"Erro ao obter plano: {e}")
            return self._generate_plan_text_from_storage()

    def _generate_plan_text_from_storage(self) -> str:
        """Gera texto do plano diretamente do armazenamento se a ferramenta de planejamento falhar."""
        try:
            if self.active_plan_id not in self.planning_tool.plans:
                return f"Erro: Plano com ID {self.active_plan_id} nÃ£o encontrado"

            plan_data = self.planning_tool.plans[self.active_plan_id]
            title = plan_data.get("title", "Plano sem tÃ­tulo")
            steps = plan_data.get("steps", [])
            step_statuses = plan_data.get("step_statuses", [])
            step_notes = plan_data.get("step_notes", [])

            # Garante que step_statuses e step_notes correspondam ao nÃºmero de passos
            while len(step_statuses) < len(steps):
                step_statuses.append(PlanStepStatus.NOT_STARTED.value)
            while len(step_notes) < len(steps):
                step_notes.append("")

            # Conta passos por status
            status_counts = {status: 0 for status in PlanStepStatus.get_all_statuses()}

            for status in step_statuses:
                if status in status_counts:
                    status_counts[status] += 1

            completed = status_counts[PlanStepStatus.COMPLETED.value]
            total = len(steps)
            progress = (completed / total) * 100 if total > 0 else 0

            plan_text = f"Plano: {title} (ID: {self.active_plan_id})\n"
            plan_text += "=" * len(plan_text) + "\n\n"

            plan_text += (
                f"Progresso: {completed}/{total} passos concluÃ­dos ({progress:.1f}%)\n"
            )
            plan_text += f"Status: {status_counts[PlanStepStatus.COMPLETED.value]} concluÃ­dos, {status_counts[PlanStepStatus.IN_PROGRESS.value]} em progresso, "
            plan_text += f"{status_counts[PlanStepStatus.BLOCKED.value]} bloqueados, {status_counts[PlanStepStatus.NOT_STARTED.value]} nÃ£o iniciados\n\n"
            plan_text += "Passos:\n"

            status_marks = PlanStepStatus.get_status_marks()

            for i, (step, status, notes) in enumerate(
                zip(steps, step_statuses, step_notes)
            ):
                # Usa marcas de status para indicar o status do passo
                status_mark = status_marks.get(
                    status, status_marks[PlanStepStatus.NOT_STARTED.value]
                )

                plan_text += f"{i}. {status_mark} {step}\n"
                if notes:
                    plan_text += f"   Notas: {notes}\n"

            return plan_text
        except Exception as e:
            logger.error(f"Erro ao gerar texto do plano do armazenamento: {e}")
            return f"Erro: NÃ£o foi possÃ­vel recuperar o plano com ID {self.active_plan_id}"

    async def _finalize_plan(self) -> str:
        """Finaliza o plano e fornece um resumo usando o LLM do fluxo diretamente."""
        plan_text = await self._get_plan_text()

        # Cria um resumo usando o LLM do fluxo diretamente
        try:
            system_message = Message.system_message(
                "VocÃª Ã© um assistente de planejamento. Sua tarefa Ã© resumir o plano concluÃ­do."
            )

            user_message = Message.user_message(
                f"O plano foi concluÃ­do. Aqui estÃ¡ o status final do plano:\n\n{plan_text}\n\nPor favor, forneÃ§a um resumo do que foi realizado e quaisquer consideraÃ§Ãµes finais."
            )

            response = await self.llm.ask(
                messages=[user_message], system_msgs=[system_message]
            )

            return f"Plano concluÃ­do:\n\n{response}"
        except Exception as e:
            logger.error(f"Erro ao finalizar plano com LLM: {e}")

            # Recorrer ao uso de um agente para o resumo
            try:
                agent = self.primary_agent
                summary_prompt = f"""
                O plano foi concluÃ­do. Aqui estÃ¡ o status final do plano:

                {plan_text}

                Por favor, forneÃ§a um resumo do que foi realizado e quaisquer consideraÃ§Ãµes finais.
                """
                summary = await agent.run(summary_prompt)
                return f"Plano concluÃ­do:\n\n{summary}"
            except Exception as e2:
                logger.error(f"Erro ao finalizar plano com agente: {e2}")
                return "Plano concluÃ­do. Erro ao gerar resumo."

```

### ARQUIVO: app/mcp/__init__.py ###
```py

```

### ARQUIVO: app/mcp/server.py ###
```py
import logging
import sys


logging.basicConfig(level=logging.INFO, handlers=[logging.StreamHandler(sys.stderr)])

import argparse
import asyncio
import atexit
import json
from inspect import Parameter, Signature
from typing import Any, Dict, Optional

from mcp.server.fastmcp import FastMCP

from app.logger import logger
from app.tool.base import BaseTool
from app.tool.bash import Bash
from app.tool.browser_use_tool import BrowserUseTool
from app.tool.str_replace_editor import StrReplaceEditor
from app.tool.terminate import Terminate


class MCPServer:
    """MCP Server implementation with tool registration and management."""

    def __init__(self, name: str = "openmanus"):
        self.server = FastMCP(name)
        self.tools: Dict[str, BaseTool] = {}

        # Initialize standard tools
        self.tools["bash"] = Bash()
        self.tools["browser"] = BrowserUseTool()
        self.tools["editor"] = StrReplaceEditor()
        self.tools["terminate"] = Terminate()

    def register_tool(self, tool: BaseTool, method_name: Optional[str] = None) -> None:
        """Register a tool with parameter validation and documentation."""
        tool_name = method_name or tool.name
        tool_param = tool.to_param()
        tool_function = tool_param["function"]

        # Define the async function to be registered
        async def tool_method(**kwargs):
            logger.info(f"Executing {tool_name}: {kwargs}")
            result = await tool.execute(**kwargs)

            logger.info(f"Result of {tool_name}: {result}")

            # Handle different types of results (match original logic)
            if hasattr(result, "model_dump"):
                return json.dumps(result.model_dump())
            elif isinstance(result, dict):
                return json.dumps(result)
            return result

        # Set method metadata
        tool_method.__name__ = tool_name
        tool_method.__doc__ = self._build_docstring(tool_function)
        tool_method.__signature__ = self._build_signature(tool_function)

        # Store parameter schema (important for tools that access it programmatically)
        param_props = tool_function.get("parameters", {}).get("properties", {})
        required_params = tool_function.get("parameters", {}).get("required", [])
        tool_method._parameter_schema = {
            param_name: {
                "description": param_details.get("description", ""),
                "type": param_details.get("type", "any"),
                "required": param_name in required_params,
            }
            for param_name, param_details in param_props.items()
        }

        # Register with server
        self.server.tool()(tool_method)
        logger.info(f"Registered tool: {tool_name}")

    def _build_docstring(self, tool_function: dict) -> str:
        """Build a formatted docstring from tool function metadata."""
        description = tool_function.get("description", "")
        param_props = tool_function.get("parameters", {}).get("properties", {})
        required_params = tool_function.get("parameters", {}).get("required", [])

        # Build docstring (match original format)
        docstring = description
        if param_props:
            docstring += "\n\nParameters:\n"
            for param_name, param_details in param_props.items():
                required_str = (
                    "(required)" if param_name in required_params else "(optional)"
                )
                param_type = param_details.get("type", "any")
                param_desc = param_details.get("description", "")
                docstring += (
                    f"    {param_name} ({param_type}) {required_str}: {param_desc}\n"
                )

        return docstring

    def _build_signature(self, tool_function: dict) -> Signature:
        """Build a function signature from tool function metadata."""
        param_props = tool_function.get("parameters", {}).get("properties", {})
        required_params = tool_function.get("parameters", {}).get("required", [])

        parameters = []

        # Follow original type mapping
        for param_name, param_details in param_props.items():
            param_type = param_details.get("type", "")
            default = Parameter.empty if param_name in required_params else None

            # Map JSON Schema types to Python types (same as original)
            annotation = Any
            if param_type == "string":
                annotation = str
            elif param_type == "integer":
                annotation = int
            elif param_type == "number":
                annotation = float
            elif param_type == "boolean":
                annotation = bool
            elif param_type == "object":
                annotation = dict
            elif param_type == "array":
                annotation = list

            # Create parameter with same structure as original
            param = Parameter(
                name=param_name,
                kind=Parameter.KEYWORD_ONLY,
                default=default,
                annotation=annotation,
            )
            parameters.append(param)

        return Signature(parameters=parameters)

    async def cleanup(self) -> None:
        """Clean up server resources."""
        logger.info("Cleaning up resources")
        # Follow original cleanup logic - only clean browser tool
        if "browser" in self.tools and hasattr(self.tools["browser"], "cleanup"):
            await self.tools["browser"].cleanup()

    def register_all_tools(self) -> None:
        """Register all tools with the server."""
        for tool in self.tools.values():
            self.register_tool(tool)

    def run(self, transport: str = "stdio") -> None:
        """Run the MCP server."""
        # Register all tools
        self.register_all_tools()

        # Register cleanup function (match original behavior)
        atexit.register(lambda: asyncio.run(self.cleanup()))

        # Start server (with same logging as original)
        logger.info(f"Starting OpenManus server ({transport} mode)")
        self.server.run(transport=transport)


def parse_args() -> argparse.Namespace:
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(description="OpenManus MCP Server")
    parser.add_argument(
        "--transport",
        choices=["stdio"],
        default="stdio",
        help="Communication method: stdio or http (default: stdio)",
    )
    return parser.parse_args()


if __name__ == "__main__":
    args = parse_args()

    # Create and run server (maintaining original flow)
    server = MCPServer()
    server.run(transport=args.transport)

```

### ARQUIVO: config/.gitignore ###
```
# prevent the local config file from being uploaded to the remote repository
config.toml

```


<!-- CONTENT_END -->`).
    *   O conteÃºdo antigo entre esses placeholders Ã© removido.
    *   A nova string concatenada (com todos os arquivos) Ã© inserida entre os placeholders.
    *   Se os placeholders nÃ£o existirem, o script pode adicionar o conteÃºdo no final do arquivo ou recriar o arquivo com o novo conteÃºdo e o cabeÃ§alho/tutorial.

**Objetivo da Ferramenta:**

O principal objetivo desta ferramenta Ã© fornecer a vocÃª, agente, uma visÃ£o "achatada" e completa de todo o cÃ³digo relevante do repositÃ³rio em um Ãºnico local. Isso elimina a necessidade de vocÃª navegar pela estrutura de diretÃ³rios ou ler mÃºltiplos arquivos individualmente para obter um entendimento holÃ­stico do projeto. Ao executar o script `generate_agent_readme.py`, vocÃª garante que as informaÃ§Ãµes aqui contidas reflitam o estado mais recente do cÃ³digo.

---

<!-- CONTENT_START -->
## ConteÃºdo Completo do RepositÃ³rio

Esta seÃ§Ã£o serÃ¡ preenchida automaticamente pelo script `generate_agent_readme.py`.
Execute o script para popular esta Ã¡rea com o cÃ³digo-fonte atual do repositÃ³rio.

**Exemplo de como o conteÃºdo serÃ¡ estruturado:**

```
### ARQUIVO: app/main.py ###
\`\`\`python
# ConteÃºdo do arquivo app/main.py
if __name__ == "__main__":
    print("AplicaÃ§Ã£o principal iniciada.")
\`\`\`

### ARQUIVO: app/utils/helpers.py ###
\`\`\`python
# ConteÃºdo do arquivo app/utils/helpers.py
def helper_function():
    return "Esta Ã© uma funÃ§Ã£o auxiliar."
\`\`\`
```
<!-- CONTENT_END -->

---

## Como Manter Este Arquivo Atualizado

Ã‰ crucial que o conteÃºdo deste arquivo, especialmente a seÃ§Ã£o "ConteÃºdo Completo do RepositÃ³rio", reflita o estado mais recente do cÃ³digo.

Para atualizar este arquivo:

1.  **Localize o script:** Encontre o script `generate_agent_readme.py` no diretÃ³rio raiz do repositÃ³rio.
2.  **Execute o script:** Abra um terminal ou console na raiz do repositÃ³rio e execute o comando:
    ```bash
    python generate_agent_readme.py
    ```
3.  **Verifique as MudanÃ§as:** ApÃ³s a execuÃ§Ã£o do script, o `AGENTREADME.MD` serÃ¡ atualizado. VocÃª pode verificar as diferenÃ§as usando `git diff AGENTREADME.MD` antes de commitar as alteraÃ§Ãµes, se desejar.

Recomenda-se executar este script sempre que houver alteraÃ§Ãµes significativas no cÃ³digo-fonte para garantir que vocÃª (e outros agentes) estejam trabalhando com a informaÃ§Ã£o mais precisa.
